from flask import Flask, request, jsonify
from flask_cors import CORS
import os
from dotenv import load_dotenv
from model.check_paraphrase_content import *
from model.check_generate_content import *

from pdf_processor_paraphrase.pdf_cutter import *
from pdf_processor_generate.extract_for_test import *

from tool.json_to_array import *
from tool.array_to_json import *

from opencc import OpenCC

cc = OpenCC('s2t')  # s2t: simplified to traditional

import logging
# âœ… åˆå§‹åŒ–ï¼šè®€å–ç’°å¢ƒè®Šæ•¸èˆ‡å®šç¾©å…¨åŸŸå¸¸æ•¸
load_dotenv()

REQUIRED_ENV_VARS = [
    "OPENAI_APIKEY",
    "BACKEND_API_URL_TEXT_GENERATE",
    "BACKEND_API_URL_TEXT_PARAPHRASE",
    "BACKEND_API_URL_PDF_GENERATE",
    "BACKEND_API_URL_PDF_PARAPHRASE",
]

SOURCE_DIRS = [
    # æ­£å¼éƒ¨ç½²ç”¨
    "dataset/paraphrased_dataset/source/ccu",
    "dataset/paraphrased_dataset/source/nccu_2018",
    "dataset/paraphrased_dataset/source/nccu_2019",
    "dataset/paraphrased_dataset/source/ncu_2019",
    "dataset/paraphrased_dataset/source/ncu_2020",
    "dataset/paraphrased_dataset/source/nsyu_2019",
    "dataset/paraphrased_dataset/source/nycu",

    # # æ¸¬è©¦ç”¨è·¯å¾‘
    # "/mnt/Agents4Financial/PlagiarismDetector/backend/dataset/paraphrased_dataset/source/ccu",
    # "/mnt/Agents4Financial/PlagiarismDetector/backend/dataset/paraphrased_dataset/source/nccu_2018",
    # "/mnt/Agents4Financial/PlagiarismDetector/backend/dataset/paraphrased_dataset/source/nccu_2019",
    # "/mnt/Agents4Financial/PlagiarismDetector/backend/dataset/paraphrased_dataset/source/ncu_2019",
    # "/mnt/Agents4Financial/PlagiarismDetector/backend/dataset/paraphrased_dataset/source/ncu_2020",
    # "/mnt/Agents4Financial/PlagiarismDetector/backend/dataset/paraphrased_dataset/source/nsyu_2019",
    # "/mnt/Agents4Financial/PlagiarismDetector/backend/dataset/paraphrased_dataset/source/nycu",
]

# æ­£å¼éƒ¨ç½²ç”¨
PDF_SAVE_DIR = "uploaded_pdfs"

# # æ¸¬è©¦ç”¨è·¯å¾‘
# PDF_SAVE_DIR = "/mnt/Agents4Financial/PlagiarismDetector/backend/uploaded_pdfs"


# âœ… æª¢æŸ¥ç’°å¢ƒè®Šæ•¸æ˜¯å¦å®Œæ•´
def validate_env():
    # æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
    missing = [var for var in REQUIRED_ENV_VARS if os.getenv(var) is None]
    if missing:
        raise EnvironmentError(
            f"Missing required environment variables: {', '.join(missing)}")

    # æª¢æŸ¥è³‡æ–™å¤¾æ˜¯å¦å­˜åœ¨
    missing_dirs = [d for d in SOURCE_DIRS if not os.path.exists(d)]
    if missing_dirs:
        raise FileNotFoundError(
            f"Missing required source directories: {', '.join(missing_dirs)}")

    print("âœ… Environment variables loaded.")
    print("âœ… All source directories exist.")


# âœ… åˆå§‹åŒ–æ‡‰ç”¨ç¨‹å¼ï¼ˆFlask app èˆ‡è³‡æ–™ï¼‰
def create_app():
    app = Flask(__name__)

    CORS(app)  # è·¨ä¾†æºè«‹æ±‚æ”¯æ´

    # è¨­å®š logger ç´šåˆ¥ç‚º DEBUG
    app.logger.setLevel(logging.DEBUG)

    validate_env()

    print(
        "Building FAISS vector store with all files... (this may take a while)"
    )
    global_paraphrase_vector_db, global_paraphrase_embedding_model, _ = build_paraphrase_vector_db(
        SOURCE_DIRS)
    # global_paraphrase_vector_db, global_paraphrase_embedding_model = None, None

    # --- è·¯ç”±å®šç¾©å€ ---
    @app.route('/')
    def home():
        return "Plagiarism Checker API is running!"

    @app.route(os.getenv("BACKEND_API_URL_TEXT_PARAPHRASE"), methods=['POST'])
    def upload_text_paraphrase():
        return paraphrase_text_check(request, global_paraphrase_vector_db,
                                     global_paraphrase_embedding_model)

    @app.route(os.getenv("BACKEND_API_URL_PDF_PARAPHRASE"), methods=['POST'])
    def upload_pdf_paraphrase():
        return paraphrase_pdf_check(request, global_paraphrase_vector_db,
                                    global_paraphrase_embedding_model)

    @app.route(os.getenv("BACKEND_API_URL_TEXT_GENERATE"), methods=['POST'])
    def upload_text_generate():
        return generate_text_check(request, global_paraphrase_vector_db,
                                   global_paraphrase_embedding_model)

    @app.route(os.getenv("BACKEND_API_URL_PDF_GENERATE"), methods=['POST'])
    def upload_pdf_generate():
        return generate_pdf_check(request, global_paraphrase_vector_db,
                                  global_paraphrase_embedding_model)

    return app


app = create_app()


def paraphrase_text_check(req, global_vector_db, global_embedding_model):
    app.logger.debug("ğŸ“¥ æ”¶åˆ° Text Paraphrase è«‹æ±‚")

    try:
        data = req.json
        text = data.get("text", "")
        app.logger.debug(f"ğŸ“„ å‚³å…¥æ–‡å­—ï¼š{text[:50]}...")

        if not text:
            app.logger.warning("âš ï¸ æ²’æœ‰æä¾›æ–‡å­—")
            return jsonify({"error": "No text provided"}), 400

        if global_vector_db is None:
            app.logger.error("âŒ Vector database æœªåˆå§‹åŒ–")
            return jsonify({"error": "Vector database not initialized"}), 500

        check_paragraph_result = cooperate_plagiarism_check(
            user_text=text,
            vector_db=global_vector_db,
            embedding_model=global_embedding_model)

        app.logger.debug("âœ… æª¢æ¸¬å®Œæˆï¼Œé–‹å§‹çµ„è£çµæœ")
        tansfer_array_to_json(check_paragraph_result, PDF_SAVE_DIR,
                              "paraphrase_text_check_result.json")

        result = {
            "plagiarism_percentage":
            round(check_paragraph_result["plagiarism_percentage"], 2),
            "plagiarism_confidence":
            round(check_paragraph_result["plagiarism_confidence"], 2),
            "original_text_and_plagiarism_snippet": [{
                "original_text":
                text,
                "plagiarism_snippet":
                check_paragraph_result["plagiarism_snippet"]
            }],
            "verdict": {
                "result": check_paragraph_result["verdict"]["result"],
                "reason":
                cc.convert(check_paragraph_result["verdict"]["reason"])
            }
        }

        app.logger.info("ğŸ“¤ å›å‚³çµæœæˆåŠŸ")
        return jsonify(result)

    except Exception as e:
        app.logger.error(f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}", exc_info=True)
        return jsonify({"error": str(e)}), 500


def paraphrase_pdf_check(req, global_vector_db, global_embedding_model):

    app.logger.debug("ğŸ“¥ æ”¶åˆ° PDF Paraphrase è«‹æ±‚")
    app.logger.debug(f"ğŸ“¦ Request Content-Type: {req.content_type}")
    app.logger.debug(f"ğŸ“¦ Request files: {req.files}")

    if 'file' not in req.files:
        app.logger.warning("âš ï¸ æ²’æœ‰æ”¶åˆ° 'file' æ¬„ä½")
        return jsonify({"error": "No file part in the request"}), 400

    uploaded_file = req.files['file']
    original_filename = uploaded_file.filename
    app.logger.debug(f"ğŸ“„ æª”æ¡ˆåç¨±ï¼š{original_filename}")

    if not original_filename.lower().endswith('.pdf'):
        app.logger.warning("âš ï¸ ä¸Šå‚³çš„ä¸æ˜¯ PDF")
        return jsonify({"error": "Only PDF files are supported"}), 400

    try:
        fixed_filename = "uploaded_paraphrased_pdf.pdf"
        os.makedirs(PDF_SAVE_DIR, exist_ok=True)
        saved_path = os.path.join(PDF_SAVE_DIR, fixed_filename)
        uploaded_file.save(saved_path)
        app.logger.info(f"âœ… PDF å·²å„²å­˜ï¼š{saved_path}")

        # é–‹å§‹è™•ç† PDF
        app.logger.info("ğŸ§  é–‹å§‹ä½¿ç”¨ Gemini è™•ç† PDF æ®µè½")
        api_key = os.getenv("GEMINI_APIKEY")
        app.logger.debug(f"ğŸ” ä½¿ç”¨ API é‡‘é‘°ï¼š{bool(api_key)}")

        processed_pdf = process_pdf(saved_path, api_key)
        tansfer_array_to_json(processed_pdf, PDF_SAVE_DIR, "data.json")

        # processed_pdf = tansfer_json_to_array(PDF_SAVE_DIR, "data.json")

    except Exception as e:
        app.logger.error(f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}", exc_info=True)
        return jsonify({"error":
                        f"Failed to save or process PDF: {str(e)}"}), 500

    # çµ±è¨ˆæ®µè½æ•¸é‡
    total_paragraph_count = 0
    for page_idx, page_paragraphs in enumerate(processed_pdf):
        if page_paragraphs:
            for para_idx, paragraph in enumerate(page_paragraphs):
                total_paragraph_count += 1

    app.logger.info(f"ğŸ“Š ç¸½æ®µè½æ•¸ï¼š{total_paragraph_count}")
    app.logger.info("ğŸ” é–‹å§‹æª¢æ¸¬æŠ„è¥²...")

    total_plagiarism_percentage = 0
    total_confidence_score = 0
    all_check_result = []
    original_text_and_plagiarism_snippet = []

    paragraph_count = 0
    for page_idx, page_paragraphs in enumerate(processed_pdf):
        if page_paragraphs:
            for para_idx, paragraph in enumerate(page_paragraphs):
                paragraph_count += 1
                app.logger.debug(f"ğŸ” æª¢æ¸¬ç¬¬ {paragraph_count} æ®µ")
                check_result = cooperate_plagiarism_check(
                    user_text=paragraph,
                    vector_db=global_vector_db,
                    embedding_model=global_embedding_model)

                original_text_and_plagiarism_snippet.append({
                    "original_text":
                    paragraph,
                    "plagiarism_snippet":
                    check_result["plagiarism_snippet"]
                })

                all_check_result.append(check_result)
                total_plagiarism_percentage += check_result[
                    "plagiarism_percentage"]
                total_confidence_score += check_result["plagiarism_confidence"]

    avg_confidence_score = total_confidence_score / total_paragraph_count
    avg_plagiarism_percentage = total_plagiarism_percentage / total_paragraph_count
    verdict = aggregate_document_verdict_simple(all_check_result)
    verdict["reason"] = cc.convert(verdict["reason"])

    result = {
        "plagiarism_percentage": round(avg_plagiarism_percentage, 2),
        "plagiarism_confidence": round(avg_confidence_score, 2),
        "original_text_and_plagiarism_snippet":
        original_text_and_plagiarism_snippet,
        "verdict": verdict,
    }

    tansfer_array_to_json(all_check_result, PDF_SAVE_DIR,
                          "all_check_result.json")
    tansfer_array_to_json(result, PDF_SAVE_DIR, "result.json")

    # result = tansfer_json_to_array(PDF_SAVE_DIR, "result.json")

    app.logger.info("âœ… æŠ„è¥²æª¢æ¸¬å®Œæˆ")
    return jsonify(result)


def generate_text_check(req, global_vector_db, global_embedding_model):
    app.logger.debug("ğŸ“¥ æ”¶åˆ° Text Generate è«‹æ±‚")

    try:
        data = req.json
        text = data.get("text", "")
        app.logger.debug(f"ğŸ“„ å‚³å…¥æ–‡å­—ï¼š{text[:50]}...")

        if not text:
            app.logger.warning("âš ï¸ æ²’æœ‰æä¾›æ–‡å­—")
            return jsonify({"error": "No text provided"}), 400

        if global_vector_db is None:
            app.logger.error("âŒ Vector database æœªåˆå§‹åŒ–")
            return jsonify({"error": "Vector database not initialized"}), 500

        check_paragraph_result = detect_from_text(text)
        tansfer_array_to_json(check_paragraph_result, PDF_SAVE_DIR,
                              "result.json")

        app.logger.debug("âœ… æª¢æ¸¬å®Œæˆï¼Œé–‹å§‹çµ„è£çµæœ")

        result = {
            "plagiarism_percentage":
            round(check_paragraph_result["plagiarism_percentage"], 2),
            "plagiarism_confidence":
            round(check_paragraph_result["plagiarism_confidence"], 2),
            "original_text_and_plagiarism_snippet": [{
                "original_text":
                text,
                "plagiarism_snippet":
                check_paragraph_result["plagiarism_snippet"]
            }],
            # "verdict":
            # check_paragraph_result["verdict"],
        }

        app.logger.info("ğŸ“¤ å›å‚³çµæœæˆåŠŸ")
        return jsonify(result)

    except Exception as e:
        app.logger.error(f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}", exc_info=True)
        return jsonify({"error": str(e)}), 500


def generate_pdf_check(req, global_vector_db, global_embedding_model):

    app.logger.debug("ğŸ“¥ æ”¶åˆ° PDF Generate è«‹æ±‚")
    app.logger.debug(f"ğŸ“¦ Request Content-Type: {req.content_type}")
    app.logger.debug(f"ğŸ“¦ Request files: {req.files}")

    if 'file' not in req.files:
        app.logger.warning("âš ï¸ æ²’æœ‰æ”¶åˆ° 'file' æ¬„ä½")
        return jsonify({"error": "No file part in the request"}), 400

    uploaded_file = req.files['file']
    original_filename = uploaded_file.filename
    app.logger.debug(f"ğŸ“„ æª”æ¡ˆåç¨±ï¼š{original_filename}")

    if not original_filename.lower().endswith('.pdf'):
        app.logger.warning("âš ï¸ ä¸Šå‚³çš„ä¸æ˜¯ PDF")
        return jsonify({"error": "Only PDF files are supported"}), 400

    try:
        fixed_filename = "uploaded_generate_pdf.pdf"
        os.makedirs(PDF_SAVE_DIR, exist_ok=True)
        saved_path = os.path.join(PDF_SAVE_DIR, fixed_filename)
        uploaded_file.save(saved_path)
        app.logger.info(f"âœ… PDF å·²å„²å­˜ï¼š{saved_path}")

        # é–‹å§‹è™•ç† PDF
        app.logger.info("ğŸ§  é–‹å§‹è™•ç† PDF æ®µè½")
        processed_pdf = extract(saved_path)

        tansfer_array_to_json(processed_pdf, PDF_SAVE_DIR, "data.json")

    except Exception as e:
        app.logger.error(f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}", exc_info=True)
        return jsonify({"error":
                        f"Failed to save or process PDF: {str(e)}"}), 500

    # çµ±è¨ˆæ®µè½æ•¸é‡
    total_paragraph_count = len(processed_pdf)
    app.logger.info(f"ğŸ“Š ç¸½æ®µè½æ•¸ï¼š{total_paragraph_count}")
    app.logger.info("ğŸ” é–‹å§‹æª¢æ¸¬æŠ„è¥²...")

    total_plagiarism_percentage = 0
    total_confidence_score = 0
    all_check_result = []
    original_text_and_plagiarism_snippet = []

    paragraph_count = 0
    for paragraph in processed_pdf:
        paragraph_count += 1
        app.logger.debug(f"ğŸ” æª¢æ¸¬ç¬¬ {paragraph_count} æ®µ")
        check_result = detect_from_text(paragraph)

        original_text_and_plagiarism_snippet.append({
            "original_text":
            paragraph,
            "plagiarism_snippet":
            check_result["plagiarism_snippet"]
        })

        all_check_result.append(check_result)
        total_plagiarism_percentage += check_result["plagiarism_percentage"]
        total_confidence_score += check_result["plagiarism_confidence"]

    avg_confidence_score = total_confidence_score / total_paragraph_count
    avg_plagiarism_percentage = total_plagiarism_percentage / total_paragraph_count

    result = {
        "plagiarism_percentage":
        round(avg_plagiarism_percentage, 2),
        "plagiarism_confidence":
        round(avg_confidence_score, 2),
        "original_text_and_plagiarism_snippet":
        original_text_and_plagiarism_snippet,
    }

    tansfer_array_to_json(all_check_result, PDF_SAVE_DIR,
                          "all_check_result.json")
    tansfer_array_to_json(result, PDF_SAVE_DIR, "result.json")

    app.logger.info("âœ… æŠ„è¥²æª¢æ¸¬å®Œæˆ")
    return jsonify(result)


# âœ… è‹¥æ˜¯ç›´æ¥åŸ·è¡Œæ­¤æª”æ¡ˆï¼Œå‰‡å•Ÿå‹•é–‹ç™¼ä¼ºæœå™¨
if __name__ == "__main__":

    load_dotenv()
    app.run(host="0.0.0.0",
            port=8077,
            debug=True,
            threaded=False,
            use_reloader=False)
