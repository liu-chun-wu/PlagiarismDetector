[
    {
        "top_docs_info": [
            {
                "content": "隨著電腦科學發展的日新月異，現在的電腦擁有更大的儲存容量，更強大的運算 能力，更快的處理速度，使得我們得以在電腦上發展各式各樣更複雜且更能為人們帶 來便利的應用。然而，随著各種推陳出新的應用，卻使得我們不得不學習更多無論是 在硬體上或是軟體上的操作，才能享受科技帶來的便利。如何發展更友善且更容易使 用的人機介面，使更多人能更容易地享受科技帶來的便利，一直是許多領域的專家學 者致力的方向。由於人臉的表情包含了人類豐富的心理與生理訊息，也是人們在日常 生活中主要的溝通管道之一，若是電腦能夠對人臉表情加以辨識，必定可使電腦與人 類之間的溝通變得更為自然，使更多人能夠享受科技帶來的便利。 科技的進步，智慧型產品的蓬勃發展，使得人機互動 (Human Computer Interaction, HCI) 的相關研究成為學術界的熱門議題。在人機介面上，自動化表情辨識系統是一 個重要的功能，一旦機器可以讀懂人的情緒的話，那麼它就可以提供一些貼心的服務， 這是在這個智慧時代中相當重要的課題。例如:根據臉部的表情辨識，感情訊息被辨 識出給機器人而能更自然且聰明地與人互動，讓機器人理解人的同時也使人感受到被 理解。 在人工智慧的研究領域裡，研究人員們皆努力研發更進階的技術及演算法，使電 腦可以擁有更多近似人類的智慧，進而更為聰明、也更為友善。在影像處理的相關研 究裡，「表情辨識」已是一發展許久的議題。臉部表情是人與人之間溝通的重要訊息 來源，也是人類用來表達情緒的細緻動作，因此基本的臉部動作亦可成為表情判斷的 主要依據，如兩邊嘴角上揚表示「喜」的情緒、皺眉頭表示「生氣」的情緒等。對於 人臉影像處理與應用，在近年來已擁有相當多的創新技術及研究文獻，如對人臉如何 追蹤偵測、如何辨識身份及如何分析表情等方面，皆有許多相關的研究及探討，若能 多特徵自動化表情辨識系統 使電腦具有強大的能力來判別人類表情的情緒變化，進而做出適當的人性化回應，將 使現今人們對電腦的一般印象全然改觀，讓人們感受到電腦的人性化與親和力。另外， 人臉情緒辨識技術亦可在心理學、社會學等社會科學的相關研究上，提供一個更為方 便的工具，以輔助學者有效的觀察及研究。 臉部表情作為人與人溝通重要的資訊，在多數情況下往往能夠代表一個人的情緒 的直接反應，因此在與他人進行互動與交流的過程中，透過表情可以流露出當下內心 的情緒，包含：開心 (Happiness) 、憤怒 (Anger) 、傷心 (Sadness) 或驚訝 (Surprise) 等 (Ekman & Friesen, 1975) (Izard, 1994)。著名心理學家Paul Ekman 教授提出了一套 臉部動作編碼理論 (Facial Action Coding System, FACS) (Ekman & Friesen, 1978) (Ekman, Friesen, & Hager, 2002) 來描述面部表情。他們根據人臉的解剖學特點，將其 劃分成若干既相互獨立又相互聯繫的動作單元 (Action Units, AU) (Kanade, Cohn, & Tian, 2000)，並將許多現實生活中人類的表情進行了分類。近些年，隨著機器學習的 發展，表情單元的編碼系統也被成功的應用於表情辨識。 人臉表情辨識是電腦視覺領域裡相當熱門的研究主題，該技術對於門禁系統、公 共安全、刑犯測謊與病患情緒監控等熱門應用有著相當重要的影響。隨著科技的日益 進步，人臉辨識的技術亦不斷地獲得進展；但是，拍攝角度、光影影響與臉部肌肉隨 著年齡逐漸萎縮下垂等外在或生理因素，使得在提升人臉表情辨識準確率的過程中， 仍然有許多需要克服的問題。自動化人臉表情辨識主要是擷取人臉表情影像中較具有 辨識能力的特徵，再透過分類器進行分類以判別該影像中的表情為何。 人臉表情辨識系統之應用相當廣泛，例如：先進駕駛輔助系統 (Advanced Driver. Assistance Systems, ADAS)，可以在檢測到駕駛員的憤怒情緒後，命令駕駛員勒緊安 全帶，提高制動器的反應響應性，也可以通過方向盤振動及警告聲，將情緒狀態告知 駕駛員，從而讓我們遠離由駕駛員精神不集中及憤怒情緒所導致的交通事故。其他情 緒辨識的應用場景，典型的有廣告效果評估、產品評測、影像分析、醫療康復和情感 機器人等，因此人臉表情辨識不僅是學術界的熱門研究議題，也因各種商品化產品附 加的龐大商業利益，不少企業紛紛投入研究。 多特徵自動化表情辨識系統",
                "cross_score": 0.7715859413146973,
                "embedding_sim": 0.8742935657501221,
                "overlaps": [
                    "人機介面",
                    "熱門的研究"
                ],
                "file_path": "dataset/paraphrased_dataset/source/ccu/429.txt"
            },
            {
                "content": "我們測量個別受測者的身體比例，並利用這些測量的數據調整虛擬人物的身材比例。 Fig. 4 顯示我們需要測量的身體骨架。為了重建受測者上半身的姿勢，我們需要將HTV Vive 的手把綁在受測者的前手臂，並將追蹤器放置於受測者的肩膀上。由於Vive 手把 與受測者的前手臂是平行的，加上先前已經量得前手臂的長度，我們可以得到他們手肘 的位置，再加上頭戴顯示器，我們便可以重建受測者上半身的姿勢。我們利用這些關節 的位置及朝向做為應用逆運動學的條件以決定其餘關節的位置。 Fig. 4 我們在實驗前測量受測者的身體比 例，並利用這些測量的長度調整虛擬人 物的身材比例。 Fig. 5 在實驗前，我們替受測者穿戴設備，首先穿戴追蹤肩膀位置的背心(左)，再綁上追蹤手臂的 Vive 手把(中)，最後戴上頭盔，完成上半身的肢體動作追蹤(右)。 與追蹤受測者上半身相比，追蹤他們的手勢是相對具有挑戰性的。雖然已經有許多 的電腦視覺技術解決了這個問題，但他們皆是假設受測者是空手的情況下。然而當在追 蹤握著筆的手的時候，手勢是常常被誤判且不穩定的。因此在這個實驗中，我們針對這 個問題採取了一個對策。基於受測者的握筆姿勢，我們塑造了一個用右手握著筆的姿勢。 至於左手，我們塑造了手平攤的姿勢。換句話說，受測者在進行實驗時，是被要求保持 著他們的握筆姿勢的。由於他們已經習慣他們的握筆姿勢幾十年了，所以這個要求不應 該讓他們覺得不習慣。此外，為了幫助受測者維持他們的握筆姿勢，即食指及拇指的位 置，我們在觸控筆上黏了一個塑膠的突起點，如Fig.6 所示。因此，在不需要脫去頭盔 的情況之下，受測者仍能依據這個塑膠的突起點維持他們的握筆姿勢。為了確保虛擬實 境中的握筆姿勢與現實中的握筆姿勢相似，我們測量了拇指的第二指節及食指的第一指 節到觸控筆筆尖的相對位置。如Fig.7 顯示受測者的兩種不同握筆姿勢。我們認為這些 相對位置對於模擬虛擬人物的握筆姿勢是有幫助的。不過由於Vive 控制器是綁在前臂 上的，我們無法追蹤手腕的動作。為了要模擬虛擬人物的握筆姿勢，首先，我們藉由 Wacom 平板偵測筆尖的位置，便可利用測量到的相對位置得到上述兩個關節的位置， 之後將這兩個位置做為計算逆運動學的條件以模擬握筆姿勢的動畫。這個策略可以在不 使用額外的碰撞偵測或預防措施下避免觸控筆與手之間的穿刺，並達到自然的握筆姿勢。 Fig. 6 我們在實驗用的觸控筆上黏上塑膠突起點，提供受測者 作為握筆姿勢的錨點。 Fig. 7 我們在實驗用的觸控筆上黏上塑膠突起點，提供受測者作為握筆姿勢的錨點。",
                "cross_score": 0.5263378024101257,
                "embedding_sim": 0.8628816604614258,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/nycu/427.txt"
            },
            {
                "content": "許多雙手互動的研究皆奠基於Guiard 的研究[2]，在此研究中為雙手的工作建立了 一套準則及模型，在雙手的互動之中，兩隻手分別扮演不同的角色並遵循著三項規則， 第一項是慣用手在非慣用手所定義的框架位置內移動，第二項是在工作中，慣用手在工 作的頻率上高於非慣用手，在工作的空間上小於非慣用手，換句話說，慣用手在精準度 方面是高於非慣用手的，第三項則是非慣用手通常先於慣用手規劃使用的空間。許多研 究基於這三項原則，更深入的探討同時利用慣用手及非慣用手作為輸入時，是否會對效 率及表現造成影響，事實指出，利用雙手進行非對稱的操作，能表現出更高的效率及表 現[34,35]，並在[35]的研究中，透過實驗證實了非慣用手很適合進行精確度要求較低的 工作。在[36]設計的互動介面上，利用右手握筆，左手手勢操控書寫區域的分工方法， 可以達到很好的效果也獲得較多使用者的喜愛。此外，很多裝置也可以證明，在同時以 雙手作為輸入時，表現出的效率是高於連續以單手作為輸入的方式[37,38,39]。 三、技術細節 在本次的研究之中，我們試圖了解人們在虛擬實境中對於精細的動作掌握度有多高， 我們試圖回答「是否人們在虛擬實境中寫字及繪圖的表現能與在現實環境中相同」這個 問題。如果答案為否，我們想知道在本次實驗中，在這兩個環境的表現差距有多大，並 且研究什麼是可以減少這兩個環境差距的潛在因素。為了達到這個目標，我們在虛擬實 境及現實環境中執行了許多實驗，並且比較受測者在這兩個環境中書寫以及繪圖的表現。 在虛擬實境中，我們研究擁有等身比例的虛擬人物與否是否會對成果產生影響；在現實 的環境之中，我們的研究使用數位設備(12.9 吋的iPad Pro 及Apple pencil)及傳統筆記 設備(紙、筆)。為了避免一些其餘的干擾因素，我們讓受測者在所有的實驗條件下使用 相同的椅子及桌子，並且固定這些設備的位置，使他們能以相同的姿勢進行實驗，以下 我們對於實驗細節進行介紹。",
                "cross_score": 0.4285541772842407,
                "embedding_sim": 0.8684317469596863,
                "overlaps": [
                    "虛擬實境"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/425.txt"
            }
        ],
        "main_analysis": "经比对，用户段落与最相似文献段落没有出现明显的文字重叠，表达方式和具体内容均有差异。用户段落为对虚拟实境与手势辨识研究现状的高度概括，未见直接抄袭行为。整体来看，不存在抄袭倾向。",
        "feedbacks": [
            "Expert 1 Feedback: 作为检查专家(Expert 1)，我的意见如下：\n\nMain Model 的分析基本可信，理由如下：\n\n- 它指出用户段落与最相似文献段落没有明显文字重叠，表达方式和内容均有差异。\n- 用户段落确实只是高度概括了虚拟实境与手势辨识的研究现状，属于常见领域综述性表述，并未看到直接抄袭。\n\n但有以下补充：\n\n- Main Model 只关注了文字层面的重叠，未进一步讨论“高度概括性描述”是否可能存在“共性表述”带来的学术不规范风险，但就当前段落而言，这种风险极低。\n- 未对“段落结构”、“逻辑顺序”等非文字重叠的抄袭模式进行分析，但对于本例的简短综述句，这类分析不是必要重点。\n\n结论：Main Model 分析可信，未有明显遗漏，结论合理。",
            "Expert 2 Feedback: 作为检查专家（Expert 2），我的审阅意见如下：\n\n1. Main Model分析可信度评价  \nMain Model 的分析基本可信。用户段落的确是对虚拟实境与手势辨识领域现状的高度概括，未见与Top 3相似文献有直接文字重叠或高度相似的表达。内容侧重于领域背景的简述，并未涉及具体细节或创新性观点，因此判断为无明显抄袭倾向是合理的。\n\n2. 是否有遗漏  \n但分析略有不足，主要体现在未进一步说明如下几点：\n\n- 用户段落虽然未与Top 3文献直接重合，但属于常见领域综述性描述，表述方式较为通用，学术独创性较低，建议补充说明“该段落为常见学科背景性陈述，类似表述在相关文献中较为普遍，不易构成抄袭”。\n- 没有关注潜在的“思想抄袭”或“观点借用”问题。虽然文字未重合，但若结构、逻辑与主流综述类似，也应指出“未见特定文献的思想结构被直接借用”。\n- 未提示用户段落如需用于正式论文，应注意增加引用支持，避免因常识性表述过于宽泛而被质疑为“拼凑”或“无源引用”。\n\n结论  \nMain Model的分析基本准确，但建议补充上述内容，使评价更全面。整体而言，用户段落没有抄袭嫌疑，但建议在学术写作中适当补充引用并提升独创性。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"用户段落为对虚拟实境与手势辨识研究现状的高度概括，属于常见领域背景性描述，未见与文献有明显文字重叠或结构抄袭，且表达通用、独创性要求较低，不易构成抄袭。虽然建议正式写作时补充引用，但当前段落不存在抄袭嫌疑，结论明确。\"\n}",
        "plagiarism_confidence": 58,
        "plagiarism_percentage": 23,
        "plagiarism_snippet": [
            "人機介面",
            "熱門的研究",
            "虛擬實境"
        ],
        "verdict": "ACCEPT"
    },
    {
        "top_docs_info": [
            {
                "content": "本論文研究目標為以單一相機做為使用平台的手部姿勢(hand pose)估計，本論文系 統以一般低價網路攝影機拍攝的彩色影像作為輸入，主要輸出為相對於手掌心的3D 關 鍵點位置(也就是3D 坐標的原點是定位於掌心，而坐標的X, Y, Z 方向在第4.3 節會再 說明)、以及2D 手部關鍵點位置。此處2D 關鍵點是指手部關鍵點在影像中的位置，因 為我們假設了一個3D 的手部模型，即使只用單一攝影機以及2D 的關鍵點也可大約推 算出3D 的手部關鍵點坐標。手部關鍵點指的是手掌的中心、手指關節、手指指尖共 21 點，請參考圖14。而手部3D 關鍵點通常被稱為手部姿勢。 圖14、手部關鍵點示意圖，紅點為手部關鍵點位置 本論文最終選擇以Panteleris 等人所設計的系統作為基礎的系統架構[15]，在此架 構上最需要改進的地方有兩個，第一是手部關鍵點位置的正確性，第二是逆向運動學 中最佳化演算法的收斂結果正確度。本論文主要針對此二問題做改進。",
                "cross_score": 0.9976972937583923,
                "embedding_sim": 0.9065431952476501,
                "overlaps": [
                    "為使用平台",
                    "的手部姿勢",
                    "手部姿勢"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/14.txt"
            },
            {
                "content": "本論文以一般攝影機做為使用平台，結合神經網路與手部模型，建立手部姿勢估 計系統，以多任務學習的方式與手部語意切割系統做整合。並以藉由手掌作為初始值 與修改迭代演算法來改善逆向運動學的收斂狀況。圖1 為本論文所提出系統的實際估 測結果。整體來說，本論文的主要貢獻有二： 一、設計實作一個關鍵點估計網路，並藉由多任務學習同時提升關鍵點估計以及語意 切割兩者的準確度。 二、提出以神經網路估計手掌方向來做為初始值，改善迭代的結果。 圖1、實際估測結果。左邊為輸入影像、標上估測出來的手指關鍵點，右邊為根據估測出來的 參數所繪製的3D 手模型。",
                "cross_score": 0.994779109954834,
                "embedding_sim": 0.9357057809829712,
                "overlaps": [
                    "本論文以",
                    "為使用平台",
                    "神經網路與手部模型",
                    "手部姿勢估"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/1.txt"
            },
            {
                "content": "本論文分成六章，第一章介紹動機與成果。第二章介紹手部姿勢與關鍵點抽取的 相關研究。第三章介紹本論文所提出的系統架構所使用到的技術描述。第四章介紹本 論文系統所針對的問題的明確定義以及如何修改、整合第三章所提到的技術成為最終 的系統架構。第五章描述實驗方式以及結果。第六章則為論文的結論以及未來方向。 第二章、手部姿勢及關鍵點抽取相關研究 手部姿勢估計一直以來都是電腦視覺領域中重要的研究方向之一，目前在此類問 題上，主流方法為藉由神經網路估計關鍵點位置，再以關鍵點資訊推論手部姿勢，因 此本章主要介紹手部姿勢以及關鍵點估計的相關研究。而在關鍵點估計的部分，由於 網路架構設計的相關研究大多都以人體關鍵點做為研究對象，且手部與人體的關鍵點 估計並無太大差異，因此此處以多人體關鍵點估計的相關研究為介紹對象。此外，本 論文最終是利用3D 手部模型做為手部姿勢估測的主要限制條件 (Model-constrained estimation method)，因此本章最後會介紹手部模型的相關研究。",
                "cross_score": 0.9890673756599426,
                "embedding_sim": 0.9216673374176025,
                "overlaps": [
                    "手部姿勢估計",
                    "手部姿勢"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/2.txt"
            }
        ],
        "main_analysis": "经比对，用户段落与前三个最相似文献段落在表达内容和结构上高度相似，但没有出现大段一字不差的文字重叠，主要为同义改写与表达调整。核心术语如“單攝影機/一般攝影機作為平台”、“結合神經網路與手部模型”、“建立手部姿勢估計系統”等表述非常接近，存在一定的借鉴痕迹，但尚未达到完全抄袭的程度。建议用户进一步优化表达方式，增加原创内容。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析整体是可信的。它准确指出用户段落与相似文献在内容和结构上高度相似，属于同义改写和表达调整，核心术语和句式也有较多重合，但没有一字不差的直接抄袭，判定为“尚未达到完全抄袭的程度”是合理的。同时，建议用户进一步优化表达、增加原创内容，也是恰当的规范建议。\n\n可能的遗漏：  \n分析中未详细说明“高度相似”是否已达到学术不当引用（如拼凑、过度依赖原文结构和术语、未充分标注引用）的程度。虽然没有一字不差的抄袭，但若核心创新点、系统描述等高度依赖参考文献，仍有学术风险。此外，未提及是否存在参考文献标注不全或引用不规范等问题。\n\n总结：  \n分析可信，但可补充对学术规范和创新性风险的进一步提醒。",
            "Expert 2 Feedback: Main Model的分析基本可信。它准确指出了用户段落与相似文献在内容和结构上的高度相似，包括核心术语和表达方式的接近，且没有出现大段完全一致的抄袭。分析也合理地建议用户优化表达并增加原创性。\n\n但分析略有遗漏：  \n1. 没有具体列举句子层面的相似表达，缺乏细节例证，影响说服力。  \n2. 未指出用户段落与参考文献在创新点或细节描述上的具体区别。  \n3. 没有评估用户段落是否对现有研究有实质性创新，还是仅停留在表述层面调整。\n\n建议：分析可更具体，列举相似表述，并进一步判断创新性与独立性。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"虽然用户段落与相似文献之间没有出现大段一字不差的直接抄袭，但其内容和结构高度相似，核心术语和表达方式几乎一致，属于同义改写和表达调整，存在较明显的借鉴痕迹。Main Model与专家意见均指出存在学术风险，包括创新性不足、可能的拼凑和过度依赖原文结构等问题。由于未能充分证明段落的原创性且存在学术不当引用的嫌疑，因此应选择ABSTAIN以保留进一步核查和修改的空间。\"\n}",
        "plagiarism_confidence": 99,
        "plagiarism_percentage": 100,
        "plagiarism_snippet": [
            "為使用平台",
            "的手部姿勢",
            "手部姿勢",
            "本論文以",
            "神經網路與手部模型",
            "手部姿勢估",
            "手部姿勢估計"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "本節整理本論文對2D 關鍵點做逆向運動學的相關實驗結果，相關技術請參考4.2 節。實驗以RHD、STB 做為測試資料集，我們依序進行了兩組實驗，首先為測試LM 演算法在此問題上的效果，所以我們排除會影響收斂的其他因素，因此用正確的2D 關 鍵點位置做為目標，並將手部模型的關節間長度比例調整至正確的比例，觀察迭代的 收斂狀況及結果。再來我們測試演算法是否robust，我們改為使用網路估計的2D 關鍵 點位置做為目標，以MANO 作為手部模型，觀察演算法結果。在本節實驗中我們專注 於3D 關鍵點估計上，因此我們假設圖片中的手已被物體偵測演算法正確框出並分類為 左、右手。在目標函數上，我們以Panteleris 等人所提出目標函數[15]為基礎進行修 改，將神經網路所估計的機率𝑝𝑖由六次方改為一次方，Eq. (9)為我們的目標方程式。下 面分別說明兩個實驗的結果。 ∑𝑝𝑖((𝑥𝑖−𝑢𝑖)2 + (𝑦𝑖−𝑣𝑖)2) 𝑖=1 (9)",
                "cross_score": 0.996703565120697,
                "embedding_sim": 0.9122459888458252,
                "overlaps": [
                    "逆向運動學"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/24.txt"
            },
            {
                "content": "本論文以一般攝影機做為使用平台，結合神經網路與手部模型，建立手部姿勢估 計系統，以多任務學習的方式與手部語意切割系統做整合。並以藉由手掌作為初始值 與修改迭代演算法來改善逆向運動學的收斂狀況。圖1 為本論文所提出系統的實際估 測結果。整體來說，本論文的主要貢獻有二： 一、設計實作一個關鍵點估計網路，並藉由多任務學習同時提升關鍵點估計以及語意 切割兩者的準確度。 二、提出以神經網路估計手掌方向來做為初始值，改善迭代的結果。 圖1、實際估測結果。左邊為輸入影像、標上估測出來的手指關鍵點，右邊為根據估測出來的 參數所繪製的3D 手模型。",
                "cross_score": 0.9947598576545715,
                "embedding_sim": 0.925938069820404,
                "overlaps": [
                    "手部姿勢估",
                    "神經網路估計"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/1.txt"
            },
            {
                "content": "本論文分成六章，第一章介紹動機與成果。第二章介紹手部姿勢與關鍵點抽取的 相關研究。第三章介紹本論文所提出的系統架構所使用到的技術描述。第四章介紹本 論文系統所針對的問題的明確定義以及如何修改、整合第三章所提到的技術成為最終 的系統架構。第五章描述實驗方式以及結果。第六章則為論文的結論以及未來方向。 第二章、手部姿勢及關鍵點抽取相關研究 手部姿勢估計一直以來都是電腦視覺領域中重要的研究方向之一，目前在此類問 題上，主流方法為藉由神經網路估計關鍵點位置，再以關鍵點資訊推論手部姿勢，因 此本章主要介紹手部姿勢以及關鍵點估計的相關研究。而在關鍵點估計的部分，由於 網路架構設計的相關研究大多都以人體關鍵點做為研究對象，且手部與人體的關鍵點 估計並無太大差異，因此此處以多人體關鍵點估計的相關研究為介紹對象。此外，本 論文最終是利用3D 手部模型做為手部姿勢估測的主要限制條件 (Model-constrained estimation method)，因此本章最後會介紹手部模型的相關研究。",
                "cross_score": 0.9939664602279663,
                "embedding_sim": 0.9149919152259827,
                "overlaps": [
                    "手部姿勢估計",
                    "神經網路估計",
                    "關鍵點估計"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/2.txt"
            }
        ],
        "main_analysis": "经检查，用户段落与最相似文献段落内容高度相关，但未发现明显的文字重叠或逐字抄袭。用户段落是对常见手部姿势估计流程的简要描述，用词和句式均有明显差异，属于对通用技术路线的表述，不构成抄袭倾向。整体属于合理的技术性归纳。",
        "feedbacks": [
            "Expert 1 Feedback: 审阅意见：\n\nMain Model 的分析总体可信。它准确指出用户段落描述的是通用的手部姿势估计技术流程，未发现明显的文字重叠或逐字抄袭，属于合理的技术性归纳，这一判断与相似文献内容相符。\n\n可能的遗漏：\n- 虽然未有逐字重合，但用户段落与相似文献在技术表述和内容上高度一致，建议补充说明其“创新性”或“独创性”有限，属于对常规技术路线的归纳性表达，建议用户适当注明参考文献以增强学术规范性。\n- 未提及用户段落是否存在“拼凑抄袭”（即将多篇文献内容综合后改写），可进一步补充检查拼凑或结构性抄袭的风险。\n\n总结：分析结论基本准确，但建议增加对创新性和学术规范的提示，并补充对拼凑抄袭的关注。",
            "Expert 2 Feedback: 作为检查专家(Expert 2)，我的审阅意见如下：\n\nMain Model的分析是可信的。它准确指出用户段落与相似文献高度相关，但无明显的文字重叠或逐字抄袭，属于对通用技术路线的合理归纳。用户段落描述的是常见的手部姿势估计流程，表达方式与相似文献存在差异，未构成抄袭。\n\n可能的遗漏：\nMain Model分析中没有进一步讨论“技术性归纳”与“合理引用”的界限，亦未提及用户段落是否需补充文献引用以体现学术规范。此外，分析中未评估用户段落在技术细节（如具体模型或算法名称）上的独特性或创新性，仅从表述相似性角度分析。\n\n简要结论：  \nMain Model分析可信，但可补充关于引用规范和创新性判断的内容。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"用户段落描述的是通用的手部姿势估计流程，表达方式与相似文献存在明显差异，无逐字重合或直接抄袭，属于合理的技术性归纳。虽然创新性有限，建议补充引用以增强学术规范性，但不构成抄袭或重大不确定性，因此可以接受。\"\n}",
        "plagiarism_confidence": 100,
        "plagiarism_percentage": 40,
        "plagiarism_snippet": [
            "逆向運動學",
            "手部姿勢估",
            "神經網路估計",
            "手部姿勢估計",
            "關鍵點估計"
        ],
        "verdict": "ACCEPT"
    },
    {
        "top_docs_info": [
            {
                "content": "本次的研究流程如圖2，研究架構如下：第一章緒論1.1 研究背景說明目前的 自然語言處理技術與發展，以及目前中文在自然語言處理的處境。在1.2 研究動機 與目的說明目前中文摘要在實際應用的困境，以及該研究的方向。第二章文獻探 討文本摘要與中文自然語言處理的差異，並且介紹本研究用到的深度學習的定義 與架構模型，及其中運用到的函數。以及最佳化類神經網路中所使用的手法，並 且介紹本研究使用的深度學習演算法，循環神經網路(RNN)、長短期記憶神經網路 (LSTM) 與序列到序列架構(sequence to sequence)搭配注意力機制(Attention)與選 字階段的搜尋手法。第三章介紹使用的資料集與評估工具，並且提出實驗架構說 明。第四章呈現這幾次實驗的評估結果。第五章將會提出本研究的結論和未來研 究方向與改進。 圖 2  論文架構 第二章、 文獻探討 本章節分為九個小節，自動文本摘要的分類介紹與中文自然語言處理的特點， 接下來介紹深度學習與更進一步的循環神經網絡與其變形的雙向循環神經網絡， 再來介紹本研究神經網絡中隱藏層所使用的長短期記憶模型與本論文主要的序列 到序列架構與注意力機制及搜索法。",
                "cross_score": 0.8516514301300049,
                "embedding_sim": 0.8876389265060425,
                "overlaps": [
                    "神經網路",
                    "神經網路"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/177.txt"
            },
            {
                "content": "本論文所提出的系統架構如圖15 所示，是以在3.2 節所介紹的系統(圖12)[15]為 基礎進行修改。在網路架構的部分，我們最終選擇MSPN[8]、yolov3[34]所採用的架 構，同時我們將系統中2D 關鍵點估計的神經網路，與deeplabv3+[31]進行整合，設計 一個多任務學習(multi-task learning)的網路架構。逆向運動學的部分，本論文以 Levenberg-Marquardt 演算法最佳化，並以ResNet[32]預測手掌orientation 作為迭代的初 始值，以及[33]中的方法修改最佳化方式，改善迭代的收斂狀況。以下介紹本論文對於 Panteleris 等人所提出的架構[15]所修改的部分。 圖15、本論文所提出的系統架構圖",
                "cross_score": 0.7639902234077454,
                "embedding_sim": 0.8854544162750244,
                "overlaps": [
                    "網路架構的"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/15.txt"
            },
            {
                "content": "本研究將在第二章進文獻回顧與歸納，包含類神經網路及市場輪廓理論介 紹等。第三章描述研究方法、資料來源、資料前處理、實驗模型設計及績效評 估方式。第四章比較不同模型的實驗結果，進而分析其績效優劣。第五章闡述 實驗結果的分析與結論，並對未來研究方向等後續建議。 本論文之架構分為五章，說明分別如下: 第一章 緒論 說明研究背景與動機、研究目的、研究範圍、研究限制、研究流程與步驟等。 第二章 文獻探討 針對本論文所要研究的問題進行文獻的探討與回顧，包含市場輪廓、類神經網 路之文獻。 第三章 研究方法 描述本研究資料篩選、資料前處理、實驗組和對照組模型的設計與架構及績效 評估模式。 第四章 實驗結果與分析 分析本實驗的實驗結果並針對不同模型的實驗結果進行績效比較。 第五章 結論與未來的研究方向 總結研究結論與未來的研究方向。 第二章、文獻探討",
                "cross_score": 0.6938658952713013,
                "embedding_sim": 0.8946430683135986,
                "overlaps": [
                    "神經網路"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/1011.txt"
            }
        ],
        "main_analysis": "经检查，用户段落“在神經網路架構方面,本論文對於神經網路架構的選擇以及組合的效益,進行多項實驗與分析。”与三段最相似文献段落不存在明显的文字重叠，也未发现完整句子的抄袭行为。用户段落表达内容为通用性学术表述，未涉及具体细节或独特表述，因此没有抄袭倾向。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析基本可信，理由如下：\n\n- 分析指出用户段落与相似文献不存在明显文字重叠或完整句子的抄袭，且用户段落为通用性学术表述，这一判断合理。\n- 相似文献的内容与用户段落虽主题接近，但表述方式、细节描述均不相同，未见直接抄袭迹象。\n\n可能的遗漏：\n\n- 分析仅关注了文字重叠和句子抄袭，未进一步检查是否存在结构性剽窃（如过度模仿文献的论述逻辑或实验设计）。\n- 未说明是否检索了所有相关数据库或仅比对了部分文献，文献覆盖范围未交代。\n- 没有评价用户段落是否应加上参考文献以增强学术规范性。\n\n总体而言，Main Model分析可信，但可补充对结构性相似和引用规范的审查。",
            "Expert 2 Feedback: Main Model的分析是可信的，理由如下：\n\n- 它明确指出用户段落为通用性学术表述，未发现与相似文献的文字重叠或完整句子抄袭。\n- 检查过程涵盖了与三段最相似文献的比对，结论清晰合理。\n\n但有一个小的遗漏：\n- 虽然分析提到“未涉及具体细节或独特表述”，但可进一步说明：用户段落所述内容（“神经网络架构的选择及组合效益的实验与分析”）属于常见学术写作表述，因此即使语义类似，也不构成抄袭。\n\n总体来说，Main Model的分析结论准确，无重大遗漏。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"用户段落为通用性学术表述，未发现与相似文献的文字重叠或完整句子抄袭，且内容未涉及具体细节或独特表达，整体无明显抄袭迹象。虽然可补充结构性相似和引用规范的审查，但现有证据不足以怀疑有抄袭或不确定。\"\n}",
        "plagiarism_confidence": 77,
        "plagiarism_percentage": 31,
        "plagiarism_snippet": [
            "神經網路",
            "網路架構的"
        ],
        "verdict": "ACCEPT"
    },
    {
        "top_docs_info": [
            {
                "content": "模型篩選的部分，我們比較了三種CPM[5]、HG[7]、MSPN[8]不同的網路架構， 以RHD 和STB 此二公開資料集做測試，從中選出適合的網路架構，作為後續研究的 基礎。從表3、圖23 的實驗結果可以看出MSPN 的效果較好，故後續實驗主要以 MSPN 進行。 表3、CPM、HG、MSPN 在RHD、STB 資料集的結果 Mean EPE RHD STB CPM 6.057 7.316 HG 5.207 6.773 MSPN 4.574 6.491 圖23、CPM、HG、MSPN 在RHD、STB 結果圖表",
                "cross_score": 0.9908868074417114,
                "embedding_sim": 0.8718103766441345,
                "overlaps": [
                    "網路架構",
                    "適合的網路架構"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/22.txt"
            },
            {
                "content": "本論文所提出的系統架構如圖15 所示，是以在3.2 節所介紹的系統(圖12)[15]為 基礎進行修改。在網路架構的部分，我們最終選擇MSPN[8]、yolov3[34]所採用的架 構，同時我們將系統中2D 關鍵點估計的神經網路，與deeplabv3+[31]進行整合，設計 一個多任務學習(multi-task learning)的網路架構。逆向運動學的部分，本論文以 Levenberg-Marquardt 演算法最佳化，並以ResNet[32]預測手掌orientation 作為迭代的初 始值，以及[33]中的方法修改最佳化方式，改善迭代的收斂狀況。以下介紹本論文對於 Panteleris 等人所提出的架構[15]所修改的部分。 圖15、本論文所提出的系統架構圖",
                "cross_score": 0.706444501876831,
                "embedding_sim": 0.8657601475715637,
                "overlaps": [
                    "網路架構",
                    "的網路架構。"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/15.txt"
            },
            {
                "content": "本研究在神經網路架構下，再加入一層隱藏層，仍透過4.2隨機森林特徵排序挑選10 個重要欄位建立多層神經網路如圖23，設定輸入10個特徵(X6、X5、X12、X18、X13、 X20、X19、X23、X17、X14)、使用二元分類建立神經網路模型：隱藏層共2層各500個 神經元、輸出層1個神經元。 其中，用df7資料集去做10-fold 交叉運算，將訓練集分割成10個子樣本，一個單獨 的子樣本被保留作為驗證模型的數據，其他10-1個樣本用來訓練。交叉驗證重複10次， 每個子樣本驗證一次，平均10次的結果或者使用其它結合方式，另為使神經網路效果強 化，epoch 改為100、batch_size 設定100與verbose 設定1，最終得到一個單一估測81.56% 如圖24。 圖 23 多層神經路訓練 圖 24 多層神經網路訓練估測值",
                "cross_score": 0.49855509400367737,
                "embedding_sim": 0.8666566610336304,
                "overlaps": [
                    "神經網路架構"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/288.txt"
            }
        ],
        "main_analysis": "经检查，用户段落与最相似文献段落在表述上有部分相似，但未发现直接的文字重叠。用户段落属于通用性描述，表达了“评估多种神经网络架构在不同数据集上的表现以选择最优架构”的常见研究流程，不构成抄袭倾向。",
        "feedbacks": [
            "Expert 1 Feedback: 作为检查专家(Expert 1)，我认为Main Model的分析是可信的。其理由如下：\n\n- Main Model准确指出，用户段落为通用性描述，未发现与相似文献的直接文字重叠。\n- 用户段落内容（“评估多种神经网络架构在不同数据集上的表现以选择最优架构”）确实是常见研究流程的描述，表述广泛，并未涉及具体模型、数据集或实验细节。\n\n但也有小幅遗漏：\n\n- Main Model未具体说明，虽然未抄袭，但用户段落与相似文献在“比较不同神经网络架构、使用多个数据集、选出最优模型”这一研究流程上有高度概念重合，但这属于学术通用表述，不构成抄袭风险。\n- Main Model可进一步强调：若用户段落未来涉及具体实验数据、模型名称或表格，需注意与文献的重合风险。\n\n结论：分析可信，无重大遗漏，仅建议补充对“高度概念重合但不构成抄袭”的进一步说明。",
            "Expert 2 Feedback: 作为检查专家(Expert 2)，我认为Main Model的分析基本可信。理由如下：\n\n- 用户段落确实为高度通用性、概括性的学术表述，没有直接文字重叠，也未涉及具体方法、模型名称或数据。\n- 相似文献Top 3虽在主题和研究流程上类似，但均包含更具体的模型、数据集和实验细节，未见与用户段落直接或明显的文本重合。\n- Main Model已指出用户段落为常见研究流程描述，不构成抄袭倾向，这与事实相符。\n\n可能的遗漏：\n- Main Model未详细说明“通用性描述”与具体文献内容之间的界限，建议补充说明：用户段落未涉及具体模型、数据集或实验细节，与文献描述的“具体做法”有明显区别，这也是不构成抄袭的关键原因。\n- 可进一步建议关注后续段落是否出现具体内容重叠，以全面判断。\n\n总结：分析可信，建议补充“通用性描述”与“具体细节”的界限说明。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"用户段落为高度通用的学术表述，未涉及具体模型、数据集或实验细节，也未与现有文献有直接文字重叠。尽管与相似文献在研究流程上存在概念上的重合，但这属于学术领域常见的通用描述，不构成抄袭风险。专家意见一致认为分析可信，仅建议未来注意具体内容的重合。因此，判定为ACCEPT。\"\n}",
        "plagiarism_confidence": 73,
        "plagiarism_percentage": 29,
        "plagiarism_snippet": [
            "網路架構",
            "適合的網路架構",
            "的網路架構。",
            "神經網路架構"
        ],
        "verdict": "ACCEPT"
    },
    {
        "top_docs_info": [
            {
                "content": "本論文以一般攝影機做為使用平台，結合神經網路與手部模型，建立手部姿勢估 計系統，以多任務學習的方式與手部語意切割系統做整合。並以藉由手掌作為初始值 與修改迭代演算法來改善逆向運動學的收斂狀況。圖1 為本論文所提出系統的實際估 測結果。整體來說，本論文的主要貢獻有二： 一、設計實作一個關鍵點估計網路，並藉由多任務學習同時提升關鍵點估計以及語意 切割兩者的準確度。 二、提出以神經網路估計手掌方向來做為初始值，改善迭代的結果。 圖1、實際估測結果。左邊為輸入影像、標上估測出來的手指關鍵點，右邊為根據估測出來的 參數所繪製的3D 手模型。",
                "cross_score": 0.9988130331039429,
                "embedding_sim": 0.9205083847045898,
                "overlaps": [
                    "逆向運動學",
                    "神經網路"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/1.txt"
            },
            {
                "content": "當我們以正確的2D 關鍵點位置作為逆向運動學的目標時，我們發現迭代的收斂狀 況並不理想，容易陷入局部最小值，此類問題常見的解決方向有二，分別為迭代初始 值以及最佳化方式。下面我們分別從這兩個方向做改善。 首先，如同4.3 節所述，我們將估計手掌朝向視為分類問題，我們嘗試兩種分類方 式，第一種以歐拉角表示手部方向(orientation)，共有三個維度，其中兩個維度的角度 範圍為0~2π，其中一個維度為0~π，每 𝜋 4分成一類，共分成256 類。第二種，我們先 將圖片進行預處理，旋轉圖片使手掌到中指垂直，同樣以歐拉角表示方向，共有兩個 維度，其中一個維度角度範圍為0~2π，另一個維度為0~π，共分32 類。由表6 的實 驗結果可看出第二種方法較好，因此我們採用第二種分類方式。 表6、兩種分類方式結果比較 正確率/旋轉誤差角度 RHD STB 256 類 30.1% 33.19 º 32.5% 37.69 º 32 類 66.5% 18.92 º 64.5% 26.36 º 接下來我們先我們對Romero 等人所提出的資料集[30]做PCA，得到PC-space，在 使用Hierarchical Optimization 演算法[33]進行實驗，我們測試分成不同階段數量的結 果，實驗結果可見圖24，可以看出在分成四個或以上的階段數量時，效果大致相同， 因此我們最終分成四個階段來執行此演算法。圖25 為本節實驗解果 圖24、Hierarchical Optimization 不同階段數量在RHD 上的實驗結果 圖25、結果比較圖，每組包含上下兩張圖片，由左到由分別為ground truth、前人提出的逆向 運動學、以及用本論文提出的設定初始值方法所算出來的結果。",
                "cross_score": 0.9969981908798218,
                "embedding_sim": 0.8920588493347168,
                "overlaps": [
                    "逆向運動學",
                    "手掌朝向"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/25.txt"
            },
            {
                "content": "本論文所提出的系統架構如圖15 所示，是以在3.2 節所介紹的系統(圖12)[15]為 基礎進行修改。在網路架構的部分，我們最終選擇MSPN[8]、yolov3[34]所採用的架 構，同時我們將系統中2D 關鍵點估計的神經網路，與deeplabv3+[31]進行整合，設計 一個多任務學習(multi-task learning)的網路架構。逆向運動學的部分，本論文以 Levenberg-Marquardt 演算法最佳化，並以ResNet[32]預測手掌orientation 作為迭代的初 始值，以及[33]中的方法修改最佳化方式，改善迭代的收斂狀況。以下介紹本論文對於 Panteleris 等人所提出的架構[15]所修改的部分。 圖15、本論文所提出的系統架構圖",
                "cross_score": 0.9836187958717346,
                "embedding_sim": 0.8917517066001892,
                "overlaps": [
                    "逆向運動學"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/15.txt"
            }
        ],
        "main_analysis": "经检查，用户段落与最相似文献段落在表达内容上高度相似，尤其是“利用神经网络推论手掌朝向的方向，并以此作为迭代估测法的初始值，改善收敛的状况”这句话，与文献中“以神经网络估计手掌方向来做为初始值，改善迭代的结果”以及相关描述几乎完全一致。两者在用词和句式上有明显重叠，存在较高的抄袭倾向。建议用户用自己的语言重新表述，并适当引用原文献来源。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析基本可信，判断用户段落与文献内容在表达和用词上高度相似，且指出了存在抄袭倾向，建议用户重新表述并引用原文。分析准确地识别了核心表达上的高度重合。\n\n可能的遗漏：\n- Main Model未具体列出与原文直接对应的相似句子，缺少逐句对比（不过已总体指出相似点）。\n- 未说明“抄袭倾向”具体表现为直接用词雷同还是结构模仿，两者在学术不端判定中略有差异。\n- 未提及是否检测到用户段落有适当引用文献，或建议如何规范引用。\n\n总体来看，分析结论是可信且到位的，但可以补充更具体的对照举例和引用规范建议。",
            "Expert 2 Feedback: Main Model的分析总体是可信的，理由如下：\n\n- 其指出用户段落与文献在表达内容和用词上高度相似，特别是“利用神经网络推论手掌朝向的方向，并以此作为迭代估测法的初始值，改善收敛的状况”这句话，确实与文献原文“以神经网络估计手掌方向来做为初始值，改善迭代的结果”等表述几乎完全一致；\n- 分析明确提出存在较高的抄袭倾向，并建议用户重写和引用原文，这与学术规范相符。\n\n可能的遗漏：\n- Main Model的分析主要聚焦于文字表达上的相似性，但没有进一步分析用户段落是否在结构、理论、数据、创新点等层面也有高度重合，或是否有对原文内容的再加工、拓展或创新。\n- 未明确指出应如何进行恰当引用（如注明具体文献出处）。\n- 没有评估段落长度、比例等对整体原创性的影响。\n\n总结：Main Model的分析可信，但可补充对创新性和引用方式的进一步说明。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"用户段落与文献在表达内容和用词上高度相似，尤其核心句子几乎与原文一致，存在较高的抄袭倾向，且未见适当引用。根据学术规范，应要求用户重写并引用原文，故不能直接接受。\"\n}",
        "plagiarism_confidence": 99,
        "plagiarism_percentage": 100,
        "plagiarism_snippet": [
            "逆向運動學",
            "神經網路",
            "手掌朝向"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "當我們以正確的2D 關鍵點位置作為逆向運動學的目標時，我們發現迭代的收斂狀 況並不理想，容易陷入局部最小值，此類問題常見的解決方向有二，分別為迭代初始 值以及最佳化方式。下面我們分別從這兩個方向做改善。 首先，如同4.3 節所述，我們將估計手掌朝向視為分類問題，我們嘗試兩種分類方 式，第一種以歐拉角表示手部方向(orientation)，共有三個維度，其中兩個維度的角度 範圍為0~2π，其中一個維度為0~π，每 𝜋 4分成一類，共分成256 類。第二種，我們先 將圖片進行預處理，旋轉圖片使手掌到中指垂直，同樣以歐拉角表示方向，共有兩個 維度，其中一個維度角度範圍為0~2π，另一個維度為0~π，共分32 類。由表6 的實 驗結果可看出第二種方法較好，因此我們採用第二種分類方式。 表6、兩種分類方式結果比較 正確率/旋轉誤差角度 RHD STB 256 類 30.1% 33.19 º 32.5% 37.69 º 32 類 66.5% 18.92 º 64.5% 26.36 º 接下來我們先我們對Romero 等人所提出的資料集[30]做PCA，得到PC-space，在 使用Hierarchical Optimization 演算法[33]進行實驗，我們測試分成不同階段數量的結 果，實驗結果可見圖24，可以看出在分成四個或以上的階段數量時，效果大致相同， 因此我們最終分成四個階段來執行此演算法。圖25 為本節實驗解果 圖24、Hierarchical Optimization 不同階段數量在RHD 上的實驗結果 圖25、結果比較圖，每組包含上下兩張圖片，由左到由分別為ground truth、前人提出的逆向 運動學、以及用本論文提出的設定初始值方法所算出來的結果。",
                "cross_score": 0.4497475326061249,
                "embedding_sim": 0.8780367970466614,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/nycu/25.txt"
            },
            {
                "content": "本論文以一般攝影機做為使用平台，結合神經網路與手部模型，建立手部姿勢估 計系統，以多任務學習的方式與手部語意切割系統做整合。並以藉由手掌作為初始值 與修改迭代演算法來改善逆向運動學的收斂狀況。圖1 為本論文所提出系統的實際估 測結果。整體來說，本論文的主要貢獻有二： 一、設計實作一個關鍵點估計網路，並藉由多任務學習同時提升關鍵點估計以及語意 切割兩者的準確度。 二、提出以神經網路估計手掌方向來做為初始值，改善迭代的結果。 圖1、實際估測結果。左邊為輸入影像、標上估測出來的手指關鍵點，右邊為根據估測出來的 參數所繪製的3D 手模型。",
                "cross_score": 0.4312129616737366,
                "embedding_sim": 0.868627667427063,
                "overlaps": [
                    "估測出來的手"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/1.txt"
            },
            {
                "content": "主成分分析 (Principle Component Analysis, PCA) (Calder, Burton, Miller, Young, & Akamatsu, 2001) (Kim, Jung, & Kim, 2002) 是一種常用的數據分析方法。PCA 通過線 多特徵自動化表情辨識系統 性變換將原始數據變換為一組各維度線性無關的表示，可用於提取數據的主要特徵分 量，常用於高維數據的降維。PCA 是人臉識別的主流方法之一。其核心思想是：重整 高維數據，提取其中的重要部分，忽略其中無關緊要的部分，換句話說，通過對原來 的樣本空間進行空間變換，使原來的座標投影到一個新的、維度較低的並且相互正交 的空間上。 給定維度等於 P 的數據集{x_1,…,x_n }，主成分分析的計算程序與結果可整理 成簡明的矩陣形式: 計算樣本平均 m = 𝑛∑ 𝑥𝑘 𝑛 𝑘=1 ，定義 n x p 階離差矩陣 X = [ (𝑥1 −𝑚)𝑇 (𝑥2 −𝑚)𝑇 ⋮ (𝑥𝑛−𝑚)𝑇] = [ 𝑥11 −𝑚1  𝑥12 −𝑚2 ⋯ 𝑥1𝑝−𝑚𝑝 𝑥21 −𝑚1  𝑥22 −𝑚2 ⋯ 𝑥2𝑝−𝑚𝑝 ⋮               ⋮            ⋱            ⋮ 𝑥𝑛1 −𝑚1  𝑥𝑛2 −𝑚2 ⋯ 𝑥𝑛𝑝−𝑚𝑝 ]         (3.9) P x P 階樣本共變異數矩陣則是 𝑆= 𝑛−1 ∑ (𝑥𝑘−𝑚) (𝑥𝑘−𝑚)𝑇 𝑛 𝑘=1 = 𝑛−1 𝑋𝑇𝑋          (3.10) 將 S 正交對角化為 S = 𝑊∧𝑊𝑇，其中 ∧= diag (𝜆1, … , 𝜆𝑝) 是特徵值矩陣，𝜆1 ≥ ⋯≥𝜆𝑝≥0 代表主成分的權值，W = [𝑤1 ⋯𝑤𝑝] 是單範正交特徵向量構成的 P x P 階正交主成分矩陣，𝑊𝑇𝑊= 𝑊𝑊𝑇= 𝐼𝑝。 定義 n x p 階主成分係數矩陣 Z = [𝑧𝑘𝑗]，其中 𝑧𝑘𝑗= (𝑥𝑘−𝑚)𝑇𝑤𝑗，因此 𝑍= [ (𝑥1 −𝑚)𝑇 ⋮ (𝑥𝑛−𝑚)𝑇 ] [𝑤1 ⋯𝑤𝑝] = 𝑋𝑊          (3.11) 上式等號兩邊右乘 𝑊𝑇，可得 𝑋= 𝑍𝑊𝑇。換一個說法，數據點 𝑥𝑘 的主成分分 解式為 多特徵自動化表情辨識系統 𝑥𝑘= 𝑚+ ∑𝑧𝑘𝑗𝑤𝑗 𝑝 𝑗=1 , 𝑘= 1, … , n         (3.12) 主成分係數 (𝑧𝑘1, . . , 𝑧𝑝) 是離差 𝑥𝑘−𝑚 參考單範正交基底 B = {𝑤1 ⋯𝑤𝑝} 的 座標向量。 HOG 與B-LBP 特徵向量維度很高，存在大量的冗餘訊息，這些訊息降低了識別 的精確度，也減緩了分類的速度。所以降維顯得非常重要，本研究採用PCA 對特徵 向量進行降維，能量保留比例90%。",
                "cross_score": 0.35709813237190247,
                "embedding_sim": 0.8664296269416809,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/ccu/449.txt"
            }
        ],
        "main_analysis": "经检查，用户段落“並以大量手勢經PCA拆解後的樣本向量空間,作為迭代估測的解空間,使最終估測出來的手勢更加自然。”与提供的最相似文献段落没有出现明显的文字重叠，表述方式和句型结构不同，仅属于相关技术领域的相近描述。未发现抄袭倾向。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析基本可信。它明确指出用户段落与相似文献之间没有明显文字重叠，表述和句型结构不同，仅是技术领域的相似描述，未发现抄袭倾向，这一判断是准确的。\n\n但分析略有遗漏：  \n1. 技术思想相似性：用户段落与相似文献都提到“用PCA降维后得到的向量空间作为后续估计/优化的解空间”，属于较深层的技术思路相似。虽然没有文字抄袭，但建议补充说明两者在技术实现或思路上的关联和区别。\n2. 引用规范性：未提及用户是否需对PCA相关通用技术背景加以适当引用，以避免学术不端风险（即使未直接抄袭）。\n3. 术语共性说明：可进一步说明PCA及其作为降维和解空间的方法，在本领域属于常用技术，使用类似表述较为普遍，减少误判风险。\n\n建议：  \n- 认可未抄袭结论，但建议补充对技术思路相似性的分析及引用规范性提示，以增强结论的严谨性。",
            "Expert 2 Feedback: 作为检查专家(Expert 2)，我的审阅意见如下：\n\nMain Model的分析总体可信，理由如下：\n\n- 审查内容准确指出用户段落与相似文献之间“没有明显文字重叠，表述方式和句型结构不同，仅属于相关技术领域的相近描述”，这一结论与实际比对结果一致。\n- 用户段落虽然涉及PCA、样本向量空间、迭代估测等相关领域通用表述，但未发现与相似文献Top 3中的具体语句有直接重合或高度相似，属于正常的学术技术叙述。\n\n但分析略有遗漏，建议补充：\n\n1. **技术思路相似性说明不足**  \n   用户段落与相似文献均涉及“PCA用于手势/特征空间降维，再用于后续估测或优化”，虽然表述不同，但技术核心思路一致。建议明确指出：技术路线高度相似，但未构成抄袭。\n\n2. **建议关注表达创新性**  \n   可建议用户在表述时适当增加自身创新点或进一步细化方法细节，以突出原创性，避免未来产生学术争议。\n\n**结论简述：**  \nMain Model分析可信，未发现抄袭，但建议补充对技术思路相似性的说明及表达创新性的建议。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"用户段落与相似文献在表述和句型结构上没有明显重叠，仅为技术领域的通用描述，未发现直接抄袭。虽然技术思路有相似性，但属于常见技术路径，并未构成学术不端。建议关注引用规范和表达创新性，但不影响本次判断结论。\"\n}",
        "plagiarism_confidence": 41,
        "plagiarism_percentage": 17,
        "plagiarism_snippet": [
            "並以大量手勢經PCA拆解後的樣本向量空間,作為迭代估測的解空間,使最終估測出來的手勢更加自然。"
        ],
        "verdict": "ACCEPT"
    },
    {
        "top_docs_info": [
            {
                "content": "本論文分成六章，第一章介紹動機與成果。第二章介紹手部姿勢與關鍵點抽取的 相關研究。第三章介紹本論文所提出的系統架構所使用到的技術描述。第四章介紹本 論文系統所針對的問題的明確定義以及如何修改、整合第三章所提到的技術成為最終 的系統架構。第五章描述實驗方式以及結果。第六章則為論文的結論以及未來方向。 第二章、手部姿勢及關鍵點抽取相關研究 手部姿勢估計一直以來都是電腦視覺領域中重要的研究方向之一，目前在此類問 題上，主流方法為藉由神經網路估計關鍵點位置，再以關鍵點資訊推論手部姿勢，因 此本章主要介紹手部姿勢以及關鍵點估計的相關研究。而在關鍵點估計的部分，由於 網路架構設計的相關研究大多都以人體關鍵點做為研究對象，且手部與人體的關鍵點 估計並無太大差異，因此此處以多人體關鍵點估計的相關研究為介紹對象。此外，本 論文最終是利用3D 手部模型做為手部姿勢估測的主要限制條件 (Model-constrained estimation method)，因此本章最後會介紹手部模型的相關研究。",
                "cross_score": 0.6992215514183044,
                "embedding_sim": 0.8204284906387329,
                "overlaps": [
                    " estimation "
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/2.txt"
            },
            {
                "content": "在過去基於深度影像進行手部姿勢估測方法中，大多數研究皆搭配手部模型進 行，透過尋找手部模型參數，使手部模型的深度資訊與深度圖像相似，通常透過迭代 最佳化演算法求解，如PSO[20]。而近期的研究，則多以神經網路估計3D 關鍵點位置 [23][24]。Wan 等人提出讓卷積神經網路同時估計2D、3D 關鍵點以及單位向量場(指向 手指頭)，藉此提升精確度的方法[23]。Ge 等人則提出使用3D 卷積神經網路來估計3D 關鍵點位置的機制[24]。",
                "cross_score": 0.5356701612472534,
                "embedding_sim": 0.821670651435852,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/nycu/3.txt"
            },
            {
                "content": "許多雙手互動的研究皆奠基於Guiard 的研究[2]，在此研究中為雙手的工作建立了 一套準則及模型，在雙手的互動之中，兩隻手分別扮演不同的角色並遵循著三項規則， 第一項是慣用手在非慣用手所定義的框架位置內移動，第二項是在工作中，慣用手在工 作的頻率上高於非慣用手，在工作的空間上小於非慣用手，換句話說，慣用手在精準度 方面是高於非慣用手的，第三項則是非慣用手通常先於慣用手規劃使用的空間。許多研 究基於這三項原則，更深入的探討同時利用慣用手及非慣用手作為輸入時，是否會對效 率及表現造成影響，事實指出，利用雙手進行非對稱的操作，能表現出更高的效率及表 現[34,35]，並在[35]的研究中，透過實驗證實了非慣用手很適合進行精確度要求較低的 工作。在[36]設計的互動介面上，利用右手握筆，左手手勢操控書寫區域的分工方法， 可以達到很好的效果也獲得較多使用者的喜愛。此外，很多裝置也可以證明，在同時以 雙手作為輸入時，表現出的效率是高於連續以單手作為輸入的方式[37,38,39]。 三、技術細節 在本次的研究之中，我們試圖了解人們在虛擬實境中對於精細的動作掌握度有多高， 我們試圖回答「是否人們在虛擬實境中寫字及繪圖的表現能與在現實環境中相同」這個 問題。如果答案為否，我們想知道在本次實驗中，在這兩個環境的表現差距有多大，並 且研究什麼是可以減少這兩個環境差距的潛在因素。為了達到這個目標，我們在虛擬實 境及現實環境中執行了許多實驗，並且比較受測者在這兩個環境中書寫以及繪圖的表現。 在虛擬實境中，我們研究擁有等身比例的虛擬人物與否是否會對成果產生影響；在現實 的環境之中，我們的研究使用數位設備(12.9 吋的iPad Pro 及Apple pencil)及傳統筆記 設備(紙、筆)。為了避免一些其餘的干擾因素，我們讓受測者在所有的實驗條件下使用 相同的椅子及桌子，並且固定這些設備的位置，使他們能以相同的姿勢進行實驗，以下 我們對於實驗細節進行介紹。",
                "cross_score": 0.4583965837955475,
                "embedding_sim": 0.8150959014892578,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/nycu/425.txt"
            }
        ],
        "main_analysis": "经检查，用户段落与提供的文献段落不存在明显的文字重叠，表述方式和用词也有较大差异。用户段落内容较为简洁、概括，没有直接抄袭文献中的具体表述或句子。因此，不存在抄袭倾向。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析总体上是可信的。它明确指出用户段落与相似文献之间没有明显的文字重叠，表达方式和用词差异较大，且内容简洁、概括，没有直接抄袭文献的具体表述或句子，因此判断不存在抄袭倾向是合理的。\n\n可能的遗漏：\n- Main Model的分析只关注了“文字重叠”和“表述方式”，但没有提及“观点抄袭”或“结构抄袭”的可能性。虽然用户段落很简短，当前未见明显此类问题，但理想情况下可补充说明未发现结构或观点上的高度相似。\n- 未提及用户段落与文献主题的相似性是否属于常见的学术表述（即“公知内容”），虽然实际分析中已隐含此点。\n\n总结：分析可信，建议可补充说明未见结构或观点抄袭，进一步完善分析。",
            "Expert 2 Feedback: Main Model 的分析总体可信。它指出用户段落与相似文献没有明显文字重叠，表达方式和用词差异较大，内容简洁、概括，没有直接抄袭文献中的具体表述或句子，因此不构成抄袭，这一判断合理。\n\n但分析有一点遗漏：虽然没有直接抄袭，但用户段落的内容（如“3D hand gesture estimation is crucial for human-computer interaction”）与文献主题高度一致，属于通用性很强的领域背景描述。建议补充说明，虽然没有文字抄袭，但内容为常见领域背景介绍，建议适当增加独特性或结合具体研究，以增强原创性。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"用户段落与文献不存在明显的文字重叠，表述方式和用词差异较大，内容为领域内常见的背景介绍，不构成抄袭。专家建议虽提到可增强独特性，但并未影响原创性判定，因此应予以接受。\"\n}",
        "plagiarism_confidence": 56,
        "plagiarism_percentage": 23,
        "plagiarism_snippet": [
            "In recent years, applications of Virtual Reality grow rapidly. Therefore, 3D hand gesture estimation that is crucial for human-computer interaction has become a hot research topic today."
        ],
        "verdict": "ACCEPT"
    },
    {
        "top_docs_info": [
            {
                "content": "本論文研究目標為以單一相機做為使用平台的手部姿勢(hand pose)估計，本論文系 統以一般低價網路攝影機拍攝的彩色影像作為輸入，主要輸出為相對於手掌心的3D 關 鍵點位置(也就是3D 坐標的原點是定位於掌心，而坐標的X, Y, Z 方向在第4.3 節會再 說明)、以及2D 手部關鍵點位置。此處2D 關鍵點是指手部關鍵點在影像中的位置，因 為我們假設了一個3D 的手部模型，即使只用單一攝影機以及2D 的關鍵點也可大約推 算出3D 的手部關鍵點坐標。手部關鍵點指的是手掌的中心、手指關節、手指指尖共 21 點，請參考圖14。而手部3D 關鍵點通常被稱為手部姿勢。 圖14、手部關鍵點示意圖，紅點為手部關鍵點位置 本論文最終選擇以Panteleris 等人所設計的系統作為基礎的系統架構[15]，在此架 構上最需要改進的地方有兩個，第一是手部關鍵點位置的正確性，第二是逆向運動學 中最佳化演算法的收斂結果正確度。本論文主要針對此二問題做改進。",
                "cross_score": 0.9767981767654419,
                "embedding_sim": 0.843753457069397,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/nycu/14.txt"
            },
            {
                "content": "本論文以一般攝影機做為使用平台，結合神經網路與手部模型，建立手部姿勢估 計系統，以多任務學習的方式與手部語意切割系統做整合。並以藉由手掌作為初始值 與修改迭代演算法來改善逆向運動學的收斂狀況。圖1 為本論文所提出系統的實際估 測結果。整體來說，本論文的主要貢獻有二： 一、設計實作一個關鍵點估計網路，並藉由多任務學習同時提升關鍵點估計以及語意 切割兩者的準確度。 二、提出以神經網路估計手掌方向來做為初始值，改善迭代的結果。 圖1、實際估測結果。左邊為輸入影像、標上估測出來的手指關鍵點，右邊為根據估測出來的 參數所繪製的3D 手模型。",
                "cross_score": 0.9641567468643188,
                "embedding_sim": 0.8557457327842712,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/nycu/1.txt"
            },
            {
                "content": "本論文分成六章，第一章介紹動機與成果。第二章介紹手部姿勢與關鍵點抽取的 相關研究。第三章介紹本論文所提出的系統架構所使用到的技術描述。第四章介紹本 論文系統所針對的問題的明確定義以及如何修改、整合第三章所提到的技術成為最終 的系統架構。第五章描述實驗方式以及結果。第六章則為論文的結論以及未來方向。 第二章、手部姿勢及關鍵點抽取相關研究 手部姿勢估計一直以來都是電腦視覺領域中重要的研究方向之一，目前在此類問 題上，主流方法為藉由神經網路估計關鍵點位置，再以關鍵點資訊推論手部姿勢，因 此本章主要介紹手部姿勢以及關鍵點估計的相關研究。而在關鍵點估計的部分，由於 網路架構設計的相關研究大多都以人體關鍵點做為研究對象，且手部與人體的關鍵點 估計並無太大差異，因此此處以多人體關鍵點估計的相關研究為介紹對象。此外，本 論文最終是利用3D 手部模型做為手部姿勢估測的主要限制條件 (Model-constrained estimation method)，因此本章最後會介紹手部模型的相關研究。",
                "cross_score": 0.9128121137619019,
                "embedding_sim": 0.8349629640579224,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/nycu/2.txt"
            }
        ],
        "main_analysis": "经检查，用户段落与最相似文献段落没有出现明显的文字重叠，表达方式和具体细节也有差异。用户段落为英文简要描述，文献为中文详细说明实现细节和背景。整体来看，不存在抄袭倾向。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析总体可信。它准确指出用户段落与最相似文献在文字表达和细节层面无明显重叠，且用户段落为英文简述，文献为中文详述实现，内容和表述方式均有差异，判断不存在抄袭倾向是合理的。\n\n但分析略有遗漏：  \n1. 仅从文字重叠和表述方式评估，未说明两者在核心思想、技术路线或系统结构上的相似性是否已达到需要引用的程度。  \n2. 未明确指出用户段落是否有必要补充引用相关文献以体现学术诚信。\n\n建议补充：虽然无抄袭倾向，但建议用户如参考了相似文献的技术路线或结构，应在论文中适当引用，以避免潜在的学术不端风险。",
            "Expert 2 Feedback: 作为检查专家（Expert 2），审阅Main Model的分析后，结论如下：\n\n分析可信度：Main Model对比了用户段落与最相似文献段落，指出两者在表达方式和细节上存在明显差异，且无文字重叠，判断不存在抄袭倾向。结合用户段落和相似文献内容，Main Model的结论是可信的。\n\n可能遗漏点：\n- Main Model仅关注了文字表达和细节差异，没有深入分析技术实现或结构是否存在高度相似。虽然没有直接抄袭，但核心思路、系统框架和方法流程与文献极为接近，建议补充关注“思想抄袭”或“结构性相似”风险。\n- 没有说明查重比对的范围和是否涵盖了所有公开文献，存在一定局限性。\n\n总体建议：Main Model的分析基本可信，但建议补充对技术路线、系统设计等层面“实质性相似”的分析，以全面评估创新性和独立性。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"经综合分析，用户段落与最相似文献在文字表述和细节实现上无明显重叠，且内容和表达方式均有差异，目前未发现直接抄袭证据。虽然专家建议关注核心思想和技术路线的相似性，并建议适当引用以规避学术风险，但现有证据仅显示合理借鉴，尚未达到需要怀疑抄袭或不确定的程度，因此可以通过。\"\n}",
        "plagiarism_confidence": 95,
        "plagiarism_percentage": 38,
        "plagiarism_snippet": [
            "This thesis aims to design a 3D hand pose estimation system for virtual reality applications using a single image as input.",
            "The proposed system uses deep learning neural networks for estimating 2D hand keypoints, and inverse-kinematic inferences of the 3D hand pose, including the orientation of the palm and the 3D angles of the finger joints, using a 3D hand model."
        ],
        "verdict": "ACCEPT"
    },
    {
        "top_docs_info": [
            {
                "content": "本論文所提出的系統架構如圖15 所示，是以在3.2 節所介紹的系統(圖12)[15]為 基礎進行修改。在網路架構的部分，我們最終選擇MSPN[8]、yolov3[34]所採用的架 構，同時我們將系統中2D 關鍵點估計的神經網路，與deeplabv3+[31]進行整合，設計 一個多任務學習(multi-task learning)的網路架構。逆向運動學的部分，本論文以 Levenberg-Marquardt 演算法最佳化，並以ResNet[32]預測手掌orientation 作為迭代的初 始值，以及[33]中的方法修改最佳化方式，改善迭代的收斂狀況。以下介紹本論文對於 Panteleris 等人所提出的架構[15]所修改的部分。 圖15、本論文所提出的系統架構圖",
                "cross_score": 0.6060781478881836,
                "embedding_sim": 0.8295397758483887,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/nycu/15.txt"
            },
            {
                "content": "當我們以神經網路所估計的2D 關鍵點位置作為輸入時，我們注意到如果有少數 2D 關鍵點估計錯誤，可能會大大影響逆向運動學之結果，因此我們將Eq. (10)稍作修 改，多加入介於0 到1 之間變數𝑟，首先將Eq.(9)中目標函數每個關鍵點的平方差都乘 上一個變數𝑟𝑖，作為每個關鍵點的權重，同時為避免最佳化演算法讓𝑟𝑖為0 來降低目標 函數的值，因此我們在目標函數後加上𝛼(1 −𝑟𝑖)2來避免，此方法可以使最佳化演算法 自己決定每個關鍵點所佔的權重，讓目標函數增加一些彈性，並非絕對相信神經網路 所估計出的結果，可將式子改寫成 ∑𝑟𝑖𝑝𝑖((𝑥𝑖−𝑢𝑖)2 + (𝑦𝑖−𝑣𝑖)2)) + 𝛼(1 −𝑟𝑖)2 𝑖=1 (10) 其中𝛼為常數。 最後為了確認本節演算法在正常狀況下的表現，我們以神經網路估計的2D 關鍵點 做為目標，MANO 作為手部模型，對本節所提到的演算法做實驗，測試個別以及同時 使用的效果，表7 為實驗結果。 表7、本節實驗結果 With Eq.(10)     Palm orientation   Hierarchical optimization   Mean EPE (mm) RHD 29.99 28.44 25.78 24.48 21.87 STB 31.29 31.03 30.88 29.57 29.47",
                "cross_score": 0.4900803864002228,
                "embedding_sim": 0.8319036960601807,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/nycu/26.txt"
            },
            {
                "content": "本論文以一般攝影機做為使用平台，結合神經網路與手部模型，建立手部姿勢估 計系統，以多任務學習的方式與手部語意切割系統做整合。並以藉由手掌作為初始值 與修改迭代演算法來改善逆向運動學的收斂狀況。圖1 為本論文所提出系統的實際估 測結果。整體來說，本論文的主要貢獻有二： 一、設計實作一個關鍵點估計網路，並藉由多任務學習同時提升關鍵點估計以及語意 切割兩者的準確度。 二、提出以神經網路估計手掌方向來做為初始值，改善迭代的結果。 圖1、實際估測結果。左邊為輸入影像、標上估測出來的手指關鍵點，右邊為根據估測出來的 參數所繪製的3D 手模型。",
                "cross_score": 0.3780819773674011,
                "embedding_sim": 0.8470070362091064,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/nycu/1.txt"
            }
        ],
        "main_analysis": "经检查，用户段落与最相似文献段落内容表达类似，但未出现明显的句子或短语直接重叠。用户段落用英文简述了神经网络架构选择、逆向运动学初值改进以及PCA用于手势估计空间收敛的思路，而文献段落以中文详细说明了类似的技术路径，但表述和细节并未直接复制。整体来看，没有抄袭倾向，但内容思路较为接近，建议适当补充引用来源以规避学术风险。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析基本可信。它准确指出了用户段落与相似文献在技术思路上的高度相似性，但没有发现明显的直接抄袭（如句子、短语的原文照搬），并建议补充引用以规避学术风险，这是合理且常规的学术建议。\n\n可能的遗漏：\n1. 细节层面分析不足：Main Model主要从整体思路和表述方式评述，没有进一步分析技术细节（如PCA具体使用方式、迭代初值设定等）是否存在“结构性抄袭”或“技术流程复现”，即使未直接用词重合，也可能构成“实质性相似”。\n2. 英文与中文表达差异：未特别指出用户段落为英文简写、文献为中文详细说明，两者在表达风格与技术深度上是否有本质区别，可能影响判断。\n3. 引用建议不够具体：只建议补充引用，但未说明应引用哪些关键内容或技术环节。\n\n综上，Main Model分析是可信的，但可进一步加强细节分析与引用建议的具体性。",
            "Expert 2 Feedback: 作为检查专家(Expert 2)，我认为Main Model的分析总体可信。具体理由如下：\n\n- 分析明确指出用户段落与相似文献“内容思路较为接近”，但“未出现明显的句子或短语直接重叠”，也就是说没有直接抄袭的现象。\n- 对比内容涵盖了神经网络架构选择、逆向运动学初值改进、PCA用于手势估计空间等关键技术点，分析能准确提炼出二者的相似与差异。\n- 分析也给出了合理建议：建议补充引用以避免学术风险，这符合学术规范。\n\n可能的遗漏：\n- Main Model的分析没有具体指出PCA相关内容在相似文献中是否有体现，用户段落提到PCA构建手势向量空间，但Top 3文献摘要似乎未提及PCA，分析对此未作特别区分。\n- 没有说明除文字表达外，整体结构、技术路线的相似度是否属于合理借鉴还是较高雷同，有进一步区分的空间。\n- 建议可以补充明确：虽然没有文本抄袭，但若技术路线或创新点过于相似，仍有必要加强引用和阐述原创贡献。\n\n总结：Main Model的分析可信，基本到位，但对PCA细节、技术路线创新性等方面可以更细致说明。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"用户段落与相似文献在技术思路上高度接近，但未发现直接抄袭（如句子、短语的原文照搬），表达方式和语言风格也有区别。虽然在整体结构和技术路径上有较强相似性，但目前证据不足以认定为抄袭，仅需补充引用以规避学术风险。因此，应判定为ACCEPT。\"\n}",
        "plagiarism_confidence": 49,
        "plagiarism_percentage": 20,
        "plagiarism_snippet": [
            "For inverse kinematics estimation, we have improved the convergence of each iteration by using the orientation information of the palm, which was inferred by a neural network, as the initial values of iterative optimizations."
        ],
        "verdict": "ACCEPT"
    },
    {
        "top_docs_info": [
            {
                "content": "本研究架構如圖1-2 所示，總共分為五個章節。第一章主要說明本篇論文的 研究背景、研究動機、研究目的與研究架構。 第二章則是專注在探討與回顧過去的文獻，第一部分主要著重於樣本選取之 解說，另一部分則是詳細了解資料離散化。 第三章將詳細描述本研究的實驗流程，包括實驗的參數設定、以及離散化結 合樣本選取模型設計與交叉驗證的步驟。 第四章為實驗與分析，說明本研究的實驗環境、介紹資料來源與資料特性， 以及離散化與樣本選取結合後之結果分析。 第五章為本論文的結論與建議，並探討未來可行的研究方向。 圖1-2 研究架構 （圖片來源：本研究） 第一章 •研究背景 •研究動機 •研究目的 •研究架構 第二章 •文獻探討 第三章 •研究架構 •架構比較 •參數設定 •實驗流程 第四章 •實驗分析 •實驗結果 第五章 •結論與建議 第二章 文獻探討",
                "cross_score": 0.04316066578030586,
                "embedding_sim": 0.8843395709991455,
                "overlaps": [
                    "本篇論文的"
                ],
                "file_path": "dataset/paraphrased_dataset/source/ncu_2019/193.txt"
            },
            {
                "content": "在整個文獻回顧的部分，我們分為2.1 區塊鏈的智慧化和2.2 評分機制的優化做論 文探討。 從以上的文獻回顧內容我們可以知道因為區塊鏈為最新發展的技術，因此本來在區 塊鏈所研究的論文就比較少，而在既有的區塊鏈研究論文中，又有許多為「概念式」的 論文，也就是並沒有實作內容，而只有提出想法，更不用說是在做區塊鏈智慧化這一塊， 屈指可數。而在評分機制的優化當中，我們可以發現大多數的論文偏向於預測及分群， 優化的論文相對較少。 本研究主要是想要讓區塊鏈智慧化，並在區塊鏈上實作評分的優化來讓區塊鏈的使 用者更為方便，從文獻回顧中我們可以發現，現在並沒有類似的研究，光是在區塊鏈或 是評分優化的論文中就已不多，何況是將兩個領域作合併研究，再加上區塊鏈及評分優 化是現在最熱門的議題，也是大家最想要研究的領域，因此本篇論文將會是第一篇兩個 領域作合併並實作的研究，希望能藉由在各領域的研究中得到許多參考方法，加強研究 的深度及廣度，並能帶給以後想要研究區塊鏈智慧化的學者們一些靈感。 第三章 研究方法與步驟",
                "cross_score": 0.035801973193883896,
                "embedding_sim": 0.8860586285591125,
                "overlaps": [
                    "本篇論文"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/849.txt"
            },
            {
                "content": "本論文研究流程如圖1-3 所示，先擬定研究主題後，確定研究動機與目的，再進行 相關文獻的探討，從中取得經驗並設立研究模型與研究的方法後，選定目標研究的資料 與對應之量測參數，並進行資料處理分析與實驗，最後以數據得出研究結論與未來的方 向。 圖1-3 研究流程(圖片來源：本研究整理) 第二章  相關文獻",
                "cross_score": 0.029285408556461334,
                "embedding_sim": 0.8846385478973389,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/ncu_2019/413.txt"
            }
        ],
        "main_analysis": "经检查，用户段落与最相似文献段落之间没有明显的文字重叠，内容上也无直接抄袭倾向。用户段落为论文致谢内容，文献段落则为研究背景与方法介绍，内容和表达方式均有明显区别。判定不存在抄袭问题。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析是可信的。理由如下：\n\n- 分析明确指出用户段落为论文致谢内容，而相似文献均为研究背景、方法和文献回顾部分，内容类型和表达方式差异明显。\n- 检查结果显示无明显文字重叠和直接抄袭倾向，判断准确。\n\n可能的遗漏：\n\n- 没有详细说明查重系统是否核查了更大范围的数据库或仅限于当前Top 3文献，但考虑到致谢内容的通用性，这种遗漏影响有限。\n- 没有特别指出，致谢内容本身通常不会作为学术不端的重点查重对象，但实际判断已体现出这一点。\n\n结论：分析可信，无重大遗漏。",
            "Expert 2 Feedback: Main Model的分析是可信的，理由如下：\n\n- 分析内容准确指出用户段落为致谢内容，与相似文献的研究方法、背景介绍等学术内容类型明显不同。\n- 检查结果表明没有明显的文字重叠和直接抄袭倾向，判断合理。\n\n可能的遗漏：\n\n- Main Model未说明是否对致谢类常用语句（如感谢导师指导等）进行常见性或模板化用语的排查。虽然致谢部分一般不作为抄袭重点，但如果大段落为模板化表达，也应简要提及。\n- 未说明是否对全篇（非只与Top3文献）进行了广泛查重，仅针对最相似的文献做了分析。\n\n总体结论：分析结论可信，无实质性遗漏，但可补充说明致谢常用语句的合理性及查重范围。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"用户段落为论文致谢内容，未与文献存在明显文字重叠，也无直接抄袭倾向。两位专家均认为分析可信，且致谢部分通常为通用表达，不作为学术不端查重重点。因此可以接受，无抄袭嫌疑。\"\n}",
        "plagiarism_confidence": 4,
        "plagiarism_percentage": 1,
        "plagiarism_snippet": [
            "本篇論文的",
            "本篇論文"
        ],
        "verdict": "ACCEPT"
    },
    {
        "top_docs_info": [
            {
                "content": "本研究運用南部某區域醫院的住院病人資料庫，以探討病人對於病房型態之選擇 進行分析，未考慮其他因素影響結果可能性，列出本研究過程中遭遇的困難及限制。 1. 研究樣本共有141,050 筆資料，資料內容可能會因為院所規模大小有所差異，研 究結果無法推論到其他醫療院所使用。 2. 研究變數中，是否開立診斷書與是否有醫療保險無法完全畫上等號，但為求模型 單純化，則將開立診斷書視為有醫療保險。而也有不少病人是在出院後才回門 診開立診斷書，申請醫療保險理賠之用。為求模型單純化，亦不將此類病患回 溯為有開立診斷書者。 3. 影響病人選擇病房類型的變數錯綜複雜，舉凡心理面、經濟面等，皆有可能使得 病人無法自由的選擇病房類型。由於這些資料有量化上的困難，為求模型的單 純性，除了個案醫院所提供的資料庫檔案以及政府部門所公佈的財務報表數據 之外，其他變數在本研究中均不予考慮。 4. 引用政府部門所公佈之各縣市鄉鎮村里平均所得，無法真實代表研究對象之個人 所得。另外，由於106~107 年度資料尚未公布，故只能以103-105 年度之均值 來替代，未來106~107 年度資料公布，可重新再跑一次模型分析。",
                "cross_score": 0.007804581429809332,
                "embedding_sim": 0.859336256980896,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/ccu/625.txt"
            },
            {
                "content": "1. 本研究使用的網站，其針對使用者社交檔案所給予的欄位稍顯不足，如果網 站可以提供將社交檔案更明確、更多樣，相信對提升問題答案的準確率、召回率與 縮短延遲時間有很大的幫助。 2. 個人網路設備無法同時抓取多個頁面，Python 技巧稍嫌不足，造成研究一開 始的資料整理與前處理延宕，爬取資料時耗日費時，最後使用人工去sync 所有相關 頁面的每筆資料，再人工剃除不需要的資料。有此經驗，將來必須將自身的python 技巧及相關的套件多多熟悉與學習。 3. 由tripadvisor 所取出的個人資料中發現，其使用者社交關係並不親近，相互 交流也不如facebook、instagram 之類的社交網站來得密切，比較像一個有旅遊問題 的人才會拜訪的網站，看完評論或問題討論後才會發出問題。",
                "cross_score": 0.006311528850346804,
                "embedding_sim": 0.8658850193023682,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/ccu/269.txt"
            },
            {
                "content": "經評估後，如圖1-2 所示，為解決目前虛擬量測在設定數學模型上的缺點並且以修 改系統架構最小化的前提下達成．本研究希望以深度學習取代人工設定數學模型部份以 獲得以下優勢： 1. 快速設定多種量測模型 2. 使用同樣的訓練方法建置不同的數學模型 3. 所有製程當下參數交由深度學習模型自動決定重要的參數與權重 4. 增加預測量測參數種類 如能獲得以上的優勢，將有機會做到在現有架構下快速的針對各個認定為重要量測 參數使用虛擬量測模型進行即時且全面的品質監控（目前約半年人工新增100 個數學模 型），且可使用同樣的訓練方法建置不同的數學模型，與先前人工建置在不同模型使用 不同方法相比，節省大量的時間與人力，且由模型自動決定重要的參數與權重，可排除 只能由人的專業知識判斷的人為因素，能加入客觀的機器判斷，降低人選錯參數的風 險，而在增加量測參數的種類上，與舊有人為無法判斷的複雜量測參數也能由模型自動 學習，增進了良率防禦的全面性。 圖1-2 虛擬量測架構—改善後(圖片來源：本研究整理)",
                "cross_score": 0.0058467332273721695,
                "embedding_sim": 0.8602645397186279,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/ncu_2019/412.txt"
            }
        ],
        "main_analysis": "经检查，用户段落与提供的最相似文献段落之间没有文字重叠，也不存在抄袭倾向。用户段落为论文致谢内容，表达对口试委员的感谢，而文献内容均为研究过程、方法、数据或技术相关的描述，两者内容和表达方式均无直接关联。",
        "feedbacks": [
            "Expert 1 Feedback: 审阅意见如下：\n\nMain Model的分析基本可信。理由如下：\n\n- 分析指出用户段落为论文致谢内容，表达感谢口试委员，内容和表达方式与相似文献均无直接关联，也未发现文字重叠或抄袭倾向。\n- 相似文献Top 3均为研究过程、方法、数据或技术说明，与用户段落的致谢内容在主题和用词上无重合。\n\n但略有遗漏之处：\n\n- 未明确说明是否检查了更广泛的数据库或仅限于Top 3文献。\n- 未提及对致谢常用表达进行比对（如“感謝…在百忙之中擔任口試委員”是常见致谢用语），是否存在套用模板但不构成抄袭的情况。\n\n结论：分析可信，未发现抄袭，但可补充说明致谢用语为惯用表达，属于学术写作规范范畴，无需过度担忧重复。",
            "Expert 2 Feedback: 作为检查专家(Expert 2)，我认为Main Model的分析是可信的，理由如下：\n\n- 分析指出用户段落为论文致谢，对口试委员表达感谢，内容为感谢与反思，并未涉及研究过程、方法或数据等学术内容。\n- 相似文献Top 3均为研究方法、数据处理、技术架构等实质性学术内容，与用户段落的表达内容和形式差异明显，没有文字重叠或抄袭倾向。\n- Main Model已明确说明两者内容和表达方式均无直接关联。\n\n可能的遗漏：\n- Main Model未特别提及“致谢”类内容在学术写作中高度通用、表达模式类似，一般不作为查重重点，建议补充说明这一点，以增强分析的全面性和权威性。\n\n总结：Main Model分析可信，无明显遗漏，仅建议补充致谢内容学术查重的常规处理原则。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"用户段落为论文致谢内容，表达感谢口试委员，内容为学术写作中常见的惯用表达。经过多方分析，未发现与相似文献有文字重叠或抄袭倾向。即使致谢用语存在模板化，也属于学术规范允许范围，无需担忧重复。因此，判定应为ACCEPT。\"\n}",
        "plagiarism_confidence": 1,
        "plagiarism_percentage": 0,
        "plagiarism_snippet": [],
        "verdict": "ACCEPT"
    },
    {
        "top_docs_info": [
            {
                "content": "高階主管(師傅)的支持 師傅在使用社群軟體前就高度支持本案的推行，在起初的說明會與專家訪談都高 度參與配合，也在過程中提供許多對於社團的期待以及希望進行的方向。因為師父的 高度支持，並且願意出資購買期刊，讓在專案執行的過程中都可以得到學員的支持而 順利推動與進行。就如Kram(1985)提出的觀點所說，師傅扮演著這種以身作則的楷 模角色，對徒弟們起了很好的示範效果。 社群網站內容與工作有高度相關 在社團建立的初期，一開始就規劃要將有關於牙技技術方面的工作所需知識放到 上團上，並且會建立說明與使用方式。在工作流程與注意事項部分，會以圖示或是標 記等方式來讓學徒更容易注意到重點部分。也因為上傳的內容與學徒本身工作有高度 相關性，便會吸引學徒們上去觀看，時間久了就會養成自行上網尋求答案的習慣。 須由領導者帶領使用 在社團建立的初期，學員們使用意願並不高，需要有人來帶領或是推廣，因此在 使用社團的初期，大多數的文章都是師傅與研究者合力發布的，並透過實作期間宣傳 社團的功能，請學徒可以自行去社團尋求解答，以便提高學徒們的使用率。當學徒們 漸漸習慣使用社團學習後，便會開始在社團裡發布文章或是問題尋求解惑，也能跟師 父參與討論。 需要文章審核機制與管理者的設置 在社團建立的初期並未想過要使用審核機制，因為認為這些有關於牙技的文章都 是有助於學徒們學習的。但在第一次訪談調查時有學徒提出了社團內文章的正確性是 否能信任，這才發現文章審核機制的必要性。如果沒有審核機制可能會導致學徒們不 相信文章上的正確性以致於降低使用意願。審核機制對於企業內使用社群網路系統的 以社會認知理論及社群網路技術建構牙體技術所認知師徒制教育訓練之研究 確是相當重要的一環，尤其是在教育訓練上，最重視的就是知識的正確性，對於錯誤 知識的容許度非常低。因此請師傅擔任管理者並審核文章的正確性。 照片或影片中，有註解說明更能提高學習者理解 在第一次評測前的所有照片或影片中，鮮少有註解或是標記來提醒學習者，因此 學徒們無法找出重點所在，以至於只能盲目觀看。因此強烈建議需要增加註解或是重 點提醒等標記，讓學習者們能更快掌握住重點所在，也能給予學習者們強烈的印象。 現在使用系統與過去沒使用系統的比較與差異以及造成差異的原因 師傅提到”因為影片能隨時觀看，如果你剛好遇到沒有常做的剛好忘記怎麼做， 那就可以再看一下影片大概了解整個步驟，然後再自己實際做，因為每個case 都長 得不一樣，也能做個差異性的比較，可以加深自己的印象”。透過可以隨時上社團看 影片與文章，可以隨時知道重點部分或注意事項，以前只有口頭講解，讓學習者不容 易吸收理解，做出來的成品跟實際講解上有出入，往往會一直詢問，這樣不但無法培 養如何自己解決問題以及讓師傅們工作更加繁忙，加上以前大部分都只有成品的圖片， 大部分的製作流程都用口頭敘述，因此時常會讓學習者忘記步驟或是重點處。因此投 入系統後希望學習者們能自行上社團尋求解答來培養自我解決問題的能力，這樣也能 加深學習的印象。因為這些影片就像是在複習以前教過的東西，只是會跟學校教的不 太一樣，臨床上的案例多就必須常常去看各種影片講解，一直去複習熟悉他的步驟。 提升學習者對於工作的了解 在社團啟用初期有明確告知牙技所內的所有實習學徒有建置Facebook 社團，跟 工作有相關的一切知識、步驟、流程與文件都能在社團中找到。而且會定期新增相關 文章與資深員工的經驗分享。尤其經驗分享這區塊，可以發現學徒們與師傅間的互動 關係逐漸加深，雙方互相討論與知識分享，讓學徒們更加了解自己的工作。師傅也提 到”學徒們從社團上可以了解到自己本身應負的責任，並且樂於分享討論，這是非常 樂見的。”學徒們也說”社團上的內容對於我了解工作是有幫助的，而且還能了時常 以社會認知理論及社群網路技術建構牙體技術所認知師徒制教育訓練之研究 與其他人討論各種案例，讓我知道很多不同的東西”。從師父與學徒給予的回饋，都 肯定了Facebook 社團建立對於新人的幫助。",
                "cross_score": 0.002690495690330863,
                "embedding_sim": 0.8572067022323608,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/ccu/583.txt"
            },
            {
                "content": "所謂的導言，位置在新聞文章的的第一段，且多被要求以5w1h 要素撰寫出新聞的 重點資訊，以精簡的筆法寫出吸引讀者的短文，在新聞文章裡佔有重要的地位 (石麗東, 1991; 陳萬達, 2008)。而5w1h 在傳統的新聞學上有著相當重要的地位，為新聞撰寫的主 體，用來幫助傳達新聞的六個重要的要素，包括事件時間、事件地點、事件原因、事件 本身、事件人物以及事件手法 (Porter, 2010)，不管是中文還是英文，有許多研究專注在 新聞的5w1h 要素抽取，目的是提供讀者精確而重要的訊息，以及避免資訊過載(Khodra, 2015; Nurdin & Maulidevi, 2018; Wang, 2012; Wang, Zhao, Zou, Wang, & Zheng, 2010)。 另外在新聞報導有著豐富經驗的石麗東學者，有過一部重要著作「當代新聞報導」， 被許多台灣名校當作專業教科書，在其書中寫到導言的重要功能，第一個是提供摘要， 再來則是吸引讀者注意，也因此非常注重各種寫作手法 (石麗東, 1991)。因而瞭解到雖 然導言跟摘要非常相似，最大的不同在於要依據寫作手法去吸引讀者。 在導言種類方面，可區分為硬式新聞導言(hard news leads)和軟式新聞導言(soft news leads)兩種大類。硬性新聞導言，也被稱做摘要性導言(summary leads)，目的是在短小的 精簡的篇幅中去提供新聞的本體資訊，包括該地點、時間、事件、人物、發生原因，以 及怎麼發生等資訊，也就是要寫出所謂的5w1h。而軟性導言又稱為新奇導言、延遲導 言，不像硬性新聞導言那樣注重寫出新聞重點，而是使用一些新奇懸疑的手法去讓讀者 注意，並使他們繼續往下閱讀 (廖柏森, 2014)。 由以上可整理出，導言有著幾種特性，分別為摘要性，需要提供5w1h 重點資訊給 讀者，在硬式新聞導言尤其重要；重要性，導言在文章的第一段，包含了新聞的重要資 訊且需要吸引讀者目光；多樣性，用多樣的寫作手法使得導言不單調，更能引起讀者興 趣。 本研究也基於導言的這些特性提出幾個研究問題，第一個問題為導言與摘要相當相 似，同樣具有簡短並快速讓讀者瞭解文章內容的特性，且同樣需要耗費大量人力去撰寫， 目前文本摘要有許多的應用，自動產生新聞標題是其中之一，其餘相關研究包括幫助產 生重點新聞、手機簡訊新聞自動摘要等等(曾元顯, 2004)，這些應用的目的都有一個共通 點，就是幫助讀者快速瞭解文章重點、篩選訊息，以及減少撰寫摘要的人力，那為何不 將這些自動產生摘要的技術應用在導言上，去滿足導言的摘要性。 第二個問題則是，由於導言的重要性，記者在撰寫時勢必得多花心思，避免撰寫出 資訊錯誤或是缺失的導言，若是能從新聞抽取出完整的5w1h 資訊並產生導言，能解決 這方面的問題，確保新聞擁有5w1h 重要資訊。 第三個問題是，儘管新聞摘要的相關研究很多，有利用演算法去計算關鍵詞 (Mihalcea & Tarau, 2004)、重要語句或者利用監督式學習方式(Nallapati, Zhou, Gulcehre, & Xiang, 2016) 去模仿人工撰寫，但都聚焦於摘要內容的精確，較不注重寫作手法。",
                "cross_score": 0.0014814190799370408,
                "embedding_sim": 0.8572007417678833,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/ncu_2020/308.txt"
            },
            {
                "content": "將產生的各種類型導言與原文的新聞導言進行比較，得到各自的Rouge 值以及最後 的平均值，使用F-measure 來呈現結果，另外將TextRank 、以及本研究公式 (TextRank+Word2Vec、標題重疊率、句子位置、句子長度)去提取前三高分句子做為摘要， 並與原文的新聞導言做比較，得到如下表4.17，而軟式導言通常包含很少新聞內容，目 的是吸引讀者興趣，而不是提供摘要，故不進行Rouge 值評分。 觀察表4.17 得知，本研究藉由抽取導言及特徵，來產生導言，同樣是抽取原文句子， 比起TextRank 來說Rouge-1 和Rouge-L 都有提升，但在Rouge-2 也就是流暢度來說卻 是下降的，可能是因為5w1h 組合方面不夠通順，以及5w1h 抽取成功率不夠高；另一 方面，單純使用本研究改進的公式，結合了TextRank+Word2Vec，以及考量標題、句子 長度、句子位置，能夠提升尋找到主題句子的機率，比起單純的TextRank 來說效果是較 好的。 表 4.17 各類型導言Rouge 值評分表 導言類型 Rouge-1 Rouge-2 Rouge-L 敘述式導言 0.3434 0.0618 0.2222 引語式導言 0.3333 0.1129 0.1904 描寫式導言 0.4171 0.1513 0.2245 提問式導言 0.2365 0.0652 0.1935 評議式導言 0.4065 0.1487 0.2601 結論式導言 0.2471 0.0459 0.2022 對比式導言 0.3267 0.1192 0.2745 導言平均 0.3300 0.1007 0.2239 TextRank 摘要 0.2896 0.1055 0.1793 本研究公式提取摘要 0.3015 0.1102 0.1956 第五章、結論 本章為依據研究結果整理出來的結論，並就研究限制及未來方向做探討。",
                "cross_score": 0.0006497951690107584,
                "embedding_sim": 0.8577189445495605,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/ncu_2020/328.txt"
            }
        ],
        "main_analysis": "经比对，用户段落与提供的最相似文献段落之间没有发现明显的文字重叠，也不存在抄袭倾向。用户段落为个人致谢，内容为感谢实验室成员的帮助，与文献中关于社群、新闻导言等内容在主题和表达上均无重合。判定为无抄袭。",
        "feedbacks": [
            "Expert 1 Feedback: 审阅意见（Expert 1）：\n\nMain Model的分析基本可信，理由如下：\n\n- 用户段落为个人致谢，内容主要是感谢实验室成员的帮助，属常见学术写作格式；\n- 相似文献Top 3均为与社群、新闻写作、教育训练相关的学术内容，主题和表达方式与用户段落无明显重合；\n- 经比对，确实不存在明显的文字抄袭或高度重合。\n\n补充意见：\n\n- Main Model仅从“文字重叠”与“主题表达”角度判断无抄袭，未提及“结构性抄袭”或“思想抄袭”。不过，鉴于致谢内容普遍性强，结构和思想重复不构成学术不端。\n- 未提及“自我抄袭”问题，但从段落内容看，不涉及此情形。\n- 建议补充说明：用户致谢段落的写作形式在学术界极为常见，类似表述在不同论文中普遍存在，难以认定为抄袭。\n\n结论：Main Model分析可信，未有明显遗漏，建议补充对致谢类文本的通用性说明。",
            "Expert 2 Feedback: 作为检查专家(Expert 2)，对Main Model的分析进行复核，结论如下：\n\n1. 分析可信度：\nMain Model指出用户段落为个人致谢内容，表达对实验室成员的感谢，与相似文献内容（主要涉及社群、新闻导言、教育训练等）在主题和表达上均无重合，也未发现明显文字重叠或抄袭倾向。这一判断是准确且可信的。用户段落属于常见的论文致谢用语，未见学术不端行为。\n\n2. 是否有遗漏：\nMain Model的分析已涵盖主要比对角度，包括文字重合、主题相关性和表达方式。没有遗漏重要的抄袭风险点。若要进一步完善，可说明致谢类内容本身极少涉及创新性表达，因此更不易构成抄袭嫌疑。\n\n结论：  \nMain Model分析可信，无明显遗漏，判断准确。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"用户段落为常见的学术致谢内容，表达感谢实验室成员的帮助，属于高度通用且模板化的写作方式。经比对，无与相关文献的文字重叠或主题表达上的重合，不存在抄袭嫌疑。两位专家意见与Main Model分析一致，均认为无遗漏和学术不端风险。因此，判定为可接受。\"\n}",
        "plagiarism_confidence": 0,
        "plagiarism_percentage": 0,
        "plagiarism_snippet": [],
        "verdict": "ACCEPT"
    },
    {
        "top_docs_info": [
            {
                "content": "本研究流程分為三大階段，如圖1 所示。首先經由資料蒐集及閱讀相關理論與文 獻，與指導教授討論並確認研究的方向，然後釐清研究背景與動機，從而產生研究目 的與問題。接著開始蒐集國內外相關文獻，經過研讀探討後，將所需內容與理論整理 分析及確認研究所欲探討之模型及變數，然後建立研究架構與推導假說。針對模型內 各項變數依參考文獻進行操作型定義與衡量問項，然後以本研究情境進行問卷內容設 計，問卷初稿完成後邀請專家學者審視問卷內容並依其建議修改，接著請同學幫忙前 測作業，最後以網路問卷方式進行調查及後續的回收。問卷回收後剔除無效問卷，接 著使用統計方法及軟體進行分析，之後根據統計分析的結果，驗證假說是否成立並解 釋所得結果，再依據研究發現提出學術及實務之意涵與建議。最後，說明研究遭遇到 的限制及提出未來可能的研究方向。 影響使用行動支付意圖之因素研究-整合科技接受模式觀點 圖 1 研究流程圖 資料來源：本研究整理",
                "cross_score": 0.0003862592566292733,
                "embedding_sim": 0.8542660474777222,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/ccu/134.txt"
            },
            {
                "content": "大數據的趨勢與資訊科技的進步，使得機器學習的成為產業、政 府、學術界爭相投入資源的目標，各式的機器學習產出成果亦如雨後 春筍般出現。然而，由於應用機器學習時，須具備一定之數理統計及 程式設計能力，造成非資訊工程科學相關之人員望而卻步，而使得其 在推廣的過程深受阻礙。 為降低非資訊工程科學相關之分析人員能快速進入機器學習之 領域，並有效率地完成一系列之資料分析流程，故透過建置一套視覺 化之資料分析系統，供使用者操作及運用。該資料分析系統以網頁作 為其操作與資訊呈現之介面，底下是以C#、PosgreSQL 及各式API 來 進行資料的處理、儲存、串連，最後是以Python 此程式語言來進行 資料之分析。 藉由操作該系統，分析人員可透過直覺化及視覺化的操作，完成 資料分析所須完成的各個階段，包含資料匯入、資料前處理、變數篩 選、確定訓練及測試集比例、選擇分析模型、分析成果產出等。此外， 在各個分析階段時，使用者可依其資料狀況及分析目的，進行適當的 處理及參數調整，以達到更佳之分析成果。 故，本研究所提出之系統概可完成下列三項之效益： (1) 提供非資訊科學相關分析人員，可快速且直覺地進行資料的匯 入、處理、訓練及測試等活動，亦可協助其有效地完成模型建 立及資料預測等目標，以加快決策制訂的效率及改善決策品 質。 (2) 協助機器學習資料分析入門使用者瞭解機器學習的執行階段， 以及每一階段中可調整之參數，以使其掌握未來的學習方向及 對應之預期成果，進而提升學習之效率與品質。 (3) 提出一個Python 與其他電腦程式語言串接的解決方法，以提 高該系統之可移植性與可延展性，讓Python 強大分析數據的 能力得以被更有效地利用與推行。",
                "cross_score": 0.0003583864017855376,
                "embedding_sim": 0.8502234816551208,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/nycu/69.txt"
            },
            {
                "content": "在整個文獻回顧的部分，我們分為2.1 區塊鏈的智慧化和2.2 評分機制的優化做論 文探討。 從以上的文獻回顧內容我們可以知道因為區塊鏈為最新發展的技術，因此本來在區 塊鏈所研究的論文就比較少，而在既有的區塊鏈研究論文中，又有許多為「概念式」的 論文，也就是並沒有實作內容，而只有提出想法，更不用說是在做區塊鏈智慧化這一塊， 屈指可數。而在評分機制的優化當中，我們可以發現大多數的論文偏向於預測及分群， 優化的論文相對較少。 本研究主要是想要讓區塊鏈智慧化，並在區塊鏈上實作評分的優化來讓區塊鏈的使 用者更為方便，從文獻回顧中我們可以發現，現在並沒有類似的研究，光是在區塊鏈或 是評分優化的論文中就已不多，何況是將兩個領域作合併研究，再加上區塊鏈及評分優 化是現在最熱門的議題，也是大家最想要研究的領域，因此本篇論文將會是第一篇兩個 領域作合併並實作的研究，希望能藉由在各領域的研究中得到許多參考方法，加強研究 的深度及廣度，並能帶給以後想要研究區塊鏈智慧化的學者們一些靈感。 第三章 研究方法與步驟",
                "cross_score": 0.0003217505000066012,
                "embedding_sim": 0.8519107103347778,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/nycu/849.txt"
            }
        ],
        "main_analysis": "经检查，用户段落与提供的三段最相似文献内容无文字重叠，且内容完全不同。用户段落为论文致谢用语，未涉及学术观点或专业内容，不存在抄袭倾向。",
        "feedbacks": [
            "Expert 1 Feedback: 作为检查专家（Expert 1），我的简要意见如下：\n\nMain Model的分析基本可信。理由如下：\n\n- 用户段落为典型的论文致谢用语，内容为感谢家人与亲友的支持和陪伴，未涉及任何学术观点、研究内容或专业知识。\n- 经与提供的三篇相似文献对比，无任何文字重叠或内容相似之处，三篇文献内容均为学术研究方法、理论综述或技术讨论，与致谢段落无关。\n- Main Model明确指出“未涉及学术观点或专业内容，不存在抄袭倾向”，判断合理。\n\n是否有遗漏：\n- 未见明显遗漏。由于致谢内容属于惯用语句，且未涉及研究实质内容，常见于学位论文，通常不构成学术不端。\n- 仅可补充说明：如有大量致谢内容高度雷同于某特定论文，可进一步留意是否为模板化使用，但本案例无此情形。\n\n结论：  \nMain Model分析可信，无明显遗漏。",
            "Expert 2 Feedback: 作为检查专家(Expert 2)，我的审阅意见如下：\n\nMain Model 的分析基本可信。理由如下：\n\n- 用户段落确实为论文常见的致谢语，内容为感谢家人、亲友支持，与学术研究内容、理论、数据等无关。\n- Main Model 检查了与三篇最相似文献的内容，无文字重叠，内容也完全不同，且用户段落未出现学术观点或专业内容。\n\n未见明显遗漏。补充建议：\n\n- 致谢内容一般不作为查重或学术不端的重点对象，Main Model 已准确指出无抄袭倾向。\n- 若需更严谨，可提及：即使与他人致谢用语有高度相似，也通常不影响学术诚信认定。\n\n结论：Main Model 分析可信，无明显遗漏。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"用户段落为论文常见的致谢语句，内容仅为感谢家人与亲友的支持与陪伴，并未涉及学术观点、专业内容或研究成果。经比对无文字重叠或内容相似，且致谢段落通常不作为学术不端查重重点对象。因此不存在抄袭或不确定情形。\"\n}",
        "plagiarism_confidence": 0,
        "plagiarism_percentage": 0,
        "plagiarism_snippet": [],
        "verdict": "ACCEPT"
    },
    {
        "top_docs_info": [
            {
                "content": "我們利用兩種不同的系統追蹤觸控筆。當接近平板時，大約在1.5 公分之內，觸控 筆的位置以及朝向可以從磁鐵的感測器偵測到。我們藉由呼叫Wacom 的API 獲得資 訊。在這個情況下，由於筆的追蹤位置的精準度很高，所以得到的視覺及觸覺的感知是 完美吻合的。然而如果不是這個情況，觸控筆的位置將會由手腕的位置及一些假設得到。 我們假設當受測者將他們的右手移動到下一個筆劃的開始位置時，他們手腕的移動是很 小的。因此我們紀錄觸控筆最後離開Wacom 平板偵測時，其與手腕的相對位置及朝向， 換句話說，受測者在現實或虛擬中感知到的觸控筆及手腕的移動可能會不同。但是很幸 運的，在書寫動作中，在空中手腕劇烈的移動並不常見。在實驗開始前，我們也要求受 測者避免這些動作。 在這兩個追蹤方法間的轉換有可能會造成一些動作上的不連續。這經常會發生，因 為當受測者將右手由空中移動到繪圖板時，系統將接收到來自繪圖板的資訊而瞬間改變 觸控筆的朝向及位置。但一般而言，如果受測者在實驗中維持他們手腕及手指的動作， 這個不連續的動作應該不明顯。在另一方面，當受測者將他們的右手從Wacom 平板的 偵測區域中移開時，由於虛擬的觸控筆保持著最後在Wacom 平板上的朝向及與手腕的 相對位置，這個不連續性並不會被使用者察覺。因為這個現象是很難由影像呈現的，我 們建議讀者參考我們附上的影片觀察這個不連續的現象。 四、實驗研究 為了瞭解在虛擬實境及現實環境中對於精密動作的控制，我們設計了許多關於寫字 及繪圖的任務並要求受測者在四個不同的條件下完成這些任務。這些條件是VR+Body, VR-Body, IPad 及Paper,其中”+”代表擁有，”-”代表沒有的縮寫。考慮到實驗時間長、頭 戴顯示器的重量及在虛擬實境中常發生的數碼動暈症，我們決定採用組間設計的方式進 行實驗。每個使用者必須完成VR+Body, VR-Body, IPad 這三種條件的其中之一，再加 上Paper 的條件。我們決定採用這個實驗的方法是因為人們已經相當習慣在紙上書寫及 繪圖。所以在Paper 條件上的成果可以視為一個最高的標準以評量數位設備是否幫助或 妨礙書寫及繪圖的表現。",
                "cross_score": 0.4629094898700714,
                "embedding_sim": 0.8711272478103638,
                "overlaps": [
                    "虛擬實境",
                    "虛擬實境中"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/428.txt"
            },
            {
                "content": "行動式VR（Mobile VR, 行動VR），由歷史上的演進來看，運算裝置由固定 式往行動式裝置演進，主要是符合人類對自由的渴望，無拘無束脫離各式各樣的 羈絆，希望在無受限或限制最小的狀況下，完成對設計的目標和相關之工作，就 算是運算能力的高低，目前有所區隔，固定式運算裝置，相較於空間極度縮小化 的行動運算裝置如平板電腦和智慧型行動電話，運算能力上雖然實際的運算能量 還是固定式運算裝置較高，但無法滿足人類愛好自由天性，雖然目前行動運算裝 置的運算能力較弱於固定式運算裝置，但因為滿足人的自由需求，對於運算裝置 的選擇，智慧型手機的銷售量已經超過電腦足可見端倪，可知就算裝置的運算能 力再高也需要符合目標對象的真正需求，才能在商務運作上立足，協助企業獲利。 由於VR 目標在於人的大腦信不信得過，所以很多VR 顯示方式被開發出來， 相對於由傳統顯示模式而來的主機固定式VR（顯示方式常由兩片獨立的小型顯示 器置於頭盔或眼鏡設備內，達到主動顯影、快速反應地顯示VR 繪圖產生出所需之 左右眼影像），讓人眼信以為真，騙過大腦，但相對而言，帶了主機固定式的VR 頭盔或眼鏡也就限制閱聽眾之「活動範圍」和「行動姿態」，有時對於使用較不 便利的閱聽眾（例如：病患，若要對其施以衛生教育），其姿態可能呈現坐姿或 臥姿，並無法久站來使用主機固定式的VR，此時可移動式的VR 顯示裝置成為首 要目標，而目前常見的智慧型行動電話（智慧型手機），更是成為絕佳之行動VR 顯示裝置。 為了讓智慧型手機配置VR 效果，設計者把原本需要真實兩片獨立置於頭盔和 眼鏡內的小型顯示器，透過軟體程式的設定，將智慧型手機的螢幕切割為左右兩 邊，由設定的程式讓左右兩邊顯示內容相同、但不同角度的VR 顯示所需之左右眼 影像，藉由運算日益快速的智慧型手機之處理器和顯示控制器，達到如同主機式 VR 般快速反應地顯示VR 繪圖產生出所需的左右眼影像，讓人眼信以為真，以求 騙過人的大腦；此種純粹藉由智慧型手機和固定手機的頭盔之組成，即稱為：行 動式VR（行動VR），其中最受注目且廣為人知，即為Google 的Cardboard［52 ］、Daydream［26］（第二代Cardboard）和Samsung Gear［53］的VR。 Google Cardboard 是Google I/O 2014 推出的VR 頭戴式顯示器，憑著價廉（約 15 美元），並於許多活動場合採贈送方式推廣。Google Cardboard 推出至今僅有近 3 年時間，依據2017 年2 月28 日Google 公布資訊，發貨量突破1000 萬，應用程 式下載量超過1.6 億次［24］。Cardboard 的成功說服Google 開發更先進之虛擬現 實硬體並任命新的虛擬現實主管［25］。2016 年5 月18 日，Google 在I/O 大會上 公布了名為Daydream 的增強型VR 平台［26］。 VR行動化與傳統上的區別，其差別最大點在於VR行動化是應用智慧型手機、 行動式裝置盛行之後的處理器與感測器等硬體裝置，以及可視覺化的軟體之後， 開始大行其道與發展興起；如同傳統上電腦PC 運算輸出模式，其結果將訊號同步 輸出於VR 眼鏡內置的左右兩副小螢幕之畫面中；但是，行動VR 較之目前的固定 式VR，雖處於應用簡易的Google Cardboard 頭盔裝置投影放大其手機畫面，並利 用軟體功能將之強制區分左右兩個手機小畫面來顯示，如果依硬體規格來衡量， 其效果似不及於固定式桌機強大運算之後的解析度，以及畫面切換速度的暢快度 相比，相較下似乎無法匹及；但因智慧型手機的行動便利性，雖解析度本來設計 適用於小螢幕，本就不高，但是經由和眼球至頭盔的超近距離，透過視覺距離的 拉近，如此讓解析度的差異極小化，因此行動VR 在此套應用上變得可行，如此傳 統的VR 在面向行動化趨勢後，已經大致上轉移至行動VR 裝置。處於如此的行動 應用下，其主要有兩個行動VR 主要的技術來源：一個是Google 的Cardboard 或 其舒適款類似「增強式Cardboard 頭盔裝置」，以及Samsung 的Gear VR 等。",
                "cross_score": 0.35553717613220215,
                "embedding_sim": 0.8683681488037109,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/nycu/805.txt"
            },
            {
                "content": "我們利用Unity 遊戲引擎實作了一個能在虛擬實境及數位設備中進行實驗的系統。 在數位設備及虛擬實境上執行的程式，除了在虛擬實境中需要顯示場景及人物外，其餘 是相同的。系統一一的顯示每個任務，並記錄受測者的每一個筆劃及完成任務所需的時 間。在使用傳統設備進行實驗上，我們替每個受測者影印需要執行的任務，以便受測者 書寫及繪圖，並將掃描得到的結果作為分析的用途，我們利用人工的方式記錄受測者完 成這些任務所需的時間。考量到實驗必須分別在數位設備及傳統設備上進行，為了能進 行有效的分析，我們使用物理坐標系測量誤差。舉例來說：所有設備的書寫區域皆被定 義在25.3 x 15.8 公分，觸控筆的筆觸則是設定為0.05 公分寬。 為了提供受測者在虛擬實境中體感的回饋，我們在現實環境中擺設了一張桌子及椅 子，並在桌子上放置一個Wacom 平版。受測者坐在椅子上使用Wacom 觸控筆進行寫 字及繪圖的任務。我們利用HTC Vive 的手把進行椅子及平板在現實中位置的定位。虛 擬實境中椅子、平板的位置及朝向將會由現實中固定好的位置決定。另外，在實驗進行 Fig. 3 在實驗前，我們會依據實驗條件，將Wacom 平板(左)、IPad(中)及紙張(右)放置於固定的位 置，以確保受測者在實驗時姿勢是不變的。 中，我們需要動態的追蹤受測者上半身身體及繪圖筆。在受測者擁有等身虛擬人物的實 驗條件中，等身的虛擬人物及虛擬的觸控筆將在虛擬實境中顯示出來，當在受測者沒有 等身虛擬人物的實驗條件中，我們只顯示虛擬的觸控筆。在兩種實驗條件之中，因為這 些追蹤器有一定重量，為了維持實驗的一致性，受測者必須將追蹤器穿戴在身上。唯一 的差別只在於對等身虛擬人物的感知與否。這樣的設定能讓我們專注於在虛擬實境中與 虛擬人物互動的效果。",
                "cross_score": 0.28645026683807373,
                "embedding_sim": 0.8679285049438477,
                "overlaps": [
                    "虛擬實境",
                    "虛擬實境中"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/426.txt"
            }
        ],
        "main_analysis": "经查验，用户段落与提供的三段最相似文献内容不存在明显文字重叠或直接抄袭现象。用户段落为对VR/AR发展、手势识别技术现状及挑战的概括性描述，未见与文献段落的句式、用词有高度一致，内容也较为通用。整体来看，无抄袭倾向。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析总体可信。其指出用户段落为对VR/AR发展与手势识别技术现状的通用性描述，未见与三段相似文献有明显文字重叠或抄袭，且内容无高度一致，结论为“无抄袭倾向”，这是合理的判断。\n\n可能遗漏之处：\n1. 语义层面：虽然未有直接文字重叠，但Main Model分析未提及是否存在“结构性抄袭”或“观点抄袭”，即用户段落是否在表达思路、论述结构等方面高度模仿了文献。\n2. 共性内容判断：未进一步说明用户段落虽为通用性综述，但是否完全脱离特定文献的表述，还是与某一文献观点高度重合。\n3. 引用情况：未提示用户段落是否应补充引用以表明其综述性内容参考了哪些文献来源。\n\n总体结论：Main Model的分析可信，未发现明显遗漏，但可进一步加强对“语义抄袭”与“结构性抄袭”的分析，以及建议用户如有参考文献应当加注。",
            "Expert 2 Feedback: Main Model 的分析基本可信，理由如下：\n\n- 其指出用户段落为对VR/AR技术发展及手势识别挑战的通用性描述，未见与三段相似文献有明显文字重叠或高度相似的句式/用词，这一判断是准确的。\n- 三篇相似文献的内容更偏向于具体系统、实验设计或移动VR的发展史，与用户段落的概述性内容确实没有直接重合。\n\n可能的遗漏：\n\n- Main Model 只判断了“直接抄袭/文字重叠”，但未提及“观点窃用”或“结构性抄袭”。用户段落虽然未直接抄袭，但其表达的技术难题和研究意义与相关领域文献高度一致，若用于学术写作，建议补充适当引用，说明信息来源。\n- 未分析用户段落是否有用过特定领域常见但未注明出处的术语或观点，尤其是“仅用单一摄像机获取手部信息”作为研究热点，这一表述是否为常识性描述或特定文献中的表述，Main Model 未加说明。\n\n结论：\nMain Model 的分析基本可信，无明显遗漏重大问题，但建议进一步提醒用户补充引用，以避免潜在的“观点未标注来源”的学术不规范风险。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"用户段落为对VR/AR及手势识别领域现状的通用性综述，未与比对文献存在明显文字重叠或直接抄袭，且内容表达属于领域常见表述，无具体可判定的观点或结构性抄袭证据。尽管专家建议学术写作应补充引用，但当前证据不足以怀疑抄袭或不确定，故可接受。\"\n}",
        "plagiarism_confidence": 37,
        "plagiarism_percentage": 15,
        "plagiarism_snippet": [
            "近年來虛擬實境(VR)及擴增實境(AR)的技術蓬勃發展,人機互動的方式上也更加多元且人性化,與此相關之應用、遊戲與日俱增。",
            "然而若要能精確的操縱虛擬實境中的各種物件,仍然需要依靠手把、手套等相關設備,大大降低使用上的便利程度以及使用者體驗,因此如何不借助任何特殊設備,僅從單一攝影機所錄製的影像中,獲取手部的相關資訊(手勢、動作...等),一直以來都是一個重要的課題。"
        ],
        "verdict": "ACCEPT"
    },
    {
        "top_docs_info": [
            {
                "content": "本論文以一般攝影機做為使用平台，結合神經網路與手部模型，建立手部姿勢估 計系統，以多任務學習的方式與手部語意切割系統做整合。並以藉由手掌作為初始值 與修改迭代演算法來改善逆向運動學的收斂狀況。圖1 為本論文所提出系統的實際估 測結果。整體來說，本論文的主要貢獻有二： 一、設計實作一個關鍵點估計網路，並藉由多任務學習同時提升關鍵點估計以及語意 切割兩者的準確度。 二、提出以神經網路估計手掌方向來做為初始值，改善迭代的結果。 圖1、實際估測結果。左邊為輸入影像、標上估測出來的手指關鍵點，右邊為根據估測出來的 參數所繪製的3D 手模型。",
                "cross_score": 0.4054238200187683,
                "embedding_sim": 0.9232867360115051,
                "overlaps": [
                    "手部語意切割系統",
                    "以藉由手",
                    "神經網路"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/1.txt"
            },
            {
                "content": "本論文研究目標為以單一相機做為使用平台的手部姿勢(hand pose)估計，本論文系 統以一般低價網路攝影機拍攝的彩色影像作為輸入，主要輸出為相對於手掌心的3D 關 鍵點位置(也就是3D 坐標的原點是定位於掌心，而坐標的X, Y, Z 方向在第4.3 節會再 說明)、以及2D 手部關鍵點位置。此處2D 關鍵點是指手部關鍵點在影像中的位置，因 為我們假設了一個3D 的手部模型，即使只用單一攝影機以及2D 的關鍵點也可大約推 算出3D 的手部關鍵點坐標。手部關鍵點指的是手掌的中心、手指關節、手指指尖共 21 點，請參考圖14。而手部3D 關鍵點通常被稱為手部姿勢。 圖14、手部關鍵點示意圖，紅點為手部關鍵點位置 本論文最終選擇以Panteleris 等人所設計的系統作為基礎的系統架構[15]，在此架 構上最需要改進的地方有兩個，第一是手部關鍵點位置的正確性，第二是逆向運動學 中最佳化演算法的收斂結果正確度。本論文主要針對此二問題做改進。",
                "cross_score": 0.16099025309085846,
                "embedding_sim": 0.9034209251403809,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/nycu/14.txt"
            },
            {
                "content": "在過去基於深度影像進行手部姿勢估測方法中，大多數研究皆搭配手部模型進 行，透過尋找手部模型參數，使手部模型的深度資訊與深度圖像相似，通常透過迭代 最佳化演算法求解，如PSO[20]。而近期的研究，則多以神經網路估計3D 關鍵點位置 [23][24]。Wan 等人提出讓卷積神經網路同時估計2D、3D 關鍵點以及單位向量場(指向 手指頭)，藉此提升精確度的方法[23]。Ge 等人則提出使用3D 卷積神經網路來估計3D 關鍵點位置的機制[24]。",
                "cross_score": 0.08860570937395096,
                "embedding_sim": 0.923132598400116,
                "overlaps": [
                    "卷積神經網路"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/3.txt"
            }
        ],
        "main_analysis": "经检查，用户段落与最相似文献段落之间没有出现大段文字重叠，表述方式和内容结构也有明显差异。虽然主题相关、部分术语（如“手部關鍵點”、“卷積神經網路”等）一致，但属于该领域常见表达，并未发现抄袭倾向。整体来看，用户段落为自行撰写，未直接抄袭文献内容。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析总体上是可信的。其理由如下：\n\n- 分析指出用户段落与相似文献在内容结构和表述上有明显差异，未出现大段文字重叠，仅有部分专业术语重合，这属于学科常用表达。\n- 分析结论“未发现抄袭倾向，整体为自行撰写”有充分依据，用户段落内容与引用文献相比有较明显的原创性。\n\n可能的遗漏：\n\n- Main Model未具体指出用户段落与相似文献之间在细节内容（如技术路线、方法描述等）上的异同，仅做了总体判断，若能举例说明差异会更有说服力。\n- 分析未提及用户段落对前人工作的引用和表述是否规范（比如是否适当引用[27][31]），这一点在学术规范检查中也较重要。\n\n结论：Main Model分析可信，但可补充更具体的差异举证及学术规范性检查。",
            "Expert 2 Feedback: 作为检查专家(Expert 2)，我认为Main Model的分析总体可信，理由如下：\n\n- 分析明确指出用户段落与相似文献在表达、内容结构上存在明显差异，没有大段文字重叠。\n- 针对术语相同的部分，分析也说明这些是领域常见表达，不构成抄袭。\n\n但分析略有遗漏，建议补充如下：\n\n1. **参考文献引用核查未提及**：用户段落中有[27][31]等引用，分析未核查这些引用是否真实、与内容是否相符，建议确认引用的准确性和完整性。\n2. **技术内容重合度进一步说明**：虽然表述不同，但用户段落与文献段落在研究目标、方法（如关键点估计、卷积神经网络等）、应用场景有高度相似，建议补充说明“研究思路和方法虽然类似，但未发现直接抄袭，仅为领域常见做法”。\n\n总结：  \nMain Model分析基本可信，但建议在引用核查和技术内容重合度方面做进一步补充和说明，以更全面客观。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"用户段落与相似文献在内容结构和表述上存在明显差异，没有大段文字重叠，术语使用为领域常见表达。虽然专家建议可进一步补充引用核查和技术内容重合度说明，但未发现直接抄袭证据，整体为原创表达，故可接受。\"\n}",
        "plagiarism_confidence": 22,
        "plagiarism_percentage": 9,
        "plagiarism_snippet": [
            "手部語意切割系統",
            "以藉由手",
            "神經網路",
            "卷積神經網路"
        ],
        "verdict": "ACCEPT"
    },
    {
        "top_docs_info": [
            {
                "content": "本論文分成六章，第一章介紹動機與成果。第二章介紹手部姿勢與關鍵點抽取的 相關研究。第三章介紹本論文所提出的系統架構所使用到的技術描述。第四章介紹本 論文系統所針對的問題的明確定義以及如何修改、整合第三章所提到的技術成為最終 的系統架構。第五章描述實驗方式以及結果。第六章則為論文的結論以及未來方向。 第二章、手部姿勢及關鍵點抽取相關研究 手部姿勢估計一直以來都是電腦視覺領域中重要的研究方向之一，目前在此類問 題上，主流方法為藉由神經網路估計關鍵點位置，再以關鍵點資訊推論手部姿勢，因 此本章主要介紹手部姿勢以及關鍵點估計的相關研究。而在關鍵點估計的部分，由於 網路架構設計的相關研究大多都以人體關鍵點做為研究對象，且手部與人體的關鍵點 估計並無太大差異，因此此處以多人體關鍵點估計的相關研究為介紹對象。此外，本 論文最終是利用3D 手部模型做為手部姿勢估測的主要限制條件 (Model-constrained estimation method)，因此本章最後會介紹手部模型的相關研究。",
                "cross_score": 0.9909092783927917,
                "embedding_sim": 0.9096295237541199,
                "overlaps": [
                    "手部姿勢估計"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/2.txt"
            },
            {
                "content": "本論文以一般攝影機做為使用平台，結合神經網路與手部模型，建立手部姿勢估 計系統，以多任務學習的方式與手部語意切割系統做整合。並以藉由手掌作為初始值 與修改迭代演算法來改善逆向運動學的收斂狀況。圖1 為本論文所提出系統的實際估 測結果。整體來說，本論文的主要貢獻有二： 一、設計實作一個關鍵點估計網路，並藉由多任務學習同時提升關鍵點估計以及語意 切割兩者的準確度。 二、提出以神經網路估計手掌方向來做為初始值，改善迭代的結果。 圖1、實際估測結果。左邊為輸入影像、標上估測出來的手指關鍵點，右邊為根據估測出來的 參數所繪製的3D 手模型。",
                "cross_score": 0.9834186434745789,
                "embedding_sim": 0.9096890091896057,
                "overlaps": [
                    "手部姿勢估"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/1.txt"
            },
            {
                "content": "本論文研究目標為以單一相機做為使用平台的手部姿勢(hand pose)估計，本論文系 統以一般低價網路攝影機拍攝的彩色影像作為輸入，主要輸出為相對於手掌心的3D 關 鍵點位置(也就是3D 坐標的原點是定位於掌心，而坐標的X, Y, Z 方向在第4.3 節會再 說明)、以及2D 手部關鍵點位置。此處2D 關鍵點是指手部關鍵點在影像中的位置，因 為我們假設了一個3D 的手部模型，即使只用單一攝影機以及2D 的關鍵點也可大約推 算出3D 的手部關鍵點坐標。手部關鍵點指的是手掌的中心、手指關節、手指指尖共 21 點，請參考圖14。而手部3D 關鍵點通常被稱為手部姿勢。 圖14、手部關鍵點示意圖，紅點為手部關鍵點位置 本論文最終選擇以Panteleris 等人所設計的系統作為基礎的系統架構[15]，在此架 構上最需要改進的地方有兩個，第一是手部關鍵點位置的正確性，第二是逆向運動學 中最佳化演算法的收斂結果正確度。本論文主要針對此二問題做改進。",
                "cross_score": 0.9797592759132385,
                "embedding_sim": 0.9047611355781555,
                "overlaps": [
                    "本論文研究",
                    "手部姿勢"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/14.txt"
            }
        ],
        "main_analysis": "经检查，用户段落与最相似文献段落之间没有明显的文字重叠，表述方式和用词均有差异。虽然主题和研究目标类似，但用户段落是对研究目的的简要说明，并未直接抄袭文献内容。因此，不存在抄袭倾向。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析基本可信，判断了用户段落与相似文献在文字表述和用词上没有明显重叠，且只是简要说明研究目的，没有直接抄袭。但分析略显简略，建议补充以下两点：\n\n1. 可进一步说明用户段落与相似文献在研究目标和背景表述上虽有类似，但没有句子结构或内容直接复制，属于正常学术表达。\n2. 可补充关注“与本实验室之前的研究[31]进行整合”这一句是否有必要对[31]文献做进一步核查，以确保没有遗漏引用或内容重合问题。\n\n综上，Main Model的分析可信，但可进一步细化以更全面覆盖潜在风险点。",
            "Expert 2 Feedback: Main Model的分析基本可信。它准确指出用户段落与相似文献在表述和用词上有明显差异，没有直接抄袭的迹象。用户段落仅为研究目的简述，没有照搬文献内容。\n\n但分析略有遗漏：  \n1. 主题与结构相似性未细致说明。虽然没有文字抄袭，但用户段落在研究动机和目标的描述上与文献主题高度一致，建议补充说明此为学术写作中常见，非抄袭。\n2. 没有提及整合前人系统的表述。用户段落中提及“与本实验室之前的研究[31]整合”，而相似文献也有系统改进和整合内容，建议提醒注意引用和表述方式的规范性，避免误判。\n\n总体结论：分析可信，建议补充对主题重合和引用规范的简要说明。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"用户段落与相似文献在文字表述、用词及句子结构上均无直接重叠，仅为常见的学术研究目的陈述。虽然主题类似，但属于学术写作中的正常现象。关于与实验室前期研究的整合部分已明确引用[31]，未发现遗漏引用或内容重合的直接证据。因此，未发现抄袭或重大不确定性，可予以接受。\"\n}",
        "plagiarism_confidence": 98,
        "plagiarism_percentage": 39,
        "plagiarism_snippet": [
            "手部姿勢估計",
            "手部姿勢估",
            "本論文研究",
            "手部姿勢"
        ],
        "verdict": "ACCEPT"
    },
    {
        "top_docs_info": [
            {
                "content": "本論文以一般攝影機做為使用平台，結合神經網路與手部模型，建立手部姿勢估 計系統，以多任務學習的方式與手部語意切割系統做整合。並以藉由手掌作為初始值 與修改迭代演算法來改善逆向運動學的收斂狀況。圖1 為本論文所提出系統的實際估 測結果。整體來說，本論文的主要貢獻有二： 一、設計實作一個關鍵點估計網路，並藉由多任務學習同時提升關鍵點估計以及語意 切割兩者的準確度。 二、提出以神經網路估計手掌方向來做為初始值，改善迭代的結果。 圖1、實際估測結果。左邊為輸入影像、標上估測出來的手指關鍵點，右邊為根據估測出來的 參數所繪製的3D 手模型。",
                "cross_score": 0.9998973608016968,
                "embedding_sim": 0.9908447265625,
                "overlaps": [
                    "本論文以一般攝影機做為使用平台",
                    "結合神經網路與手部模型",
                    "建立手部姿勢估",
                    "以多任務學習的方式與手部語意切割系統做整合。並以藉由手掌作為初始值 與修改迭代演算法來改善逆向運動學的收斂狀況。圖1",
                    "為本論文所提出系統的實際估",
                    "測結果。整體來說",
                    "本論文的主要貢獻有二",
                    "一、設計實作一個關鍵點估計網路",
                    "並藉由多任務學習同時提升關鍵點估計以及語意",
                    "切割兩者的準確度。",
                    "二、提出以神經網路估計手掌方向來做為初始值",
                    "改善迭代的結果。"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/1.txt"
            },
            {
                "content": "本論文研究目標為以單一相機做為使用平台的手部姿勢(hand pose)估計，本論文系 統以一般低價網路攝影機拍攝的彩色影像作為輸入，主要輸出為相對於手掌心的3D 關 鍵點位置(也就是3D 坐標的原點是定位於掌心，而坐標的X, Y, Z 方向在第4.3 節會再 說明)、以及2D 手部關鍵點位置。此處2D 關鍵點是指手部關鍵點在影像中的位置，因 為我們假設了一個3D 的手部模型，即使只用單一攝影機以及2D 的關鍵點也可大約推 算出3D 的手部關鍵點坐標。手部關鍵點指的是手掌的中心、手指關節、手指指尖共 21 點，請參考圖14。而手部3D 關鍵點通常被稱為手部姿勢。 圖14、手部關鍵點示意圖，紅點為手部關鍵點位置 本論文最終選擇以Panteleris 等人所設計的系統作為基礎的系統架構[15]，在此架 構上最需要改進的地方有兩個，第一是手部關鍵點位置的正確性，第二是逆向運動學 中最佳化演算法的收斂結果正確度。本論文主要針對此二問題做改進。",
                "cross_score": 0.9974374771118164,
                "embedding_sim": 0.9220966100692749,
                "overlaps": [
                    "機做為使用平台",
                    "手部姿勢",
                    "逆向運動學"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/14.txt"
            },
            {
                "content": "本論文分成六章，第一章介紹動機與成果。第二章介紹手部姿勢與關鍵點抽取的 相關研究。第三章介紹本論文所提出的系統架構所使用到的技術描述。第四章介紹本 論文系統所針對的問題的明確定義以及如何修改、整合第三章所提到的技術成為最終 的系統架構。第五章描述實驗方式以及結果。第六章則為論文的結論以及未來方向。 第二章、手部姿勢及關鍵點抽取相關研究 手部姿勢估計一直以來都是電腦視覺領域中重要的研究方向之一，目前在此類問 題上，主流方法為藉由神經網路估計關鍵點位置，再以關鍵點資訊推論手部姿勢，因 此本章主要介紹手部姿勢以及關鍵點估計的相關研究。而在關鍵點估計的部分，由於 網路架構設計的相關研究大多都以人體關鍵點做為研究對象，且手部與人體的關鍵點 估計並無太大差異，因此此處以多人體關鍵點估計的相關研究為介紹對象。此外，本 論文最終是利用3D 手部模型做為手部姿勢估測的主要限制條件 (Model-constrained estimation method)，因此本章最後會介紹手部模型的相關研究。",
                "cross_score": 0.9930375218391418,
                "embedding_sim": 0.9342111349105835,
                "overlaps": [
                    "手部姿勢",
                    "本論文所提出",
                    "神經網路估計"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/2.txt"
            }
        ],
        "main_analysis": "有明显文字重叠，用户段落与最相似文献段落内容几乎完全一致，包括用词、结构和主要表述，仅个别字词有格式差异。这种情况属于高度抄袭倾向。建议用户进行大幅度改写和原创表达。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析是可信的，理由如下：\n\n- 它准确指出用户段落与最相似文献在用词、结构和主要表述上几乎完全一致，仅有细微格式差异，这属于高度重合。\n- 该分析结论“高度抄袭倾向，建议大幅改写和原创表达”是符合学术规范要求的。\n\n是否有遗漏：\n- Main Model的分析已涵盖了主要的相似性问题，没有明显遗漏。它关注了文本重叠和原创性缺失，是检测抄袭时最核心的关注点。\n- 如果需要进一步完善，可以补充具体指出哪些句子或段落完全一致，并说明可能涉及的知识产权/学术诚信风险，但对于一般查重分析来说，已达到要求。\n\n结论：  \nMain Model的分析可信，未见明显遗漏，建议按其意见对文本进行大幅度改写与原创表达。",
            "Expert 2 Feedback: 作为检查专家（Expert 2），根据你提供的资料，Main Model 的分析是可信的，理由如下：\n\n- 明显文字重叠：用户段落与最相似文献的内容高度一致，不仅用词、句式、结构几乎完全相同，仅有极小的格式或个别字词差异。\n- 抄袭倾向明显：这属于标准的“高度抄袭”，不是偶然的表述雷同。\n\n是否有遗漏：\n- Main Model 的分析准确指出了高度抄袭问题，但可以补充说明用户段落几乎是“原文复制粘贴”，原创性极低。\n- 分析中未指出是否对抄袭部分有引用或标注（从段落来看应当没有），可以明确补充“未见适当引用，属于未经授权的抄袭”。\n- Main Model 只建议大幅改写，但可进一步建议用户用自己语言重新阐述研究内容，并进行必要的引用和文献标注。\n\n总结：\nMain Model 的分析可信，基本无遗漏，但可进一步强调未见引用及建议具体的改写和引用方式。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"根据Main Model和两位专家的分析，用户段落与最相似文献存在高度文字重叠和内容一致，属于明显抄袭，且未见适当引用或改写。因此应怀疑有抄袭，不应直接接受。\"\n}",
        "plagiarism_confidence": 100,
        "plagiarism_percentage": 100,
        "plagiarism_snippet": [
            "本論文以一般攝影機做為使用平台",
            "結合神經網路與手部模型",
            "建立手部姿勢估",
            "以多任務學習的方式與手部語意切割系統做整合。並以藉由手掌作為初始值 與修改迭代演算法來改善逆向運動學的收斂狀況。圖1",
            "為本論文所提出系統的實際估",
            "測結果。整體來說",
            "本論文的主要貢獻有二",
            "一、設計實作一個關鍵點估計網路",
            "並藉由多任務學習同時提升關鍵點估計以及語意",
            "切割兩者的準確度。",
            "二、提出以神經網路估計手掌方向來做為初始值",
            "改善迭代的結果。",
            "機做為使用平台",
            "手部姿勢",
            "逆向運動學",
            "本論文所提出",
            "神經網路估計"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "本論文分成六章，第一章介紹動機與成果。第二章介紹手部姿勢與關鍵點抽取的 相關研究。第三章介紹本論文所提出的系統架構所使用到的技術描述。第四章介紹本 論文系統所針對的問題的明確定義以及如何修改、整合第三章所提到的技術成為最終 的系統架構。第五章描述實驗方式以及結果。第六章則為論文的結論以及未來方向。 第二章、手部姿勢及關鍵點抽取相關研究 手部姿勢估計一直以來都是電腦視覺領域中重要的研究方向之一，目前在此類問 題上，主流方法為藉由神經網路估計關鍵點位置，再以關鍵點資訊推論手部姿勢，因 此本章主要介紹手部姿勢以及關鍵點估計的相關研究。而在關鍵點估計的部分，由於 網路架構設計的相關研究大多都以人體關鍵點做為研究對象，且手部與人體的關鍵點 估計並無太大差異，因此此處以多人體關鍵點估計的相關研究為介紹對象。此外，本 論文最終是利用3D 手部模型做為手部姿勢估測的主要限制條件 (Model-constrained estimation method)，因此本章最後會介紹手部模型的相關研究。",
                "cross_score": 0.9700120687484741,
                "embedding_sim": 0.9711213707923889,
                "overlaps": [
                    "本論文分成六章",
                    "第一章介紹動機與成果。第二章介紹手部姿勢與關鍵點抽取的",
                    "相關研究。第三章介紹本論文所提出的系統架構所使用到的技術描述。第四章介紹本",
                    "論文系統所針對的問題的明確定義以及如何修改、整合第三章所提到的技術成為最終",
                    "的系統架構。第五章描述實驗方式以及結果。第六章則為論文的結論以及未來方向。",
                    " 手部姿勢估計一直以來都是電腦視覺領域中重要的研究方向之一",
                    "目前在此類問",
                    "主流方法為藉由神經網路估計關鍵點位置",
                    "再以關鍵點資訊推論手部姿勢",
                    "此本章主要介紹手部姿勢以及關鍵點估計的相關研究。而在關鍵點估計的部分",
                    "網路架構設計的相關研究大多都以人體關鍵點做為研究對象",
                    "且手部與人體的關鍵點",
                    "估計並無太大差異",
                    "因此此處以多人體關鍵點估計的相關研究為介紹對象。此外",
                    "論文最終是利用3D",
                    "手部模型做為手部姿勢估測的主要限制條件",
                    "(Model-constrained estimation method)",
                    "因此本章最後會介紹手部模型的相關研究。"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/2.txt"
            },
            {
                "content": "本論文所提出的系統架構如圖15 所示，是以在3.2 節所介紹的系統(圖12)[15]為 基礎進行修改。在網路架構的部分，我們最終選擇MSPN[8]、yolov3[34]所採用的架 構，同時我們將系統中2D 關鍵點估計的神經網路，與deeplabv3+[31]進行整合，設計 一個多任務學習(multi-task learning)的網路架構。逆向運動學的部分，本論文以 Levenberg-Marquardt 演算法最佳化，並以ResNet[32]預測手掌orientation 作為迭代的初 始值，以及[33]中的方法修改最佳化方式，改善迭代的收斂狀況。以下介紹本論文對於 Panteleris 等人所提出的架構[15]所修改的部分。 圖15、本論文所提出的系統架構圖",
                "cross_score": 0.9461199641227722,
                "embedding_sim": 0.9068381786346436,
                "overlaps": [
                    "本論文所提出的系統架構",
                    "網路架構"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/15.txt"
            },
            {
                "content": "本論文研究目標為以單一相機做為使用平台的手部姿勢(hand pose)估計，本論文系 統以一般低價網路攝影機拍攝的彩色影像作為輸入，主要輸出為相對於手掌心的3D 關 鍵點位置(也就是3D 坐標的原點是定位於掌心，而坐標的X, Y, Z 方向在第4.3 節會再 說明)、以及2D 手部關鍵點位置。此處2D 關鍵點是指手部關鍵點在影像中的位置，因 為我們假設了一個3D 的手部模型，即使只用單一攝影機以及2D 的關鍵點也可大約推 算出3D 的手部關鍵點坐標。手部關鍵點指的是手掌的中心、手指關節、手指指尖共 21 點，請參考圖14。而手部3D 關鍵點通常被稱為手部姿勢。 圖14、手部關鍵點示意圖，紅點為手部關鍵點位置 本論文最終選擇以Panteleris 等人所設計的系統作為基礎的系統架構[15]，在此架 構上最需要改進的地方有兩個，第一是手部關鍵點位置的正確性，第二是逆向運動學 中最佳化演算法的收斂結果正確度。本論文主要針對此二問題做改進。",
                "cross_score": 0.9461186528205872,
                "embedding_sim": 0.9247417449951172,
                "overlaps": [
                    "本論文系",
                    "本論文最終"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/14.txt"
            }
        ],
        "main_analysis": "用户段落与最相似文献段落存在大量文字重叠，包括章节安排、技术描述、手部姿势估计方法等内容，几乎逐字一致，部分句子仅作细微调整，整体结构和表达高度相似。  \n结论：存在明显抄袭倾向。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析可信度较高。理由如下：\n\n- 分析准确指出用户段落与相似文献在章节结构、内容描述、表达方式等方面存在大段文字高度重合，且多处为逐字或仅作细微调整，属于典型抄袭特征。\n- 结论“存在明显抄袭倾向”与实际比对内容相符。\n\n可能的遗漏：\n\n- 分析未明确指出是否有引用或标注来源（如未加引号、未注明参考文献等），这一点在判断抄袭严重程度时很重要。\n- 未详细说明重叠比例（如百分比），若有具体数值将更具说服力。\n- 未评论用户段落是否有原创性内容或改写的成分，是否有超出原文的独特贡献。\n\n总体而言，Main Model的分析结论可信，但可以补充对引用规范、重叠比例和原创性成分的具体说明，使结论更为严谨全面。",
            "Expert 2 Feedback: 审阅意见如下：\n\n1. 分析可信度  \nMain Model的分析可信度高。用户段落与相似文献的确存在大段文字高度重合，结构、内容、表述几乎一致，仅有极少部分微调，属于明显的抄袭倾向。\n\n2. 是否有遗漏  \nMain Model的分析基本完整，已指出了内容重合、结构一致等核心问题。但有以下小建议可补充：\n\n- 可进一步说明相似内容是否涉及关键创新点或仅为通用综述，以判断抄袭的严重性。\n- 可以简要提及相似文献的来源（如是否为公开论文、学位论文等），有助于判断抄袭影响。\n- 没有对是否有适当引用或改写进行说明（例如是否列明出处），这也影响抄袭判定。\n\n总体结论：  \nMain Model的分析可信，未出现明显遗漏，已足以支持“存在明显抄袭倾向”的结论。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"根据Main Model和两位专家的分析，用户段落与相似文献在章节结构、内容表述等方面存在大段文字高度重合，属于明显的抄袭倾向。同时，未见有适当引用或改写的说明，无法排除抄袭嫌疑。因此应选择ABSTAIN。\"\n}",
        "plagiarism_confidence": 95,
        "plagiarism_percentage": 98,
        "plagiarism_snippet": [
            "本論文分成六章",
            "第一章介紹動機與成果。第二章介紹手部姿勢與關鍵點抽取的",
            "相關研究。第三章介紹本論文所提出的系統架構所使用到的技術描述。第四章介紹本",
            "論文系統所針對的問題的明確定義以及如何修改、整合第三章所提到的技術成為最終",
            "的系統架構。第五章描述實驗方式以及結果。第六章則為論文的結論以及未來方向。",
            " 手部姿勢估計一直以來都是電腦視覺領域中重要的研究方向之一",
            "目前在此類問",
            "主流方法為藉由神經網路估計關鍵點位置",
            "再以關鍵點資訊推論手部姿勢",
            "此本章主要介紹手部姿勢以及關鍵點估計的相關研究。而在關鍵點估計的部分",
            "網路架構設計的相關研究大多都以人體關鍵點做為研究對象",
            "且手部與人體的關鍵點",
            "估計並無太大差異",
            "因此此處以多人體關鍵點估計的相關研究為介紹對象。此外",
            "論文最終是利用3D",
            "手部模型做為手部姿勢估測的主要限制條件",
            "(Model-constrained estimation method)",
            "因此本章最後會介紹手部模型的相關研究。",
            "本論文所提出的系統架構",
            "網路架構",
            "本論文系",
            "本論文最終"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "在過去基於深度影像進行手部姿勢估測方法中，大多數研究皆搭配手部模型進 行，透過尋找手部模型參數，使手部模型的深度資訊與深度圖像相似，通常透過迭代 最佳化演算法求解，如PSO[20]。而近期的研究，則多以神經網路估計3D 關鍵點位置 [23][24]。Wan 等人提出讓卷積神經網路同時估計2D、3D 關鍵點以及單位向量場(指向 手指頭)，藉此提升精確度的方法[23]。Ge 等人則提出使用3D 卷積神經網路來估計3D 關鍵點位置的機制[24]。",
                "cross_score": 0.9986427426338196,
                "embedding_sim": 0.9989044666290283,
                "overlaps": [
                    "在過去基於深度影像進行手部姿勢估測方法中",
                    "大多數研究皆搭配手部模型進",
                    "透過尋找手部模型參數",
                    "使手部模型的深度資訊與深度圖像相似",
                    "通常透過迭代",
                    "最佳化演算法求解",
                    "如PSO[20]。而近期的研究",
                    "則多以神經網路估計3D 關鍵點位置",
                    "[23][24]。Wan",
                    "等人提出讓卷積神經網路同時估計",
                    "2D、3D 關鍵點以及單位向量場(指向",
                    "手指頭)",
                    "藉此提升精確度的方法[23]。Ge",
                    "等人則提出使用3D",
                    "卷積神經網路來估計3D 關鍵點位置的機制[24]。"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/3.txt"
            },
            {
                "content": "本論文分成六章，第一章介紹動機與成果。第二章介紹手部姿勢與關鍵點抽取的 相關研究。第三章介紹本論文所提出的系統架構所使用到的技術描述。第四章介紹本 論文系統所針對的問題的明確定義以及如何修改、整合第三章所提到的技術成為最終 的系統架構。第五章描述實驗方式以及結果。第六章則為論文的結論以及未來方向。 第二章、手部姿勢及關鍵點抽取相關研究 手部姿勢估計一直以來都是電腦視覺領域中重要的研究方向之一，目前在此類問 題上，主流方法為藉由神經網路估計關鍵點位置，再以關鍵點資訊推論手部姿勢，因 此本章主要介紹手部姿勢以及關鍵點估計的相關研究。而在關鍵點估計的部分，由於 網路架構設計的相關研究大多都以人體關鍵點做為研究對象，且手部與人體的關鍵點 估計並無太大差異，因此此處以多人體關鍵點估計的相關研究為介紹對象。此外，本 論文最終是利用3D 手部模型做為手部姿勢估測的主要限制條件 (Model-constrained estimation method)，因此本章最後會介紹手部模型的相關研究。",
                "cross_score": 0.9303051233291626,
                "embedding_sim": 0.905024528503418,
                "overlaps": [
                    "手部姿勢",
                    "神經網路估計",
                    "關鍵點位置"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/2.txt"
            },
            {
                "content": "本論文研究目標為以單一相機做為使用平台的手部姿勢(hand pose)估計，本論文系 統以一般低價網路攝影機拍攝的彩色影像作為輸入，主要輸出為相對於手掌心的3D 關 鍵點位置(也就是3D 坐標的原點是定位於掌心，而坐標的X, Y, Z 方向在第4.3 節會再 說明)、以及2D 手部關鍵點位置。此處2D 關鍵點是指手部關鍵點在影像中的位置，因 為我們假設了一個3D 的手部模型，即使只用單一攝影機以及2D 的關鍵點也可大約推 算出3D 的手部關鍵點坐標。手部關鍵點指的是手掌的中心、手指關節、手指指尖共 21 點，請參考圖14。而手部3D 關鍵點通常被稱為手部姿勢。 圖14、手部關鍵點示意圖，紅點為手部關鍵點位置 本論文最終選擇以Panteleris 等人所設計的系統作為基礎的系統架構[15]，在此架 構上最需要改進的地方有兩個，第一是手部關鍵點位置的正確性，第二是逆向運動學 中最佳化演算法的收斂結果正確度。本論文主要針對此二問題做改進。",
                "cross_score": 0.9256382584571838,
                "embedding_sim": 0.8949517011642456,
                "overlaps": [
                    "手部模型",
                    "最佳化演算法"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/14.txt"
            }
        ],
        "main_analysis": "用户段落与最相似文献段落存在大量文字重叠，句子结构和表述几乎完全一致，仅有极少词语调整。这种情况属于高度抄袭，明显有抄袭倾向。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析是可信的。理由如下：\n\n- 用户段落与最相似文献段落在内容、句式和表述上几乎完全一致，仅有极少词语调整，属于高度重合。\n- 此种大段落、逐句雷同，明显构成抄袭行为，抄袭倾向非常明显。\n\n是否有遗漏：  \n分析未见明显遗漏，已准确指出了高度重合和抄袭倾向。不过，若需更全面，可补充说明：\n- 可进一步指出用户段落未做任何实质性内容改写或个人理解的表达。\n- 可建议用户对该部分进行重写，或增加引用标注以避免学术不端。\n\n总结：分析可信，基本无遗漏，结论明确。",
            "Expert 2 Feedback: 作为检查专家（Expert 2），我认为Main Model的分析“用户段落与最相似文献段落存在大量文字重叠，句子结构和表述几乎完全一致，仅有极少词语调整。这种情况属于高度抄袭，明显有抄袭倾向”是可信的。理由如下：\n\n- 用户段落与Top 1相似文献段落内容高度一致，几乎逐字重叠，仅有极少词语变动，句式结构未做实质性修改；\n- 涉及的技术描述、引用顺序、例举内容等均完全对齐，未见明显原创性表达。\n\n可能遗漏之处：\n\n- Main Model只分析了文字重叠，并未考察引用是否规范，未讨论是否有适当标明出处；\n- 未分析用户段落是否有对原文内容做出实质性扩展或独立见解；\n- 未说明其他两篇相似文献的重合情况，仅聚焦于Top 1。\n\n总体结论：Main Model的分析可信，判断准确，但可补充对引用合规性和其他相似文献的简要说明。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"两位专家的反馈均明确指出用户段落与最相似文献段落存在高度重合、句式和内容几乎完全一致，仅有极少词语调整，属于典型的抄袭行为。Main Model 的分析判断准确且可信，且未见明显遗漏。因此，应当接受Main Model的分析结论。\"\n}",
        "plagiarism_confidence": 95,
        "plagiarism_percentage": 38,
        "plagiarism_snippet": [
            "在過去基於深度影像進行手部姿勢估測方法中",
            "大多數研究皆搭配手部模型進",
            "透過尋找手部模型參數",
            "使手部模型的深度資訊與深度圖像相似",
            "通常透過迭代",
            "最佳化演算法求解",
            "如PSO[20]。而近期的研究",
            "則多以神經網路估計3D 關鍵點位置",
            "[23][24]。Wan",
            "等人提出讓卷積神經網路同時估計",
            "2D、3D 關鍵點以及單位向量場(指向",
            "手指頭)",
            "藉此提升精確度的方法[23]。Ge",
            "等人則提出使用3D",
            "卷積神經網路來估計3D 關鍵點位置的機制[24]。",
            "手部姿勢",
            "神經網路估計",
            "關鍵點位置",
            "手部模型",
            "最佳化演算法"
        ],
        "verdict": "ACCEPT"
    },
    {
        "top_docs_info": [
            {
                "content": "使用擬人視覺技術的方法是以一般光學影像資料作為輸入，只需以相機拍攝，相 較於前兩者最為便利，但同時也最為困難。在近期神經網路相關技術及硬體發展逐漸 成熟後，開始有大幅進展。 此類方法依據架構設計，可再細分為one-stage[13]以及two-stage[14][15] [16]兩 種。前者直接估計關鍵點3D 位置，如Spurr 等人藉由VAE 模型學習潛在空間與不同 資訊間的關係[13]。後者則是先估計2D 手部關鍵點位置，再利用2D 的資訊估計3D 關鍵點的位置，Zimmermann 和Brox 最早提出以神經網路估計單視角RGB 圖片的手 部關鍵點3D 位置的論文[14]，藉由神經網路從2D 關鍵點的heatmaps 來估計3D 關鍵 點位置，圖4 為該論文提出的系統架構圖，目前許多研究的架構設計皆從此論文修 改。其中，Panteleris 等人利用手部模型對2D 關鍵點做逆向運動學(inverse kinematics) 得到3D 關鍵點位置[15]。Cai 等人則是設計弱監督式學習(weakly supervised learning)的 網路架構，只需要3D 渲染的3D 關鍵點位置以及真實影像的深度資訊就可以訓練網 路，無需真實影像資料的3D 關鍵點位置[16]。 圖4、Zimmermann 和Brox 所提出的整體架構圖[14]",
                "cross_score": 0.992395281791687,
                "embedding_sim": 0.8871394395828247,
                "overlaps": [
                    "使用擬人視覺技術的方法是以一般光學影像資料作為輸入",
                    "只需以相機拍攝",
                    "較於前兩者最為便利",
                    "但同時也最為困難。在近期神經網路相關技術及硬體發展逐漸",
                    "開始有大幅進展。"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/4.txt"
            },
            {
                "content": "神經網路是一種透過「權重」去估計輸入資料的「非線性關係」(Chollet，2017)，之所以 會叫神經網路，便是因為其計算數據的方式就像人類的大腦，並不是單純的線性問題。 但是在實際執行上，時常會因為追求正確率，而發生過度擬合(Overfitting)的問題，也就 是為了追求正確性導致太過偏向樣本內的形式，這樣的模型在樣本外往往就會變得很差。面 對這樣的問題，初步可以嘗試調整隱藏層與神經元的數量，在此必須切記神經元數量不可少 於目標數，否則會出現瓶頸問題，而在本研究中，也會進一步採用常用的Dropout 方式來進 一步改善過度擬合現象，以確保模型在樣本內與樣本外都能有良好的性能，做出正確的預測。",
                "cross_score": 0.03188417851924896,
                "embedding_sim": 0.8585586547851562,
                "overlaps": [
                    "神經網路"
                ],
                "file_path": "dataset/paraphrased_dataset/source/ncu_2019/345.txt"
            },
            {
                "content": "本質影像(Intrinsic image)的概念由Barrow and Tenenbaum [3] 所提出，旨在從一張 輸入的影像中萃取出特徵影像，像是深度(depth)、表面反射率(surface reflectance)、表 面朝向(surface orientation)、遮擋(occlusion)等等。本質影像的模型中假設一張影像I 可 表示成實體影像(reflection/albedo) R 及光影影像(shading/illumination) S 逐點相乘。 𝐼=  𝑅∙ 𝑆 實體影像代表一個物體表面的反射率，即物體的表面顏色，對於不同的相機視角及光 照條件具有不變性；而光影影像則會隨著相機視角, 物體的幾何分布，會有不同的明 暗、陰影[11]。本質影像經常被用在許多電腦視覺、圖學、攝影學的應用上，像是重新 上色(recoloring)[4, 20]、重新打光(relighting)[21, 22]、風格化(stylization)[20]、材質編輯 (material editing)[4]等等。 大多用來解決本質影像分解的傳統方法都是基於對場景特徵、物理現象的假設， 藉由觀察物體和光線在場景中在物理上的交互作用進行發想，像是上述所提的方程 式，或是透過條件隨機場(conditional random fields, CRFs) [1]的方法。其中，最廣為人 知的就是Retinex 圖像增強演算法[13]，Retinex 演算法中假設實體影像具有大範圍的一 致性，所以較大的梯度(gradient)通常對應到實體影像；而較小的梯度則通常對應到較 平滑的光影變化。因此，對於較銳利的光影變化或是材質的多樣性較高，就成了一個 很大的限制。 近年來，許多深度學習架構的方法[5, 6, 7, 8, 11, 12]被提出來解決本質影像分解的 問題，比較先前的研究多是提倡僅透過深度學習就能產生還不錯的結果，到最近幾年 的研究則是發現透過深度學習的架構與物理性質假設的結合能夠產生更好的結果，[11] 加入了物理性質條件，[8]結合了條件隨機場(CRFs)的概念，[5]則提出用對抗概念的網 路架構，與我們研究最相關的就是Janner et al.[7]。 我們的目標是要學習室內場景的光源配置，Janner et al.[7]則是學習單一物件的顏 色、形狀和光影條件。從下圖中，我們可以思考一下對於圖6a 的陶瓷花瓶而言，依照 我們對真實世界的認知，可以很直覺地將顏色、形狀、光影條件分解成如圖6b 的形 式，但如圖6c 分解成平坦形狀或像圖6d 分解出奇怪的顏色和光影卻也能重組成原始 影像，這就是在本質影像分解上因缺乏限制而造成的困難之處。因此我們要的結果不 只是一個有效的答案，還要是一個實際上最有可能的結果。 圖 6 說明從一張影像進行本質分解可能得到的分解方式有很多種 於是，[7]提出了一個自動編碼器(autoencoder)的架構，包含了一個共享convolution 的編碼器(encoder)及三個分支的解碼器(decoder)，三個分支分別是顏色、形狀和光源條 件。形狀和光源條件會用來訓練一個可微分的光影函數(shading function)，即是將光影 的效果套用到形狀上，再由此輸出和顏色結合成原本的輸入。這樣的架構不僅能藉由 輸入一張影像的得到本質的分解，也能重建出影像，因此可以透過沒有本質分解參考 標準的影像來加強中間部分本質分解的表現。 圖 7 Janner et al.[7]用來進行本質影像分解的自動編碼器架構，藉由分解出顏色、形狀和光源條件，再 由形狀和光源條件組合出光影函數，進而與顏色進行相乘後能夠得到原始圖像。 圖8 是由此架構訓練出的結果。利用ShapeNet 的飛機類別進行訓練並在汽車類別 上進行預測。Direct transfer 是用影像輸入並進行本質分解，因此僅能使用具有參考標 準的資料，由於飛機類別的顏色大多偏向白色，即便是色彩繽紛的汽車在顏色上也變 得很淡。Self-supervised 即是加入了後方重建影像的架構，從結果中我們可以發現加入 了這樣的架構能有效增強在顏色上的辨識程度，顯然這樣的架構是有效的。 圖 8 比較有無加入self-supervised 的概念訓練出的結果",
                "cross_score": 0.025990569964051247,
                "embedding_sim": 0.8501657843589783,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/nycu/441.txt"
            }
        ],
        "main_analysis": "经比对，用户段落与最相似文献段落第一段存在高度文字重叠，几乎完全一致，仅有极少字词差异。该情况属于明显的抄袭行为，因为用户段落基本直接照搬了文献内容。建议进行改写或注明出处。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析是可信的。理由如下：\n\n- 分析准确指出了用户段落与相似文献第一段存在高度文字重叠，内容几乎完全一致，仅有极少词语差异，判断为明显抄袭是合理的。\n- 分析给出了改写或注明出处的建议，符合学术规范。\n\n可能的遗漏：\n- 分析仅关注了第一段的重合，并未对用户段落与相似文献其余部分的相似性进行说明（例如后续内容是否也有抄袭）。\n- 未具体说明哪些字词存在差异，可进一步细化指出以增强说服力。\n- 未分析用户段落是否有加入原创性内容。\n\n总体来说，Main Model的结论可信，但可补充更详细的比对说明和对原创性内容的判断。",
            "Expert 2 Feedback: 作为检查专家（Expert 2），我认为Main Model的分析基本可信。理由如下：\n\n- Main Model准确指出了用户段落与相似文献第一段之间存在高度文字重叠，内容几乎完全一致，仅有极少字词差异，这种情况确实属于明显抄袭。\n- 分析建议用户进行改写或注明出处，这符合学术规范。\n\n可能的遗漏：\n\n- Main Model只分析了用户段落与相似文献第一段的相似性，未对用户段落与相似文献其他部分（如后续方法细节、背景说明等）进行比对，但根据提供内容，用户段落只涉及第一段内容，因此影响不大。\n- Main Model未明确说明该段落是否构成全部抄袭（即是否存在“拼接抄袭”或“多源抄袭”现象），但在本例中用户段落较短，且与第一段重合，问题不大。\n\n结论：  \nMain Model的分析可信，未有明显遗漏，结论准确。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"根据Main Model和两位专家的分析，用户段落与相似文献第一段存在高度文字重叠，内容几乎一致，仅有极少字词差异，属于明显抄袭行为。尽管分析主要关注第一段，但用户段落与文献内容的重合已经足以构成抄袭嫌疑，因此不应直接接受。\"\n}",
        "plagiarism_confidence": 35,
        "plagiarism_percentage": 68,
        "plagiarism_snippet": [
            "使用擬人視覺技術的方法是以一般光學影像資料作為輸入",
            "只需以相機拍攝",
            "較於前兩者最為便利",
            "但同時也最為困難。在近期神經網路相關技術及硬體發展逐漸",
            "開始有大幅進展。",
            "神經網路"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "本論文研究目標為以單一相機做為使用平台的手部姿勢(hand pose)估計，本論文系 統以一般低價網路攝影機拍攝的彩色影像作為輸入，主要輸出為相對於手掌心的3D 關 鍵點位置(也就是3D 坐標的原點是定位於掌心，而坐標的X, Y, Z 方向在第4.3 節會再 說明)、以及2D 手部關鍵點位置。此處2D 關鍵點是指手部關鍵點在影像中的位置，因 為我們假設了一個3D 的手部模型，即使只用單一攝影機以及2D 的關鍵點也可大約推 算出3D 的手部關鍵點坐標。手部關鍵點指的是手掌的中心、手指關節、手指指尖共 21 點，請參考圖14。而手部3D 關鍵點通常被稱為手部姿勢。 圖14、手部關鍵點示意圖，紅點為手部關鍵點位置 本論文最終選擇以Panteleris 等人所設計的系統作為基礎的系統架構[15]，在此架 構上最需要改進的地方有兩個，第一是手部關鍵點位置的正確性，第二是逆向運動學 中最佳化演算法的收斂結果正確度。本論文主要針對此二問題做改進。",
                "cross_score": 0.23100697994232178,
                "embedding_sim": 0.9208223819732666,
                "overlaps": [
                    "手部模型",
                    "逆向運動學"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/14.txt"
            },
            {
                "content": "這項技術是在2018 年由Pantelerish 等人所提出的論文[15]，提出一個3D 手部關 鍵點估計的方法，分為三個步驟，首先藉由物體偵測(object detection)框出圖片中左 手、右手的位置並將其裁切下來，再對裁切下來的圖片進行手部關鍵點估計，得到2D 關鍵點位置，最後將左手圖片翻轉成為右手，搭配3D 手部模型，以逆向運動學找出對 應的3D 手模型參數，以此求出3D 關鍵點位置，圖12 為發表在[15]的系統架構圖。論 文中物體偵測和關鍵點估計直接使用當時的state-of-the-art 模型。下面介紹逆向運動學 以及Levenberg-Marquardt 最佳化演算法。 圖12、[15]所提出的系統架構圖",
                "cross_score": 0.20159387588500977,
                "embedding_sim": 0.929735541343689,
                "overlaps": [
                    "的論文[1",
                    "手部模型",
                    "逆向運動學",
                    "[15]"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/10.txt"
            },
            {
                "content": "在過去基於深度影像進行手部姿勢估測方法中，大多數研究皆搭配手部模型進 行，透過尋找手部模型參數，使手部模型的深度資訊與深度圖像相似，通常透過迭代 最佳化演算法求解，如PSO[20]。而近期的研究，則多以神經網路估計3D 關鍵點位置 [23][24]。Wan 等人提出讓卷積神經網路同時估計2D、3D 關鍵點以及單位向量場(指向 手指頭)，藉此提升精確度的方法[23]。Ge 等人則提出使用3D 卷積神經網路來估計3D 關鍵點位置的機制[24]。",
                "cross_score": 0.1361812949180603,
                "embedding_sim": 0.9214125871658325,
                "overlaps": [
                    "以神經網路估計",
                    "神經網路",
                    " 等人則"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/3.txt"
            }
        ],
        "main_analysis": "经检查，用户段落与最相似文献段落不存在明显的文字重叠，表述方式和内容组织均有较大差异，用户段落属于对相关方法的总结和归纳，没有直接抄袭文献内容。整体来看，不存在抄袭倾向。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析总体是可信的，判断用户段落没有明显抄袭、表述方式和内容组织与相似文献不同，结论基本准确。用户段落确实以综述和归纳方式重述相关方法，并无直接照搬原文。\n\n可能的小幅遗漏：  \n分析中未特别提及对关键术语（如“逆向運動學”、“weakly supervised learning”等）的表述是否与原文存在概念性重复，不过根据提供内容，这些术语属学科通用表达，不构成抄袭。\n\n建议：  \n如需更严谨，可补充说明用户段落对文献中Panteleris等人[15]、Zimmermann和Brox[14]等方法的引用属于学术常规，没有超出合理引用范围。整体来看，Main Model的分析结论可信，无明显遗漏。",
            "Expert 2 Feedback: Main Model的分析基本可信。其指出用户段落与相似文献在文字表述、内容组织上有明显差异，用户段落为方法总结归纳，没有直接抄袭文献内容，这一判断是合理的。\n\n但有以下可能的遗漏：\n\n1. 概念表达与结构借鉴：虽然没有直接文字重叠，但用户段落对方法的分类（one-stage、two-stage）、关键文献（如Panteleris、Zimmermann等）的引用顺序和内容组织，与相似文献非常接近。应补充说明是否存在“结构性借鉴”或“概念性依赖”，这在学术诚信中也需注意。\n2. 引用完整性检查：用户段落中提及的文献[13][14][15][16]，应核实其引用是否准确、完整，避免遗漏或误引。\n3. 表达方式评估：虽然没有原文重叠，但若高度依赖他人文献的叙述逻辑，应建议增加作者原创性分析和个性化表述。\n\n建议：结论可信，但建议补充对“内容结构借鉴”及“引用准确性”的审查，以确保更全面的评估。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"用户段落与相似文献在文字表述和内容组织上存在明显差异，属于对相关方法的总结归纳，并未直接抄袭原文内容。虽然结构和引用顺序与文献类似，但属于学术综述常见写作方式，且已规范引用相关文献。不存在明显抄袭或不确定性，因此应接受。\"\n}",
        "plagiarism_confidence": 19,
        "plagiarism_percentage": 8,
        "plagiarism_snippet": [
            "手部模型",
            "逆向運動學",
            "的論文[1",
            "[15]",
            "以神經網路估計",
            "神經網路",
            " 等人則"
        ],
        "verdict": "ACCEPT"
    },
    {
        "top_docs_info": [
            {
                "content": "多人關鍵點估計主要有兩種方式，分別為top-down[8][10]以及bottom-up[9][11]。 前者首先找出圖片中人物的位置並裁切，再做單人的關鍵點估計。後者則是先估計出 圖片中所有關鍵點位置，再區別哪些關鍵點屬於同一個人。本論文採用top-down 的方 式，因此下面針對單人關鍵點估計的方法進行討論。 在過去此類問題大多先建構各個身體部位之間的關係，組成人體的pictorial structures 模型(如圖5 所示)，去尋找圖片中與人相似的形狀[1][2][3][4]，然而這種方法 較無法處理被遮擋的部位，而神經網路可大幅改善此狀況[5]。 有別於過去直接估計關鍵點在圖片上的位置[6]，近期的研究則改為估計各個關鍵 點的heatmaps[5][7][8]。神經網路架構的部分，Wei 等人建立一個多階段估計的網路架 構，以利學習關鍵點之間的關係[5]。Newell 等人則在以encoder-decoder 架構作為多階 段估計中的組件，有效的融合不同尺度的特徵[7]。圖6 為他們所提出的網路架構圖。 在近期研究中多以這個架構為基礎做改良，如Li 等人所提出的跨階段特徵結合(cross stage feature aggregation)的方法[8]，可以改善Netwell 等人的架構中，多階段估計特徵 丟失的問題。 圖5、pictorial structures 模型示意圖，圖片出自[3] 圖6、多階段encoder-decoder 架構示意圖，圖片出自[7]",
                "cross_score": 0.998645007610321,
                "embedding_sim": 0.9259973764419556,
                "overlaps": [
                    "多人關鍵點估計主要有兩種方式",
                    "分別為top-down[8][10]以及bottom-up[9][11]。",
                    "前者首先找出圖片中人物的位置並裁切",
                    "再做單人的關鍵點估計。後者則是先估計出",
                    "圖片中所有關鍵點位置",
                    "再區別哪些關鍵點屬於同一個人。本論文採用",
                    "top-down 的方",
                    "因此下面針對單人關鍵點估計的方法進行討論。"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/5.txt"
            },
            {
                "content": "本論文分成六章，第一章介紹動機與成果。第二章介紹手部姿勢與關鍵點抽取的 相關研究。第三章介紹本論文所提出的系統架構所使用到的技術描述。第四章介紹本 論文系統所針對的問題的明確定義以及如何修改、整合第三章所提到的技術成為最終 的系統架構。第五章描述實驗方式以及結果。第六章則為論文的結論以及未來方向。 第二章、手部姿勢及關鍵點抽取相關研究 手部姿勢估計一直以來都是電腦視覺領域中重要的研究方向之一，目前在此類問 題上，主流方法為藉由神經網路估計關鍵點位置，再以關鍵點資訊推論手部姿勢，因 此本章主要介紹手部姿勢以及關鍵點估計的相關研究。而在關鍵點估計的部分，由於 網路架構設計的相關研究大多都以人體關鍵點做為研究對象，且手部與人體的關鍵點 估計並無太大差異，因此此處以多人體關鍵點估計的相關研究為介紹對象。此外，本 論文最終是利用3D 手部模型做為手部姿勢估測的主要限制條件 (Model-constrained estimation method)，因此本章最後會介紹手部模型的相關研究。",
                "cross_score": 0.7914913892745972,
                "embedding_sim": 0.8903146386146545,
                "overlaps": [
                    "關鍵點位置",
                    "關鍵點估計的"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/2.txt"
            },
            {
                "content": "在多物件追蹤當中，會根據[1]的方式做初始化，方式可以分為Detection- Based Tracking(DBT)和Detection-Free Tracking(DFT)。對於多人重疊偵測，透過 另一種MOT 的方法。其中包含Visual Representation 和Statistical Measuring。 Visual Representation 主要是透過不同的特徵來分辨。Statistical Measuring 主要是 建立在Visual Representation 後，來找出兩個不同人物的相似程度。Occlusion Handling 主要分成Part-to-whole, Hypothesize-and-test, Buffer-and-recover. Part-to- whole 是在被遮擋時人物的一部分仍然可見的基礎上。Hypothesize-and-test 通過 假設和根據手和頭觀察結果測試來迴避遮擋。Buffer-and-recover 是發生遮擋時緩 衝觀察並在被遮擋前記錄人物的狀態，遮擋結束後，基於緩衝觀察和遮擋前儲存 的狀態來恢復人物狀態。 Multi-target tracking 在camera network 中是成長最快的其中之一，但同時也 需要克服光線變化的問題，[4]作者利用convolutional neural network 提取特徵， 用來計算關係矩陣。為了克服光線問題，透過兩張同一時間、同一人、不同光線 與方向。經過調亮、調暗、三層不同設計的convolution layers 後，可以有不錯的 效果。在攝影機引起的光線問題或是具有光線差異的情況下，可以透過關係矩陣、 深度CNN、fully connected layers 來判斷。",
                "cross_score": 0.7129422426223755,
                "embedding_sim": 0.8718558549880981,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/nycu/635.txt"
            }
        ],
        "main_analysis": "存在高度文字重叠，用户段落与最相似文献段落的首段几乎完全一致，仅有个别字词和格式上的微小差异。存在明显抄袭倾向，请注意引用和改写原文内容，避免直接复制。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model 的分析可信。其指出用户段落与相似文献首段存在高度文字重叠，仅有个别字词和格式上的微小差异，确实属于明显抄袭倾向，这与比对内容相符。分析已准确指出主要问题——未进行充分改写或引用，直接复制原文。\n\n未见明显遗漏。分析聚焦于高度重叠和抄袭倾向这一核心问题，已经足够简明准确。如需补充，可建议具体说明应如何改写或规范引用，但以现有分析已满足检查要求。",
            "Expert 2 Feedback: 你的要求是以“检查专家（Expert 2）”的身份，判断Main Model的分析是否可信，以及是否有遗漏。以下是简要评审：\n\n1. 可信度分析  \nMain Model的分析是可信的。它明确指出用户段落与相似文献的首段几乎完全一致，仅有格式或个别字词差异，存在明显抄袭倾向。这一结论与实际文本比对结果相符，证据充分。\n\n2. 是否有遗漏  \n分析集中在文字重叠和抄袭倾向的判断，但未涉及以下细节：\n- 没有具体指出用户段落与相似文献的重合比例（如相似度百分比）。\n- 未说明是否有适当引用原文（但从描述看，应当没有）。\n- 未分析后续内容是否也存在抄袭，或仅限于首段。\n- 没有针对“引用和改写建议”给出具体修改意见。\n\n总评：  \nMain Model的分析结论准确可信，但略显简略。可以补充具体重合比例、引用情况、全文范围内的查重情况，以及对如何改写和引用的具体建议。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"Main Model 的分析结论与实际比对结果一致，能够准确指出用户段落存在高度文字重叠和明显抄袭倾向，分析可信且无明显错误或遗漏，专家反馈也未提出重大异议，因此可以接受本次分析。\"\n}",
        "plagiarism_confidence": 83,
        "plagiarism_percentage": 33,
        "plagiarism_snippet": [
            "多人關鍵點估計主要有兩種方式",
            "分別為top-down[8][10]以及bottom-up[9][11]。",
            "前者首先找出圖片中人物的位置並裁切",
            "再做單人的關鍵點估計。後者則是先估計出",
            "圖片中所有關鍵點位置",
            "再區別哪些關鍵點屬於同一個人。本論文採用",
            "top-down 的方",
            "因此下面針對單人關鍵點估計的方法進行討論。",
            "關鍵點位置",
            "關鍵點估計的"
        ],
        "verdict": "ACCEPT"
    },
    {
        "top_docs_info": [
            {
                "content": "神經網路是一種透過「權重」去估計輸入資料的「非線性關係」(Chollet，2017)，之所以 會叫神經網路，便是因為其計算數據的方式就像人類的大腦，並不是單純的線性問題。 但是在實際執行上，時常會因為追求正確率，而發生過度擬合(Overfitting)的問題，也就 是為了追求正確性導致太過偏向樣本內的形式，這樣的模型在樣本外往往就會變得很差。面 對這樣的問題，初步可以嘗試調整隱藏層與神經元的數量，在此必須切記神經元數量不可少 於目標數，否則會出現瓶頸問題，而在本研究中，也會進一步採用常用的Dropout 方式來進 一步改善過度擬合現象，以確保模型在樣本內與樣本外都能有良好的性能，做出正確的預測。",
                "cross_score": 0.862055242061615,
                "embedding_sim": 0.8842170238494873,
                "overlaps": [
                    "神經網路"
                ],
                "file_path": "dataset/paraphrased_dataset/source/ncu_2019/345.txt"
            },
            {
                "content": "使用擬人視覺技術的方法是以一般光學影像資料作為輸入，只需以相機拍攝，相 較於前兩者最為便利，但同時也最為困難。在近期神經網路相關技術及硬體發展逐漸 成熟後，開始有大幅進展。 此類方法依據架構設計，可再細分為one-stage[13]以及two-stage[14][15] [16]兩 種。前者直接估計關鍵點3D 位置，如Spurr 等人藉由VAE 模型學習潛在空間與不同 資訊間的關係[13]。後者則是先估計2D 手部關鍵點位置，再利用2D 的資訊估計3D 關鍵點的位置，Zimmermann 和Brox 最早提出以神經網路估計單視角RGB 圖片的手 部關鍵點3D 位置的論文[14]，藉由神經網路從2D 關鍵點的heatmaps 來估計3D 關鍵 點位置，圖4 為該論文提出的系統架構圖，目前許多研究的架構設計皆從此論文修 改。其中，Panteleris 等人利用手部模型對2D 關鍵點做逆向運動學(inverse kinematics) 得到3D 關鍵點位置[15]。Cai 等人則是設計弱監督式學習(weakly supervised learning)的 網路架構，只需要3D 渲染的3D 關鍵點位置以及真實影像的深度資訊就可以訓練網 路，無需真實影像資料的3D 關鍵點位置[16]。 圖4、Zimmermann 和Brox 所提出的整體架構圖[14]",
                "cross_score": 0.7503064274787903,
                "embedding_sim": 0.8709566593170166,
                "overlaps": [
                    "神經網路"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/4.txt"
            },
            {
                "content": "多人關鍵點估計主要有兩種方式，分別為top-down[8][10]以及bottom-up[9][11]。 前者首先找出圖片中人物的位置並裁切，再做單人的關鍵點估計。後者則是先估計出 圖片中所有關鍵點位置，再區別哪些關鍵點屬於同一個人。本論文採用top-down 的方 式，因此下面針對單人關鍵點估計的方法進行討論。 在過去此類問題大多先建構各個身體部位之間的關係，組成人體的pictorial structures 模型(如圖5 所示)，去尋找圖片中與人相似的形狀[1][2][3][4]，然而這種方法 較無法處理被遮擋的部位，而神經網路可大幅改善此狀況[5]。 有別於過去直接估計關鍵點在圖片上的位置[6]，近期的研究則改為估計各個關鍵 點的heatmaps[5][7][8]。神經網路架構的部分，Wei 等人建立一個多階段估計的網路架 構，以利學習關鍵點之間的關係[5]。Newell 等人則在以encoder-decoder 架構作為多階 段估計中的組件，有效的融合不同尺度的特徵[7]。圖6 為他們所提出的網路架構圖。 在近期研究中多以這個架構為基礎做改良，如Li 等人所提出的跨階段特徵結合(cross stage feature aggregation)的方法[8]，可以改善Netwell 等人的架構中，多階段估計特徵 丟失的問題。 圖5、pictorial structures 模型示意圖，圖片出自[3] 圖6、多階段encoder-decoder 架構示意圖，圖片出自[7]",
                "cross_score": 0.7000834941864014,
                "embedding_sim": 0.9086463451385498,
                "overlaps": [
                    "在過去此類問題大多先建構各個身體部位之間的關係",
                    "組成人體的",
                    "pictorial structures 模型(如圖5",
                    "去尋找圖片中與人相似的形狀[1][2][3][4]",
                    "然而這種方法",
                    "較無法處理被遮擋的部位",
                    "而神經網路可大幅改善此狀況[5]。"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/5.txt"
            }
        ],
        "main_analysis": "存在明显的文字重叠，尤其是“在過去此類問題大多先建構各個身體部位之間的關係,組成人體的 pictorial structures 模型(如圖5所示),去尋找圖片中與人相似的形狀[1][2][3][4],然而這種方法較無法處理被遮擋的部位,而神經網路可大幅改善此狀況[5]。”两段几乎完全一致，属于直接抄袭。该用户段落有明显抄袭倾向。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析基本可信。理由如下：\n\n- Main Model准确指出了用户段落与第三篇相似文献中“在過去此類問題大多先建構各個身體部位之間的關係,組成人體的 pictorial structures 模型(如圖5所示),去尋找圖片中與人相似的形狀[1][2][3][4],然而這種方法較無法處理被遮擋的部位,而神經網路可大幅改善此狀況[5]。”存在高度重合，确实属于直接抄袭。\n- 该分析结论“有明显抄袭倾向”是成立的。\n\n可能遗漏：\n- 没有进一步分析用户段落是否还有其他内容与前三篇文献存在相似（如结构或用词），仅关注了最明显的重复部分。\n- 未指出是否有引用不当或参考文献标注问题。\n- 未说明抄袭段落的比例和影响范围。\n\n总结：Main Model的分析可信，但可以补充更全面的相似性分析和引用规范评述。",
            "Expert 2 Feedback: 审阅意见：\n\nMain Model的分析认为用户段落“在過去此類問題大多先建構各個身體部位之間的關係,組成人體的 pictorial structures 模型(如圖5所示),去尋找圖片中與人相似的形狀[1][2][3][4],然而這種方法較無法處理被遮擋的部位,而神經網路可大幅改善此狀況[5]。”与相似文献内容几乎完全一致，判定为直接抄袭，有明显抄袭倾向。\n\n可信性评价：\n- 该分析是可信的。通过与相似文献的第三段比对，用户段落确实与文献内容高度一致，属于原文照搬，构成抄袭。\n- Main Model准确指出了文字重叠和内容一致的问题。\n\n是否有遗漏：\n- Main Model的分析只关注了文字重叠和抄袭问题，没有进一步指出抄袭的具体来源（如具体文献出处）。\n- 没有讨论用户段落是否有对原文内容进行任何改写或个人理解（但从比对来看，基本为原文复制）。\n- 未涉及用户段落与其他两篇相似文献的关系，但这不影响对抄袭的判断。\n\n结论：  \nMain Model的分析可信，判断准确，但可进一步补充抄袭内容的具体出处和缺乏改写的情况，整体无明显遗漏。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"用户段落与相似文献存在高度文字重合，属于直接抄袭，缺乏改写和个人理解，存在明显抄袭倾向。因此，应选择ABSTAIN，避免接受涉嫌抄袭的内容。\"\n}",
        "plagiarism_confidence": 77,
        "plagiarism_percentage": 89,
        "plagiarism_snippet": [
            "神經網路",
            "在過去此類問題大多先建構各個身體部位之間的關係",
            "組成人體的",
            "pictorial structures 模型(如圖5",
            "去尋找圖片中與人相似的形狀[1][2][3][4]",
            "然而這種方法",
            "較無法處理被遮擋的部位",
            "而神經網路可大幅改善此狀況[5]。"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "多人關鍵點估計主要有兩種方式，分別為top-down[8][10]以及bottom-up[9][11]。 前者首先找出圖片中人物的位置並裁切，再做單人的關鍵點估計。後者則是先估計出 圖片中所有關鍵點位置，再區別哪些關鍵點屬於同一個人。本論文採用top-down 的方 式，因此下面針對單人關鍵點估計的方法進行討論。 在過去此類問題大多先建構各個身體部位之間的關係，組成人體的pictorial structures 模型(如圖5 所示)，去尋找圖片中與人相似的形狀[1][2][3][4]，然而這種方法 較無法處理被遮擋的部位，而神經網路可大幅改善此狀況[5]。 有別於過去直接估計關鍵點在圖片上的位置[6]，近期的研究則改為估計各個關鍵 點的heatmaps[5][7][8]。神經網路架構的部分，Wei 等人建立一個多階段估計的網路架 構，以利學習關鍵點之間的關係[5]。Newell 等人則在以encoder-decoder 架構作為多階 段估計中的組件，有效的融合不同尺度的特徵[7]。圖6 為他們所提出的網路架構圖。 在近期研究中多以這個架構為基礎做改良，如Li 等人所提出的跨階段特徵結合(cross stage feature aggregation)的方法[8]，可以改善Netwell 等人的架構中，多階段估計特徵 丟失的問題。 圖5、pictorial structures 模型示意圖，圖片出自[3] 圖6、多階段encoder-decoder 架構示意圖，圖片出自[7]",
                "cross_score": 0.9506955742835999,
                "embedding_sim": 0.95632404088974,
                "overlaps": [
                    "有別於過去直接估計關鍵點在圖片上的位置[6]",
                    "近期的研究則改為估計各個關鍵 點的heatmaps[5][7][8]。神經網路架構的部分",
                    "等人建立一個多階段估計的網路架",
                    "以利學習關鍵點之間的關係[5]。Newell",
                    "等人則在以",
                    "encoder-decoder 架構作為多階",
                    "段估計中的組件",
                    "有效的融合不同尺度的特徵[7]。圖6",
                    "為他們所提出的網路架構圖。",
                    "在近期研究中多以這個架構為基礎做改良",
                    "等人所提出的跨階段特徵結合(cross stage feature aggregation)的方法[8]",
                    "可以改善",
                    "Netwell",
                    "等人的架構中",
                    "多階段估計特徵",
                    "丟失的問題。"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/5.txt"
            },
            {
                "content": "Multi-Stage Pose Network (MSPN) [8]為Microsoft COCO 2018 [17]關鍵點估計競賽 的冠軍。對於分類問題，神經網路越深效果應該越好，因此多階段估計網路架構表現 應優於單階段估計，然而當時在MS COCO 資料集上，卻是單階段估計架構表現較突 出。因此Li 等人以當時表現較優的Netwell 等人[7]多階段網路架構為例，提出三個多 階段估計網路架構的問題，並加以改進，實驗結果請參考圖11。 首先，Netwell 等人提出的用來組成多階段網路架構的encoder-decoder 模組設計並 不好，在降採樣(down sampling)時，特徵的通道(channels)數量仍然保持相同，導致大 量特徵資訊流失。 第二，由於重複降低採樣率(down sampling)及提升採樣率(up sampling)的過程，無 法保證能保留前面階段有用特徵，換句話說網路模型將不易最佳化。因此Li 等人提出 跨階段特徵結合(cross-stage feature aggregation)，將降低採樣率所得到的特徵與前一階 段的特徵相加，以保留有用的特徵。 第三，在多階段估計中，在越後面的階段中，神經網路所估計之關鍵點位置會越 精確，因此在訓練上採用傳統方法上常用的coarse-to-fine 技巧，不同於[7]在所有階段 皆以相同目標做訓練，而是在越後面的階段使用越精確的heatmaps 作為訓練目標。 圖10、MSPN[8]網路架構圖 圖11、[8]所提出的三個改善方法在MS COCO 資料集上的結果",
                "cross_score": 0.8931942582130432,
                "embedding_sim": 0.927731990814209,
                "overlaps": [
                    "神經網路",
                    "網路架構",
                    "跨階段特徵結合(cross",
                    "stage feature aggregation)"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/9.txt"
            },
            {
                "content": "使用擬人視覺技術的方法是以一般光學影像資料作為輸入，只需以相機拍攝，相 較於前兩者最為便利，但同時也最為困難。在近期神經網路相關技術及硬體發展逐漸 成熟後，開始有大幅進展。 此類方法依據架構設計，可再細分為one-stage[13]以及two-stage[14][15] [16]兩 種。前者直接估計關鍵點3D 位置，如Spurr 等人藉由VAE 模型學習潛在空間與不同 資訊間的關係[13]。後者則是先估計2D 手部關鍵點位置，再利用2D 的資訊估計3D 關鍵點的位置，Zimmermann 和Brox 最早提出以神經網路估計單視角RGB 圖片的手 部關鍵點3D 位置的論文[14]，藉由神經網路從2D 關鍵點的heatmaps 來估計3D 關鍵 點位置，圖4 為該論文提出的系統架構圖，目前許多研究的架構設計皆從此論文修 改。其中，Panteleris 等人利用手部模型對2D 關鍵點做逆向運動學(inverse kinematics) 得到3D 關鍵點位置[15]。Cai 等人則是設計弱監督式學習(weakly supervised learning)的 網路架構，只需要3D 渲染的3D 關鍵點位置以及真實影像的深度資訊就可以訓練網 路，無需真實影像資料的3D 關鍵點位置[16]。 圖4、Zimmermann 和Brox 所提出的整體架構圖[14]",
                "cross_score": 0.6864904165267944,
                "embedding_sim": 0.9052273631095886,
                "overlaps": [
                    "神經網路",
                    "所提出的"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/4.txt"
            }
        ],
        "main_analysis": "用户段落与最相似文献段落Top 1存在大量文字重叠，部分句子几乎完全一致，例如“有別於過去直接估計關鍵點在圖片上的位置[6],近期的研究則改為估計各個關鍵點的heatmaps[5][7][8]。”等内容与文献段落高度相似，甚至标点和引用顺序都一致。整体来看，存在明显的抄袭倾向。建议用户重新表述内容，或注明出处，并避免大段落照搬。",
        "feedbacks": [
            "Expert 1 Feedback: 作为检查专家（Expert 1），我的意见如下：\n\n1. 可信度评价  \nMain Model的分析是可信的。分析准确指出了用户段落与相似文献存在大量文字重叠，且举例说明了几乎完全一致的句子，包括标点和引用顺序。这种直接、具体的对比方式，有力地支持了“存在明显抄袭倾向”的结论。\n\n2. 是否有遗漏  \n整体分析较为全面，但可进一步补充以下两点：\n\n- 没有详细说明哪些内容属于常见背景知识或技术术语（如“heatmaps”、“encoder-decoder架构”），哪些属于原文独特表述。若部分内容为领域通用表述，则应酌情区分。\n- 未提及用户段落是否有对原文进行合理引用或改写的尝试，仅从文字相似度角度出发。可以建议进一步检视引用规范和改写质量。\n\n结论  \nMain Model分析可信，结论基本准确。建议在后续分析中补充对学科通用表述的甄别，以及对引用规范的进一步核查。",
            "Expert 2 Feedback: Main Model的分析基本可信。理由如下：\n\n- 分析准确指出了用户段落与相似文献段落存在大量文字重叠，包括具体句子和结构，且列举了明显的例子，支撑“存在抄袭倾向”的结论。\n- 分析建议用户重新表述内容或注明出处，符合学术规范要求。\n\n可能的遗漏：\n\n- 分析未提及是否有检测到用户段落中存在原创性内容或改写部分，全部聚焦于重叠和抄袭，略显片面。\n- 未指出具体抄袭比例或相似度分数，仅以主观表述为主，缺乏量化指标支撑。\n- 没有详细说明引用格式是否规范，仅笼统建议注明出处。\n- 未分析用户段落在结构、内容上是否有合理的创新或总结。\n\n总体结论：  \nMain Model的分析可信，判断依据明确，但可以补充量化相似度、对引用规范性和原创部分的评述，使结论更全面。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"根据Main Model和两位专家的分析，用户段落与相似文献存在大量文字重叠，部分句子几乎完全一致，且引用和改写不够充分，存在明显抄袭嫌疑。同时，分析未能完全区分通用术语与独特表述，缺少对引用规范和原创内容的细致评估，因此无法排除抄袭或不当引用的可能性，应选择ABSTAIN。\"\n}",
        "plagiarism_confidence": 84,
        "plagiarism_percentage": 92,
        "plagiarism_snippet": [
            "有別於過去直接估計關鍵點在圖片上的位置[6]",
            "近期的研究則改為估計各個關鍵 點的heatmaps[5][7][8]。神經網路架構的部分",
            "等人建立一個多階段估計的網路架",
            "以利學習關鍵點之間的關係[5]。Newell",
            "等人則在以",
            "encoder-decoder 架構作為多階",
            "段估計中的組件",
            "有效的融合不同尺度的特徵[7]。圖6",
            "為他們所提出的網路架構圖。",
            "在近期研究中多以這個架構為基礎做改良",
            "等人所提出的跨階段特徵結合(cross stage feature aggregation)的方法[8]",
            "可以改善",
            "Netwell",
            "等人的架構中",
            "多階段估計特徵",
            "丟失的問題。",
            "神經網路",
            "網路架構",
            "跨階段特徵結合(cross",
            "stage feature aggregation)",
            "所提出的"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "本節討論手部模型的選擇，包括了Hsu [28]、Libhand [29]、和MANO[30]等三種手 部模型介紹。這三者各有其優點，Hsu 利用Blender 所設計的模型，在手部關節轉動上 符合真實人類的手部狀況，而Libhand 以真實手部影像做渲染，視覺上較接近真實影像， MANO 則是有形狀參數，可以改變手部關節比例。考量未來的發展性，本論文最終選擇 以MANO 作為手部模型，並結合Hsu 的手部模型中靜態關節角度限制。本論文使用 Hasson 等人所提供的MANO 手部模型的PyTorch 版本[35]，渲染的軟體則是使用Kato 等人所開發的可微分渲染程式庫[36]。",
                "cross_score": 0.985275387763977,
                "embedding_sim": 0.9944458603858948,
                "overlaps": [
                    "本節討論手部模型的選擇",
                    "Hsu [28]、Libhand [29]、和",
                    "MANO[30]等三種手",
                    "部模型介紹。這三者各有其優點",
                    "Hsu 利用",
                    "Blender 所設計的模型",
                    "在手部關節轉動上",
                    "符合真實人類的手部狀況",
                    "Libhand 以真實手部影像做渲染",
                    "視覺上較接近真實影像",
                    " MANO 則是有形狀參數",
                    "可以改變手部關節比例。考量未來的發展性",
                    "本論文最終選擇",
                    "MANO 作為手部模型",
                    "Hsu 的手部模型中靜態關節角度限制。本論文使用 Hasson 等人所提供的",
                    "MANO 手部模型的",
                    "PyTorch 版本",
                    "[35]",
                    "渲染的軟體則是使用",
                    "Kato 等人所開發的可微分渲染程式庫",
                    "[36]。"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/6.txt"
            },
            {
                "content": "Hsu [28]的手部模型為本實驗室研究生過去以Blender 所製作的手部模型，擁有26 個自由度，分別為每根手指的ADB、MP、PIP、DIP 的關節角度，以及控制掌心位置 及方向的6 維的全域自由度，同時此手部模型考量了靜態、動態的關節角度限制，因 此擺出的姿勢，相當接近真實人類的狀況。表一為關節的角度限制，圖7 為Blender 手 部模型圖。 表1、靜態關節限制，表格出自[28] Thumb Index Middle Ring Little ADB -40~40 -30~30 -30~30 -30~30 -30~30 MP -51.7~0 -66.3~0 -77.3~0 -88.4~0 -105.8~0 PIP -51.7~0 -95.7~0 -109.2~0 -114~0 -102.9~0 DIP -66.3~0 -70.6~0 -89.7~0 -76.4~0 -90~0 圖7、blender 手部模型，圖片出自[28]",
                "cross_score": 0.9649088978767395,
                "embedding_sim": 0.9109592437744141,
                "overlaps": [
                    "Hsu [28]",
                    "Blender 所",
                    "關節角度限制"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/7.txt"
            },
            {
                "content": "本論文研究目標為以單一相機做為使用平台的手部姿勢(hand pose)估計，本論文系 統以一般低價網路攝影機拍攝的彩色影像作為輸入，主要輸出為相對於手掌心的3D 關 鍵點位置(也就是3D 坐標的原點是定位於掌心，而坐標的X, Y, Z 方向在第4.3 節會再 說明)、以及2D 手部關鍵點位置。此處2D 關鍵點是指手部關鍵點在影像中的位置，因 為我們假設了一個3D 的手部模型，即使只用單一攝影機以及2D 的關鍵點也可大約推 算出3D 的手部關鍵點坐標。手部關鍵點指的是手掌的中心、手指關節、手指指尖共 21 點，請參考圖14。而手部3D 關鍵點通常被稱為手部姿勢。 圖14、手部關鍵點示意圖，紅點為手部關鍵點位置 本論文最終選擇以Panteleris 等人所設計的系統作為基礎的系統架構[15]，在此架 構上最需要改進的地方有兩個，第一是手部關鍵點位置的正確性，第二是逆向運動學 中最佳化演算法的收斂結果正確度。本論文主要針對此二問題做改進。",
                "cross_score": 0.31968891620635986,
                "embedding_sim": 0.8797522783279419,
                "overlaps": [
                    "hand ",
                    "本論文最終選擇以",
                    "。本論文"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/14.txt"
            }
        ],
        "main_analysis": "经过比对，用户段落与最相似文献段落的第一段存在高度文字重叠，几乎一字不差，句子结构和内容完全相同，仅有极少量标点和格式上的微小差异。这种情况属于严重的抄袭倾向。建议用户进行改写，并明确引用来源。",
        "feedbacks": [
            "Expert 1 Feedback: 审阅意见如下：\n\nMain Model 的分析可信，理由如下：  \n- 分析明确指出用户段落与相似文献段落高度重叠，文字结构几乎完全一致，仅有极少数格式和标点差异，这种情况确实属于严重抄袭倾向。\n- 分析结论合理，建议用户进行改写并明确引用来源，符合学术规范。\n\n可能的遗漏：  \n- 没有详细指出具体哪些句子或段落存在重叠（尽管整体描述很清楚，但若能标注具体句子更具说服力）。\n- 未提及是否检查了引用格式和引用编号的准确性。\n- 没有说明如果仅做引用而不改写，是否可接受（即“直接引用但注明来源”是否可以被接受）。\n\n总体而言，Main Model 的分析基本可信，核心结论无误，建议可适当补充更具体的重叠内容标注与对引用合规性的补充说明。",
            "Expert 2 Feedback: Main Model 的分析是可信的。理由如下：\n\n- 分析清楚指出用户段落与相似文献第一段“高度文字重叠，几乎一字不差”，并具体说明“句子结构和内容完全相同，仅有极少量标点和格式上的微小差异”。这是判定严重抄袭的有效证据。\n- 分析结论（建议用户改写并明确引用来源）与检测出的文本相似度问题相符，处理建议合理。\n\n未见明显遗漏。分析已涵盖：\n- 文字重叠的具体情况；\n- 抄袭倾向的严重程度；\n- 改写与引用的建议。\n\n补充建议（非必须）：可以进一步说明如有其他段落也存在相似问题，建议用户整体自查全文，确保学术规范。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"根据Main Model和两位专家的意见，用户段落与相似文献存在高度文字重叠，句子结构和内容几乎完全一致，仅有极少数格式和标点差异，属于严重抄袭倾向。虽然分析结论合理，但由于存在明显的抄袭风险，无法直接接受，应建议用户改写并明确引用来源。\"\n}",
        "plagiarism_confidence": 76,
        "plagiarism_percentage": 88,
        "plagiarism_snippet": [
            "本節討論手部模型的選擇",
            "Hsu [28]、Libhand [29]、和",
            "MANO[30]等三種手",
            "部模型介紹。這三者各有其優點",
            "Hsu 利用",
            "Blender 所設計的模型",
            "在手部關節轉動上",
            "符合真實人類的手部狀況",
            "Libhand 以真實手部影像做渲染",
            "視覺上較接近真實影像",
            " MANO 則是有形狀參數",
            "可以改變手部關節比例。考量未來的發展性",
            "本論文最終選擇",
            "MANO 作為手部模型",
            "Hsu 的手部模型中靜態關節角度限制。本論文使用 Hasson 等人所提供的",
            "MANO 手部模型的",
            "PyTorch 版本",
            "[35]",
            "渲染的軟體則是使用",
            "Kato 等人所開發的可微分渲染程式庫",
            "[36]。",
            "Hsu [28]",
            "Blender 所",
            "關節角度限制",
            "hand ",
            "本論文最終選擇以",
            "。本論文"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "Hsu [28]的手部模型為本實驗室研究生過去以Blender 所製作的手部模型，擁有26 個自由度，分別為每根手指的ADB、MP、PIP、DIP 的關節角度，以及控制掌心位置 及方向的6 維的全域自由度，同時此手部模型考量了靜態、動態的關節角度限制，因 此擺出的姿勢，相當接近真實人類的狀況。表一為關節的角度限制，圖7 為Blender 手 部模型圖。 表1、靜態關節限制，表格出自[28] Thumb Index Middle Ring Little ADB -40~40 -30~30 -30~30 -30~30 -30~30 MP -51.7~0 -66.3~0 -77.3~0 -88.4~0 -105.8~0 PIP -51.7~0 -95.7~0 -109.2~0 -114~0 -102.9~0 DIP -66.3~0 -70.6~0 -89.7~0 -76.4~0 -90~0 圖7、blender 手部模型，圖片出自[28]",
                "cross_score": 0.9799396991729736,
                "embedding_sim": 0.9543294906616211,
                "overlaps": [
                    "Hsu [28]",
                    "的手部模型為本實驗室研究生過去以",
                    "Blender 所製作的手部模型",
                    "26 個自由度",
                    "分別為每根手指的",
                    "ADB、MP、PIP、DIP 的關節角度",
                    "以及控制掌心位置",
                    "及方向的",
                    "6 維的全域自由度",
                    "同時此手部模型考量了靜態、動態的關節角度限制",
                    "此擺出的姿勢",
                    "相當接近真實人類的狀況。表一為關節的角度限制",
                    "lender 手部模型"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/7.txt"
            },
            {
                "content": "本節討論手部模型的選擇，包括了Hsu [28]、Libhand [29]、和MANO[30]等三種手 部模型介紹。這三者各有其優點，Hsu 利用Blender 所設計的模型，在手部關節轉動上 符合真實人類的手部狀況，而Libhand 以真實手部影像做渲染，視覺上較接近真實影像， MANO 則是有形狀參數，可以改變手部關節比例。考量未來的發展性，本論文最終選擇 以MANO 作為手部模型，並結合Hsu 的手部模型中靜態關節角度限制。本論文使用 Hasson 等人所提供的MANO 手部模型的PyTorch 版本[35]，渲染的軟體則是使用Kato 等人所開發的可微分渲染程式庫[36]。",
                "cross_score": 0.9770475625991821,
                "embedding_sim": 0.9156196713447571,
                "overlaps": [
                    "Hsu [28]",
                    "Blender 所",
                    "的手部模型",
                    "關節角度限制",
                    " 手部模型"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/6.txt"
            },
            {
                "content": "本論文研究目標為以單一相機做為使用平台的手部姿勢(hand pose)估計，本論文系 統以一般低價網路攝影機拍攝的彩色影像作為輸入，主要輸出為相對於手掌心的3D 關 鍵點位置(也就是3D 坐標的原點是定位於掌心，而坐標的X, Y, Z 方向在第4.3 節會再 說明)、以及2D 手部關鍵點位置。此處2D 關鍵點是指手部關鍵點在影像中的位置，因 為我們假設了一個3D 的手部模型，即使只用單一攝影機以及2D 的關鍵點也可大約推 算出3D 的手部關鍵點坐標。手部關鍵點指的是手掌的中心、手指關節、手指指尖共 21 點，請參考圖14。而手部3D 關鍵點通常被稱為手部姿勢。 圖14、手部關鍵點示意圖，紅點為手部關鍵點位置 本論文最終選擇以Panteleris 等人所設計的系統作為基礎的系統架構[15]，在此架 構上最需要改進的地方有兩個，第一是手部關鍵點位置的正確性，第二是逆向運動學 中最佳化演算法的收斂結果正確度。本論文主要針對此二問題做改進。",
                "cross_score": 0.672591507434845,
                "embedding_sim": 0.8616496324539185,
                "overlaps": [
                    " 的手部模型"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/14.txt"
            }
        ],
        "main_analysis": "存在大量文字重叠，用户段落与最相似文献段落在叙述手部模型的内容、结构及表达方式上几乎完全一致，仅有个别字词的细微差异，属于明显的抄袭倾向。建议用户进行改写，并标注引用来源。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析是可信的。分析明确指出用户段落与相似文献在结构、内容和表达上高度重叠，仅有细微字词差异，确实属于明显的抄袭倾向，且建议改写和标注引用，符合学术规范要求。未见明显遗漏，分析已涵盖主要抄袭特征，且未忽略对引用标注的建议。整体判断准确、结论可靠。",
            "Expert 2 Feedback: Main Model的分析是可信的。理由如下：\n\n- 分析准确指出用户段落与相似文献在内容、结构和表达方式上高度一致，且仅有极小幅度修改，属于明显抄袭倾向；\n- 建议用户改写并标注引用来源，符合学术规范。\n\n未明显遗漏关键问题。若需补充，可进一步建议用户采用自己的语言进行实质性改写，或说明引用比例，以避免学术不端风险。整体分析已覆盖核心问题。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"用户段落与相似文献在内容、结构及表达方式上高度重叠，仅有细微字词差异，存在明显抄袭倾向。根据学术规范，需对该段落进行实质性改写并标明引用来源，因此不应直接接受，需采取ABSTAIN。\"\n}",
        "plagiarism_confidence": 88,
        "plagiarism_percentage": 94,
        "plagiarism_snippet": [
            "Hsu [28]",
            "的手部模型為本實驗室研究生過去以",
            "Blender 所製作的手部模型",
            "26 個自由度",
            "分別為每根手指的",
            "ADB、MP、PIP、DIP 的關節角度",
            "以及控制掌心位置",
            "及方向的",
            "6 維的全域自由度",
            "同時此手部模型考量了靜態、動態的關節角度限制",
            "此擺出的姿勢",
            "相當接近真實人類的狀況。表一為關節的角度限制",
            "lender 手部模型",
            "Blender 所",
            "的手部模型",
            "關節角度限制",
            " 手部模型",
            " 的手部模型"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "本節討論手部模型的選擇，包括了Hsu [28]、Libhand [29]、和MANO[30]等三種手 部模型介紹。這三者各有其優點，Hsu 利用Blender 所設計的模型，在手部關節轉動上 符合真實人類的手部狀況，而Libhand 以真實手部影像做渲染，視覺上較接近真實影像， MANO 則是有形狀參數，可以改變手部關節比例。考量未來的發展性，本論文最終選擇 以MANO 作為手部模型，並結合Hsu 的手部模型中靜態關節角度限制。本論文使用 Hasson 等人所提供的MANO 手部模型的PyTorch 版本[35]，渲染的軟體則是使用Kato 等人所開發的可微分渲染程式庫[36]。",
                "cross_score": 0.9300784468650818,
                "embedding_sim": 0.9107353687286377,
                "overlaps": [
                    "Libhand ",
                    "[29]",
                    "Libhand ",
                    "手部模型"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/6.txt"
            },
            {
                "content": "Hsu [28]的手部模型為本實驗室研究生過去以Blender 所製作的手部模型，擁有26 個自由度，分別為每根手指的ADB、MP、PIP、DIP 的關節角度，以及控制掌心位置 及方向的6 維的全域自由度，同時此手部模型考量了靜態、動態的關節角度限制，因 此擺出的姿勢，相當接近真實人類的狀況。表一為關節的角度限制，圖7 為Blender 手 部模型圖。 表1、靜態關節限制，表格出自[28] Thumb Index Middle Ring Little ADB -40~40 -30~30 -30~30 -30~30 -30~30 MP -51.7~0 -66.3~0 -77.3~0 -88.4~0 -105.8~0 PIP -51.7~0 -95.7~0 -109.2~0 -114~0 -102.9~0 DIP -66.3~0 -70.6~0 -89.7~0 -76.4~0 -90~0 圖7、blender 手部模型，圖片出自[28]",
                "cross_score": 0.42484867572784424,
                "embedding_sim": 0.8629003763198853,
                "overlaps": [
                    "手部模型",
                    "手部模型"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/7.txt"
            },
            {
                "content": "在過去基於深度影像進行手部姿勢估測方法中，大多數研究皆搭配手部模型進 行，透過尋找手部模型參數，使手部模型的深度資訊與深度圖像相似，通常透過迭代 最佳化演算法求解，如PSO[20]。而近期的研究，則多以神經網路估計3D 關鍵點位置 [23][24]。Wan 等人提出讓卷積神經網路同時估計2D、3D 關鍵點以及單位向量場(指向 手指頭)，藉此提升精確度的方法[23]。Ge 等人則提出使用3D 卷積神經網路來估計3D 關鍵點位置的機制[24]。",
                "cross_score": 0.3571697175502777,
                "embedding_sim": 0.8647560477256775,
                "overlaps": [
                    "手部姿勢"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/3.txt"
            }
        ],
        "main_analysis": "经检查，用户段落与最相似文献段落之间没有明显的文字重叠，表述方式和细节描述均有差异。用户段落是对Libhand模型的独立介绍，没有直接复制文献内容，不存在抄袭倾向。整体来看，属于合理的信息转述与总结。",
        "feedbacks": [
            "Expert 1 Feedback: 审阅意见：\n\nMain Model的分析基本可信，能够准确判断用户段落没有与相似文献存在明显文字重叠，也未发现抄袭倾向，整体属于合理的信息转述与总结。\n\n但略有遗漏之处：分析仅关注了文字表达的相似性，未进一步探讨用户段落中的技术描述（如“以OGRE为基础”“皮肤材质由真实手部影像制作”）与原文献内容在事实层面的对应关系，未核查是否有误导性表述或细节出入。建议后续可增加对事实准确性的核对，以确保内容不仅无抄袭，也无事实性错误。\n\n结论：分析可信，但可补充对技术细节真实性的核查。",
            "Expert 2 Feedback: Main Model的分析总体可信，能够准确指出用户段落与相似文献在表达方式和细节描述上的差异，且未发现明显的文字重叠或抄袭倾向，判断合理。\n\n但分析略有遗漏：没有具体举例说明用户段落与文献在描述细节上的不同（如对Libhand渲染材质来源、使用目的等表述的差异），也未提及是否有事实性错误或对原文意思的歪曲。建议补充对内容准确性和表述差异的具体例证，以增强分析的说服力。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"用户段落与相似文献不存在明显文字重叠，表述方式和细节均有差异，未发现抄袭倾向。虽然专家建议补充对事实准确性的核查，但现有分析已明确说明为合理转述与总结，未见误导或明显错误。因此可判定为合理使用，无需怀疑抄袭。\"\n}",
        "plagiarism_confidence": 57,
        "plagiarism_percentage": 23,
        "plagiarism_snippet": [
            "Libhand ",
            "[29]",
            "手部模型",
            "手部姿勢"
        ],
        "verdict": "ACCEPT"
    },
    {
        "top_docs_info": [
            {
                "content": "本節討論手部模型的選擇，包括了Hsu [28]、Libhand [29]、和MANO[30]等三種手 部模型介紹。這三者各有其優點，Hsu 利用Blender 所設計的模型，在手部關節轉動上 符合真實人類的手部狀況，而Libhand 以真實手部影像做渲染，視覺上較接近真實影像， MANO 則是有形狀參數，可以改變手部關節比例。考量未來的發展性，本論文最終選擇 以MANO 作為手部模型，並結合Hsu 的手部模型中靜態關節角度限制。本論文使用 Hasson 等人所提供的MANO 手部模型的PyTorch 版本[35]，渲染的軟體則是使用Kato 等人所開發的可微分渲染程式庫[36]。",
                "cross_score": 0.897074282169342,
                "embedding_sim": 0.9230231642723083,
                "overlaps": [
                    "MANO",
                    "[30]",
                    " MANO",
                    "MANO ",
                    "手部模型"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/6.txt"
            },
            {
                "content": "Hsu [28]的手部模型為本實驗室研究生過去以Blender 所製作的手部模型，擁有26 個自由度，分別為每根手指的ADB、MP、PIP、DIP 的關節角度，以及控制掌心位置 及方向的6 維的全域自由度，同時此手部模型考量了靜態、動態的關節角度限制，因 此擺出的姿勢，相當接近真實人類的狀況。表一為關節的角度限制，圖7 為Blender 手 部模型圖。 表1、靜態關節限制，表格出自[28] Thumb Index Middle Ring Little ADB -40~40 -30~30 -30~30 -30~30 -30~30 MP -51.7~0 -66.3~0 -77.3~0 -88.4~0 -105.8~0 PIP -51.7~0 -95.7~0 -109.2~0 -114~0 -102.9~0 DIP -66.3~0 -70.6~0 -89.7~0 -76.4~0 -90~0 圖7、blender 手部模型，圖片出自[28]",
                "cross_score": 0.7359763383865356,
                "embedding_sim": 0.8774610757827759,
                "overlaps": [
                    "手部模型",
                    "Blend",
                    "手部模型"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/7.txt"
            },
            {
                "content": "本論文分成六章，第一章介紹動機與成果。第二章介紹手部姿勢與關鍵點抽取的 相關研究。第三章介紹本論文所提出的系統架構所使用到的技術描述。第四章介紹本 論文系統所針對的問題的明確定義以及如何修改、整合第三章所提到的技術成為最終 的系統架構。第五章描述實驗方式以及結果。第六章則為論文的結論以及未來方向。 第二章、手部姿勢及關鍵點抽取相關研究 手部姿勢估計一直以來都是電腦視覺領域中重要的研究方向之一，目前在此類問 題上，主流方法為藉由神經網路估計關鍵點位置，再以關鍵點資訊推論手部姿勢，因 此本章主要介紹手部姿勢以及關鍵點估計的相關研究。而在關鍵點估計的部分，由於 網路架構設計的相關研究大多都以人體關鍵點做為研究對象，且手部與人體的關鍵點 估計並無太大差異，因此此處以多人體關鍵點估計的相關研究為介紹對象。此外，本 論文最終是利用3D 手部模型做為手部姿勢估測的主要限制條件 (Model-constrained estimation method)，因此本章最後會介紹手部模型的相關研究。",
                "cross_score": 0.5084472894668579,
                "embedding_sim": 0.8834884166717529,
                "overlaps": [
                    "本論文所",
                    "手部模型"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/2.txt"
            }
        ],
        "main_analysis": "经检查，用户段落与最相似文献段落之间没有明显的文字重叠，表述方式和内容组织也存在较大差异。用户段落对MANO模型的描述更为具体，强调了其参数类型和数据集来源，而文献段落则着重于不同手部模型的对比及选型理由。因此，不存在抄袭倾向。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析基本可信，理由如下：\n\n- 其指出用户段落与相似文献在表述方式和内容组织上存在明显差异，且无明显文字重叠，这一判断从现有材料来看是准确的。\n- 分析还具体指出用户段落描述更细致，强调了MANO模型的参数类型和数据集来源，而相似文献则更侧重模型对比和选型理由，这一内容归纳也是准确的。\n\n可能的遗漏：\n\n- Main Model分析未明确对“信息内容上的实质性相似”进行评价。虽然文字和结构不同，但若信息点（如MANO模型是基于3D扫描、参数类型、数据集等）完全一致，可能涉及“实质内容借鉴”，分析未对此进行充分说明。\n- 分析未提及是否检查了更广泛的文献或只对Top 3做了比对，可能存在遗漏其他相似来源的风险。\n\n总体评价：分析结论基本可信，但建议补充对“实质内容相似性”的进一步说明，以确保结论更为严谨。",
            "Expert 2 Feedback: Main Model 的分析基本可信，理由如下：\n\n- 它明确指出用户段落与相似文献之间没有明显的文字重叠，表述方式和内容组织存在较大差异。\n- 分析中具体对比了两段内容关注点的不同，指出用户段落更聚焦于MANO模型的技术细节和数据集来源，而文献则偏重不同模型的对比及选型理由。\n\n可能的遗漏：\n\n- 没有详细检查用户段落中涉及的技术细节（如LBS方法、3D扫描学习参数等）是否与MANO原始论文或常见公开资料表达完全一致，存在“技术性表述抄袭”风险的可能性，但未被提及。\n- 没有说明是否对更广泛的文献或网络资料进行查重，仅仅对比了Top 3相似文献，可能存在遗漏其他来源的风险。\n\n总结：整体分析可信，但可补充说明对“技术性表述”与更广泛资料来源的查重情况，以更全面排除抄袭可能。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"虽然用户段落与相似文献在文字和结构上没有明显重叠，内容组织也不同，但两位专家均指出存在未充分排查‘实质内容相似性’和‘技术性表述抄袭’的风险，且未明确说明是否检索了更广泛的文献或资料。因此，存在一定的不确定性，建议ABSTAIN以待进一步查证。\"\n}",
        "plagiarism_confidence": 71,
        "plagiarism_percentage": 86,
        "plagiarism_snippet": [
            "MANO",
            "[30]",
            " MANO",
            "MANO ",
            "手部模型",
            "Blend",
            "本論文所"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "本論文分成六章，第一章介紹動機與成果。第二章介紹手部姿勢與關鍵點抽取的 相關研究。第三章介紹本論文所提出的系統架構所使用到的技術描述。第四章介紹本 論文系統所針對的問題的明確定義以及如何修改、整合第三章所提到的技術成為最終 的系統架構。第五章描述實驗方式以及結果。第六章則為論文的結論以及未來方向。 第二章、手部姿勢及關鍵點抽取相關研究 手部姿勢估計一直以來都是電腦視覺領域中重要的研究方向之一，目前在此類問 題上，主流方法為藉由神經網路估計關鍵點位置，再以關鍵點資訊推論手部姿勢，因 此本章主要介紹手部姿勢以及關鍵點估計的相關研究。而在關鍵點估計的部分，由於 網路架構設計的相關研究大多都以人體關鍵點做為研究對象，且手部與人體的關鍵點 估計並無太大差異，因此此處以多人體關鍵點估計的相關研究為介紹對象。此外，本 論文最終是利用3D 手部模型做為手部姿勢估測的主要限制條件 (Model-constrained estimation method)，因此本章最後會介紹手部模型的相關研究。",
                "cross_score": 0.982955276966095,
                "embedding_sim": 0.9208174347877502,
                "overlaps": [
                    "本論文所提出的",
                    "手部姿勢估測"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/2.txt"
            },
            {
                "content": "本論文以一般攝影機做為使用平台，結合神經網路與手部模型，建立手部姿勢估 計系統，以多任務學習的方式與手部語意切割系統做整合。並以藉由手掌作為初始值 與修改迭代演算法來改善逆向運動學的收斂狀況。圖1 為本論文所提出系統的實際估 測結果。整體來說，本論文的主要貢獻有二： 一、設計實作一個關鍵點估計網路，並藉由多任務學習同時提升關鍵點估計以及語意 切割兩者的準確度。 二、提出以神經網路估計手掌方向來做為初始值，改善迭代的結果。 圖1、實際估測結果。左邊為輸入影像、標上估測出來的手指關鍵點，右邊為根據估測出來的 參數所繪製的3D 手模型。",
                "cross_score": 0.9745604395866394,
                "embedding_sim": 0.9106782674789429,
                "overlaps": [
                    "本論文所提出",
                    "設計實作"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/1.txt"
            },
            {
                "content": "本論文研究目標為以單一相機做為使用平台的手部姿勢(hand pose)估計，本論文系 統以一般低價網路攝影機拍攝的彩色影像作為輸入，主要輸出為相對於手掌心的3D 關 鍵點位置(也就是3D 坐標的原點是定位於掌心，而坐標的X, Y, Z 方向在第4.3 節會再 說明)、以及2D 手部關鍵點位置。此處2D 關鍵點是指手部關鍵點在影像中的位置，因 為我們假設了一個3D 的手部模型，即使只用單一攝影機以及2D 的關鍵點也可大約推 算出3D 的手部關鍵點坐標。手部關鍵點指的是手掌的中心、手指關節、手指指尖共 21 點，請參考圖14。而手部3D 關鍵點通常被稱為手部姿勢。 圖14、手部關鍵點示意圖，紅點為手部關鍵點位置 本論文最終選擇以Panteleris 等人所設計的系統作為基礎的系統架構[15]，在此架 構上最需要改進的地方有兩個，第一是手部關鍵點位置的正確性，第二是逆向運動學 中最佳化演算法的收斂結果正確度。本論文主要針對此二問題做改進。",
                "cross_score": 0.9706631898880005,
                "embedding_sim": 0.8958235383033752,
                "overlaps": [
                    "的手部姿勢",
                    "的系統架構"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/14.txt"
            }
        ],
        "main_analysis": "经检查，用户段落与提供的三段最相似文献内容没有明显的文字重叠，表述方式和内容组织也存在差异。用户段落为自身系统设计过程的描述，未见直接照搬或抄袭文献内容。总体来看，不存在抄袭倾向。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析基本可信。它指出用户段落没有与相似文献有明显的文字重叠，表述和内容组织也有差异，且用户段落确实是描述系统设计过程的自述，未见直接抄袭。该判断与相似文献内容对比后是合理的。\n\n可能的遗漏：\n- Main Model分析主要关注了“文字重叠”和表述方式，但未特别说明是否有“结构性抄袭”或“观点抄袭”——即虽然没有逐字抄袭，但是否存在章节组织、技术路线直接借鉴而未标注的问题。\n- 未提及用户段落是否需要引用相关文献，尤其是在强调“参考许多现有已发表的技术”时，是否应在此处加注参考文献。\n\n综上，Main Model分析总体可信，但可进一步补充对“结构性抄袭”与引用规范的检查。",
            "Expert 2 Feedback: Main Model的分析基本可信。它正确指出用户段落与三段相似文献在表述方式和内容组织上存在差异，没有明显文字重叠，也未发现直接抄袭或照搬现象，这与实际比对结果一致。\n\n但分析略有遗漏：  \n1. 语义/结构借鉴未深入：虽然没有文字重叠，但用户段落在章节安排、内容顺序和表达思路上与相似文献存在一定的结构性借鉴，Main Model未提及这一点。\n2. 未提原创性建议：Main Model未提醒用户，如果引用大量他人技术或思路，应适当注明参考来源以避免学术不端嫌疑。\n3. 深度不足：分析主要关注表面文字重叠，未讨论技术内容、创新点是否足够突出。\n\n总体结论：分析可信，但应补充对结构性借鉴和引用规范的提醒。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"用户段落与相似文献无明显文字重叠，表述和内容组织存在差异，未发现直接抄袭现象。虽然存在参考他人技术但未注明文献的问题，但这属于引用规范范畴，不足以判断为抄袭。综合专家意见与文本内容，目前无确凿证据表明存在抄袭，可予以接受。\"\n}",
        "plagiarism_confidence": 98,
        "plagiarism_percentage": 39,
        "plagiarism_snippet": [
            "本論文所提出的",
            "手部姿勢估測",
            "本論文所提出",
            "設計實作",
            "的手部姿勢",
            "的系統架構"
        ],
        "verdict": "ACCEPT"
    },
    {
        "top_docs_info": [
            {
                "content": "Multi-Stage Pose Network (MSPN) [8]為Microsoft COCO 2018 [17]關鍵點估計競賽 的冠軍。對於分類問題，神經網路越深效果應該越好，因此多階段估計網路架構表現 應優於單階段估計，然而當時在MS COCO 資料集上，卻是單階段估計架構表現較突 出。因此Li 等人以當時表現較優的Netwell 等人[7]多階段網路架構為例，提出三個多 階段估計網路架構的問題，並加以改進，實驗結果請參考圖11。 首先，Netwell 等人提出的用來組成多階段網路架構的encoder-decoder 模組設計並 不好，在降採樣(down sampling)時，特徵的通道(channels)數量仍然保持相同，導致大 量特徵資訊流失。 第二，由於重複降低採樣率(down sampling)及提升採樣率(up sampling)的過程，無 法保證能保留前面階段有用特徵，換句話說網路模型將不易最佳化。因此Li 等人提出 跨階段特徵結合(cross-stage feature aggregation)，將降低採樣率所得到的特徵與前一階 段的特徵相加，以保留有用的特徵。 第三，在多階段估計中，在越後面的階段中，神經網路所估計之關鍵點位置會越 精確，因此在訓練上採用傳統方法上常用的coarse-to-fine 技巧，不同於[7]在所有階段 皆以相同目標做訓練，而是在越後面的階段使用越精確的heatmaps 作為訓練目標。 圖10、MSPN[8]網路架構圖 圖11、[8]所提出的三個改善方法在MS COCO 資料集上的結果",
                "cross_score": 0.9687914252281189,
                "embedding_sim": 0.9505389928817749,
                "overlaps": [
                    "Multi-Stage Pose Network (MSPN) [8]為Microsoft COCO 2018 [17]關鍵點估計競賽",
                    "的冠軍。對於分類問題",
                    "神經網路越深效果應該越好",
                    "因此多階段估計網路架構表現",
                    "應優於單階段估計",
                    "然而當時在MS COCO 資料集上",
                    "卻是單階段估計架構表現較突",
                    "出。因此Li",
                    "等人以當時表現較優的Netwell",
                    "等人[7]多階段網路架構為例",
                    "提出三個多",
                    "階段估計網路架構的問題",
                    "並加以改進",
                    "實驗結果請參考圖"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/9.txt"
            },
            {
                "content": "多人關鍵點估計主要有兩種方式，分別為top-down[8][10]以及bottom-up[9][11]。 前者首先找出圖片中人物的位置並裁切，再做單人的關鍵點估計。後者則是先估計出 圖片中所有關鍵點位置，再區別哪些關鍵點屬於同一個人。本論文採用top-down 的方 式，因此下面針對單人關鍵點估計的方法進行討論。 在過去此類問題大多先建構各個身體部位之間的關係，組成人體的pictorial structures 模型(如圖5 所示)，去尋找圖片中與人相似的形狀[1][2][3][4]，然而這種方法 較無法處理被遮擋的部位，而神經網路可大幅改善此狀況[5]。 有別於過去直接估計關鍵點在圖片上的位置[6]，近期的研究則改為估計各個關鍵 點的heatmaps[5][7][8]。神經網路架構的部分，Wei 等人建立一個多階段估計的網路架 構，以利學習關鍵點之間的關係[5]。Newell 等人則在以encoder-decoder 架構作為多階 段估計中的組件，有效的融合不同尺度的特徵[7]。圖6 為他們所提出的網路架構圖。 在近期研究中多以這個架構為基礎做改良，如Li 等人所提出的跨階段特徵結合(cross stage feature aggregation)的方法[8]，可以改善Netwell 等人的架構中，多階段估計特徵 丟失的問題。 圖5、pictorial structures 模型示意圖，圖片出自[3] 圖6、多階段encoder-decoder 架構示意圖，圖片出自[7]",
                "cross_score": 0.8723265528678894,
                "embedding_sim": 0.9064823985099792,
                "overlaps": [
                    "關鍵點估計",
                    "個多階段估計"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/5.txt"
            },
            {
                "content": "模型篩選的部分，我們比較了三種CPM[5]、HG[7]、MSPN[8]不同的網路架構， 以RHD 和STB 此二公開資料集做測試，從中選出適合的網路架構，作為後續研究的 基礎。從表3、圖23 的實驗結果可以看出MSPN 的效果較好，故後續實驗主要以 MSPN 進行。 表3、CPM、HG、MSPN 在RHD、STB 資料集的結果 Mean EPE RHD STB CPM 6.057 7.316 HG 5.207 6.773 MSPN 4.574 6.491 圖23、CPM、HG、MSPN 在RHD、STB 結果圖表",
                "cross_score": 0.8300369381904602,
                "embedding_sim": 0.8886722326278687,
                "overlaps": [
                    "實驗結果"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/22.txt"
            }
        ],
        "main_analysis": "用户段落与最相似文献段落Top 1存在高度文字重叠，绝大部分语句几乎完全一致，仅有个别词汇和标点微调。该情况属于明显的抄袭倾向，因为内容未作实质性改写或总结，直接复用了原文表述。建议进行彻底重写，并适当增加个人理解或评论。",
        "feedbacks": [
            "Expert 1 Feedback: 作为检查专家(Expert 1)，我认为Main Model的分析是可信的，理由如下：\n\n- 分析准确指出了用户段落与相似文献Top 1存在高度文字重叠，绝大部分语句几乎完全一致，仅有细微改动。这种情况确实属于明显的抄袭倾向，符合学术不端的判定标准。\n- 分析给出了合理建议：建议彻底重写，并增加个人理解或评论，这符合学术写作规范的要求。\n\n是否有遗漏：\n- Main Model的分析主要聚焦于文字重叠和抄袭判断，未进一步指出哪些具体句子或段落重复，未对相似比例做量化（如重复率%），但这对本轮审核影响不大。\n- 没有讨论是否存在“合理引用”或“致谢”情况，但从内容看，确实未作实质改写。\n- 没有评价内容的技术准确性，仅从文本相似和学术规范角度出发。\n\n总体结论：Main Model的分析可信，结论准确，建议合理。对相似性和抄袭问题的判断无明显遗漏，若需更详尽报告可进一步量化重复内容。",
            "Expert 2 Feedback: 审阅意见如下：\n\n1. 分析可信度  \nMain Model的分析可信。它准确指出用户段落与相似文献Top 1存在高度文字重叠，绝大部分语句几乎完全一致，仅有个别词汇和标点微调，属于明显的抄袭倾向。该判断有理有据，结论明确。\n\n2. 是否有遗漏  \n分析中未遗漏主要问题。对内容的高度重合、缺乏实质性改写、未体现个人理解等方面均有指出，且给出“建议彻底重写”的整改意见，覆盖了学术不端的核心风险。\n\n总结  \nMain Model分析结论可信，内容全面，无明显遗漏。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"用户段落与相似文献存在高度文字重叠，绝大部分语句几乎完全一致，仅有细微改动，属于明显的抄袭倾向。根据学术规范，应对涉嫌抄袭的内容暂不通过，建议作者进行彻底重写。因此应选择ABSTAIN。\"\n}",
        "plagiarism_confidence": 89,
        "plagiarism_percentage": 95,
        "plagiarism_snippet": [
            "Multi-Stage Pose Network (MSPN) [8]為Microsoft COCO 2018 [17]關鍵點估計競賽",
            "的冠軍。對於分類問題",
            "神經網路越深效果應該越好",
            "因此多階段估計網路架構表現",
            "應優於單階段估計",
            "然而當時在MS COCO 資料集上",
            "卻是單階段估計架構表現較突",
            "出。因此Li",
            "等人以當時表現較優的Netwell",
            "等人[7]多階段網路架構為例",
            "提出三個多",
            "階段估計網路架構的問題",
            "並加以改進",
            "實驗結果請參考圖",
            "關鍵點估計",
            "個多階段估計",
            "實驗結果"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "多人關鍵點估計主要有兩種方式，分別為top-down[8][10]以及bottom-up[9][11]。 前者首先找出圖片中人物的位置並裁切，再做單人的關鍵點估計。後者則是先估計出 圖片中所有關鍵點位置，再區別哪些關鍵點屬於同一個人。本論文採用top-down 的方 式，因此下面針對單人關鍵點估計的方法進行討論。 在過去此類問題大多先建構各個身體部位之間的關係，組成人體的pictorial structures 模型(如圖5 所示)，去尋找圖片中與人相似的形狀[1][2][3][4]，然而這種方法 較無法處理被遮擋的部位，而神經網路可大幅改善此狀況[5]。 有別於過去直接估計關鍵點在圖片上的位置[6]，近期的研究則改為估計各個關鍵 點的heatmaps[5][7][8]。神經網路架構的部分，Wei 等人建立一個多階段估計的網路架 構，以利學習關鍵點之間的關係[5]。Newell 等人則在以encoder-decoder 架構作為多階 段估計中的組件，有效的融合不同尺度的特徵[7]。圖6 為他們所提出的網路架構圖。 在近期研究中多以這個架構為基礎做改良，如Li 等人所提出的跨階段特徵結合(cross stage feature aggregation)的方法[8]，可以改善Netwell 等人的架構中，多階段估計特徵 丟失的問題。 圖5、pictorial structures 模型示意圖，圖片出自[3] 圖6、多階段encoder-decoder 架構示意圖，圖片出自[7]",
                "cross_score": 0.7134460806846619,
                "embedding_sim": 0.8955205678939819,
                "overlaps": [
                    "網路架構的",
                    "encoder-decoder "
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/5.txt"
            },
            {
                "content": "並使用 K-means (forgy's algorithm) [29] 對訓練集的邊界框尺寸類聚出K 個不同長寬的初始錨框，使得網路在迴歸分析物件大小時能更快速的收 斂，透過這種方式，YOLOv2 使用五個錨框就能得到九個錨框才能達到的 效果。Redmon 和 Farhadi 在2018 年又改進 YOLOv2 而提出了YOLOv3 [16]。在骨幹方面，採用 Darknet-53 做為新的網路骨幹，以大量1×1 及 3×3 卷積來降低參數量；且為了防止網路深度過深而導致的梯度消失 (gradient vanishing) 和網路退化 (degradation) 的問題發生，引入殘差模 組 (residual block) [9] 來解決，如圖 2.6 所示；並在每次卷積後面加入批 量正規劃 [8] 以防止過擬合 (overfitting) 的發生。 - 11 - 圖 2.6. YOLOv3 之殘差模塊。 由於大多數的偵測網路都只使用最後一層特徵圖去進行特徵提取， 從而進行目標偵測，但最後一層的特徵圖屬於高階特徵，若只使用高階特 徵圖會引此忽略小物件的部分資訊，因此對於小物件的偵測效果是會較 差的。有鑑於此，YOLOv3 引入 Lin et al. [30] 所提出的特徵金字塔網路 (Feature pyramid networks, FPN)，把低解析度的多語義資訊特徵與高解析 度的少語義資訊進行融合，並在不同特徵層裡進行預測，使得高解析度下 的特徵圖也具有豐富的語義特徵，讓小物件的辨識率上升。 圖 2.7. FPN 網路架構。 - 12 - 由於一階段方法在速度上較快，二階段網路在精確度較高，各有其優 缺點，為了繼承兩者的優點，同時克服兩者的缺點，Zhang et al. [31] 提 出了 RefineDet (single-shot refinement neural network, RefineDet)，該網路 屬於階層式物件偵測系統，這種系統有兩階段網路的準確性，並且保持了 與一階段網路相同的速度，架構如圖 2.8 所示。作者提出錨框修正模組 (anchor refinement module, ARM) 、目標檢測模組 (object detection module, ODM) 兩個模組。ARM 負責粗略地調整錨框的位置和大小做為候選區塊， 其功能類似 Faster R-CNN 裡 RPN 的功能，之後由 ODM 再進行一次 迴歸計算出候選區塊位置及大小的偏移量，由於經過兩次的迴歸，最終的 結果會比第一次來的更精確。 圖 2.8. RefineDet 網路架構。 預測框和實際 (ground truth) 框的交集面積比聯集面積 (Intersection over Union, IoU) 是用來判斷物件是否有被找出的評估數值，比值越高代 表預測框與實際框的相近；越高越好，但需要一個門檻值做為預測成功與 否的標準，也就是 IoU 門檻值 (IoU threshold)。Redmon 和Farhadi [32] 提出的 Cascade R-CNN，用隨著階層增加而不斷調升訓練時判定用的 - 13 - IoU 門檻值，來增強各聯集階段所能提出的候選區塊品質以取得更好的 預測結果。 圖 2.9. Cascade R-CNN 架構。",
                "cross_score": 0.4659022390842438,
                "embedding_sim": 0.8722012042999268,
                "overlaps": [
                    "ing)"
                ],
                "file_path": "dataset/paraphrased_dataset/source/ncu_2020/334.txt"
            },
            {
                "content": "Multi-Stage Pose Network (MSPN) [8]為Microsoft COCO 2018 [17]關鍵點估計競賽 的冠軍。對於分類問題，神經網路越深效果應該越好，因此多階段估計網路架構表現 應優於單階段估計，然而當時在MS COCO 資料集上，卻是單階段估計架構表現較突 出。因此Li 等人以當時表現較優的Netwell 等人[7]多階段網路架構為例，提出三個多 階段估計網路架構的問題，並加以改進，實驗結果請參考圖11。 首先，Netwell 等人提出的用來組成多階段網路架構的encoder-decoder 模組設計並 不好，在降採樣(down sampling)時，特徵的通道(channels)數量仍然保持相同，導致大 量特徵資訊流失。 第二，由於重複降低採樣率(down sampling)及提升採樣率(up sampling)的過程，無 法保證能保留前面階段有用特徵，換句話說網路模型將不易最佳化。因此Li 等人提出 跨階段特徵結合(cross-stage feature aggregation)，將降低採樣率所得到的特徵與前一階 段的特徵相加，以保留有用的特徵。 第三，在多階段估計中，在越後面的階段中，神經網路所估計之關鍵點位置會越 精確，因此在訓練上採用傳統方法上常用的coarse-to-fine 技巧，不同於[7]在所有階段 皆以相同目標做訓練，而是在越後面的階段使用越精確的heatmaps 作為訓練目標。 圖10、MSPN[8]網路架構圖 圖11、[8]所提出的三個改善方法在MS COCO 資料集上的結果",
                "cross_score": 0.3824218213558197,
                "embedding_sim": 0.9083232879638672,
                "overlaps": [
                    "Netwell",
                    "等人提出的用來組成多階段網路架構的",
                    "encoder-decoder 模組設計並",
                    "在降採樣(down sampling)時",
                    "特徵的通道(channels)數量仍然保持相同",
                    "量特徵資訊流失。"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/9.txt"
            }
        ],
        "main_analysis": "存在明显的文字重叠与高度相似，尤其是“Netwell等人提出的用來組成多階段網路架構的 encoder-decoder 模組設計並不好,在降採樣(down sampling)時,特徵的通道(channels)數量仍然保持相同,導致大量特徵資訊流失”这句话几乎与第三段最相似文献内容完全一致，存在抄袭倾向。建议进行改写并注明引用来源。",
        "feedbacks": [
            "Expert 1 Feedback: 审阅意见如下：\n\n1. 分析可信度  \nMain Model 分析是可信的。用户段落中“Netwell等人提出的用來組成多階段網路架構的 encoder-decoder 模組設計並不好,在降採樣(down sampling)時,特徵的通道(channels)數量仍然保持相同,導致大量特徵資訊流失”与相似文献Top 3中的第三段内容高度一致，几乎原文照搬，确有明显抄袭嫌疑。\n\n2. 是否有遗漏  \n分析未有明显遗漏。Main Model 已明确指出文字重叠和抄袭问题，并建议改写和标注引用来源。对于此类文本相似性检测，分析已经覆盖了核心问题。\n\n结论  \nMain Model 的分析可信，结论准确，无明显遗漏。",
            "Expert 2 Feedback: 作为检查专家(Expert 2)，针对Main Model的分析，简要点评如下：\n\n可信性：\n- Main Model准确指出了用户段落与第三篇相似文献内容存在高度相似，特别是“Netwell等人提出的...导致大量特徵資訊流失”一句几乎完全一致，判断为存在抄袭倾向是可信的。\n- 分析结论合理，建议改写并注明引用来源是合适的学术规范。\n\n是否有遗漏：\n- Main Model仅关注了文字重叠与抄袭倾向，未对用户段落的技术内容（如对Netwell等人架构的评价）是否合理进行技术性分析。\n- 未检查用户段落是否还存在其他潜在的抄袭内容（如与第一、二篇相似文献的关系）。\n- 未指出具体应如何进行改写或引用，建议更具体地指导如何合规修改。\n\n总体结论：  \nMain Model的分析可信且聚焦于查重与学术规范，但略显单一，缺乏对技术内容的深入审查及更细致的改写建议。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"根据Main Model和两位专家的意见，用户段落与第三篇相似文献内容高度一致，存在明显抄袭倾向，且未进行适当改写或注明引用来源。因此，存在学术不端的风险，应选择ABSTAIN。\"\n}",
        "plagiarism_confidence": 52,
        "plagiarism_percentage": 76,
        "plagiarism_snippet": [
            "網路架構的",
            "encoder-decoder ",
            "ing)",
            "Netwell",
            "等人提出的用來組成多階段網路架構的",
            "encoder-decoder 模組設計並",
            "在降採樣(down sampling)時",
            "特徵的通道(channels)數量仍然保持相同",
            "量特徵資訊流失。"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "Multi-Stage Pose Network (MSPN) [8]為Microsoft COCO 2018 [17]關鍵點估計競賽 的冠軍。對於分類問題，神經網路越深效果應該越好，因此多階段估計網路架構表現 應優於單階段估計，然而當時在MS COCO 資料集上，卻是單階段估計架構表現較突 出。因此Li 等人以當時表現較優的Netwell 等人[7]多階段網路架構為例，提出三個多 階段估計網路架構的問題，並加以改進，實驗結果請參考圖11。 首先，Netwell 等人提出的用來組成多階段網路架構的encoder-decoder 模組設計並 不好，在降採樣(down sampling)時，特徵的通道(channels)數量仍然保持相同，導致大 量特徵資訊流失。 第二，由於重複降低採樣率(down sampling)及提升採樣率(up sampling)的過程，無 法保證能保留前面階段有用特徵，換句話說網路模型將不易最佳化。因此Li 等人提出 跨階段特徵結合(cross-stage feature aggregation)，將降低採樣率所得到的特徵與前一階 段的特徵相加，以保留有用的特徵。 第三，在多階段估計中，在越後面的階段中，神經網路所估計之關鍵點位置會越 精確，因此在訓練上採用傳統方法上常用的coarse-to-fine 技巧，不同於[7]在所有階段 皆以相同目標做訓練，而是在越後面的階段使用越精確的heatmaps 作為訓練目標。 圖10、MSPN[8]網路架構圖 圖11、[8]所提出的三個改善方法在MS COCO 資料集上的結果",
                "cross_score": 0.9111093282699585,
                "embedding_sim": 0.9066770076751709,
                "overlaps": [
                    "由於重複降低採樣率(down sampling)及提升採樣率(up sampling)的過程",
                    "法保證能保留前面階段有用特徵",
                    "換句話說網路模型將不易最佳化。因此Li",
                    "等人提出",
                    "跨階段特徵結合(cross-stage feature aggregation)",
                    "將降低採樣率所得到的特徵與前一階",
                    "段的特徵相加",
                    "以保留有用的特徵。"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/9.txt"
            },
            {
                "content": "為了使實驗結果穩定，本實驗採用五折交叉驗證，將資料集分割為80%訓練資料和 20%的測試資料，將訓練資料經過第一階段特徵選取方法產生特徵子集，在將此特徵子 集作為訓練資料進行第二階段的特徵選取，使用的特徵選取演算法有別於第一階段中 所使用之演算法，最後將經過兩次特徵選取的訓練資料放入SVM 分類器進行建模，接 著放入測試資料得到預測正確率和F1-score，五次平均的預測正確率和F1-score 即為 本實驗之結果，並且記錄CPU 運算時間，流程可以參考圖3-7 ，每一折所選取的特徵 子集可能不同，但由於門檻值的設計，最後的結果特徵子集會趨向穩定。",
                "cross_score": 0.1622675210237503,
                "embedding_sim": 0.8810292482376099,
                "overlaps": [
                    "階段特徵",
                    "階段的特徵",
                    "用的特徵"
                ],
                "file_path": "dataset/paraphrased_dataset/source/ncu_2019/446.txt"
            },
            {
                "content": "多人關鍵點估計主要有兩種方式，分別為top-down[8][10]以及bottom-up[9][11]。 前者首先找出圖片中人物的位置並裁切，再做單人的關鍵點估計。後者則是先估計出 圖片中所有關鍵點位置，再區別哪些關鍵點屬於同一個人。本論文採用top-down 的方 式，因此下面針對單人關鍵點估計的方法進行討論。 在過去此類問題大多先建構各個身體部位之間的關係，組成人體的pictorial structures 模型(如圖5 所示)，去尋找圖片中與人相似的形狀[1][2][3][4]，然而這種方法 較無法處理被遮擋的部位，而神經網路可大幅改善此狀況[5]。 有別於過去直接估計關鍵點在圖片上的位置[6]，近期的研究則改為估計各個關鍵 點的heatmaps[5][7][8]。神經網路架構的部分，Wei 等人建立一個多階段估計的網路架 構，以利學習關鍵點之間的關係[5]。Newell 等人則在以encoder-decoder 架構作為多階 段估計中的組件，有效的融合不同尺度的特徵[7]。圖6 為他們所提出的網路架構圖。 在近期研究中多以這個架構為基礎做改良，如Li 等人所提出的跨階段特徵結合(cross stage feature aggregation)的方法[8]，可以改善Netwell 等人的架構中，多階段估計特徵 丟失的問題。 圖5、pictorial structures 模型示意圖，圖片出自[3] 圖6、多階段encoder-decoder 架構示意圖，圖片出自[7]",
                "cross_score": 0.15981709957122803,
                "embedding_sim": 0.8790080547332764,
                "overlaps": [
                    "down ",
                    "跨階段特徵結合(cross",
                    "stage feature aggregation)"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/5.txt"
            }
        ],
        "main_analysis": "经检查，用户段落与最相似文献段落2在表述上几乎完全重叠，特别是“由於重複降低採樣率(down sampling)及提升採樣率(up sampling)的過程,無法保證能保留前面階段有用特徵,換句話說網路模型將不易最佳化。因此Li等人提出跨階段特徵結合(cross-stage feature aggregation),將降低採樣率所得到的特徵與前一階段的特徵相加,以保留有用的特徵。”这句话与文献内容基本一致，仅有个别词语细微调整。\n\n结论：存在明显的文字重叠，属于抄袭倾向。建议进行改写并注明出处。",
        "feedbacks": [
            "Expert 1 Feedback: 作为检查专家（Expert 1），我的意见如下：\n\nMain Model 的分析可信。用户段落与相似文献段落2在表述上高度重合，几乎是逐句复制，仅做了微小词语调整。分析中指出了具体重合句，并给出了改写和标注出处的建议，判断为“存在明显的文字重叠，属于抄袭倾向”是合理且准确的。\n\n没有明显遗漏。分析已覆盖了主要问题（文字重叠、抄袭倾向），并给出改进建议。若要更完善，可补充说明抄袭的学术风险或具体建议如何改写，但这并不影响分析的可信度和完整性。\n\n结论：Main Model 的分析可信，未发现明显遗漏。",
            "Expert 2 Feedback: 审阅意见：\n\nMain Model的分析基本可信，能够准确指出用户段落与相似文献段落2在表述上的高度重叠，特别是对具体语句的比对较为详细，结论（存在明显抄袭倾向，建议改写并注明出处）也较为恰当。\n\n可能的遗漏：\n1. 未具体指出重叠比例或更细致的相似度指标，仅以“几乎完全重叠”定性描述，缺少量化依据。\n2. 未区分是否为公共知识或领域常用表达（如部分方法介绍），但因涉及具体改进方法和表述，确实应认定为需注明出处的内容。\n3. 没有针对用户段落是否有自行理解或创新表达进行评价，仅关注了表面文字重叠。\n\n建议：\n分析结论可信，但可补充更具体的重叠比例说明，并简单说明该段内容为什么必须注明出处（如为他人首创方法描述）。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"用户段落与文献内容存在高度文字重叠，且表达基本一致，仅有细微调整，属于抄袭倾向。虽然分析结论可信，但鉴于明显的重合和未注明出处，无法直接接受，应怀疑有抄袭。\"\n}",
        "plagiarism_confidence": 41,
        "plagiarism_percentage": 71,
        "plagiarism_snippet": [
            "由於重複降低採樣率(down sampling)及提升採樣率(up sampling)的過程",
            "法保證能保留前面階段有用特徵",
            "換句話說網路模型將不易最佳化。因此Li",
            "等人提出",
            "跨階段特徵結合(cross-stage feature aggregation)",
            "將降低採樣率所得到的特徵與前一階",
            "段的特徵相加",
            "以保留有用的特徵。",
            "階段特徵",
            "階段的特徵",
            "用的特徵",
            "down ",
            "跨階段特徵結合(cross",
            "stage feature aggregation)"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "Multi-Stage Pose Network (MSPN) [8]為Microsoft COCO 2018 [17]關鍵點估計競賽 的冠軍。對於分類問題，神經網路越深效果應該越好，因此多階段估計網路架構表現 應優於單階段估計，然而當時在MS COCO 資料集上，卻是單階段估計架構表現較突 出。因此Li 等人以當時表現較優的Netwell 等人[7]多階段網路架構為例，提出三個多 階段估計網路架構的問題，並加以改進，實驗結果請參考圖11。 首先，Netwell 等人提出的用來組成多階段網路架構的encoder-decoder 模組設計並 不好，在降採樣(down sampling)時，特徵的通道(channels)數量仍然保持相同，導致大 量特徵資訊流失。 第二，由於重複降低採樣率(down sampling)及提升採樣率(up sampling)的過程，無 法保證能保留前面階段有用特徵，換句話說網路模型將不易最佳化。因此Li 等人提出 跨階段特徵結合(cross-stage feature aggregation)，將降低採樣率所得到的特徵與前一階 段的特徵相加，以保留有用的特徵。 第三，在多階段估計中，在越後面的階段中，神經網路所估計之關鍵點位置會越 精確，因此在訓練上採用傳統方法上常用的coarse-to-fine 技巧，不同於[7]在所有階段 皆以相同目標做訓練，而是在越後面的階段使用越精確的heatmaps 作為訓練目標。 圖10、MSPN[8]網路架構圖 圖11、[8]所提出的三個改善方法在MS COCO 資料集上的結果",
                "cross_score": 0.8618485331535339,
                "embedding_sim": 0.8950759172439575,
                "overlaps": [
                    "在多階段估計中",
                    "在越後面的階段中",
                    "神經網路所估計之關鍵點位置會越",
                    "因此在訓練上採用傳統方法上常用的coarse-to-fine",
                    "不同於[7]在所有階段",
                    "皆以相同目標做訓練",
                    "而是在越後面的階段使用越精確的heatmaps 作為訓練目標。"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/9.txt"
            },
            {
                "content": "多人關鍵點估計主要有兩種方式，分別為top-down[8][10]以及bottom-up[9][11]。 前者首先找出圖片中人物的位置並裁切，再做單人的關鍵點估計。後者則是先估計出 圖片中所有關鍵點位置，再區別哪些關鍵點屬於同一個人。本論文採用top-down 的方 式，因此下面針對單人關鍵點估計的方法進行討論。 在過去此類問題大多先建構各個身體部位之間的關係，組成人體的pictorial structures 模型(如圖5 所示)，去尋找圖片中與人相似的形狀[1][2][3][4]，然而這種方法 較無法處理被遮擋的部位，而神經網路可大幅改善此狀況[5]。 有別於過去直接估計關鍵點在圖片上的位置[6]，近期的研究則改為估計各個關鍵 點的heatmaps[5][7][8]。神經網路架構的部分，Wei 等人建立一個多階段估計的網路架 構，以利學習關鍵點之間的關係[5]。Newell 等人則在以encoder-decoder 架構作為多階 段估計中的組件，有效的融合不同尺度的特徵[7]。圖6 為他們所提出的網路架構圖。 在近期研究中多以這個架構為基礎做改良，如Li 等人所提出的跨階段特徵結合(cross stage feature aggregation)的方法[8]，可以改善Netwell 等人的架構中，多階段估計特徵 丟失的問題。 圖5、pictorial structures 模型示意圖，圖片出自[3] 圖6、多階段encoder-decoder 架構示意圖，圖片出自[7]",
                "cross_score": 0.841000497341156,
                "embedding_sim": 0.8721761107444763,
                "overlaps": [
                    "關鍵點位置",
                    "的heatmaps"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/5.txt"
            },
            {
                "content": "本節列出神經網路訓練時所用參數，表2 為詳細的參數設定，包含學習率、批次 訓練數量、Epoch 等，其中學習率在每訓練15 個Epoch 後會更新一次，更新方式為當 前學習率乘上Gamma。 同時為提升網路泛化能力，我們使用資料擴增(Data Augmentation)技術，隨機將圖 片旋轉-30~30 度並隨機調整圖片的大小，介於原本大小的0.5 倍至1 倍，圖片縮小後 在周圍做zero padding，使其與原圖大小相同。為了避免過擬合(overfitting)，在訓練時 我們將2D 關鍵點位置隨機加上雜訊，此雜訊為平均值為0、標準差為1.5 的高斯分 布。 此外由於STB 資料集為六段影像資料，每段影像中背景以及手部位置都無太大變 化，所以資料集中只有六種背景，因此在實驗以STB 資料集作為訓練資料時，為避免 過擬合等問題，我們會先在RHD 資料集上訓練10 個Epoch 作為預訓練。 本論文於5.5 與5.6 小節中關鍵點估計相關實驗皆以此設定做訓練，之後不特別進 行說明。 表2、實驗相關參數 Epoch Batch size Learning rate 1e-4 Gamma 0.1 Resize Data argumentation RandomRotate:-30~30 RandomResize : 0.5~1.0 Keypoints noise : N(0, 1.5)",
                "cross_score": 0.6986168622970581,
                "embedding_sim": 0.8722500205039978,
                "overlaps": [
                    "神經網路",
                    "關鍵點位置",
                    "作為訓練"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/21.txt"
            }
        ],
        "main_analysis": "有明显文字重叠，尤其是“在多階段估計中,在越後面的階段中,神經網路所估計之關鍵點位置會越精確，因此在訓練上採用傳統方法上常用的coarse-to-fine技巧,不同於[7]在所有階段皆以相同目標做訓練,而是在越後面的階段使用越精確的heatmaps作為訓練目標”这一句与文献段落三中的表述几乎完全一致，属于高度相似甚至原文照搬，存在抄袭倾向。建议用户进行改写并注明出处。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析是可信的。它准确指出了用户段落与相似文献（尤其是文献段落三）在关键句子上的高度重合，甚至存在原文照搬的问题，这属于抄袭范畴。分析结论与实际文献内容相符，理由充分。\n\n未明显遗漏：分析已指出相似内容的具体位置和抄袭风险，没有遗漏主要问题。若要更全面，可以补充建议如何正确引用或改写原文，但在“可信性”与“遗漏”两点上，当前分析已基本完整。",
            "Expert 2 Feedback: 你的Main Model分析是可信的，理由如下：\n\n- 分析准确指出了用户段落与参考文献（尤其是文献段落三）高度重合，确实属于原文照搬，存在抄袭风险。\n- 分析也合理建议用户需要进行改写并注明出处，这符合学术规范。\n\n可能的遗漏：\n\n- 没有指出具体应该如何进行改写（如可用同义替换、结构调整、增加个人理解等方式）。\n- 没有提及如果引用原文，如何规范引用（如加引号并标明出处）。\n- 没有分析除文字重叠外，内容理解或表达上是否还有其他问题（比如表达是否准确、逻辑是否清晰）。\n\n总结：  \nMain Model分析可信，核心问题已覆盖，建议可补充改写建议和引用规范说明。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"用户段落与参考文献内容高度重合，存在原文照搬和明显的抄袭风险。两位专家和Main Model分析均已明确指出了这一问题，因此不能通过，应选择ABSTAIN。\"\n}",
        "plagiarism_confidence": 80,
        "plagiarism_percentage": 90,
        "plagiarism_snippet": [
            "在多階段估計中",
            "在越後面的階段中",
            "神經網路所估計之關鍵點位置會越",
            "因此在訓練上採用傳統方法上常用的coarse-to-fine",
            "不同於[7]在所有階段",
            "皆以相同目標做訓練",
            "而是在越後面的階段使用越精確的heatmaps 作為訓練目標。",
            "關鍵點位置",
            "的heatmaps",
            "神經網路",
            "作為訓練"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "本論文研究目標為以單一相機做為使用平台的手部姿勢(hand pose)估計，本論文系 統以一般低價網路攝影機拍攝的彩色影像作為輸入，主要輸出為相對於手掌心的3D 關 鍵點位置(也就是3D 坐標的原點是定位於掌心，而坐標的X, Y, Z 方向在第4.3 節會再 說明)、以及2D 手部關鍵點位置。此處2D 關鍵點是指手部關鍵點在影像中的位置，因 為我們假設了一個3D 的手部模型，即使只用單一攝影機以及2D 的關鍵點也可大約推 算出3D 的手部關鍵點坐標。手部關鍵點指的是手掌的中心、手指關節、手指指尖共 21 點，請參考圖14。而手部3D 關鍵點通常被稱為手部姿勢。 圖14、手部關鍵點示意圖，紅點為手部關鍵點位置 本論文最終選擇以Panteleris 等人所設計的系統作為基礎的系統架構[15]，在此架 構上最需要改進的地方有兩個，第一是手部關鍵點位置的正確性，第二是逆向運動學 中最佳化演算法的收斂結果正確度。本論文主要針對此二問題做改進。",
                "cross_score": 0.9900740385055542,
                "embedding_sim": 0.9401658773422241,
                "overlaps": [
                    "[15]",
                    "逆向運動學",
                    "最佳化演算法"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/14.txt"
            },
            {
                "content": "本論文分成六章，第一章介紹動機與成果。第二章介紹手部姿勢與關鍵點抽取的 相關研究。第三章介紹本論文所提出的系統架構所使用到的技術描述。第四章介紹本 論文系統所針對的問題的明確定義以及如何修改、整合第三章所提到的技術成為最終 的系統架構。第五章描述實驗方式以及結果。第六章則為論文的結論以及未來方向。 第二章、手部姿勢及關鍵點抽取相關研究 手部姿勢估計一直以來都是電腦視覺領域中重要的研究方向之一，目前在此類問 題上，主流方法為藉由神經網路估計關鍵點位置，再以關鍵點資訊推論手部姿勢，因 此本章主要介紹手部姿勢以及關鍵點估計的相關研究。而在關鍵點估計的部分，由於 網路架構設計的相關研究大多都以人體關鍵點做為研究對象，且手部與人體的關鍵點 估計並無太大差異，因此此處以多人體關鍵點估計的相關研究為介紹對象。此外，本 論文最終是利用3D 手部模型做為手部姿勢估測的主要限制條件 (Model-constrained estimation method)，因此本章最後會介紹手部模型的相關研究。",
                "cross_score": 0.9652822613716125,
                "embedding_sim": 0.9240182638168335,
                "overlaps": [
                    "的系統架構",
                    "神經網路估計",
                    "手部模型"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/2.txt"
            },
            {
                "content": "本論文以一般攝影機做為使用平台，結合神經網路與手部模型，建立手部姿勢估 計系統，以多任務學習的方式與手部語意切割系統做整合。並以藉由手掌作為初始值 與修改迭代演算法來改善逆向運動學的收斂狀況。圖1 為本論文所提出系統的實際估 測結果。整體來說，本論文的主要貢獻有二： 一、設計實作一個關鍵點估計網路，並藉由多任務學習同時提升關鍵點估計以及語意 切割兩者的準確度。 二、提出以神經網路估計手掌方向來做為初始值，改善迭代的結果。 圖1、實際估測結果。左邊為輸入影像、標上估測出來的手指關鍵點，右邊為根據估測出來的 參數所繪製的3D 手模型。",
                "cross_score": 0.954560399055481,
                "embedding_sim": 0.9277112483978271,
                "overlaps": [
                    "手部模型",
                    "逆向運動學",
                    "以神經網路估計"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/1.txt"
            }
        ],
        "main_analysis": "经检查，用户段落与最相似文献段落没有大段文字重叠，主要内容为对同一技术或论文的总结与转述，表述方式和细节描述有明显差异。用户段落属于对原论文方法的再阐述，没有直接抄袭的倾向。整体来看，不存在抄袭问题。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析是可信的，理由如下：\n\n- 分析明确指出用户段落与最相似文献段落之间没有大段文字重叠，且表述方式和细节描述有明显差异，属于对同一技术的再阐述而非抄袭。\n- 检查内容关注了转述与抄袭的区别，结论合理。\n\n可能的遗漏：\n\n- 没有具体指出是否有引用不规范或遗漏引用的问题（如用户段落是否对[15]进行了明确标注和引用方式是否合适）。\n- 没有针对技术内容的准确性进行评价，仅关注了文字重合和抄袭问题。\n\n总结：分析可信，但如能补充对引用规范和技术表述准确性的检查会更完整。",
            "Expert 2 Feedback: 作为检查专家(Expert 2)，我认为Main Model的分析基本可信，理由如下：\n\n- Main Model明确指出用户段落与最相似文献段落没有大段文字重叠，表述方式和细节描述也有明显差异。\n- 分析指出用户段落为对原论文方法的再阐述，没有直接抄袭的倾向。\n- 结论明确认定不存在抄袭问题。\n\n可能的遗漏：\n\n- Main Model的分析主要关注了文字重叠和表达方式，未详细评估用户段落是否存在结构性“洗稿”（即大幅改写但核心内容和结构高度一致）的可能性。\n- 没有提及用户是否对原论文进行了适当引用（如明确标注引用出处），但从用户段落来看有提及“[15]”，这一点可以补充确认。\n- 没有对专业术语和关键技术描述的一致性进行深度比对（如是否有逐句照搬、仅更换词语顺序等现象）。\n\n总体建议：\n\nMain Model的分析可信，结论可靠。但建议补充说明是否检查了“洗稿”或结构抄袭的可能，以及用户引用的准确性和规范性。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"用户段落与原文没有大段文字重叠，表达方式和细节有明显差异，属于对原论文的再阐述，并且已标明引用[15]。虽然建议进一步检查引用规范和‘洗稿’风险，但现有证据和分析均显示无抄袭或高度可疑行为，因此可以接受。\"\n}",
        "plagiarism_confidence": 97,
        "plagiarism_percentage": 39,
        "plagiarism_snippet": [
            "[15]",
            "逆向運動學",
            "最佳化演算法",
            "的系統架構",
            "神經網路估計",
            "手部模型",
            "以神經網路估計"
        ],
        "verdict": "ACCEPT"
    },
    {
        "top_docs_info": [
            {
                "content": "LM 演算法是一個非線性最佳化演算法，結合了梯度下降法和牛頓法的優點，改善 梯度下降法的收斂問題，並解決牛頓法中海森矩陣可能不可逆的狀況。下面說明演算 法迭代方式。 考慮函數𝒇: 𝑹𝑛→𝑹𝑚，若想對Eq. (2)進行最佳化則可依Eq. (3)進行迭代 𝑆(𝑥) = 1 2 ∑(𝑓𝑖(𝑥))2 𝑚 𝑖=1 (2) 𝑥𝑖+1 = 𝑥𝑖−(𝐽𝑇𝐽+ 𝜆 𝑑𝑖𝑎𝑔(𝐽𝑇𝐽)) −1∇𝑓(𝑥𝑖) (3) 其中𝐽為Jacobian matrix，𝑥𝑖為第i 次迭代結果。",
                "cross_score": 0.9995526671409607,
                "embedding_sim": 0.8634644746780396,
                "overlaps": [
                    "考慮函數",
                    "Eq. (2)",
                    "進行最佳化則可依",
                    "Eq. (3)",
                    "進行迭代"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/12.txt"
            },
            {
                "content": "基因演算法(GA)是由John Holland 所發明[24]，其演算法過程是受到自然界中的 演化過程所啟發，達爾文的進化論提到生物演化是依循「物競天擇、適者生存」 (natural selection, survival of the fitness)，透過天擇的機制，適者得以生存 和繁殖，並將其優勢性狀遺傳給後代，基因演算法即是模仿此機制來挑選出最佳的特 徵子集，基因演算法有以下幾個步驟[25, 26]： 1. 初始族群(Initial Population)： 隨機產生初代染色體，所謂的染色體是由一組二進制位元(bit)所組成，每一位元 都是代表一個特徵，若是位元為1 則代表此特徵有被選取，0 則代表未被選取。 2. 計算適應函數(Fitness function)： 計算染色體之適應函數值，越高的適應函數值代表適應能力越好，被選擇的機會 也越大。 3. 選擇(Selection)： 依照適應函數值的高低來選擇染色體，所選的染色體將會用來產生出下一代的族 群。 4. 交配(Crossover)： 藉由交配機率(Crossover Probability)來決定染色體是否要交配，染色體要交配 的位置是隨機選擇的，進行交配的目的是為了能夠找出最接近最佳解的答案。 5. 突變(Mutation)： 藉由突變機率(Mutation Probability)來決定染色體是否要進行突變，所謂的突 變就是將染色體中的位元從0 變為1 或是從1 變為0，突變是為了避免演算法過早進行 收斂。 6. 滿足終止條件(Stop Condition Reached)： 評估新產生染色體之適應函數值，取代舊族群中適應函數值低於其之染色體，迭 代進行步驟3~5，直到達成終止條件，終止條件可為適應函數值不再增加、到達最大迭 代次數或是到達設定的執行時間等，此時的特徵子集即為最佳解。",
                "cross_score": 0.09316787123680115,
                "embedding_sim": 0.8583424687385559,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/ncu_2019/435.txt"
            },
            {
                "content": "當我們以神經網路所估計的2D 關鍵點位置作為輸入時，我們注意到如果有少數 2D 關鍵點估計錯誤，可能會大大影響逆向運動學之結果，因此我們將Eq. (10)稍作修 改，多加入介於0 到1 之間變數𝑟，首先將Eq.(9)中目標函數每個關鍵點的平方差都乘 上一個變數𝑟𝑖，作為每個關鍵點的權重，同時為避免最佳化演算法讓𝑟𝑖為0 來降低目標 函數的值，因此我們在目標函數後加上𝛼(1 −𝑟𝑖)2來避免，此方法可以使最佳化演算法 自己決定每個關鍵點所佔的權重，讓目標函數增加一些彈性，並非絕對相信神經網路 所估計出的結果，可將式子改寫成 ∑𝑟𝑖𝑝𝑖((𝑥𝑖−𝑢𝑖)2 + (𝑦𝑖−𝑣𝑖)2)) + 𝛼(1 −𝑟𝑖)2 𝑖=1 (10) 其中𝛼為常數。 最後為了確認本節演算法在正常狀況下的表現，我們以神經網路估計的2D 關鍵點 做為目標，MANO 作為手部模型，對本節所提到的演算法做實驗，測試個別以及同時 使用的效果，表7 為實驗結果。 表7、本節實驗結果 With Eq.(10)     Palm orientation   Hierarchical optimization   Mean EPE (mm) RHD 29.99 28.44 25.78 24.48 21.87 STB 31.29 31.03 30.88 29.57 29.47",
                "cross_score": 0.0898817852139473,
                "embedding_sim": 0.8612626791000366,
                "overlaps": [
                    "Eq. (",
                    " Eq."
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/26.txt"
            }
        ],
        "main_analysis": "有明显文字重叠，尤其是“考慮函數f: Rⁿ → Rᵐ,若想對 Eq. (2) 進行最佳化則可依 Eq. (3) 進行迭代”等句子，几乎与文献段落中的表述完全一致，属于直接摘抄。存在抄袭倾向，建议用户进行改写并注明引用来源。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析是可信的。它准确指出了用户段落与相似文献在措辞上的高度重叠，尤其是“考慮函數f: Rⁿ → Rᵐ,若想對 Eq. (2) 進行最佳化則可依 Eq. (3) 進行迭代”这句话几乎为直接摘抄，存在明显抄袭风险。建议用户进行改写并注明引用来源。\n\n可能的遗漏：  \nMain Model的分析仅关注了文字重叠和抄袭风险，没有对其他潜在问题（如段落内容的科学性、表达逻辑等）进行评价。如果需要更全面的审查，还应检查内容准确性、上下文连贯性等方面。",
            "Expert 2 Feedback: 作为检查专家(Expert 2)，我认为Main Model的分析是可信的，理由如下：\n\n- 文字重叠分析准确：Main Model指出“考慮函數f: Rⁿ → Rᵐ,若想對 Eq. (2) 進行最佳化則可依 Eq. (3) 進行迭代”等内容与相似文献中的表述几乎一致，且确实属于直接摘抄。\n- 抄袭倾向判断合理：鉴于句子结构和措辞几乎未变，判断存在抄袭倾向是符合事实的。\n\n可能的遗漏：\n- Main Model只指出了具体一处文字重叠（关于优化方程的描述），但没有说明其他部分是否存在类似问题。若全文只检查了该一句，建议扩大检测范围。\n- Main Model没有对是否引用了来源进行说明（比如文中是否有标注引用），这一点可以进一步明确。\n- 没有说明抄袭比例或整体重合度，仅针对一句话做出评价，建议可补充整体相似度信息以辅助判断。\n\n结论：  \nMain Model的分析结论可信，抓住了主要的文字重合问题。为更全面客观，建议补充对全文或段落整体的相似度分析，以及检查引用标注情况。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"用户段落与文献表述高度重叠，存在直接摘抄嫌疑，且未见明确引用来源。根据Main Model及两位专家的反馈，抄袭风险较高，无法确认内容为用户原创，因此应选择ABSTAIN。\"\n}",
        "plagiarism_confidence": 39,
        "plagiarism_percentage": 70,
        "plagiarism_snippet": [
            "考慮函數",
            "Eq. (2)",
            "進行最佳化則可依",
            "Eq. (3)",
            "進行迭代",
            "Eq. (",
            " Eq."
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "YOLO 系列 (You only look once, YOLO) 是關於物件偵測 (object detection) 的類神經網路演算法，以darknet架構實作，darknet 是一開源的神經網路框架，實作該框架的作者Joseph Redmon用C及 CUDA撰寫，沒有用到任何著名深度學習框架，輕量、依賴少、演算 法高效率。本研究依照官網(https://github.com/AlexeyAB/darknet)說 明，以MSVS 2015, CUDA 10.0, cuDNN 7.4 及OpenCV 3.42 將 darknet.sln及其原始碼建置成darknet.exe。此執行檔即可用來訓練和 停車場入口之車牌影像辨識 預測自己想辨識的物件。 圖 45 訓練範例圖做標籤 資料來源:本研究整理  官網https://github.com/AlexeyAB/YOLO_mark，提供製作學習範例 做此標籤的工具，YOLO_mark.exe。 圖 46 在6898 iterations 時截圖 資料來源:本研究整理 停車場入口之車牌影像辨識 圖 47 iterations=20000，avg. loss=0.0023 資料來源:本研究整理 在圖46，我們可看出訓練一開始loss由4.5以上到截圖時已降致 0.0036，共訓練了64x6898=441472。其中64為batch，一次訓練的批量。 每 100 次 會 儲 存 當 時 權 重 ， YOLO_car2_100.weights ， YOLO_car2_200.weights，YOLO_car2_300.weights，直到45000次，會 儲存成YOLO_car2_final.weights。 以上訓練好的權重*.weights 及組態檔*.cfg ，我們運用OpenCV DNN module的readNetFromDarknet(modelConfiguration, modelBinary)載入，經 以下幾列指令： Mat inputBlob = blobFromImage(srcImg, 1 / 255.F, Size(416, 416), Scalar(), true, false); YOLONet.setInput(inputBlob, \"data\"); Mat detectionMat = YOLONet.forward(\"detection_out\"); 我們設定confidence 閥值0.25。大於0.25閥值者視為車牌物件，由取 得它的中心點座標及其寛高。分別乘上整張汽車影像寛高即可得正確 的車牌位置，將其截取即為車牌的影像。 因OpenCV目前不支援GPU、CUDA，而Darknet提供了可用於預 停車場入口之車牌影像辨識 測(forword)的動態連結程式庫(dll)，Detector detector(modelConfiguration, modelBinary)，在主程序中連結呼叫， 將汽車影像Mat格式代入，std::vector<bbox_t>result_vec = detector.detect(srcImg)，即可取得正確的車牌位置，將其截取即為車 牌的影像。為了可將YOLO detector宣告為global，便於整體程式有 多樣參數。將Detector的建構式新增不用立即load weights及 configuration。即Detector detector()，在選項確定導入時再呼叫 detector.init(modelConfiguration, modelBinary)。",
                "cross_score": 0.9563522338867188,
                "embedding_sim": 0.8794821500778198,
                "overlaps": [
                    "神經網路"
                ],
                "file_path": "dataset/paraphrased_dataset/source/ccu/416.txt"
            },
            {
                "content": "YOLO (You Only Look Once) [6] 實現了real time 的object detection，它為 單一網路設計，只需對圖片作一次CNN 就能判斷圖中物體的類別和位置，辨 識速度非常快。YOLO 的概念是將圖片切割成7*7 的網格，對於每個網格都預 測兩個候選框，根據threshold 將confidence 較低的預測框刪除後，再透過 NMS(Non-Maximum Suppression)去除多餘的框，YOLO 的基本概念可參考下面 圖2-2。 本篇論文在第四章節實驗結果部分有Mask R-CNN 及YOLO 的Baseline 比 對，即為使用訓練好的model 對我們的資料集作測試。另外，[11]此篇論文應 用YOLO 網路架構結合AGMM 的前景資訊，偵測頂照式魚眼攝影機下的人， 但我們發現在其中結果較佳的實驗中，訓練資料的場景和測試資料的場景是相 同的，並且在輸入前景資訊時，忽略掉影像邊緣較難偵測的部分，因此結果部 分僅參考。 圖2- 2 YOLO 概念示意圖[6] 第三章 研究方法 此章節會介紹本篇論文人物偵測系統的網路架構以及相關細節，為了訓練 Mask R-CNN 模型，我們會將利用頂照式魚眼攝影機錄製的影片作擷取影像，標 記我們所需要的訓練資料，輸入圖片至Mask R-CNN 網路架構後，訓練適合我們 資料集的模型，接著即可利用訓練好的模型對頂照式魚眼攝影機下的人物作偵測， 下面的章節內容會詳細介紹並說明之。",
                "cross_score": 0.9344569444656372,
                "embedding_sim": 0.8970096111297607,
                "overlaps": [
                    "real",
                    "time",
                    "網路架構",
                    "網路架構"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/448.txt"
            },
            {
                "content": "並使用 K-means (forgy's algorithm) [29] 對訓練集的邊界框尺寸類聚出K 個不同長寬的初始錨框，使得網路在迴歸分析物件大小時能更快速的收 斂，透過這種方式，YOLOv2 使用五個錨框就能得到九個錨框才能達到的 效果。Redmon 和 Farhadi 在2018 年又改進 YOLOv2 而提出了YOLOv3 [16]。在骨幹方面，採用 Darknet-53 做為新的網路骨幹，以大量1×1 及 3×3 卷積來降低參數量；且為了防止網路深度過深而導致的梯度消失 (gradient vanishing) 和網路退化 (degradation) 的問題發生，引入殘差模 組 (residual block) [9] 來解決，如圖 2.6 所示；並在每次卷積後面加入批 量正規劃 [8] 以防止過擬合 (overfitting) 的發生。 - 11 - 圖 2.6. YOLOv3 之殘差模塊。 由於大多數的偵測網路都只使用最後一層特徵圖去進行特徵提取， 從而進行目標偵測，但最後一層的特徵圖屬於高階特徵，若只使用高階特 徵圖會引此忽略小物件的部分資訊，因此對於小物件的偵測效果是會較 差的。有鑑於此，YOLOv3 引入 Lin et al. [30] 所提出的特徵金字塔網路 (Feature pyramid networks, FPN)，把低解析度的多語義資訊特徵與高解析 度的少語義資訊進行融合，並在不同特徵層裡進行預測，使得高解析度下 的特徵圖也具有豐富的語義特徵，讓小物件的辨識率上升。 圖 2.7. FPN 網路架構。 - 12 - 由於一階段方法在速度上較快，二階段網路在精確度較高，各有其優 缺點，為了繼承兩者的優點，同時克服兩者的缺點，Zhang et al. [31] 提 出了 RefineDet (single-shot refinement neural network, RefineDet)，該網路 屬於階層式物件偵測系統，這種系統有兩階段網路的準確性，並且保持了 與一階段網路相同的速度，架構如圖 2.8 所示。作者提出錨框修正模組 (anchor refinement module, ARM) 、目標檢測模組 (object detection module, ODM) 兩個模組。ARM 負責粗略地調整錨框的位置和大小做為候選區塊， 其功能類似 Faster R-CNN 裡 RPN 的功能，之後由 ODM 再進行一次 迴歸計算出候選區塊位置及大小的偏移量，由於經過兩次的迴歸，最終的 結果會比第一次來的更精確。 圖 2.8. RefineDet 網路架構。 預測框和實際 (ground truth) 框的交集面積比聯集面積 (Intersection over Union, IoU) 是用來判斷物件是否有被找出的評估數值，比值越高代 表預測框與實際框的相近；越高越好，但需要一個門檻值做為預測成功與 否的標準，也就是 IoU 門檻值 (IoU threshold)。Redmon 和Farhadi [32] 提出的 Cascade R-CNN，用隨著階層增加而不斷調升訓練時判定用的 - 13 - IoU 門檻值，來增強各聯集階段所能提出的候選區塊品質以取得更好的 預測結果。 圖 2.9. Cascade R-CNN 架構。",
                "cross_score": 0.9325447082519531,
                "embedding_sim": 0.8791257739067078,
                "overlaps": [
                    "2018 年",
                    " (re",
                    " FPN "
                ],
                "file_path": "dataset/paraphrased_dataset/source/ncu_2020/334.txt"
            }
        ],
        "main_analysis": "经比对，用户段落与提供的三段最相似文献内容之间没有出现大段原文文字重叠，表述方式和用词均有明显差异。虽然内容涉及相同的YOLO架构、残差网络、FPN等相关技术点，但用户段落为自主整理、概括性描述，并未直接复制粘贴文献句子。因此，不存在抄袭倾向。",
        "feedbacks": [
            "Expert 1 Feedback: 审阅结论如下：\n\n1. 可信度分析  \nMain Model 的分析基本可信。经比对，用户段落与相似文献的用词和表述方式有明显差异，内容为自主整理和概括，没有大段原文重叠或直接复制的痕迹，因此“未发现抄袭倾向”的结论合理。\n\n2. 可能的遗漏  \n但分析略有不足，建议补充以下两点以更为严谨：\n\n- 概念性表达与常见叙述：虽然表述不同，但部分技术描述（如“残差网络”、“FPN”、“多尺度特征融合”）属于YOLOv3常见、标准化的介绍内容，本就难以完全避免相似。应进一步说明判定时已考虑到该类技术术语和学科通用表达的合理重合。\n- 深度比对与片段分析：分析仅说明“无大段原文重叠”，建议补充是否存在句子级短语或片段的潜在相似，确保未遗漏小段落或关键技术细节的直接照搬。\n\n结论：  \n分析结论可信，但建议补充上述两点说明，以确保审查更为全面、严谨。",
            "Expert 2 Feedback: Main Model的分析总体可信，其理由如下：\n\n- 经过比对，用户段落与相似文献内容在表述上确实存在明显差异，没有发现大段原文复制，属于自主整理和总结，且未直接套用文献句子。\n- 分析准确指出，虽然技术点一致（如YOLO、残差网络、FPN等），但未见抄袭迹象。\n\n可能的小遗漏：\n- 没有具体列举“最相似”的文献片段与用户段落的句式对照（如关键句比对），若补充对照会更具说服力。\n- 没有说明用户段落是否存在“片段性拼接”或“句型改写但内容高度依赖”的情形，建议补充这方面的考量。\n\n结论：分析可信，结论合理，建议补充具体比对细节与改写型抄袭的排查说明会更完善。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"两位专家与Main Model分析均认为用户段落与文献在表述和用词上存在明显差异，属于自主整理和概括，未发现大段原文复制或抄袭迹象。尽管建议补充更细致的比对细节和对通用技术术语重合的合理解释，但目前已有分析已能支持‘未发现抄袭倾向’的结论，因此可以接受。\"\n}",
        "plagiarism_confidence": 94,
        "plagiarism_percentage": 38,
        "plagiarism_snippet": [
            "神經網路",
            "real",
            "time",
            "網路架構",
            "2018 年",
            " (re",
            " FPN "
        ],
        "verdict": "ACCEPT"
    },
    {
        "top_docs_info": [
            {
                "content": "Yolo 為2018 年提出的物體偵測神經網路架構，當時在[17][40]兩個資料集皆為 state-of-the-art，同時能達到實時(real-time)偵測。本篇為yolo 系列的第三代，方法與前 一代相似，主要以兩種方式改良網路架構，首先，它使用了resnet[32]中的殘差網路架 構設計更深的網路，其次，它參考了FPN 的架構設計，加入多尺度預測以及多尺度特 徵融合。 在物體偵測的方法上，yolo 採用one-stage 的方式，直接從圖片中偵測定界框 (bounding box)，其方式如下，首先將圖片等分成S × S個區塊(如圖13 所示)，而每個區 塊會有N 個事先設計好的anchor box，而神經網路則負責預測每個anchor box 的長寬 變化、中心位置位移以及所屬類別。網路估計結果與定界框關係可參考Eq. (4)到Eq. (7)， 𝑏𝑥= 𝜎(𝑡𝑥) + 𝑐𝑥 (4) 𝑏𝑦= 𝜎(𝑡𝑦) + 𝑐𝑦 (5) 𝑏𝑤= 𝑝𝑤𝑒𝑡𝑤 (6) 𝑏ℎ= 𝑝ℎ𝑒𝑡ℎ (7) 其中𝑡𝑥, 𝑡𝑦, 𝑡𝑤, 𝑡ℎ為網路估計的結果，(𝑏𝑥, 𝑏𝑦)為定界框中心位置，(𝑏𝑤, 𝑏ℎ)為定界框 的寬與長，(𝑝ℎ, 𝑝𝑤)為anchor box 的寬與長，(𝑐𝑥, 𝑦𝑦)為anchor box 所在區域左上角的位 置，𝜎()則代表羅吉斯函數。 圖13、圖片等分𝐒× 𝐒個區塊示意圖，圖片出自[42] 第四章、問題描述及系統架構",
                "cross_score": 0.9623339176177979,
                "embedding_sim": 0.9524068832397461,
                "overlaps": [
                    "在物體偵測的方法上，yolo 採用",
                    "one-stage 的方式，直接從圖片中偵測定界框 (bounding box)，其方式如下，首先將圖片等分成",
                    "13 所示)，而每個區",
                    "N 個事先設計好的",
                    "anchor box，而神經網路則負責預測每個",
                    "anchor box 的長寬",
                    "變化、中心位置位移以及所屬類別。網路估計結果與定界框關係可參考",
                    "Eq. (4)",
                    "Eq. (7)"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/13.txt"
            },
            {
                "content": "原架構 9DoF SE-YOLO 為一階段偵測網路，由於要將對齊偵測模組 (align detection model, ADM) 加入原架構，使網路能先提出能對預訂的錨 框個別進行大小及位置的調整，再以錨框內的特徵迴歸出更準確的結果， 因此我們提出的架構會有兩階段偵測和一次的輸出。 第一次偵測為針對影像平面的物件偵測，以cx, cy 表示影像左上角至 網格的水平及垂直距離，σ為 sigmoid 函數，tx, ty 為預測物件的中心點座 - 32 - 標，並在每個網格中預先定義一種長寬比的錨框 (anchor box) pw, ph，錨 框的設置方式如同 YOLOv3 是以離線的 K-means 類聚訓練集的物件真 實數據 (ground truth) 的長寬比，但不同的是YOLOv3 設置五種不同長寬 比的錨框。而tw、th 為預測框之長寬大小比例，及是否包含物體的置信度 to (confidence)，預測值對應於邊界框值bx、by、bw、bh，如圖 3.9 所示， 我們將預測的值用以調整所預定的錨框，得到學習到的錨框 (learned anchor)。 圖 3.9. 第一次偵測的錨框與學習到的錨框之關係。 第一次偵測出的張量格式為預測之物件在圖像平面的資訊，包括表 示預測框中心點的平移分量x, y，及預測框的寬高w, h，如圖 3.10 所示。 - 33 - 圖 3.10. 第一次偵測所得到的資料之張量格式。 第二次偵測為針對物件偵測的位置與類別與原架構相同，為針對3D 空間的物件偵測。以cx, cy 表示影像左上角至網格的水平及垂直距離，σ 為 sigmoid 函數，tx, ty 為預測物件的中心點座標，tz 為預測之深度，pw, ph, pl 為在每個網格中設有的錨框之長寬高，tw, th, tl 為預測框之長寬高大小比 例， qt , 1qt , qt , qt 為以四元數表示的預測框之旋轉姿態，預測值對應於 邊界框值bx, by, bz, bw, bh, bl, qb , 1qb , qb , 3qb ，如圖 3.2 所示。 第二次偵測輸出的張量格式為預測的物件在3D 空間下的9DoF 資 訊，包括表示預測框中心點的平移分量x, y, z，預測框姿態的四元數旋轉 分量q0, q1, q2, q3，此外預測物件在真實世界下的長寬高w, h, l，如圖 3.3 所示。 - 34 -",
                "cross_score": 0.9318868517875671,
                "embedding_sim": 0.9004862308502197,
                "overlaps": [
                    "anchor box",
                    " anchor"
                ],
                "file_path": "dataset/paraphrased_dataset/source/ncu_2020/343.txt"
            },
            {
                "content": "Yolo v3 一個是one-stage learning 方法，不需要region proposal 的階段，經過單一次 檢測即可獲得最終的偵測結果，雖然辨識率大多比起two-stage learning 來說較低，但整 體仍是可接受範圍，利用整張影像直接輸入網路架構，直接預測 bounding box 的座標 以及其信心值和所屬的類別，在速度方面仍具有相當大的優勢。在本研究中，由於要將 一張影像切割成八張Virtual PTZ 影像作偵測（3.2.2），所以速度方面不希望太慢，因此 選擇此架構來進行研究。 Yolo v3 採用Darknet-53 來提取特徵，特徵層從單層的13x13 變成了3 種層(13x13、 26x26、52x52)，13x13 層用來檢測大型物件、26x26 檢測中型物件、52x52 檢測小型物 件，利用多尺度的特徵增加特徵的豐富程度，Yolo v3 採用類似於FPN(Feature Pyramid Networks)的Upsampling 和Concatenation 的做法融合了這3 種尺寸，並且在不同特徵層 獨立進行偵測，使得對於小目標偵測的效果有明顯的提升。",
                "cross_score": 0.821898877620697,
                "embedding_sim": 0.8918759822845459,
                "overlaps": [
                    "olo ",
                    "one-stage ",
                    "bounding box"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/468.txt"
            }
        ],
        "main_analysis": "存在大量文字重叠，用户段落与第一条最相似文献段落几乎完全一致，包括描述YOLO的one-stage方法、图片分区、anchor box的设置和神经网络预测内容，以及对Eq. (4)到Eq. (7)的引用。这样的情况属于明显的抄袭倾向，建议进行改写或注明出处。",
        "feedbacks": [
            "Expert 1 Feedback: 【专家评审意见】\n\n1. 分析可信度  \nMain Model 分析认为用户段落与第一条相似文献在描述YOLO的one-stage方法、图片分区、anchor box设定和神经网络预测内容等部分几乎完全一致，属于明显抄袭倾向。这一判断是可信的。通过比对原文和用户段落内容，确实可以看到大段文字高度重合，结构和表述方式基本一致，且连公式引用顺序都一致，基本可以判定为抄袭。\n\n2. 是否有遗漏  \nMain Model 分析聚焦于用户段落与第一条相似文献的文字重合和表述一致性，未对其他两条相似文献进行详细比对。但由于用户段落与第一条文献已高度一致，其他两条虽然相关，但重合度较低，因此分析的重点选择是合理的，没有明显遗漏。\n\n建议：  \n- 分析结论准确，建议用户段落需进行改写或注明出处，以避免学术不端。  \n- 若需更全面，可以进一步核查与Top 2、Top 3文献的相似性，但不影响主要判断。\n\n综上，Main Model 分析可信，无明显遗漏。",
            "Expert 2 Feedback: 作为检查专家(Expert 2)，我认为Main Model的分析是可信的。理由如下：\n\n- Main Model明确指出用户段落与相似文献第一条存在大量文字重叠，描述YOLO的one-stage方法、图片分区、anchor box设置等内容几乎完全一致。\n- Main Model也指出了对公式Eq. (4)到Eq. (7)的引用方式完全相同，属于明显抄袭倾向，建议改写或注明出处。\n- 这些判断有事实依据，且引用比对准确。\n\n可能的遗漏：\n- Main Model主要关注了文字表述和公式引用的相似性，但未提及图片（如图13）是否也有引用不当或抄袭问题。\n- 未进一步讨论用户段落是否存在适当的引用标注。\n- 未对第二、三条相似文献内容与用户段落的相似度做进一步分析，但根据已给出的证据，第一条已足以说明问题。\n\n结论：分析可信，建议可补充对图片引用和引用标注情况的检查。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"根据Main Model和两位专家的分析，用户段落与第一条相似文献存在大量文字重叠和表述一致，属于明显的抄袭倾向，且未见有适当的引用标注。虽然对其他文献的比对未详细展开，但已有证据足以怀疑存在抄袭。因此应选择ABSTAIN。\"\n}",
        "plagiarism_confidence": 91,
        "plagiarism_percentage": 95,
        "plagiarism_snippet": [
            "在物體偵測的方法上，yolo 採用",
            "one-stage 的方式，直接從圖片中偵測定界框 (bounding box)，其方式如下，首先將圖片等分成",
            "13 所示)，而每個區",
            "N 個事先設計好的",
            "anchor box，而神經網路則負責預測每個",
            "anchor box 的長寬",
            "變化、中心位置位移以及所屬類別。網路估計結果與定界框關係可參考",
            "Eq. (4)",
            "Eq. (7)",
            "anchor box",
            " anchor",
            "olo ",
            "one-stage ",
            "bounding box"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "Yolo 為2018 年提出的物體偵測神經網路架構，當時在[17][40]兩個資料集皆為 state-of-the-art，同時能達到實時(real-time)偵測。本篇為yolo 系列的第三代，方法與前 一代相似，主要以兩種方式改良網路架構，首先，它使用了resnet[32]中的殘差網路架 構設計更深的網路，其次，它參考了FPN 的架構設計，加入多尺度預測以及多尺度特 徵融合。 在物體偵測的方法上，yolo 採用one-stage 的方式，直接從圖片中偵測定界框 (bounding box)，其方式如下，首先將圖片等分成S × S個區塊(如圖13 所示)，而每個區 塊會有N 個事先設計好的anchor box，而神經網路則負責預測每個anchor box 的長寬 變化、中心位置位移以及所屬類別。網路估計結果與定界框關係可參考Eq. (4)到Eq. (7)， 𝑏𝑥= 𝜎(𝑡𝑥) + 𝑐𝑥 (4) 𝑏𝑦= 𝜎(𝑡𝑦) + 𝑐𝑦 (5) 𝑏𝑤= 𝑝𝑤𝑒𝑡𝑤 (6) 𝑏ℎ= 𝑝ℎ𝑒𝑡ℎ (7) 其中𝑡𝑥, 𝑡𝑦, 𝑡𝑤, 𝑡ℎ為網路估計的結果，(𝑏𝑥, 𝑏𝑦)為定界框中心位置，(𝑏𝑤, 𝑏ℎ)為定界框 的寬與長，(𝑝ℎ, 𝑝𝑤)為anchor box 的寬與長，(𝑐𝑥, 𝑦𝑦)為anchor box 所在區域左上角的位 置，𝜎()則代表羅吉斯函數。 圖13、圖片等分𝐒× 𝐒個區塊示意圖，圖片出自[42] 第四章、問題描述及系統架構",
                "cross_score": 0.9651057124137878,
                "embedding_sim": 0.9096834659576416,
                "overlaps": [
                    "為網路估計的結果，(",
                    "為定界框中心位置，(",
                    "為定界框",
                    "的寬與長，(",
                    "anchor box 的寬與長，(",
                    "anchor box 所在區域左上角的位"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/13.txt"
            },
            {
                "content": "原架構 9DoF SE-YOLO 為一階段偵測網路，由於要將對齊偵測模組 (align detection model, ADM) 加入原架構，使網路能先提出能對預訂的錨 框個別進行大小及位置的調整，再以錨框內的特徵迴歸出更準確的結果， 因此我們提出的架構會有兩階段偵測和一次的輸出。 第一次偵測為針對影像平面的物件偵測，以cx, cy 表示影像左上角至 網格的水平及垂直距離，σ為 sigmoid 函數，tx, ty 為預測物件的中心點座 - 32 - 標，並在每個網格中預先定義一種長寬比的錨框 (anchor box) pw, ph，錨 框的設置方式如同 YOLOv3 是以離線的 K-means 類聚訓練集的物件真 實數據 (ground truth) 的長寬比，但不同的是YOLOv3 設置五種不同長寬 比的錨框。而tw、th 為預測框之長寬大小比例，及是否包含物體的置信度 to (confidence)，預測值對應於邊界框值bx、by、bw、bh，如圖 3.9 所示， 我們將預測的值用以調整所預定的錨框，得到學習到的錨框 (learned anchor)。 圖 3.9. 第一次偵測的錨框與學習到的錨框之關係。 第一次偵測出的張量格式為預測之物件在圖像平面的資訊，包括表 示預測框中心點的平移分量x, y，及預測框的寬高w, h，如圖 3.10 所示。 - 33 - 圖 3.10. 第一次偵測所得到的資料之張量格式。 第二次偵測為針對物件偵測的位置與類別與原架構相同，為針對3D 空間的物件偵測。以cx, cy 表示影像左上角至網格的水平及垂直距離，σ 為 sigmoid 函數，tx, ty 為預測物件的中心點座標，tz 為預測之深度，pw, ph, pl 為在每個網格中設有的錨框之長寬高，tw, th, tl 為預測框之長寬高大小比 例， qt , 1qt , qt , qt 為以四元數表示的預測框之旋轉姿態，預測值對應於 邊界框值bx, by, bz, bw, bh, bl, qb , 1qb , qb , 3qb ，如圖 3.2 所示。 第二次偵測輸出的張量格式為預測的物件在3D 空間下的9DoF 資 訊，包括表示預測框中心點的平移分量x, y, z，預測框姿態的四元數旋轉 分量q0, q1, q2, q3，此外預測物件在真實世界下的長寬高w, h, l，如圖 3.3 所示。 - 34 -",
                "cross_score": 0.8886919021606445,
                "embedding_sim": 0.8762455582618713,
                "overlaps": [
                    "tx, ty",
                    "anchor box",
                    " anchor"
                ],
                "file_path": "dataset/paraphrased_dataset/source/ncu_2020/343.txt"
            },
            {
                "content": "在輸入端，YOLOv3 只使用 RGB 的色彩資訊作為輸入的資料，因為 YOLOv3 只進行平面的物件偵測；但為了偵測物件的三維空間資訊，深度 資料是不可或缺的，因此作者在輸入端增加一個單通道 (channel) 的深度 資料，變為使用 RGB-D 四通道資料作為輸入端資料，使網路可以獲得色 彩與深度資訊，並以 Darknet-53 提取特徵。 - 24 - 在偵測物件位置及類別的方面，以cx, cy 表示影像左上角至網格的水 平及垂直距離，σ為 sigmoid 函數，tx, ty 為預測物件的中心點座標，tz 為 預測之深度，pw, ph, pl 為在每個網格中設有的錨框之長寬高。在 YOLOv3 的錨框尺寸會根據特徵圖大小而調整，不同於 YOLOv3 的圖像座標之錨 框設計，採用的錨框尺寸是物件在相機座標下的長寬高，因此不會根據特 徵圖的大小而調整；tw, th, tl 為預測框之長寬高大小比例， qt , 1qt , qt , qt 為以四元數 (quaternion) 表示的預測框之旋轉姿態，預測值對應於邊界 框值bx, by, bz, bw, bh, bl, qb , 1qb , qb , 3qb ，如圖 3.2 所示。 圖 3.2. 9DoF SE-YOLO 的預測邊界框與錨框之關係。 9DoF SE-YOLO 的輸出張量 (tensor) 格式為預測之物件在三維空間 下的 9DoF 資訊，包括用來表示預測框中心點的平移分量x, y, z，預測框 - 25 - 姿態的四元數旋轉分量q0, q1, q2, q3，此外預測框的w, h, l 為物體在真實 世界下的長寬高，如圖 3.3 所示。 圖 3.3. 輸出的特徵圖張量格式。 其中預測值x, y 為圖像座標，為了求出物件在真實世界的相機座標 Tx, Ty, Tz，透過預測值Tz 與相機的內參矩陣，由公式 (3.1) 可求出物件邊 界框之平移分量Tx 和Ty，並以預測值w, h, l 建立出物件邊界框的八個角 點，最後以q0, q1, q2, q3 求出物件邊界框的旋轉姿態，         x x z y y z T x f p T T y f p T ，                     (3.1) - 26 - 其中f 為相機焦距，(px, py)為影像平面中心點。",
                "cross_score": 0.7375028729438782,
                "embedding_sim": 0.8588449954986572,
                "overlaps": [
                    "cx, cy"
                ],
                "file_path": "dataset/paraphrased_dataset/source/ncu_2020/338.txt"
            }
        ],
        "main_analysis": "有明显文字重叠，存在抄袭倾向。  \n用户段落与文献段落中的变量定义（tx, ty, tw, th、bx, by、bw, bh、ph, pw、cx, cy）及其所代表的意义几乎完全一致，表述顺序和内容高度相似，仅有少量词语调整，缺乏原创性。建议用户用自己的话进行改写或注明引用来源。",
        "feedbacks": [
            "Expert 1 Feedback: 作为检查专家(Expert 1)，我的审阅意见如下：\n\nMain Model 的分析是可信的。其指出用户段落与相似文献在变量定义、表述顺序和内容上高度一致，仅有少量词语调整，缺乏原创性，判断存在明显文字重叠和抄袭倾向，这一结论有充分依据。\n\n但Main Model的分析略有遗漏之处：\n- 未具体指出“用户段落”与哪一篇（或哪几篇）相似文献的重叠最为严重，建议明确引用相应文献段落或编号，便于溯源。\n- 未评价用户段落是否有对关键公式或推导进行了创新性解释或补充，建议进一步考察用户是否仅是抄袭变量定义，还是整体内容缺乏创新。\n- 未对“注明引用来源”这一建议给出具体方式（如参考文献格式、引用位置），可进一步完善建议。\n\n总体结论：分析可信，结论准确，但可补充对比细节和改写/引用的具体建议。",
            "Expert 2 Feedback: Main Model的分析基本可信。其指出用户段落与相似文献在变量定义、表述顺序和内容上高度相似，仅有少量词语调整，缺乏原创性，有抄袭倾向，这与相似文献内容对比后是成立的。\n\n但分析略有遗漏：  \n1. Main Model未具体指出用户段落是否直接引用了公式或仅限于变量定义层面。实际上，用户段落只是列举变量意义，没有涉及公式推导或完整段落复述，抄袭程度可进一步细化。\n2. Main Model未区分“通用变量解释”与“独特表达”。YOLO相关变量定义在学术界较为通用，如直接照搬文献表达则需标注引用，但若只涉及变量名及简要定义，可建议用户以更个性化方式表述。\n\n综上，Main Model结论大体正确，但可补充对抄袭程度的精细判断及变量定义通用性的说明。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"用户段落与相似文献在变量定义、表述顺序和内容上高度一致，仅有少量词语调整，缺乏原创性，存在明显的文字重叠和抄袭倾向。虽然这些变量定义在领域内较为通用，但用户未进行个性化改写或明确标注引用，无法排除抄袭可能性，因此应选择ABSTAIN。\"\n}",
        "plagiarism_confidence": 86,
        "plagiarism_percentage": 93,
        "plagiarism_snippet": [
            "為網路估計的結果，(",
            "為定界框中心位置，(",
            "為定界框",
            "的寬與長，(",
            "anchor box 的寬與長，(",
            "anchor box 所在區域左上角的位",
            "tx, ty",
            "anchor box",
            " anchor",
            "cx, cy"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "本論文分成六章，第一章介紹動機與成果。第二章介紹手部姿勢與關鍵點抽取的 相關研究。第三章介紹本論文所提出的系統架構所使用到的技術描述。第四章介紹本 論文系統所針對的問題的明確定義以及如何修改、整合第三章所提到的技術成為最終 的系統架構。第五章描述實驗方式以及結果。第六章則為論文的結論以及未來方向。 第二章、手部姿勢及關鍵點抽取相關研究 手部姿勢估計一直以來都是電腦視覺領域中重要的研究方向之一，目前在此類問 題上，主流方法為藉由神經網路估計關鍵點位置，再以關鍵點資訊推論手部姿勢，因 此本章主要介紹手部姿勢以及關鍵點估計的相關研究。而在關鍵點估計的部分，由於 網路架構設計的相關研究大多都以人體關鍵點做為研究對象，且手部與人體的關鍵點 估計並無太大差異，因此此處以多人體關鍵點估計的相關研究為介紹對象。此外，本 論文最終是利用3D 手部模型做為手部姿勢估測的主要限制條件 (Model-constrained estimation method)，因此本章最後會介紹手部模型的相關研究。",
                "cross_score": 0.9680633544921875,
                "embedding_sim": 0.9411404132843018,
                "overlaps": [
                    "手部姿勢",
                    "論文系統",
                    "手部姿勢"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/2.txt"
            },
            {
                "content": "本論文以一般攝影機做為使用平台，結合神經網路與手部模型，建立手部姿勢估 計系統，以多任務學習的方式與手部語意切割系統做整合。並以藉由手掌作為初始值 與修改迭代演算法來改善逆向運動學的收斂狀況。圖1 為本論文所提出系統的實際估 測結果。整體來說，本論文的主要貢獻有二： 一、設計實作一個關鍵點估計網路，並藉由多任務學習同時提升關鍵點估計以及語意 切割兩者的準確度。 二、提出以神經網路估計手掌方向來做為初始值，改善迭代的結果。 圖1、實際估測結果。左邊為輸入影像、標上估測出來的手指關鍵點，右邊為根據估測出來的 參數所繪製的3D 手模型。",
                "cross_score": 0.9616437554359436,
                "embedding_sim": 0.9273208379745483,
                "overlaps": [
                    "機做為使用平台",
                    "手部姿勢"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/1.txt"
            },
            {
                "content": "本論文研究目標為以單一相機做為使用平台的手部姿勢(hand pose)估計，本論文系 統以一般低價網路攝影機拍攝的彩色影像作為輸入，主要輸出為相對於手掌心的3D 關 鍵點位置(也就是3D 坐標的原點是定位於掌心，而坐標的X, Y, Z 方向在第4.3 節會再 說明)、以及2D 手部關鍵點位置。此處2D 關鍵點是指手部關鍵點在影像中的位置，因 為我們假設了一個3D 的手部模型，即使只用單一攝影機以及2D 的關鍵點也可大約推 算出3D 的手部關鍵點坐標。手部關鍵點指的是手掌的中心、手指關節、手指指尖共 21 點，請參考圖14。而手部3D 關鍵點通常被稱為手部姿勢。 圖14、手部關鍵點示意圖，紅點為手部關鍵點位置 本論文最終選擇以Panteleris 等人所設計的系統作為基礎的系統架構[15]，在此架 構上最需要改進的地方有兩個，第一是手部關鍵點位置的正確性，第二是逆向運動學 中最佳化演算法的收斂結果正確度。本論文主要針對此二問題做改進。",
                "cross_score": 0.9260082840919495,
                "embedding_sim": 0.9735018014907837,
                "overlaps": [
                    "本論文研究目標為以單一相機做為使用平台的手部姿勢(hand pose)估計",
                    "本論文系",
                    "統以一般低價網路攝影機拍攝的彩色影像作為輸入",
                    "主要輸出為相對於手掌心的3D",
                    "鍵點位置(也就是3D",
                    "坐標的原點是定位於掌心",
                    "而坐標的X, Y, Z",
                    "方向在第4.3",
                    "說明)、以及2D",
                    "手部關鍵點位置。此處2D 關鍵點是指手部關鍵點在影像中的位置",
                    "為我們假設了一個3D",
                    "的手部模型",
                    "即使只用單一攝影機以及2D",
                    "的關鍵點也可大約推",
                    "算出3D",
                    "的手部關鍵點坐標。手部關鍵點指的是手掌的中心、手指關節、手指指尖共",
                    "請參考圖14。而手部3D",
                    "關鍵點通常被稱為手部姿勢。"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/14.txt"
            }
        ],
        "main_analysis": "存在大量文字重叠，尤其是在系统输入、输出定义、手部关键点说明等部分，用户段落与第三条最相似文献段落几乎一致，仅有少量措辞和标点差异。已构成明显抄袭倾向，建议用户重新表述内容，避免直接引用。",
        "feedbacks": [
            "Expert 1 Feedback: 审阅意见如下：\n\n1. 分析可信度  \nMain Model 分析是可信的。它准确指出了用户段落与第三条相似文献在系统输入/输出定义、手部关键点描述等方面存在大量文字重叠，内容几乎一致，仅有细微的措辞和标点变化。这种情况确实已构成明显抄袭倾向，分析结论成立。\n\n2. 是否有遗漏  \nMain Model 分析基本覆盖了核心问题，即直接抄袭和内容重叠。但分析略显简略，可以补充以下两点以更全面：\n\n- 可进一步指出用户段落与相似文献的重叠比例（例如具体句子或段落），以及是否有结构或技术创新，否则容易被认为是“拼接”或“复制粘贴”。\n- 可建议用户在改写时，除了表述方式外，应增加自身的研究思考和创新点，避免仅停留在文字层面的修改。\n\n总体，Main Model 分析结论可信，没有重大遗漏，但可进一步细化和完善建议内容。",
            "Expert 2 Feedback: 作为检查专家（Expert 2），我认为Main Model的分析是可信的，理由如下：\n\n- Main Model准确指出了用户段落与第三条相似文献在系统输入、输出定义、手部关键点说明等关键表述上存在大量文字重叠，属于明显的抄袭倾向。\n- 分析已明确建议用户需重新表述内容，避免直接引用原文，符合学术规范。\n\n是否有遗漏：\n\n- Main Model的分析主要聚焦于“文字重叠”和“抄袭倾向”两个层面，未对技术内容、创新点、结构等方面做进一步分析，但针对抄袭判定已足够。\n- 若需补充，可进一步说明是否有未注明引用、是否影响论文整体创新性等，但就当前问题而言，Main Model的分析已覆盖主要问题点。\n\n结论：分析可信，未有明显遗漏。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"根据Main Model分析及两位专家意见，用户段落与第三条相似文献在系统输入/输出定义、手部关键点说明等处存在大量文字重叠，内容几乎一致，仅有少量措辞和标点差异，已构成明显抄袭倾向。因此应怀疑存在抄袭，不宜直接接受。\"\n}",
        "plagiarism_confidence": 95,
        "plagiarism_percentage": 98,
        "plagiarism_snippet": [
            "手部姿勢",
            "論文系統",
            "機做為使用平台",
            "本論文研究目標為以單一相機做為使用平台的手部姿勢(hand pose)估計",
            "本論文系",
            "統以一般低價網路攝影機拍攝的彩色影像作為輸入",
            "主要輸出為相對於手掌心的3D",
            "鍵點位置(也就是3D",
            "坐標的原點是定位於掌心",
            "而坐標的X, Y, Z",
            "方向在第4.3",
            "說明)、以及2D",
            "手部關鍵點位置。此處2D 關鍵點是指手部關鍵點在影像中的位置",
            "為我們假設了一個3D",
            "的手部模型",
            "即使只用單一攝影機以及2D",
            "的關鍵點也可大約推",
            "算出3D",
            "的手部關鍵點坐標。手部關鍵點指的是手掌的中心、手指關節、手指指尖共",
            "請參考圖14。而手部3D",
            "關鍵點通常被稱為手部姿勢。"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "本論文所提出的系統架構如圖15 所示，是以在3.2 節所介紹的系統(圖12)[15]為 基礎進行修改。在網路架構的部分，我們最終選擇MSPN[8]、yolov3[34]所採用的架 構，同時我們將系統中2D 關鍵點估計的神經網路，與deeplabv3+[31]進行整合，設計 一個多任務學習(multi-task learning)的網路架構。逆向運動學的部分，本論文以 Levenberg-Marquardt 演算法最佳化，並以ResNet[32]預測手掌orientation 作為迭代的初 始值，以及[33]中的方法修改最佳化方式，改善迭代的收斂狀況。以下介紹本論文對於 Panteleris 等人所提出的架構[15]所修改的部分。 圖15、本論文所提出的系統架構圖",
                "cross_score": 0.9756255745887756,
                "embedding_sim": 0.974783182144165,
                "overlaps": [
                    "所提出的系統架構如圖15",
                    "是以在3.2",
                    "節所介紹的系統(圖12)[15]為 基礎進行修改。在網路架構的部分",
                    "我們最終選擇MSPN[8]、yolov3[34]所採用的架 構",
                    "同時我們將系統中2D",
                    "關鍵點估計的神經網路",
                    "與deeplabv3+[31]進行整合",
                    "設計 一個多任務學習(multi-task learning)的網路架構。逆向運動學的部分",
                    "本論文以 Levenberg-Marquardt 演算法最佳化",
                    "ResNet[32]預測手掌",
                    "orientation 作為迭代的初 始值",
                    "以及[33]中的方法修改最佳化方式",
                    "改善迭代的收斂狀況。以下介紹本論文對於 Panteleris 等人所提出的架構[15]所修改的部分。 ",
                    "所提出的"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/15.txt"
            },
            {
                "content": "當我們以神經網路所估計的2D 關鍵點位置作為輸入時，我們注意到如果有少數 2D 關鍵點估計錯誤，可能會大大影響逆向運動學之結果，因此我們將Eq. (10)稍作修 改，多加入介於0 到1 之間變數𝑟，首先將Eq.(9)中目標函數每個關鍵點的平方差都乘 上一個變數𝑟𝑖，作為每個關鍵點的權重，同時為避免最佳化演算法讓𝑟𝑖為0 來降低目標 函數的值，因此我們在目標函數後加上𝛼(1 −𝑟𝑖)2來避免，此方法可以使最佳化演算法 自己決定每個關鍵點所佔的權重，讓目標函數增加一些彈性，並非絕對相信神經網路 所估計出的結果，可將式子改寫成 ∑𝑟𝑖𝑝𝑖((𝑥𝑖−𝑢𝑖)2 + (𝑦𝑖−𝑣𝑖)2)) + 𝛼(1 −𝑟𝑖)2 𝑖=1 (10) 其中𝛼為常數。 最後為了確認本節演算法在正常狀況下的表現，我們以神經網路估計的2D 關鍵點 做為目標，MANO 作為手部模型，對本節所提到的演算法做實驗，測試個別以及同時 使用的效果，表7 為實驗結果。 表7、本節實驗結果 With Eq.(10)     Palm orientation   Hierarchical optimization   Mean EPE (mm) RHD 29.99 28.44 25.78 24.48 21.87 STB 31.29 31.03 30.88 29.57 29.47",
                "cross_score": 0.8931875228881836,
                "embedding_sim": 0.9283150434494019,
                "overlaps": [
                    "關鍵點位置",
                    "關鍵點估計",
                    "逆向運動學"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/26.txt"
            },
            {
                "content": "當我們以正確的2D 關鍵點位置作為逆向運動學的目標時，我們發現迭代的收斂狀 況並不理想，容易陷入局部最小值，此類問題常見的解決方向有二，分別為迭代初始 值以及最佳化方式。下面我們分別從這兩個方向做改善。 首先，如同4.3 節所述，我們將估計手掌朝向視為分類問題，我們嘗試兩種分類方 式，第一種以歐拉角表示手部方向(orientation)，共有三個維度，其中兩個維度的角度 範圍為0~2π，其中一個維度為0~π，每 𝜋 4分成一類，共分成256 類。第二種，我們先 將圖片進行預處理，旋轉圖片使手掌到中指垂直，同樣以歐拉角表示方向，共有兩個 維度，其中一個維度角度範圍為0~2π，另一個維度為0~π，共分32 類。由表6 的實 驗結果可看出第二種方法較好，因此我們採用第二種分類方式。 表6、兩種分類方式結果比較 正確率/旋轉誤差角度 RHD STB 256 類 30.1% 33.19 º 32.5% 37.69 º 32 類 66.5% 18.92 º 64.5% 26.36 º 接下來我們先我們對Romero 等人所提出的資料集[30]做PCA，得到PC-space，在 使用Hierarchical Optimization 演算法[33]進行實驗，我們測試分成不同階段數量的結 果，實驗結果可見圖24，可以看出在分成四個或以上的階段數量時，效果大致相同， 因此我們最終分成四個階段來執行此演算法。圖25 為本節實驗解果 圖24、Hierarchical Optimization 不同階段數量在RHD 上的實驗結果 圖25、結果比較圖，每組包含上下兩張圖片，由左到由分別為ground truth、前人提出的逆向 運動學、以及用本論文提出的設定初始值方法所算出來的結果。",
                "cross_score": 0.8296728134155273,
                "embedding_sim": 0.9278152585029602,
                "overlaps": [
                    "關鍵點位置",
                    "逆向運動學",
                    "最佳化方式"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/25.txt"
            }
        ],
        "main_analysis": "经检查，用户段落与最相似文献段落存在大量文字重叠，特别是在系统架构描述、网络结构选择及优化方法部分，许多句子和表述几乎完全一致，仅有少量词序或连接词的微调。这种情况已属于明显的抄袭倾向，建议进行大幅度改写并标明引用出处。",
        "feedbacks": [
            "Expert 1 Feedback: 作为检查专家（Expert 1），我认为Main Model的分析基本可信，理由如下：\n\n1. 分析准确性：Main Model准确指出了用户段落与相似文献在系统架构描述、网络结构选择及优化方法等关键部分存在大量文字重叠，且重叠句子和表述几乎完全一致，这属于典型的抄袭行为。\n2. 分析结论合理：Main Model建议大幅度改写并标明引用出处，这符合学术规范和查重处理的通用要求。\n\n可能的遗漏：\n\n- Main Model没有具体列举出哪些句子或段落高度重合，缺乏具体实例（虽然已指出“许多句子和表述几乎完全一致”）。\n- 未对引用标注是否规范进行进一步分析（如是否有明显引用但未用引号、是否存在拼接抄袭等具体情况）。\n- 没有分析用户段落中是否有创新性内容，全部聚焦在重合和抄袭风险上。\n\n总体结论：Main Model的分析可信，结论合理，但略显简略，可补充具体重合例句和对引用规范性的细致检查。",
            "Expert 2 Feedback: 作为检查专家（Expert 2），我认为Main Model的分析基本可信，理由如下：\n\n1. 明确指出大量文字重叠：分析准确指出用户段落与相似文献在系统架构描述、网络结构选择及优化方法等核心内容上有大量文字重叠，且表述几乎一致，仅有词序微调，这属于明显抄袭。\n2. 给出改写与引用建议：分析建议大幅度改写并标明引用出处，符合学术规范要求。\n\n可能的遗漏：\n\n- 未具体指出哪些句子或段落存在重叠，可进一步举例以增强说服力。\n- 未分析是否有图表、公式或数据也被直接引用或抄袭。\n- 未评价参考文献引用是否规范，例如是否正确标注了[15]、[8]等出处。\n\n总体结论：分析可信，结论合理，但可补充更具体的重合内容举例和对引用规范的进一步检查。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"根据Main Model及两位专家的分析，用户段落与相似文献存在大量文字重叠，表述几乎完全一致，仅有少量调整，这属于明显的抄袭风险。虽然分析中未给出具体重合句子，但已有充分理由怀疑存在抄袭，因此不能直接接受，应当选择ABSTAIN。\"\n}",
        "plagiarism_confidence": 90,
        "plagiarism_percentage": 95,
        "plagiarism_snippet": [
            "所提出的系統架構如圖15",
            "是以在3.2",
            "節所介紹的系統(圖12)[15]為 基礎進行修改。在網路架構的部分",
            "我們最終選擇MSPN[8]、yolov3[34]所採用的架 構",
            "同時我們將系統中2D",
            "關鍵點估計的神經網路",
            "與deeplabv3+[31]進行整合",
            "設計 一個多任務學習(multi-task learning)的網路架構。逆向運動學的部分",
            "本論文以 Levenberg-Marquardt 演算法最佳化",
            "ResNet[32]預測手掌",
            "orientation 作為迭代的初 始值",
            "以及[33]中的方法修改最佳化方式",
            "改善迭代的收斂狀況。以下介紹本論文對於 Panteleris 等人所提出的架構[15]所修改的部分。 ",
            "所提出的",
            "關鍵點位置",
            "關鍵點估計",
            "逆向運動學",
            "最佳化方式"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "本論文以一般攝影機做為使用平台，結合神經網路與手部模型，建立手部姿勢估 計系統，以多任務學習的方式與手部語意切割系統做整合。並以藉由手掌作為初始值 與修改迭代演算法來改善逆向運動學的收斂狀況。圖1 為本論文所提出系統的實際估 測結果。整體來說，本論文的主要貢獻有二： 一、設計實作一個關鍵點估計網路，並藉由多任務學習同時提升關鍵點估計以及語意 切割兩者的準確度。 二、提出以神經網路估計手掌方向來做為初始值，改善迭代的結果。 圖1、實際估測結果。左邊為輸入影像、標上估測出來的手指關鍵點，右邊為根據估測出來的 參數所繪製的3D 手模型。",
                "cross_score": 0.845242440700531,
                "embedding_sim": 0.8881199955940247,
                "overlaps": [
                    "作為初始值",
                    "神經網路"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/1.txt"
            },
            {
                "content": "過去的研究皆顯示良好的初始值對於非線性最佳化有巨大的影響([21][26])，然而 Xu 和Cheng[21]或Ye 等人[26]所提出的技術是基於深度資訊的方法，無法直接使用在 我們的研究中。根據前人研究所獲得的經驗[21][44][28]，我們可以知道，手掌是否能 找到是結果好壞的關鍵。因此我們以估計手掌朝向的方向，作為初始值。近期較為相 關的研究把估計人體的方向視為一種分類問題[22][43]，，如圖16 所示，將水平360 度分成八個方向，並用神經網路進行分類，來達到估計人體方向的目的。 圖16、人體朝向分類示意圖，圖片出自[43] 本論文的問題與Choi 等人[22]或Liu 等人[43]所提出的情況略有不同。在我們的使 用情境下，手掌朝向可能是任意方向，因此本論文必需使用不同的分類方式。我們採 用了兩種不同的方法，一是把所有3D 方向依歐拉角分成256 個不同的方向(x, z 軸各分 成8 類角度，y 軸分成4 類角度)。另一種方法則是假設掌心到中指的MP 關節的直線 在圖片中為垂直線，以y 軸為選轉軸的360 度分8 類，以x 軸為旋轉軸的180 度分4 類，共32 類。經實驗證實，以這種假設做分類相較於不做假設分成256 類的好處有 二，第一是容易製造訓練資料集，第二是圖片經過預處理後神經網路訓練結果也較 好，詳細實驗請參考5.7 節。文中坐標軸方向請參考圖17。 圖17、角度分類法的坐標軸示意圖",
                "cross_score": 0.7560569643974304,
                "embedding_sim": 0.9359731674194336,
                "overlaps": [
                    "找到是結果好壞的關鍵。因此我們以估計手掌朝向的方向",
                    "作為初始值。近期較為相",
                    "關的研究把估計人體的方向視為一種分類問題[22][43]",
                    "如圖16",
                    "將水平360",
                    "度分成八個方向",
                    "並用神經網路進行分類",
                    "來達到估計人體方向的目的。"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/16.txt"
            },
            {
                "content": "當我們以正確的2D 關鍵點位置作為逆向運動學的目標時，我們發現迭代的收斂狀 況並不理想，容易陷入局部最小值，此類問題常見的解決方向有二，分別為迭代初始 值以及最佳化方式。下面我們分別從這兩個方向做改善。 首先，如同4.3 節所述，我們將估計手掌朝向視為分類問題，我們嘗試兩種分類方 式，第一種以歐拉角表示手部方向(orientation)，共有三個維度，其中兩個維度的角度 範圍為0~2π，其中一個維度為0~π，每 𝜋 4分成一類，共分成256 類。第二種，我們先 將圖片進行預處理，旋轉圖片使手掌到中指垂直，同樣以歐拉角表示方向，共有兩個 維度，其中一個維度角度範圍為0~2π，另一個維度為0~π，共分32 類。由表6 的實 驗結果可看出第二種方法較好，因此我們採用第二種分類方式。 表6、兩種分類方式結果比較 正確率/旋轉誤差角度 RHD STB 256 類 30.1% 33.19 º 32.5% 37.69 º 32 類 66.5% 18.92 º 64.5% 26.36 º 接下來我們先我們對Romero 等人所提出的資料集[30]做PCA，得到PC-space，在 使用Hierarchical Optimization 演算法[33]進行實驗，我們測試分成不同階段數量的結 果，實驗結果可見圖24，可以看出在分成四個或以上的階段數量時，效果大致相同， 因此我們最終分成四個階段來執行此演算法。圖25 為本節實驗解果 圖24、Hierarchical Optimization 不同階段數量在RHD 上的實驗結果 圖25、結果比較圖，每組包含上下兩張圖片，由左到由分別為ground truth、前人提出的逆向 運動學、以及用本論文提出的設定初始值方法所算出來的結果。",
                "cross_score": 0.3507709205150604,
                "embedding_sim": 0.8767433166503906,
                "overlaps": [
                    "估計手掌朝向",
                    "分類問題"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/25.txt"
            }
        ],
        "main_analysis": "存在大量文字重叠，用户段落与第二条相似文献段落在表达和内容上几乎完全一致，仅有极少字词调整，属于明显的抄袭行为。建议用户重新表述并注明引用来源。",
        "feedbacks": [
            "Expert 1 Feedback: 您的Main Model分析是可信的，结论准确。理由如下：\n\n- 事实准确：用户段落与相似文献第二条存在大量文字重叠，表达和内容几乎完全一致，仅个别词语做了微调，确实属于明显抄袭。\n- 建议合理：建议用户重新表述并注明引用来源，符合学术规范。\n\n可能的补充：\n\n- Main Model分析仅关注了文字重叠，并未具体指出用户段落中未标注引用，且直接使用了原文结构和内容，这属于更严重的学术不端，应进一步提醒用户引用规范。\n- Main Model可以补充说明：即使引用了参考文献，原文复制粘贴也不被允许，应以自己的语言进行总结和归纳。\n\n总体来看，Main Model的结论可信，分析全面，没有明显遗漏，仅建议在学术规范提醒方面更具体细致。",
            "Expert 2 Feedback: 作为检查专家(Expert 2)，我的审阅意见如下：\n\n1. 可信度评价  \nMain Model的分析是可信的。用户段落与相似文献第二条内容在表达和内容上确实高度一致，仅作了极少字词调整，属于明显的抄袭行为。\n\n2. 有无遗漏  \nMain Model的分析基本覆盖了主要问题（即文本高度重叠和抄袭），但略有遗漏：  \n- 没有具体指出用户段落没有对原始文献进行适当引用（如缺乏引用标注），而抄袭行为不仅仅是内容重叠，还包括未注明来源。\n- 没有进一步建议如何进行改写或规范引用格式。\n\n综上，Main Model的分析结论可信，但可以补充“未注明引用来源”这一点，并建议用户重写并严格注明出处。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"用户段落与相似文献存在大量文字重叠，表达和内容几乎完全一致，且未注明引用来源，属于明显的抄袭行为。因此应怀疑存在抄袭，不应接受。\"\n}",
        "plagiarism_confidence": 65,
        "plagiarism_percentage": 83,
        "plagiarism_snippet": [
            "作為初始值",
            "神經網路",
            "找到是結果好壞的關鍵。因此我們以估計手掌朝向的方向",
            "作為初始值。近期較為相",
            "關的研究把估計人體的方向視為一種分類問題[22][43]",
            "如圖16",
            "將水平360",
            "度分成八個方向",
            "並用神經網路進行分類",
            "來達到估計人體方向的目的。",
            "估計手掌朝向",
            "分類問題"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "當我們以正確的2D 關鍵點位置作為逆向運動學的目標時，我們發現迭代的收斂狀 況並不理想，容易陷入局部最小值，此類問題常見的解決方向有二，分別為迭代初始 值以及最佳化方式。下面我們分別從這兩個方向做改善。 首先，如同4.3 節所述，我們將估計手掌朝向視為分類問題，我們嘗試兩種分類方 式，第一種以歐拉角表示手部方向(orientation)，共有三個維度，其中兩個維度的角度 範圍為0~2π，其中一個維度為0~π，每 𝜋 4分成一類，共分成256 類。第二種，我們先 將圖片進行預處理，旋轉圖片使手掌到中指垂直，同樣以歐拉角表示方向，共有兩個 維度，其中一個維度角度範圍為0~2π，另一個維度為0~π，共分32 類。由表6 的實 驗結果可看出第二種方法較好，因此我們採用第二種分類方式。 表6、兩種分類方式結果比較 正確率/旋轉誤差角度 RHD STB 256 類 30.1% 33.19 º 32.5% 37.69 º 32 類 66.5% 18.92 º 64.5% 26.36 º 接下來我們先我們對Romero 等人所提出的資料集[30]做PCA，得到PC-space，在 使用Hierarchical Optimization 演算法[33]進行實驗，我們測試分成不同階段數量的結 果，實驗結果可見圖24，可以看出在分成四個或以上的階段數量時，效果大致相同， 因此我們最終分成四個階段來執行此演算法。圖25 為本節實驗解果 圖24、Hierarchical Optimization 不同階段數量在RHD 上的實驗結果 圖25、結果比較圖，每組包含上下兩張圖片，由左到由分別為ground truth、前人提出的逆向 運動學、以及用本論文提出的設定初始值方法所算出來的結果。",
                "cross_score": 0.2361260950565338,
                "embedding_sim": 0.9140169620513916,
                "overlaps": [
                    "手掌朝向",
                    "我們採用"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/25.txt"
            },
            {
                "content": "過去的研究皆顯示良好的初始值對於非線性最佳化有巨大的影響([21][26])，然而 Xu 和Cheng[21]或Ye 等人[26]所提出的技術是基於深度資訊的方法，無法直接使用在 我們的研究中。根據前人研究所獲得的經驗[21][44][28]，我們可以知道，手掌是否能 找到是結果好壞的關鍵。因此我們以估計手掌朝向的方向，作為初始值。近期較為相 關的研究把估計人體的方向視為一種分類問題[22][43]，，如圖16 所示，將水平360 度分成八個方向，並用神經網路進行分類，來達到估計人體方向的目的。 圖16、人體朝向分類示意圖，圖片出自[43] 本論文的問題與Choi 等人[22]或Liu 等人[43]所提出的情況略有不同。在我們的使 用情境下，手掌朝向可能是任意方向，因此本論文必需使用不同的分類方式。我們採 用了兩種不同的方法，一是把所有3D 方向依歐拉角分成256 個不同的方向(x, z 軸各分 成8 類角度，y 軸分成4 類角度)。另一種方法則是假設掌心到中指的MP 關節的直線 在圖片中為垂直線，以y 軸為選轉軸的360 度分8 類，以x 軸為旋轉軸的180 度分4 類，共32 類。經實驗證實，以這種假設做分類相較於不做假設分成256 類的好處有 二，第一是容易製造訓練資料集，第二是圖片經過預處理後神經網路訓練結果也較 好，詳細實驗請參考5.7 節。文中坐標軸方向請參考圖17。 圖17、角度分類法的坐標軸示意圖",
                "cross_score": 0.1588965505361557,
                "embedding_sim": 0.9603505730628967,
                "overlaps": [
                    "本論文的問題與Choi",
                    "等人[22]或Liu",
                    "等人[43]所提出的情況略有不同。在我們的使",
                    "用情境下",
                    "手掌朝向可能是任意方向",
                    "因此本論文必需使用不同的分類方式。我們採",
                    "用了兩種不同的方法",
                    "一是把所有3D",
                    "方向依歐拉角分成256",
                    "個不同的方向(x,",
                    "軸分成4",
                    "類角度)。另一種方法則是假設掌心到中指的MP",
                    "關節的直線",
                    "在圖片中為垂直線",
                    "軸為選轉軸的360",
                    "軸為旋轉軸的180",
                    "類。經實驗證實",
                    "以這種假設做分類相較於不做假設分成256",
                    "類的好處有",
                    "第一是容易製造訓練資料集",
                    "第二是圖片經過預處理後神經網路訓練結果也較",
                    "詳細實驗請參考5.7",
                    "節。文中坐標軸方向請參考圖17。"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/16.txt"
            },
            {
                "content": "2D、3D 關鍵點的部分，我們用以下三種方法作為衡量效果的標準，mean EPE(endpoint error):估計結果與正解之間的歐式距離的平均，PCK(percentage of correct keypoints):估計結果EPE 低於某個閥值的資料在資料集中的占比，AUC(area under the curve):用不同閥值的PCK 所畫成的曲線下的面積。此外由於我們是以單張圖片做估 計，因此我們不考慮尺度(scale)以及平移(translation)的差異，也就是說我們會將估計結 果按比例縮放、平移。而語意分割則是使用mIOU(mean intersection over union)當作評 估的標準。手掌朝向分類的部分，我們以正確率以及角度誤差來評估結果優劣，正確 率代表分類正確的百分比，而角度誤差是預測手掌朝向方向的結果與真正的結果之間 的最短的旋轉角度。",
                "cross_score": 0.12811590731143951,
                "embedding_sim": 0.8988685607910156,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/nycu/20.txt"
            }
        ],
        "main_analysis": "存在大量文字重叠，用户段落与最相似文献段落在描述“采用两种分类方法”、“将3D方向依欧拉角分为256类或32类”、“分类假设的优点”等内容时，表述几乎完全一致，甚至部分句子结构未做实质性调整。这种情况属于明显的抄袭倾向。",
        "feedbacks": [
            "Expert 1 Feedback: 作为检查专家（Expert 1），我认为Main Model的分析是可信的，理由如下：\n\n- Main Model准确指出了用户段落与相似文献（尤其是Top 3中的第2条）在“采用两种分类方法”、“3D方向依欧拉角分为256类或32类”、“分类假设的优点”等关键内容上的高度重叠，且表述与句子结构几乎未变。这些内容确实在用户段落与相似文献中大段落地直接对应，属于明显的抄袭倾向。\n- Main Model对具体重叠内容的概括是准确和直接的，没有夸大或遗漏主要事实。\n\n可能的遗漏：\n- Main Model的分析可以进一步补充——除了“表述几乎完全一致，甚至部分句子结构未做实质性调整”外，用户段落对原文的整体结构、核心数据（如分类数量、坐标轴设定等）也未作任何创新性改写，这进一步加重了抄袭的嫌疑。\n- Main Model未提及用户段落是否有对原文观点进行扩展、批判或创新（如是否有独立实验、不同的数据来源等），这一点可以作为进一步评判学术不端程度的参考。\n\n总体结论：Main Model的分析可信，没有实质性遗漏，但可补充用户段落缺乏创新或独立性。",
            "Expert 2 Feedback: 审阅意见如下：\n\n1. 可信性判断  \nMain Model 的分析是可信的。用户段落与相似文献Top 3中的第三段落在核心内容（采用两种分类方法、分类细节、分类假设带来的优点等）上存在大量文字重叠，表述方式几乎一致，甚至连部分句子结构、专业术语、分段方式都没有明显调整，属于明显的抄袭/剽窃行为。Main Model 的判断准确。\n\n2. 是否有遗漏  \nMain Model 的分析基本全面，但可以补充几点：\n\n- 用户段落与相似文献不仅在技术描述上重合，连表达顺序、分点内容都高度一致，几乎逐字复制，建议明确指出“段落整体抄袭”，而不仅仅是“部分句子结构未做实质性调整”。\n- Main Model 只关注了文字重叠，但未进一步分析是否有对原文内容进行创新性加工、解释或批判，实际并没有。用户段落只是轻微调整了部分语序。\n- 可建议Main Model补充说明：用户段落未对引用文献内容进行明确标注，存在学术不规范问题。\n\n结论  \nMain Model 的分析可信，未有实质性遗漏，但可补充强调“整体抄袭”特征及学术规范性问题。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"Main Model 的分析可信，准确指出了用户段落与相似文献在核心内容、表述、结构上的高度重叠，属于明显抄袭倾向。两位专家均认为分析结论准确、无实质性遗漏，仅建议补充细节，但未质疑判断本身。因此，应当接受 Main Model 的分析结论。\"\n}",
        "plagiarism_confidence": 17,
        "plagiarism_percentage": 7,
        "plagiarism_snippet": [
            "手掌朝向",
            "我們採用",
            "本論文的問題與Choi",
            "等人[22]或Liu",
            "等人[43]所提出的情況略有不同。在我們的使",
            "用情境下",
            "手掌朝向可能是任意方向",
            "因此本論文必需使用不同的分類方式。我們採",
            "用了兩種不同的方法",
            "一是把所有3D",
            "方向依歐拉角分成256",
            "個不同的方向(x,",
            "軸分成4",
            "類角度)。另一種方法則是假設掌心到中指的MP",
            "關節的直線",
            "在圖片中為垂直線",
            "軸為選轉軸的360",
            "軸為旋轉軸的180",
            "類。經實驗證實",
            "以這種假設做分類相較於不做假設分成256",
            "類的好處有",
            "第一是容易製造訓練資料集",
            "第二是圖片經過預處理後神經網路訓練結果也較",
            "詳細實驗請參考5.7",
            "節。文中坐標軸方向請參考圖17。"
        ],
        "verdict": "ACCEPT"
    },
    {
        "top_docs_info": [
            {
                "content": "Hierarchical optimization 的方法是由Schröder 等人所提出的最佳化方法[33]，主要 目的為改善逆向運動學中最佳化演算的收斂性，可以減少不自然姿勢以及收斂至局部 最小值的情況。 在實際情況下，手部不同關節的靈活度並不相同，然而在一般的最佳化演算法中 是直接對所有的維度一起求解，並且所有的維度都是一樣的權重，所以較容易有不自 然的手部姿勢出現。因此論文提出coarse-to-fine 的多階段最佳化方式，並不直接使用 全部的維度進行迭代，而是先在較低的維度中求解，再依序增加維度大小，讓演算法 先在較重要的空間中找解，再逐漸微調。而最佳化求解的空間則是以PCA 對手勢資料 集的關節角度計算來取得，得到的PCA 空間能表達各個關節之間的聯繫以及各個關節 的靈活度。演算法pseudo code 可參考圖18。 圖18、Hierarchical optimization 演算法pseudo code",
                "cross_score": 0.9990235567092896,
                "embedding_sim": 0.9283788204193115,
                "overlaps": [
                    "Hierarchical optimization 的方法是由Schröder 等人所提出的最佳化方法[33]",
                    "目的為改善逆向運動學中最佳化演算的收斂性",
                    "可以減少不自然姿勢以及收斂至局部",
                    "最小值的情況。"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/17.txt"
            },
            {
                "content": "當我們以正確的2D 關鍵點位置作為逆向運動學的目標時，我們發現迭代的收斂狀 況並不理想，容易陷入局部最小值，此類問題常見的解決方向有二，分別為迭代初始 值以及最佳化方式。下面我們分別從這兩個方向做改善。 首先，如同4.3 節所述，我們將估計手掌朝向視為分類問題，我們嘗試兩種分類方 式，第一種以歐拉角表示手部方向(orientation)，共有三個維度，其中兩個維度的角度 範圍為0~2π，其中一個維度為0~π，每 𝜋 4分成一類，共分成256 類。第二種，我們先 將圖片進行預處理，旋轉圖片使手掌到中指垂直，同樣以歐拉角表示方向，共有兩個 維度，其中一個維度角度範圍為0~2π，另一個維度為0~π，共分32 類。由表6 的實 驗結果可看出第二種方法較好，因此我們採用第二種分類方式。 表6、兩種分類方式結果比較 正確率/旋轉誤差角度 RHD STB 256 類 30.1% 33.19 º 32.5% 37.69 º 32 類 66.5% 18.92 º 64.5% 26.36 º 接下來我們先我們對Romero 等人所提出的資料集[30]做PCA，得到PC-space，在 使用Hierarchical Optimization 演算法[33]進行實驗，我們測試分成不同階段數量的結 果，實驗結果可見圖24，可以看出在分成四個或以上的階段數量時，效果大致相同， 因此我們最終分成四個階段來執行此演算法。圖25 為本節實驗解果 圖24、Hierarchical Optimization 不同階段數量在RHD 上的實驗結果 圖25、結果比較圖，每組包含上下兩張圖片，由左到由分別為ground truth、前人提出的逆向 運動學、以及用本論文提出的設定初始值方法所算出來的結果。",
                "cross_score": 0.985476553440094,
                "embedding_sim": 0.8762776255607605,
                "overlaps": [
                    "Hierarchical ",
                    "ptimization ",
                    "法[33]"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/25.txt"
            },
            {
                "content": "當我們以神經網路所估計的2D 關鍵點位置作為輸入時，我們注意到如果有少數 2D 關鍵點估計錯誤，可能會大大影響逆向運動學之結果，因此我們將Eq. (10)稍作修 改，多加入介於0 到1 之間變數𝑟，首先將Eq.(9)中目標函數每個關鍵點的平方差都乘 上一個變數𝑟𝑖，作為每個關鍵點的權重，同時為避免最佳化演算法讓𝑟𝑖為0 來降低目標 函數的值，因此我們在目標函數後加上𝛼(1 −𝑟𝑖)2來避免，此方法可以使最佳化演算法 自己決定每個關鍵點所佔的權重，讓目標函數增加一些彈性，並非絕對相信神經網路 所估計出的結果，可將式子改寫成 ∑𝑟𝑖𝑝𝑖((𝑥𝑖−𝑢𝑖)2 + (𝑦𝑖−𝑣𝑖)2)) + 𝛼(1 −𝑟𝑖)2 𝑖=1 (10) 其中𝛼為常數。 最後為了確認本節演算法在正常狀況下的表現，我們以神經網路估計的2D 關鍵點 做為目標，MANO 作為手部模型，對本節所提到的演算法做實驗，測試個別以及同時 使用的效果，表7 為實驗結果。 表7、本節實驗結果 With Eq.(10)     Palm orientation   Hierarchical optimization   Mean EPE (mm) RHD 29.99 28.44 25.78 24.48 21.87 STB 31.29 31.03 30.88 29.57 29.47",
                "cross_score": 0.9133427143096924,
                "embedding_sim": 0.8592093586921692,
                "overlaps": [
                    "Hierarchical optimization "
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/26.txt"
            }
        ],
        "main_analysis": "存在大量文字重叠，用户段落与最相似文献段落的前半部分几乎完全一致，特别是在Hierarchical optimization 方法的来源、目的及其在逆向运动学中的应用描述上，几乎逐字相同。这种情况属于明显的抄袭倾向。建议用户对内容进行改写，并注明引用来源。",
        "feedbacks": [
            "Expert 1 Feedback: 作为检查专家（Expert 1），我的意见如下：\n\nMain Model 的分析结论“存在大量文字重叠，属于明显的抄袭倾向，建议改写并注明引用”是可信的。理由如下：\n\n- 用户段落与相似文献前半部分几乎逐字重合，尤其在方法来源、目的及应用场景的描述上，属于明显的文字复制。\n- Main Model 已指出应进行改写并注明引用，符合学术规范。\n\n但Main Model 分析有如下小的遗漏：\n\n- 未明确指出用户段落是否有适当的引用标注（虽然文中有[33]，但未评述其是否与原文献对应、格式是否规范）。\n- 未提及该段落是否有对原文献内容进行了适当的理解性表达或仅仅是机械复制（实际为后者，但可进一步说明）。\n- 未对抄袭的严重程度做进一步细化（如是完全照搬还是部分改写）。\n\n总结：Main Model 的结论可信，但可补充对引用标注规范性的检查及抄袭类型细分的建议。",
            "Expert 2 Feedback: 作为检查专家（Expert 2），我认为Main Model的分析基本可信，理由如下：\n\n- Main Model准确指出了用户段落与相似文献段落之间存在大量文字重叠，尤其是在对Hierarchical optimization方法的来源、目的及应用的描述上几乎一致，这属于明显的抄袭倾向。\n- Main Model也提出了合理的建议：要求用户改写内容并注明引用来源。\n\n是否有遗漏：\n- Main Model的分析较为简明，但可以补充说明“抄袭倾向”的依据（如文字重合比例、句式结构完全一致等具体标准）。\n- 可进一步建议用户如何进行改写（例如：用自己的语言总结原文观点，避免逐字照搬）。\n- Main Model未对引用格式是否规范进行评价（如是否有适当的文献标注）。\n\n总体结论：Main Model的分析可信，能够准确识别抄袭风险。建议在反馈中补充更具体的改写指导和引用规范说明，以帮助用户合规撰写。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"用户段落与相似文献存在大量文字重叠，内容几乎逐字照搬，属于明显的抄袭行为。虽然有引用标注[33]，但未能体现对原文的理解性表达，且引用格式是否规范未有明确说明。因此，应当怀疑有抄袭，不能直接接受。\"\n}",
        "plagiarism_confidence": 97,
        "plagiarism_percentage": 98,
        "plagiarism_snippet": [
            "Hierarchical optimization 的方法是由Schröder 等人所提出的最佳化方法[33]",
            "目的為改善逆向運動學中最佳化演算的收斂性",
            "可以減少不自然姿勢以及收斂至局部",
            "最小值的情況。",
            "Hierarchical ",
            "ptimization ",
            "法[33]",
            "Hierarchical optimization "
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "Hierarchical optimization 的方法是由Schröder 等人所提出的最佳化方法[33]，主要 目的為改善逆向運動學中最佳化演算的收斂性，可以減少不自然姿勢以及收斂至局部 最小值的情況。 在實際情況下，手部不同關節的靈活度並不相同，然而在一般的最佳化演算法中 是直接對所有的維度一起求解，並且所有的維度都是一樣的權重，所以較容易有不自 然的手部姿勢出現。因此論文提出coarse-to-fine 的多階段最佳化方式，並不直接使用 全部的維度進行迭代，而是先在較低的維度中求解，再依序增加維度大小，讓演算法 先在較重要的空間中找解，再逐漸微調。而最佳化求解的空間則是以PCA 對手勢資料 集的關節角度計算來取得，得到的PCA 空間能表達各個關節之間的聯繫以及各個關節 的靈活度。演算法pseudo code 可參考圖18。 圖18、Hierarchical optimization 演算法pseudo code",
                "cross_score": 0.3946533501148224,
                "embedding_sim": 0.9546601176261902,
                "overlaps": [
                    "在實際情況下",
                    "手部不同關節的靈活度並不相同",
                    "然而在一般的最佳化演算法中",
                    "是直接對所有的維度一起求解",
                    "並且所有的維度都是一樣的權重",
                    "所以較容易有不自",
                    "然的手部姿勢出現。因此論文提出",
                    "coarse-to-fine",
                    "的多階段最佳化方式",
                    "並不直接使用",
                    "全部的維度進行迭代",
                    "而是先在較低的維度中求解",
                    "再依序增加維度大小",
                    "讓演算法",
                    "先在較重要的空間中找解",
                    "再逐漸微調。而最佳化求解的空間則是以PCA",
                    "對手勢資料",
                    "集的關節角度計算來取得",
                    "得到的PCA",
                    "空間能表達各個關節之間的聯繫以及各個關節",
                    "的靈活度。演算法",
                    "pseudo code 可參考圖18。"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/17.txt"
            },
            {
                "content": "當我們以神經網路所估計的2D 關鍵點位置作為輸入時，我們注意到如果有少數 2D 關鍵點估計錯誤，可能會大大影響逆向運動學之結果，因此我們將Eq. (10)稍作修 改，多加入介於0 到1 之間變數𝑟，首先將Eq.(9)中目標函數每個關鍵點的平方差都乘 上一個變數𝑟𝑖，作為每個關鍵點的權重，同時為避免最佳化演算法讓𝑟𝑖為0 來降低目標 函數的值，因此我們在目標函數後加上𝛼(1 −𝑟𝑖)2來避免，此方法可以使最佳化演算法 自己決定每個關鍵點所佔的權重，讓目標函數增加一些彈性，並非絕對相信神經網路 所估計出的結果，可將式子改寫成 ∑𝑟𝑖𝑝𝑖((𝑥𝑖−𝑢𝑖)2 + (𝑦𝑖−𝑣𝑖)2)) + 𝛼(1 −𝑟𝑖)2 𝑖=1 (10) 其中𝛼為常數。 最後為了確認本節演算法在正常狀況下的表現，我們以神經網路估計的2D 關鍵點 做為目標，MANO 作為手部模型，對本節所提到的演算法做實驗，測試個別以及同時 使用的效果，表7 為實驗結果。 表7、本節實驗結果 With Eq.(10)     Palm orientation   Hierarchical optimization   Mean EPE (mm) RHD 29.99 28.44 25.78 24.48 21.87 STB 31.29 31.03 30.88 29.57 29.47",
                "cross_score": 0.3834523558616638,
                "embedding_sim": 0.8758241534233093,
                "overlaps": [
                    "最佳化演算法"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/26.txt"
            },
            {
                "content": "本論文以一般攝影機做為使用平台，結合神經網路與手部模型，建立手部姿勢估 計系統，以多任務學習的方式與手部語意切割系統做整合。並以藉由手掌作為初始值 與修改迭代演算法來改善逆向運動學的收斂狀況。圖1 為本論文所提出系統的實際估 測結果。整體來說，本論文的主要貢獻有二： 一、設計實作一個關鍵點估計網路，並藉由多任務學習同時提升關鍵點估計以及語意 切割兩者的準確度。 二、提出以神經網路估計手掌方向來做為初始值，改善迭代的結果。 圖1、實際估測結果。左邊為輸入影像、標上估測出來的手指關鍵點，右邊為根據估測出來的 參數所繪製的3D 手模型。",
                "cross_score": 0.37118786573410034,
                "embedding_sim": 0.8742375373840332,
                "overlaps": [
                    "手部姿勢"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/1.txt"
            }
        ],
        "main_analysis": "经检查，用户段落与最相似文献段落在多处存在高度文字重叠，尤其是关于“手部不同關節的靈活度並不相同”、“coarse-to-fine的多階段最佳化方式”、“PCA對手勢資料集的關節角度計算來取得”等表述几乎完全一致，甚至连结构与表述顺序都相同，只有极少量词语变动。这种情况属于严重的抄袭倾向。建议用户对内容进行彻底改写，并明确引用原文献来源。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析基本可信。理由如下：\n\n- 分析准确指出了用户段落与相似文献在多个关键表述上高度重合，具体举例了几乎完全一致的语句和结构，判断为严重抄袭倾向，结论有理有据。\n- 分析建议用户彻底改写并标明引用来源，这一处理意见也符合学术规范。\n\n可能的遗漏：\n- 分析未明确指出用户段落是否有原创内容或是否对原文有实质性创新表达。\n- 分析未对抄袭比例或具体重复率做量化说明（如百分比），仅为定性描述。\n- 未对引用文献的具体来源（如论文题目、作者等）进行详细标识，可能影响溯源和后续处理。\n\n总体结论：分析可信，建议补充具体重复率和原文献详细信息，以增强说服力和操作性。",
            "Expert 2 Feedback: Main Model的分析总体可信，判断依据如下：\n\n- 分析准确指出了用户段落与相似文献在关键表述、结构和用词方面的高度重合，属于严重抄袭倾向，并给出了合理的修改与引用建议。\n- 具体对比细节充分，涵盖了主要重合点（如“手部不同關節的靈活度並不相同”、“coarse-to-fine的多階段最佳化方式”、“PCA對手勢資料集的關節角度計算來取得”等），没有夸大或遗漏核心问题。\n\n可能的遗漏：\n- 分析主要聚焦于文字重叠和抄袭倾向，未对技术内容本身的合理性或创新性进行评价。\n- 未说明如果进行改写，应如何体现原文献的引用格式或举例说明标准做法。\n\n建议：分析已达到查重目的，如需进一步完善，可补充对如何规范引用、改写的具体指导。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"根据Main Model和两位专家的分析，用户段落与相似文献在关键表述、结构和用词方面高度重合，属于严重抄袭倾向，且缺乏对原文献的引用。虽然分析准确，但抄袭嫌疑明显，不能直接接受，需进一步核查或要求用户改写并规范引用。因此应选择ABSTAIN。\"\n}",
        "plagiarism_confidence": 38,
        "plagiarism_percentage": 69,
        "plagiarism_snippet": [
            "在實際情況下",
            "手部不同關節的靈活度並不相同",
            "然而在一般的最佳化演算法中",
            "是直接對所有的維度一起求解",
            "並且所有的維度都是一樣的權重",
            "所以較容易有不自",
            "然的手部姿勢出現。因此論文提出",
            "coarse-to-fine",
            "的多階段最佳化方式",
            "並不直接使用",
            "全部的維度進行迭代",
            "而是先在較低的維度中求解",
            "再依序增加維度大小",
            "讓演算法",
            "先在較重要的空間中找解",
            "再逐漸微調。而最佳化求解的空間則是以PCA",
            "對手勢資料",
            "集的關節角度計算來取得",
            "得到的PCA",
            "空間能表達各個關節之間的聯繫以及各個關節",
            "的靈活度。演算法",
            "pseudo code 可參考圖18。",
            "最佳化演算法",
            "手部姿勢"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "我們將本論文的結果與[38][39]比較，在此兩篇論文中皆是以CPM 的網路架構為 基礎做修改，因此我們在CPM、HG、MSPN 三種網路架構上都進行實驗，表4 為比較 有無多任務學習的實驗結果，有用多任務學習時在關鍵點以及語意切割上表現皆優於 不使用，表5 則是本論文結果與[38][39]比較，可以看出不論在關鍵點或是語意切割 上，本論文使用方法表現皆優於[38][39]。 表4、有無多任務學習實驗結果比較 Mean EPE/ mIOU Without multi-task learning With multi-task learning Keypoints Mask Keypoints Mask CPM 6.057 85.77% 5.857 88.62% HG 5.207 86.01% 5.101 88.65% MSPN 4.574 86.95% 4.410 88.87% 表5、本論文與[38][39]在RHD 上關鍵點與語意切割結果 [38] [39] Proposed Keypoints (Mean EPE) 7.468 5.908 5.857 Mask (mIOU) 87.25% 86.85% 88.62%",
                "cross_score": 0.936751127243042,
                "embedding_sim": 0.8858647346496582,
                "overlaps": [
                    "[38][39]",
                    "的網路架構為",
                    "基礎做修改，",
                    "網路架構上"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/23.txt"
            },
            {
                "content": "過去多項研究[10][38][39]皆表明，若同時學習多個相關性高的任務，對不同任務 皆有正面的影響，Gkioxari 和Girshick[10]提出以物體偵測的網路架構為基礎進行修 改，同時進行物體偵測、切割、和關鍵點估計三種任務，圖19 為實驗結果，可以看出 預測切割可以提升關鍵點估計的效果。而Popa 等人[38]或Wang 等人[39]皆以關鍵點估 計網路架構為基礎做修改，多任務的部分，Popa 等人採用的方法同時進行關鍵點估 計、語意切割和3D 重建，以提升3D 重建的結果，而Wang 等人所提出的技術則是同 時進行關鍵點估計和語意切割兩種任務。在網路架構上，前面提到的三種系統都是採 用encoder-decoder 架構，對於不同的任務使用同一個encoder 獲取特徵，再分別以不 同的decoder 估計結果。在網路訓練上，則是將不同任務的損失函數依照權重相加，成 為一個新的損失函數，來進行訓練，Eq. (8)為新的損失函數方程式。 𝐿(𝑥, 𝑇) = ∑𝑤𝑖𝐿𝑖(𝑥𝑖, 𝑇𝑖) 𝑛 𝑖=1 (8) 其中𝐿為新損失函數，𝐿𝑖為第𝑖個任務的損失函數，𝑥𝑖為第𝑖個任務的輸出，𝑇𝑖為第𝑖 個任務的ground truth。 圖19、[10]的多任務學習實驗結果 如上所述，語意切割與關鍵點估計的多任務學習可以提升關鍵點估計的結果，因 此我們嘗試將Wang 等人提出的MSPN 架構[8]與語意切割系統deeplabv3+的網路架構 [37]進行合併。讓兩者共用同一個encoder，並將語意切割系統的結果與encoder 結果輸 入到MSPN 的decoder 中。 圖20 為示意圖，虛點紅色框為MSPN 的網路架構，虛線藍色框則為deeplabv3+的 網路架構。 圖20、MSPN 與Deeplab V3+合併示意圖 第五章、實驗過程與結果",
                "cross_score": 0.7228859066963196,
                "embedding_sim": 0.9495538473129272,
                "overlaps": [
                    "過去多項研究[10][38][39]皆表明，若同時學習多個相關性高的任務，對不同任務",
                    "皆有正面的影響，Gkioxari",
                    "和Girshick[10]提出以物體偵測的網路架構為基礎進行修",
                    "改，同時進行物體偵測、切割、和關鍵點估計三種任務，圖19",
                    "為實驗結果，可以看出",
                    "預測切割可以提升關鍵點估計的效果。而Popa",
                    "等人[38]或Wang",
                    "等人[39]皆以關鍵點估",
                    "計網路架構為基礎做修改，多任務的部分，Popa",
                    "等人採用的方法同時進行關鍵點估",
                    "計、語意切割和3D",
                    "重建，以提升3D",
                    "重建的結果，而Wang",
                    "等人所提出的技術則是同",
                    "時進行關鍵點估計和語意切割兩種任務。在網路架構上，前面提到的三種系統都是採",
                    "encoder-decoder 架構，對於不同的任務使用同一個encoder 獲取特徵，再分別以不",
                    "decoder 估計結果。在網路訓練上，則是將不同任務的損失函數依照權重相加，成",
                    "為一個新的損失函數，來進行訓練，Eq. (8)為新的損失函數方程式。"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/18.txt"
            },
            {
                "content": "多人關鍵點估計主要有兩種方式，分別為top-down[8][10]以及bottom-up[9][11]。 前者首先找出圖片中人物的位置並裁切，再做單人的關鍵點估計。後者則是先估計出 圖片中所有關鍵點位置，再區別哪些關鍵點屬於同一個人。本論文採用top-down 的方 式，因此下面針對單人關鍵點估計的方法進行討論。 在過去此類問題大多先建構各個身體部位之間的關係，組成人體的pictorial structures 模型(如圖5 所示)，去尋找圖片中與人相似的形狀[1][2][3][4]，然而這種方法 較無法處理被遮擋的部位，而神經網路可大幅改善此狀況[5]。 有別於過去直接估計關鍵點在圖片上的位置[6]，近期的研究則改為估計各個關鍵 點的heatmaps[5][7][8]。神經網路架構的部分，Wei 等人建立一個多階段估計的網路架 構，以利學習關鍵點之間的關係[5]。Newell 等人則在以encoder-decoder 架構作為多階 段估計中的組件，有效的融合不同尺度的特徵[7]。圖6 為他們所提出的網路架構圖。 在近期研究中多以這個架構為基礎做改良，如Li 等人所提出的跨階段特徵結合(cross stage feature aggregation)的方法[8]，可以改善Netwell 等人的架構中，多階段估計特徵 丟失的問題。 圖5、pictorial structures 模型示意圖，圖片出自[3] 圖6、多階段encoder-decoder 架構示意圖，圖片出自[7]",
                "cross_score": 0.061356931924819946,
                "embedding_sim": 0.9094327092170715,
                "overlaps": [
                    "[10]",
                    "網路架構",
                    "架構為基礎做",
                    "等人所提出的"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/5.txt"
            }
        ],
        "main_analysis": "用户段落与最相似文献段落的第二段存在大量文字重叠，句式、内容和结构几乎完全相同，部分句子甚至一字未改，属于明显的抄袭倾向。建议对相关内容进行改写并注明引用来源。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析可信，理由如下：\n\n- 分析明确指出用户段落与相似文献第二段存在大量文字重叠，句式、内容和结构几乎完全相同，甚至有一字未改的现象，这属于明显抄袭。\n- 建议内容合理，建议对相关内容进行改写并注明引用来源，符合学术规范。\n\n是否有遗漏：\n- Main Model的分析主要关注文字重叠和抄袭倾向，未具体指出哪些句子一字未改，也未量化相似度（如重复率百分比）。\n- 未进一步分析用户段落是否在引用部分有遗漏（如未正确标注全部参考文献）。\n- 未评价用户段落内容的创新性或与原文的区别，仅聚焦在文本重合。\n\n结论：分析可信，未出现明显疏漏，但可以补充更细致的重复内容标注和引用规范的具体建议。",
            "Expert 2 Feedback: 结论：\n\nMain Model的分析是可信的。分析明确指出了用户段落与相似文献第二段存在大量文字重叠，内容、句式、结构均高度相似，属于明显的抄袭倾向。建议改写并注明引用，结论合理、依据充分。\n\n可能遗漏：\n- Main Model只关注了第二段的重叠，没有提及用户段落是否与相似文献的其他段落存在相似或抄袭问题。\n- 未指出具体哪些句子、表述或段落一字未改，缺乏详细例证。\n- 未对用户段落中引用是否规范、是否标明出处进行评价。\n- 未讨论用户段落是否有对原文内容进行实质性扩展、总结或创新。\n\n总体而言，Main Model的分析可信，但可进一步细化并补充上述细节以增强说服力和全面性。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"根据Main Model和两位专家的分析，用户段落与相似文献存在大量文字重叠，句式、内容和结构高度相似，甚至有一字未改的情况，属于明显的抄袭倾向。虽然引用了部分文献，但整体内容缺乏实质性改写，且引用规范有待进一步核查。因此，应选择ABSTAIN。\"\n}",
        "plagiarism_confidence": 57,
        "plagiarism_percentage": 79,
        "plagiarism_snippet": [
            "[38][39]",
            "的網路架構為",
            "基礎做修改，",
            "網路架構上",
            "過去多項研究[10][38][39]皆表明，若同時學習多個相關性高的任務，對不同任務",
            "皆有正面的影響，Gkioxari",
            "和Girshick[10]提出以物體偵測的網路架構為基礎進行修",
            "改，同時進行物體偵測、切割、和關鍵點估計三種任務，圖19",
            "為實驗結果，可以看出",
            "預測切割可以提升關鍵點估計的效果。而Popa",
            "等人[38]或Wang",
            "等人[39]皆以關鍵點估",
            "計網路架構為基礎做修改，多任務的部分，Popa",
            "等人採用的方法同時進行關鍵點估",
            "計、語意切割和3D",
            "重建，以提升3D",
            "重建的結果，而Wang",
            "等人所提出的技術則是同",
            "時進行關鍵點估計和語意切割兩種任務。在網路架構上，前面提到的三種系統都是採",
            "encoder-decoder 架構，對於不同的任務使用同一個encoder 獲取特徵，再分別以不",
            "decoder 估計結果。在網路訓練上，則是將不同任務的損失函數依照權重相加，成",
            "為一個新的損失函數，來進行訓練，Eq. (8)為新的損失函數方程式。",
            "[10]",
            "網路架構",
            "架構為基礎做",
            "等人所提出的"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "過去多項研究[10][38][39]皆表明，若同時學習多個相關性高的任務，對不同任務 皆有正面的影響，Gkioxari 和Girshick[10]提出以物體偵測的網路架構為基礎進行修 改，同時進行物體偵測、切割、和關鍵點估計三種任務，圖19 為實驗結果，可以看出 預測切割可以提升關鍵點估計的效果。而Popa 等人[38]或Wang 等人[39]皆以關鍵點估 計網路架構為基礎做修改，多任務的部分，Popa 等人採用的方法同時進行關鍵點估 計、語意切割和3D 重建，以提升3D 重建的結果，而Wang 等人所提出的技術則是同 時進行關鍵點估計和語意切割兩種任務。在網路架構上，前面提到的三種系統都是採 用encoder-decoder 架構，對於不同的任務使用同一個encoder 獲取特徵，再分別以不 同的decoder 估計結果。在網路訓練上，則是將不同任務的損失函數依照權重相加，成 為一個新的損失函數，來進行訓練，Eq. (8)為新的損失函數方程式。 𝐿(𝑥, 𝑇) = ∑𝑤𝑖𝐿𝑖(𝑥𝑖, 𝑇𝑖) 𝑛 𝑖=1 (8) 其中𝐿為新損失函數，𝐿𝑖為第𝑖個任務的損失函數，𝑥𝑖為第𝑖個任務的輸出，𝑇𝑖為第𝑖 個任務的ground truth。 圖19、[10]的多任務學習實驗結果 如上所述，語意切割與關鍵點估計的多任務學習可以提升關鍵點估計的結果，因 此我們嘗試將Wang 等人提出的MSPN 架構[8]與語意切割系統deeplabv3+的網路架構 [37]進行合併。讓兩者共用同一個encoder，並將語意切割系統的結果與encoder 結果輸 入到MSPN 的decoder 中。 圖20 為示意圖，虛點紅色框為MSPN 的網路架構，虛線藍色框則為deeplabv3+的 網路架構。 圖20、MSPN 與Deeplab V3+合併示意圖 第五章、實驗過程與結果",
                "cross_score": 0.9331079721450806,
                "embedding_sim": 0.8815814256668091,
                "overlaps": [
                    "為新損失函數，",
                    "個任務的損失函數，",
                    "個任務的輸出，",
                    "個任務的",
                    "ground truth。"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/18.txt"
            },
            {
                "content": "由於 9DoF SE-YOLO 作者對輸出張量進行擴增，因此定義了新增項 的損失函數。座標位置新增z 項，邊界框增加l 項，    yolo angle penalty L L L L .                             (3.5) ˆ ˆ ˆ 1 [( ) ( ) ( ) ] ˆ ˆ ˆ 1 [( ) ( ) ( ) ] ˆ 1 [ ln ] S B obj ij x x y y z z yolo coord i j S B obj ij w w coord h h l l i j S B obj ij ij ij coord i j ij noobj t t t t t t t t t t t t C C                            L ˆ [(1 )ln(1 )] ˆ [ ln ] S B noobj ij ij i j S B classes obj ij coord k k i j k C C c c             (3.6) - 30 - 加入四元數的損失函數，以均方誤差 (mean-square error, MSE) 來計算預 測值與實際 (ground truth) 的誤差， ˆ ˆ [( ) ( ) ˆ ˆ +( ) ( ) ]            S B obj quater ij i i i i angle i j i i i i q q q q q q q q L (3.7) 為了讓網路學習單位四元數的特性，借鑒 Pavllo et al. [36] 提出的懲罰損 失 (penalty loss)，參考單位四元數特性，加入一個旋轉四元數限制項的損 失函數，能以網路學習的方式，使旋轉四元數更具彈性地調整，在邊界框 在旋轉的迴歸上，可達到更好的效果， ˆ ˆ ˆ ˆ ( 1)          S B obj pty ij i i i i penalty i j q q q q L (3.8) 其中， pty：超參數，常數設為0.01。",
                "cross_score": 0.5470811128616333,
                "embedding_sim": 0.8651292324066162,
                "overlaps": [
                    "損失函數",
                    "的損失函數，",
                    "ground truth"
                ],
                "file_path": "dataset/paraphrased_dataset/source/ncu_2020/341.txt"
            },
            {
                "content": "經由前兩小節之實驗驗證後，本研究將針對LSTM 及TCN 做出進一步的改良，根據文 獻中所提及，預測的結果會取決於損失函數和模型本身(Granger, 1999)，因此本研究已經在前 兩小節進行模型的比較與挑選，接著能夠提升結果的方式便是改進損失函數的部分。在本研 究當中，我們預先採用了大家最常採用的MSE 做為損失函數，再進行客製化損失函數時本研 究為了過度修改損失函數導致無法求得正解，因此採用增加微調項目的方式來讓學習往正確 的方向收斂，本研究所設計之客製化損失函數如圖 31，透過將實際值與預測值的Tensor 進 行複製並滾動一天，以求得兩天間價格的差距，再透過實際值與預測值兩者的價格差距相乘 後取正負號，來判斷預測方向是否與實際方向相同，當方向相同時會降低0.01 個單位的誤差 值，方向錯誤時給予逞罰增加0.01 個單位的誤差，以此達到考量方向的損失函數學習方式。 圖 31 客製化損失函數 在逞罰值的選擇上，本研究也針對不同的數值進行測試，在參數上選擇了1、0.1、0.01 及 0.001 四種數值最為比較，其中0.001 因為數值較小，較難以有效干涉到學習過程，因此學習 後的結果皆與直接使用MSE 相差無幾，因次被本研究排除，而1 的部分則是干涉太大，導致 無法正常學習，也被本研究排除，最後本研究針對0.1 及0.01 進行了嘗試，最終選擇0.01 的 原因在於若是選擇0.1 雖然能依據方向去學習，但是實際學習中的誤差值時常無法收斂，而 0.01 雖然引響較0.1 小但是能夠正常收斂，因此本研究在最後選擇0.01 作為本研究之客製化 損失函數之參數選擇。 本研究將客製化損失函數結合LSTM 及TCN 模型，透過各項參數組合之測試，找出參 數與決定係數(𝑅2)與平均絕對縮放誤差(MASE)之間的關聯。首先，本研究針對LSTM 模型進 行三樣商品的比對，其結果如下表 13 及圖 32 至圖 34，雖然在訓練集下都是保持著很高𝑅2， 但是從原油商品來看，測試集的𝑅2與MASE 的結果明顯較尚未使用客製化損失函數來得低， 黃金及黃豆商品的差異並不明顯，從表 13 及圖 34 可以見得，原油商品在經過客製化損失函 數調整後之準確度明顯大幅下降，黃金則黃豆反而些微上升，這也讓本研究考量是否對於原 油這種在使用客製化損失函數前指標就相對較低的商品，反而無法帶來正向的效果。 表 13 客製化損失函數LSTM 模型之運算結果 隱藏層 神經元 黃金 train 0.992 0.994 0.994 0.994 0.993 0.989 0.993 0.993 0.992 0.993 test 0.956 0.966 0.967 0.965 0.96 0.937 0.959 0.962 0.963 0.965 MASE 0.886 0.75 0.741 0.761 0.838 1.06 0.846 0.803 0.806 0.774 黃豆 train 0.974 0.966 0.966 0.98 0.98 0.977 0.979 0.976 0.981 0.981 test 0.926 0.896 0.847 0.951 0.954 0.918 0.935 0.911 0.945 0.949 MASE 0.629 0.778 0.943 0.466 0.44 0.639 0.562 0.671 0.506 0.482 原油 train 0.975 0.984 0.966 0.958 0.962 0.978 0.982 0.99 0.99 0.99 test 0.347 0.659 0.203 -0.053 0.017 0.442 0.568 0.835 0.865 0.862 MASE 5.109 3.498 6.333 7.227 6.905 4.455 3.811 2.039 2.11 2.238 圖 32 客製化損失函數LSTM 模型在黃金之選擇 圖 33 客製化損失函數LSTM 模型在黃豆之選擇 圖 34 客製化損失函數LSTM 模型在原油之選擇 在TCN 的部分，本研究同樣根據啟動函數、Filters、Dilations 以及Dropout_rate 四個面 向個別測試，TCN 模型之計算結果如下表 14 至表 17。 啟動函數部分（參見表 14），在訓練集的部分都呈現了很高的𝑅2，而在測試集部分在黃 金和黃豆差異不明顯，甚至黃豆的ReLu 較好，原油商品上是SeLu 較ReLu 優異，MASE 亦 同，並且可以從圖 35 至圖 37 見得，僅有原油商品的SeLu 與ReLu 差距較明顯，位於圖形 右下角，黃金及黃豆因單位很小，本研究認定其無明顯差異。此處的其他參數分別為Filters:256、 Dilations:[32]及Dropour_rate:0.2。 Filters 的部分（參見表 15），在測試集部分在黃金商品無特別突出，黃豆則是在32、512 及1024 較高，但差異也不大，原油則是在參數128 至512 的區域較優異，MASE 亦同，並且 可以從圖 38 至圖 40 見得黃金因單位很小，本研究認定其無明顯差異，黃豆商品則是32、 512 及1024 的點較其他參數明顯位於右下角處，原油商品在參數128 至512 範圍的點，位於 圖形右下角，但是也可以觀察到這時候的MASE 指標呈現的結果其實是相對於比較差的結果。 此處的其他參數分別為啟動函數：SeLu、Dilations:[32]及Dropour_rate:0.2。 Dilations 部分（參見表 16），在測試集部分黃金和原油並無特別突出，黃豆則是8 至128 都有差不多的表現，MASE 亦同，並且可以從圖 41 至圖 43 見得，黃金在參數512 的點較其 他點差，偏向左上角，黃豆則是在8 至128 的範圍十分集中，座落於右下角，然而原油商品 的MASE 其實都很高，屬於不佳的結果。此處的其他參數分別為啟動函數：SeLu、Filters:256、 及Dropour_rate:0.2。 Dropout_rate 部分（參見表 17），在測試集部分黃金及黃豆在0 及0.2 較優，原油在參數 0.5 較優，MASE 亦同，並且可以從圖 44 至圖 46 見得，黃金在0 及0.2 的點都落於圖形右 下角，黃豆在0 與0.2 表現較佳，且與其餘兩點有明顯之差異，原油僅有0.5 一點的MASE 屬 於較佳結果，且位於圖形之右下角。此處的其他參數分別為啟動函數：SeLu、Filters:256、及 Dilations:[32]。 根據上述結果，可以發現，經由客製化損失函數調整過的模型，對於石油的學習情況有 些下降，原因可能來自於石油商品原本的學習成果在傳統指標上就相較於另外兩種商品低， 但這樣的結果是否會直接影響到獲利情形，本研究將在下一節繼續探討。 表 14 客製化損失函數TCN 模型之運算結果（啟動函數） 啟動函數 SeLu ReLu 黃金 train 0.979 0.983 test 0.96 0.956 MASE 0.833 0.892 黃豆 train 0.953 0.971 test 0.907 0.929 MASE 0.711 0.597 原油 train 0.988 0.979 test 0.936 0.663 MASE 1.592 3.192 圖 35 客製化損失函數TCN 的啟動函數在黃金之選擇 圖 36 客製化損失函數TCN 的啟動函數在黃豆之選擇 圖 37 客製化損失函數TCN 的啟動函數在原油之選擇 表 15 客製化損失函數TCN 模型之運算結果（Filters） Filters 黃金 train 0.988 0.982 0.981 0.979 0.961 0.932 test 0.961 0.939 0.964 0.96 0.949 0.952 MASE 0.81 1.077 0.766 0.833 0.961 0.924 黃豆 train 0.981 0.909 0.93 0.953 0.962 0.951 test 0.952 0.898 0.884 0.907 0.937 0.93 MASE 0.468 0.756 0.829 0.711 0.552 0.597 原油 train 0.966 0.95 0.987 0.988 0.991 0.983 test 0.402 0.321 0.825 0.936 0.922 0.759 MASE 4.757 5.151 2.447 1.592 1.811 3.381 圖 38 客製化損失函數TCN 的Filters 在黃金之選擇 圖 39 客製化損失函數TCN 的Filters 在黃豆之選擇 圖 40 客製化損失函數TCN 的Filters 在原油之選擇 表 16 客製化損失函數TCN 模型之運算結果（Dilations） Dilations 黃金 train 0.985 0.981 0.979 0.97 0.948 0.963 0.928 test 0.96 0.956 0.96 0.948 0.925 0.93 0.849 MASE 0.829 0.892 0.833 0.981 1.22 1.184 1.831 黃豆 train 0.977 0.96 0.953 0.959 0.959 0.87 0.844 test 0.954 0.946 0.907 0.932 0.929 0.71 0.748 MASE 0.442 0.491 0.711 0.582 0.604 1.306 1.284 原油 train 0.989 0.986 0.988 0.989 0.991 0.967 0.968 test 0.948 0.918 0.936 0.959 0.903 0.849 0.881 MASE 1.435 1.682 1.592 1.161 1.568 2.196 1.631 圖 41 客製化損失函數TCN 的Dilations 在黃金之選擇 圖 42 客製化損失函數TCN 的Dilations 在黃豆之選擇 圖 43 客製化損失函數TCN 的Dilations 在原油之選擇 表 17 客製化損失函數TCN 模型之運算結果（Dropout_rate） Dropout_rate 0.2 0.5 0.7 黃金 train 0.981 0.979 0.967 0.963 test 0.959 0.96 0.903 0.912 MASE 0.85 0.833 1.222 1.198 黃豆 train 0.982 0.953 0.778 0.179 test 0.95 0.907 0.525 -0.169 MASE 0.462 0.711 1.88 2.687 原油 train 0.99 0.988 0.983 0.99 test 0.913 0.936 0.98 0.936 MASE 1.765 1.592 0.781 1.38 圖 44 客製化損失函數TCN 的Dropout_rate 在黃金之選擇 圖 45 客製化損失函數TCN 的Dropout_rate 在黃豆之選擇 圖 46 客製化損失函數TCN 的Dropout_rate 在原油之選擇",
                "cross_score": 0.4132554829120636,
                "embedding_sim": 0.8708356618881226,
                "overlaps": [
                    "損失函數，",
                    "的損失函數"
                ],
                "file_path": "dataset/paraphrased_dataset/source/ncu_2019/361.txt"
            }
        ],
        "main_analysis": "经比对，用户段落“其中L為新損失函數，Li為第i個任務的損失函數，xi為第i個任務的輸出，Ti為第i個任務的 ground truth。”与最相似文献段落中的“其中𝐿為新損失函數，𝐿𝑖為第𝑖個任務的損失函數，𝑥𝑖為第𝑖個任務的輸出，𝑇𝑖為第𝑖 個任務的ground truth。”存在高度文字重叠，仅做了极细微的格式或字体调整，内容表达完全一致。此处属于标准定义性语句，但若大量采用该表述，仍有抄袭嫌疑，建议适当改写或注明出处。",
        "feedbacks": [
            "Expert 1 Feedback: 审查意见：\n\nMain Model 的分析基本可信，理由如下：\n\n- 分析准确指出用户段落与相似文献段落高度重合，仅有格式或字体微调，内容表达完全一致。\n- 明确认定该表述为“标准定义性语句”，但也指出若大面积采用仍有抄袭嫌疑，并提出改写或注明出处的建议。\n- 分析结论与事实相符，未夸大或遗漏段落内容的本质。\n\n可能的遗漏：\n\n- 分析只关注了该句为“标准定义性语句”，但未进一步说明在学术写作中类似标准定义/公式描述一般可适当引用，只需注意比例和引用规范。\n- 没有具体指出“标准定义性语句”是否在文献引用/致谢等层面已经被妥善处理。\n- 没有说明若全文仅少量类似表述，通常不影响论文原创性评价，若大面积采用才构成严重问题。\n\n总结：  \nMain Model 分析可信，结论准确。但可补充说明“标准定义性语句”在学术写作中的合理使用范围，以及如何妥善引用，提升分析的完整性。",
            "Expert 2 Feedback: 审阅意见如下：\n\n1. 分析可信度  \nMain Model的分析是可信的。用户段落“其中L為新損失函數，Li為第i個任務的損失函數，xi為第i個任務的輸出，Ti為第i個任務的 ground truth。”与相似文献段落在内容和表达上几乎完全一致，仅有极细微的格式差别。属于高度重合，分析结论准确。\n\n2. 是否有遗漏  \n分析未明显遗漏重点，但可补充以下细节：\n\n- 该表述属于标准定义性语句，在学术写作中常见。若全文仅偶尔出现，问题不大；但如大段落、多处采用该种表述且未注明出处，则有抄袭风险，应当提醒用户合理引用或改写。\n- Main Model分析未对“是否需改写或引用”做更细致建议，仅简单指出建议改写或注明出处。可进一步强调学术诚信的重要性。\n\n结论  \nMain Model分析可信，未遗漏主要内容，但可补充强调引用规范及标准定义语句的合理使用范围。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"用户段落为标准定义性语句，与常见学术表述一致，仅有极细微格式差异。该类表述在学术写作中合理、常见，若全文仅偶尔出现，不影响原创性评价。专家意见与主模型分析均认为无实质性抄袭，仅建议注意引用规范。因此，应予以接受。\"\n}",
        "plagiarism_confidence": 63,
        "plagiarism_percentage": 25,
        "plagiarism_snippet": [
            "為新損失函數，",
            "個任務的損失函數，",
            "個任務的輸出，",
            "個任務的",
            "ground truth。",
            "損失函數",
            "的損失函數，",
            "ground truth",
            "損失函數，",
            "的損失函數"
        ],
        "verdict": "ACCEPT"
    },
    {
        "top_docs_info": [
            {
                "content": "過去多項研究[10][38][39]皆表明，若同時學習多個相關性高的任務，對不同任務 皆有正面的影響，Gkioxari 和Girshick[10]提出以物體偵測的網路架構為基礎進行修 改，同時進行物體偵測、切割、和關鍵點估計三種任務，圖19 為實驗結果，可以看出 預測切割可以提升關鍵點估計的效果。而Popa 等人[38]或Wang 等人[39]皆以關鍵點估 計網路架構為基礎做修改，多任務的部分，Popa 等人採用的方法同時進行關鍵點估 計、語意切割和3D 重建，以提升3D 重建的結果，而Wang 等人所提出的技術則是同 時進行關鍵點估計和語意切割兩種任務。在網路架構上，前面提到的三種系統都是採 用encoder-decoder 架構，對於不同的任務使用同一個encoder 獲取特徵，再分別以不 同的decoder 估計結果。在網路訓練上，則是將不同任務的損失函數依照權重相加，成 為一個新的損失函數，來進行訓練，Eq. (8)為新的損失函數方程式。 𝐿(𝑥, 𝑇) = ∑𝑤𝑖𝐿𝑖(𝑥𝑖, 𝑇𝑖) 𝑛 𝑖=1 (8) 其中𝐿為新損失函數，𝐿𝑖為第𝑖個任務的損失函數，𝑥𝑖為第𝑖個任務的輸出，𝑇𝑖為第𝑖 個任務的ground truth。 圖19、[10]的多任務學習實驗結果 如上所述，語意切割與關鍵點估計的多任務學習可以提升關鍵點估計的結果，因 此我們嘗試將Wang 等人提出的MSPN 架構[8]與語意切割系統deeplabv3+的網路架構 [37]進行合併。讓兩者共用同一個encoder，並將語意切割系統的結果與encoder 結果輸 入到MSPN 的decoder 中。 圖20 為示意圖，虛點紅色框為MSPN 的網路架構，虛線藍色框則為deeplabv3+的 網路架構。 圖20、MSPN 與Deeplab V3+合併示意圖 第五章、實驗過程與結果",
                "cross_score": 0.8924659490585327,
                "embedding_sim": 0.9268140196800232,
                "overlaps": [
                    "如上所述，語意切割與關鍵點估計的多任務學習可以提升關鍵點估計的結果，因",
                    "此我們嘗試將Wang",
                    "等人提出的MSPN",
                    "架構[8]與語意切割系統",
                    "deeplabv3+的網路架構",
                    "[37]進行合併。讓兩者共用同一個encoder，並將語意切割系統的結果與",
                    "encoder 結果輸",
                    "入到MSPN",
                    "的decoder"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/18.txt"
            },
            {
                "content": "本論文所提出的系統架構如圖15 所示，是以在3.2 節所介紹的系統(圖12)[15]為 基礎進行修改。在網路架構的部分，我們最終選擇MSPN[8]、yolov3[34]所採用的架 構，同時我們將系統中2D 關鍵點估計的神經網路，與deeplabv3+[31]進行整合，設計 一個多任務學習(multi-task learning)的網路架構。逆向運動學的部分，本論文以 Levenberg-Marquardt 演算法最佳化，並以ResNet[32]預測手掌orientation 作為迭代的初 始值，以及[33]中的方法修改最佳化方式，改善迭代的收斂狀況。以下介紹本論文對於 Panteleris 等人所提出的架構[15]所修改的部分。 圖15、本論文所提出的系統架構圖",
                "cross_score": 0.8345367312431335,
                "embedding_sim": 0.8825486898422241,
                "overlaps": [
                    "關鍵點估計的",
                    "deeplabv3+",
                    "的網路架構"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/15.txt"
            },
            {
                "content": "我們將本論文的結果與[38][39]比較，在此兩篇論文中皆是以CPM 的網路架構為 基礎做修改，因此我們在CPM、HG、MSPN 三種網路架構上都進行實驗，表4 為比較 有無多任務學習的實驗結果，有用多任務學習時在關鍵點以及語意切割上表現皆優於 不使用，表5 則是本論文結果與[38][39]比較，可以看出不論在關鍵點或是語意切割 上，本論文使用方法表現皆優於[38][39]。 表4、有無多任務學習實驗結果比較 Mean EPE/ mIOU Without multi-task learning With multi-task learning Keypoints Mask Keypoints Mask CPM 6.057 85.77% 5.857 88.62% HG 5.207 86.01% 5.101 88.65% MSPN 4.574 86.95% 4.410 88.87% 表5、本論文與[38][39]在RHD 上關鍵點與語意切割結果 [38] [39] Proposed Keypoints (Mean EPE) 7.468 5.908 5.857 Mask (mIOU) 87.25% 86.85% 88.62%",
                "cross_score": 0.6376364231109619,
                "embedding_sim": 0.8918848037719727,
                "overlaps": [
                    "的網路架構",
                    "MSPN"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/23.txt"
            }
        ],
        "main_analysis": "存在大量文字重叠，用户段落与相似文献段落的部分内容几乎完全一致（如“語意切割與關鍵點估計的多任務學習可以提升關鍵點估計的結果，因此我們嘗試將Wang等人提出的MSPN架構[8]與語意切割系統 deeplabv3+的網路架構[37]進行合併。讓兩者共用同一個encoder，並將語意切割系統的結果與 encoder 結果輸入到MSPN的decoder中。”）。存在明显抄袭倾向，建议进行内容重写或注明引用来源。",
        "feedbacks": [
            "Expert 1 Feedback: 审阅意见：\n\n1. 分析可信度  \nMain Model的分析是可信的。用户段落与相似文献中的内容在措辞和结构上高度重叠，关键句子几乎完全一致，属于明显的文字复制或抄袭行为。分析中指出了这一点，并建议重写或注明引用来源，这一结论是准确且合理的。\n\n2. 是否有遗漏  \n分析未明显遗漏关键问题。已指出文字重叠及抄袭风险，且给出改进建议（重写或引用）。  \n如需更完善，可进一步建议：  \n- 检查全篇是否还有类似重复内容；  \n- 若为学术论文，提醒用户严格按照学术规范处理引用和改写。  \n\n总体结论：  \nMain Model的分析是可信且到位的，未有明显遗漏。",
            "Expert 2 Feedback: Main Model的分析是可信的，理由如下：\n\n- 分析准确指出了用户段落与相似文献在表述和内容上的高度重叠，尤其是关键句子几乎完全一致，存在明显抄袭倾向；\n- 明确建议重写内容或注明引用，符合学术规范。\n\n可能的遗漏：\n- 未进一步说明哪些部分属于公知方法、哪些属于可直接引用的常用表达，是否可以适当简化重写难度的建议；\n- 未分析用户段落是否有任何创新性表达或与原文不同之处。\n\n总体来说，Main Model的分析结论明确且可信，但可以补充对创新性和表达差异的具体分析。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"根据Main Model及两位专家的意见，用户段落与已知文献存在大量文字重叠，关键句几乎完全一致，存在明显抄袭嫌疑，尚未见到对相关内容的适当引用或改写。因此无法确认其为原创内容，应选择ABSTAIN。\"\n}",
        "plagiarism_confidence": 79,
        "plagiarism_percentage": 89,
        "plagiarism_snippet": [
            "如上所述，語意切割與關鍵點估計的多任務學習可以提升關鍵點估計的結果，因",
            "此我們嘗試將Wang",
            "等人提出的MSPN",
            "架構[8]與語意切割系統",
            "deeplabv3+的網路架構",
            "[37]進行合併。讓兩者共用同一個encoder，並將語意切割系統的結果與",
            "encoder 結果輸",
            "入到MSPN",
            "的decoder",
            "關鍵點估計的",
            "deeplabv3+",
            "的網路架構",
            "MSPN"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "2D、3D 關鍵點的部分，我們用以下三種方法作為衡量效果的標準，mean EPE(endpoint error):估計結果與正解之間的歐式距離的平均，PCK(percentage of correct keypoints):估計結果EPE 低於某個閥值的資料在資料集中的占比，AUC(area under the curve):用不同閥值的PCK 所畫成的曲線下的面積。此外由於我們是以單張圖片做估 計，因此我們不考慮尺度(scale)以及平移(translation)的差異，也就是說我們會將估計結 果按比例縮放、平移。而語意分割則是使用mIOU(mean intersection over union)當作評 估的標準。手掌朝向分類的部分，我們以正確率以及角度誤差來評估結果優劣，正確 率代表分類正確的百分比，而角度誤差是預測手掌朝向方向的結果與真正的結果之間 的最短的旋轉角度。",
                "cross_score": 0.9812676906585693,
                "embedding_sim": 0.9965689182281494,
                "overlaps": [
                    "2D、3D 關鍵點的部分，我們用以下三種方法作為衡量效果的標準，mean EPE(endpoint error):估計結果與正解之間的歐式距離的平均，PCK(percentage of correct keypoints):估計結果",
                    "EPE 低於某個閥值的資料在資料集中的占比，AUC(area under the curve):用不同閥值的",
                    "PCK 所畫成的曲線下的面積。此外由於我們是以單張圖片做估",
                    "計，因此我們不考慮尺度(scale)以及平移(translation)的差異，也就是說我們會將估計結",
                    "果按比例縮放、平移。而語意分割則是使用",
                    "mIOU(mean intersection over union)當作評",
                    "估的標準。手掌朝向分類的部分，我們以正確率以及角度誤差來評估結果優劣，正確",
                    "率代表分類正確的百分比，而角度誤差是預測手掌朝向方向的結果與真正的結果之間",
                    "的最短的旋轉角度。"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/20.txt"
            },
            {
                "content": "當我們以神經網路所估計的2D 關鍵點位置作為輸入時，我們注意到如果有少數 2D 關鍵點估計錯誤，可能會大大影響逆向運動學之結果，因此我們將Eq. (10)稍作修 改，多加入介於0 到1 之間變數𝑟，首先將Eq.(9)中目標函數每個關鍵點的平方差都乘 上一個變數𝑟𝑖，作為每個關鍵點的權重，同時為避免最佳化演算法讓𝑟𝑖為0 來降低目標 函數的值，因此我們在目標函數後加上𝛼(1 −𝑟𝑖)2來避免，此方法可以使最佳化演算法 自己決定每個關鍵點所佔的權重，讓目標函數增加一些彈性，並非絕對相信神經網路 所估計出的結果，可將式子改寫成 ∑𝑟𝑖𝑝𝑖((𝑥𝑖−𝑢𝑖)2 + (𝑦𝑖−𝑣𝑖)2)) + 𝛼(1 −𝑟𝑖)2 𝑖=1 (10) 其中𝛼為常數。 最後為了確認本節演算法在正常狀況下的表現，我們以神經網路估計的2D 關鍵點 做為目標，MANO 作為手部模型，對本節所提到的演算法做實驗，測試個別以及同時 使用的效果，表7 為實驗結果。 表7、本節實驗結果 With Eq.(10)     Palm orientation   Hierarchical optimization   Mean EPE (mm) RHD 29.99 28.44 25.78 24.48 21.87 STB 31.29 31.03 30.88 29.57 29.47",
                "cross_score": 0.5181448459625244,
                "embedding_sim": 0.9089124202728271,
                "overlaps": [
                    "D 關鍵點",
                    "ean EPE"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/26.txt"
            },
            {
                "content": "當我們以正確的2D 關鍵點位置作為逆向運動學的目標時，我們發現迭代的收斂狀 況並不理想，容易陷入局部最小值，此類問題常見的解決方向有二，分別為迭代初始 值以及最佳化方式。下面我們分別從這兩個方向做改善。 首先，如同4.3 節所述，我們將估計手掌朝向視為分類問題，我們嘗試兩種分類方 式，第一種以歐拉角表示手部方向(orientation)，共有三個維度，其中兩個維度的角度 範圍為0~2π，其中一個維度為0~π，每 𝜋 4分成一類，共分成256 類。第二種，我們先 將圖片進行預處理，旋轉圖片使手掌到中指垂直，同樣以歐拉角表示方向，共有兩個 維度，其中一個維度角度範圍為0~2π，另一個維度為0~π，共分32 類。由表6 的實 驗結果可看出第二種方法較好，因此我們採用第二種分類方式。 表6、兩種分類方式結果比較 正確率/旋轉誤差角度 RHD STB 256 類 30.1% 33.19 º 32.5% 37.69 º 32 類 66.5% 18.92 º 64.5% 26.36 º 接下來我們先我們對Romero 等人所提出的資料集[30]做PCA，得到PC-space，在 使用Hierarchical Optimization 演算法[33]進行實驗，我們測試分成不同階段數量的結 果，實驗結果可見圖24，可以看出在分成四個或以上的階段數量時，效果大致相同， 因此我們最終分成四個階段來執行此演算法。圖25 為本節實驗解果 圖24、Hierarchical Optimization 不同階段數量在RHD 上的實驗結果 圖25、結果比較圖，每組包含上下兩張圖片，由左到由分別為ground truth、前人提出的逆向 運動學、以及用本論文提出的設定初始值方法所算出來的結果。",
                "cross_score": 0.11830150336027145,
                "embedding_sim": 0.9212065935134888,
                "overlaps": [
                    "D 關鍵點",
                    "手掌朝向"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/25.txt"
            }
        ],
        "main_analysis": "存在严重的文字重叠，用户段落与第一条最相似文献段落几乎完全一致，仅在个别标点和分段上略有差异，表述和内容高度重合，属于明显的抄袭行为。建议用户进行改写或注明出处。",
        "feedbacks": [
            "Expert 1 Feedback: 作为检查专家（Expert 1），我认为Main Model的分析是可信的，理由如下：\n\n- 分析准确指出了用户段落与第一条相似文献段落在内容、表述上的高度重合，确实属于明显的抄袭行为；\n- 指出了仅有个别标点和分段上的细微差异，这与实际比对结果一致。\n\n是否有遗漏：\n- Main Model的分析聚焦于文字重叠与抄袭，但未详细说明哪些具体表述或数据是完全一致的（虽然从内容来看已经很明显）。\n- 没有对引用规范（如是否应注明出处）进行具体建议，仅简单建议“改写或注明出处”，未给出更细致的修改建议。\n- 未对第二、三条相似文献进行分析，但从内容来看，用户段落与第一条相似文献的重合度最高，主观判断影响不大。\n\n结论：Main Model的分析可信，未有明显遗漏，但可以补充更具体的改写建议和引用规范说明。",
            "Expert 2 Feedback: 作为检查专家（Expert 2），对Main Model的分析进行审查后，结论如下：\n\n1. 分析可信度：\nMain Model的分析是可信的。用户段落与第一条相似文献段落几乎完全一致，仅在标点和分段上有微小差异。两者在内容、表述、结构等方面高度重合，属于明显的抄袭行为。因此，建议用户进行改写或注明出处，这一结论符合事实。\n\n2. 是否有遗漏：\nMain Model的分析没有明显遗漏。它准确识别了高度重合和抄袭的问题，并给出了合理建议。虽然未对其它两条相似文献进行详细比对，但由于首条文献已与用户段落高度一致，结论已足够明确，且分析重点突出，未遗漏核心问题。\n\n综上，Main Model的分析可信且全面，基本无明显遗漏。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"用户段落与第一条相似文献段落高度重合，仅有标点和分段的微小差异，内容、表述基本一致，属于明显的抄袭行为。因此不能直接接受，应当怀疑有抄袭。\"\n}",
        "plagiarism_confidence": 54,
        "plagiarism_percentage": 77,
        "plagiarism_snippet": [
            "2D、3D 關鍵點的部分，我們用以下三種方法作為衡量效果的標準，mean EPE(endpoint error):估計結果與正解之間的歐式距離的平均，PCK(percentage of correct keypoints):估計結果",
            "EPE 低於某個閥值的資料在資料集中的占比，AUC(area under the curve):用不同閥值的",
            "PCK 所畫成的曲線下的面積。此外由於我們是以單張圖片做估",
            "計，因此我們不考慮尺度(scale)以及平移(translation)的差異，也就是說我們會將估計結",
            "果按比例縮放、平移。而語意分割則是使用",
            "mIOU(mean intersection over union)當作評",
            "估的標準。手掌朝向分類的部分，我們以正確率以及角度誤差來評估結果優劣，正確",
            "率代表分類正確的百分比，而角度誤差是預測手掌朝向方向的結果與真正的結果之間",
            "的最短的旋轉角度。",
            "D 關鍵點",
            "ean EPE",
            "手掌朝向"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "本節列出神經網路訓練時所用參數，表2 為詳細的參數設定，包含學習率、批次 訓練數量、Epoch 等，其中學習率在每訓練15 個Epoch 後會更新一次，更新方式為當 前學習率乘上Gamma。 同時為提升網路泛化能力，我們使用資料擴增(Data Augmentation)技術，隨機將圖 片旋轉-30~30 度並隨機調整圖片的大小，介於原本大小的0.5 倍至1 倍，圖片縮小後 在周圍做zero padding，使其與原圖大小相同。為了避免過擬合(overfitting)，在訓練時 我們將2D 關鍵點位置隨機加上雜訊，此雜訊為平均值為0、標準差為1.5 的高斯分 布。 此外由於STB 資料集為六段影像資料，每段影像中背景以及手部位置都無太大變 化，所以資料集中只有六種背景，因此在實驗以STB 資料集作為訓練資料時，為避免 過擬合等問題，我們會先在RHD 資料集上訓練10 個Epoch 作為預訓練。 本論文於5.5 與5.6 小節中關鍵點估計相關實驗皆以此設定做訓練，之後不特別進 行說明。 表2、實驗相關參數 Epoch Batch size Learning rate 1e-4 Gamma 0.1 Resize Data argumentation RandomRotate:-30~30 RandomResize : 0.5~1.0 Keypoints noise : N(0, 1.5)",
                "cross_score": 0.8945282101631165,
                "embedding_sim": 0.8719930648803711,
                "overlaps": [
                    "訓練資料"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/21.txt"
            },
            {
                "content": "此實驗的結果分為兩個部分，一是訓練集內已有測試集先前的資料，二是訓練集 內並未包含測試集的先前資料，以此來測試是否需要有先前的資料才有辦法準確判斷 出原地踏步的角度。 1. 測試資料有先前的資料在訓練集內 在第一種情形中，我們將其中一人的其中一天資料當作測試集，其餘的資料（測 試者以及其他所有人的資料）當作訓練集。 若測試資料五種角度所有資料的每個步間資料都取得一個預測標籤，這些標籤的 正確率有95% 若將五種角度分開看，每個角度都利用預測的各個步間資料的標籤做投票，則正 確率為 100% 2. 測試資料為非訓練集內的資料 在第二種情形中，我們將其中一人的所有資料當作測試集，其餘的資料（其他所 有人的資料）當作訓練集。 若測試資料五種角度所有資料的每個步間資料都取得一個預測標籤，這些標籤的 正確率有81.91% 若將五種角度分開看，每個角度都利用預測的各個步間資料的標籤做投票，則正 確率為 100%",
                "cross_score": 0.6578213572502136,
                "embedding_sim": 0.8659111857414246,
                "overlaps": [
                    " 測試資料"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/260.txt"
            },
            {
                "content": "本篇論文使用到的訓練資料來自不同場所，主要的影片來源來自四個場景， 將之列舉如下: 1.  學校實驗室 2.  商店A 3.  Bomni-DB 資料集 [14] 4.  模擬商店B 其中學校實驗室此資料集有兩支頂照式魚眼攝影機，分別架設於實驗室的前 後端，見圖3-1；商店A 為真實的商店場景，設有一支魚眼攝影機；Bomni-DB 則是網路上找到的魚眼資料集，設有一支魚眼攝影機涵蓋整個場景，見圖3-2； 而模擬商店B 此場景則設有三支魚眼攝影機，拍攝的畫面可參考圖3-2。 圖 3- 1 學校實驗室場景圖 圖 3- 2 Bomni-DB 和模擬商店場景圖 上圖3-1 是在相同實驗室場景中，兩支頂照式魚眼攝影機於不同角度的個別 拍攝畫面。取得影片後，首先將數段資料集影片擷取影像作為訓練資料，而每組 資料集的影片解析度不盡相同，詳細的資料集介紹會放在第四章節作介紹。",
                "cross_score": 0.4964037537574768,
                "embedding_sim": 0.8664383292198181,
                "overlaps": [
                    "訓練資料",
                    "此資料集"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/449.txt"
            }
        ],
        "main_analysis": "经检查，用户段落与最相似文献段落没有明显的文字重叠，描述也更为简洁明了，仅对RHD数据集的基本情况作了介绍。不存在抄袭倾向，内容表达属于常见的数据集说明。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析基本可信。它指出用户段落仅简要介绍了RHD数据集的基本情况，没有与最相似文献出现明显文字重叠，也未发现抄袭倾向，判断合理。用户段落的内容属于常见的数据集说明，表述客观、简洁。\n\n可能遗漏之处：\n- 分析未说明用户段落的表述是否与其他未检索到的资料（如RHD原始论文或官方说明）存在高度相似，理论上数据集介绍类内容常见于官方文档，应注意与官方描述的一致性。\n- 分析未详细比对“手和人的分割、手部关键点、场景深度三种标签”这一表述是否为独特归纳或常见说法，但总体风险较低。\n\n总结：分析可信，结论合理，无重大遗漏，建议补充核查与RHD官方文档的重合度。",
            "Expert 2 Feedback: 作为检查专家(Expert 2)，我认为Main Model的分析基本可信。理由如下：\n\n- Main Model指出用户段落与最相似文献段落没有明显文字重叠，内容为数据集的基本介绍，表达常见，无抄袭倾向。从提供的相似文献Top 3来看，确实没有直接关于RHD数据集的详细描述或与用户段落内容相同的句子，主题也不完全一致。\n\n但分析有以下小的遗漏：\n\n- Main Model只分析了文字重叠和表达方式，没有进一步核查用户段落内容的准确性（即RHD数据集的描述是否真实、数据量是否正确等），仅从文献相似度角度出发。\n- 分析未说明用户段落虽然未抄袭，但属于对公开数据集的常规介绍，这类内容本身原创性较低，容易在多个文献中出现类似表述，建议在正式发表时注意引用原数据集来源。\n\n综上，Main Model分析可信，但建议补充内容准确性和引用规范的核查。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"用户段落仅对RHD数据集进行了常规性、简要的基本介绍，未与现有文献或资料出现明显文字重叠，也未发现抄袭倾向。虽然数据集介绍内容本身原创性较低，但此类表述为学术常见用语，当前无证据显示存在抄袭或不确定情形，因此应予以接受。\"\n}",
        "plagiarism_confidence": 68,
        "plagiarism_percentage": 27,
        "plagiarism_snippet": [
            "訓練資料",
            " 測試資料",
            "此資料集"
        ],
        "verdict": "ACCEPT"
    },
    {
        "top_docs_info": [
            {
                "content": "本節列出神經網路訓練時所用參數，表2 為詳細的參數設定，包含學習率、批次 訓練數量、Epoch 等，其中學習率在每訓練15 個Epoch 後會更新一次，更新方式為當 前學習率乘上Gamma。 同時為提升網路泛化能力，我們使用資料擴增(Data Augmentation)技術，隨機將圖 片旋轉-30~30 度並隨機調整圖片的大小，介於原本大小的0.5 倍至1 倍，圖片縮小後 在周圍做zero padding，使其與原圖大小相同。為了避免過擬合(overfitting)，在訓練時 我們將2D 關鍵點位置隨機加上雜訊，此雜訊為平均值為0、標準差為1.5 的高斯分 布。 此外由於STB 資料集為六段影像資料，每段影像中背景以及手部位置都無太大變 化，所以資料集中只有六種背景，因此在實驗以STB 資料集作為訓練資料時，為避免 過擬合等問題，我們會先在RHD 資料集上訓練10 個Epoch 作為預訓練。 本論文於5.5 與5.6 小節中關鍵點估計相關實驗皆以此設定做訓練，之後不特別進 行說明。 表2、實驗相關參數 Epoch Batch size Learning rate 1e-4 Gamma 0.1 Resize Data argumentation RandomRotate:-30~30 RandomResize : 0.5~1.0 Keypoints noise : N(0, 1.5)",
                "cross_score": 0.9480364918708801,
                "embedding_sim": 0.902086615562439,
                "overlaps": [
                    "資料集為",
                    "影像資料",
                    "作為訓練資料"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/21.txt"
            },
            {
                "content": "此節主要做的實驗是將每個場景的資料個別拆分為兩部分，一部分作為訓 練資料，剩餘的部分作為測試資料，比例取三比一，例如：「商店A」總共有 150 張圖片，隨機抽取其中112 張作為訓練資料，剩餘的38 張則為測試資料。 此實驗的目的是當訓練資料和測試資料的背景相同時，在訓練時我們會讓機器 學習到影像背景的區域，而學習時會將背景的部分視為negative sample，藉此 測試是否能使得偵測結果更加準確，且使False Positive(FP)的個數下降，可以 和上一小節交錯場景測試作比對。",
                "cross_score": 0.9437883496284485,
                "embedding_sim": 0.8801584839820862,
                "overlaps": [
                    "作為訓練資料",
                    "為測試資料。"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/454.txt"
            },
            {
                "content": "本篇論文使用到的訓練資料來自不同場所，主要的影片來源來自四個場景， 將之列舉如下: 1.  學校實驗室 2.  商店A 3.  Bomni-DB 資料集 [14] 4.  模擬商店B 其中學校實驗室此資料集有兩支頂照式魚眼攝影機，分別架設於實驗室的前 後端，見圖3-1；商店A 為真實的商店場景，設有一支魚眼攝影機；Bomni-DB 則是網路上找到的魚眼資料集，設有一支魚眼攝影機涵蓋整個場景，見圖3-2； 而模擬商店B 此場景則設有三支魚眼攝影機，拍攝的畫面可參考圖3-2。 圖 3- 1 學校實驗室場景圖 圖 3- 2 Bomni-DB 和模擬商店場景圖 上圖3-1 是在相同實驗室場景中，兩支頂照式魚眼攝影機於不同角度的個別 拍攝畫面。取得影片後，首先將數段資料集影片擷取影像作為訓練資料，而每組 資料集的影片解析度不盡相同，詳細的資料集介紹會放在第四章節作介紹。",
                "cross_score": 0.901207685470581,
                "embedding_sim": 0.8952796459197998,
                "overlaps": [
                    "作為訓練資料"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/449.txt"
            }
        ],
        "main_analysis": "经检查，用户段落与最相似文献段落之间存在部分内容的描述高度相似，尤其是在对STB数据集的结构（六段影片、每段3000张图片、训练与测试划分）进行说明时，表述方式和数据完全一致，且均以“STB资料集”称呼该数据集。虽然没有出现完全逐字抄袭，但内容表述非常接近，存在较明显的抄袭倾向。建议用户用自己的语言重新组织描述，并注明数据集来源。",
        "feedbacks": [
            "Expert 1 Feedback: 审阅意见：\n\nMain Model的分析可信，理由如下：\n\n- 分析准确指出了用户段落与相似文献在描述STB数据集结构（影片数量、图片数量、训练/测试划分等）方面表述高度相似，且具体数据和命名方式几乎一致，存在明显的抄袭倾向。\n- 分析建议用户用自己的语言重新组织描述并注明数据集来源，属于合理的学术规范建议。\n\n是否有遗漏：\n\n- Main Model 没有遗漏主要问题。相似性分析已涵盖了结构描述和表述方式的相似，且未放大或遗漏其他不相关内容。\n- 若需补充，可进一步明确用户段落与相似文献在表达顺序和用词上的具体相似点（如“每段影片3000张图片”、“五段做训练、一段做测试”等表述的雷同），以增强分析的说服力。\n\n总结：Main Model的分析基本可信，无明显遗漏。",
            "Expert 2 Feedback: 审阅意见如下：\n\nMain Model的分析总体可信。其准确指出了用户段落与相关文献在描述STB数据集结构方面高度相似，尤其在数据集划分方式、图片数量等细节描述上表述几乎一致，并且提醒用户需重述并标明数据集来源，符合学术规范要求。\n\n是否有遗漏：\n- Main Model未指出用户段落是否存在对数据集以外内容（如实验参数、数据增强等）的抄袭或引用问题，但就本段落内容而言，主要描述确实集中在数据集本身。\n- Main Model未进一步说明“较明显的抄袭倾向”与“学术不端”的界限，例如是否属于常规的数据集描述惯用表述，还是属于不可接受的文本相似。\n- Main Model没有具体引用相似文献的原句作为对比，若能展示更具体的对比，可信度会更高。\n\n结论：  \nMain Model分析可信，能准确反映用户段落与相似文献的高度重合情况，但可进一步补充具体文本对比，并明确界定文本相似与抄袭的界限。对当前内容而言，未见明显遗漏。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"用户段落与已知文献在数据集结构、具体数值和表述方式上高度相似，虽未完全逐字抄袭，但存在明显的抄袭倾向。两位专家和主模型均指出相似性高且需重述并注明来源，因此有合理怀疑抄袭或学术不端行为，无法直接判定为原创，应选择ABSTAIN。\"\n}",
        "plagiarism_confidence": 93,
        "plagiarism_percentage": 97,
        "plagiarism_snippet": [
            "資料集為",
            "影像資料",
            "作為訓練資料",
            "為測試資料。"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "本節列出神經網路訓練時所用參數，表2 為詳細的參數設定，包含學習率、批次 訓練數量、Epoch 等，其中學習率在每訓練15 個Epoch 後會更新一次，更新方式為當 前學習率乘上Gamma。 同時為提升網路泛化能力，我們使用資料擴增(Data Augmentation)技術，隨機將圖 片旋轉-30~30 度並隨機調整圖片的大小，介於原本大小的0.5 倍至1 倍，圖片縮小後 在周圍做zero padding，使其與原圖大小相同。為了避免過擬合(overfitting)，在訓練時 我們將2D 關鍵點位置隨機加上雜訊，此雜訊為平均值為0、標準差為1.5 的高斯分 布。 此外由於STB 資料集為六段影像資料，每段影像中背景以及手部位置都無太大變 化，所以資料集中只有六種背景，因此在實驗以STB 資料集作為訓練資料時，為避免 過擬合等問題，我們會先在RHD 資料集上訓練10 個Epoch 作為預訓練。 本論文於5.5 與5.6 小節中關鍵點估計相關實驗皆以此設定做訓練，之後不特別進 行說明。 表2、實驗相關參數 Epoch Batch size Learning rate 1e-4 Gamma 0.1 Resize Data argumentation RandomRotate:-30~30 RandomResize : 0.5~1.0 Keypoints noise : N(0, 1.5)",
                "cross_score": 0.9989626407623291,
                "embedding_sim": 0.9085861444473267,
                "overlaps": [
                    "本節列出神經網路訓練時所用參數",
                    "為詳細的參數設定",
                    "包含學習率、批次",
                    "訓練數量、Epoch",
                    "其中學習率在每訓練15",
                    "個Epoch",
                    "後會更新一次",
                    "更新方式為當",
                    "前學習率乘上Gamma。"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/21.txt"
            },
            {
                "content": "本論文的實驗參數設定如下：  Batch Size 為30  訓練的Epoch 為60，每次Epoch 會包含394 個Mini Batch  訓練時的Learning Rate 設為0.0001，Decay Rate 設為0.99  Fine-tuning 時Learning Rate 設為0.0001，Decay Rate 設為0  Loss Function 中所使用的𝑁∗，若是沒有特別提及時則是設為3。",
                "cross_score": 0.9248145222663879,
                "embedding_sim": 0.9057919979095459,
                "overlaps": [
                    "參數設定",
                    "Epoch",
                    "Epoch"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/491.txt"
            },
            {
                "content": "批次大小代表一次送進模型的資料有多少筆。丟棄率為當次的訓練中保 留的神經元占總數的多少比例，避免過度擬合(overfitting)的情況發生。參數 的設定如表 4.2 所示。 表 4.2 參數設定 參數名稱 設定值 GloVe 詞向量維度 隱藏層中神經元數目 批次大小 學習率 0.01 L2-正規化 0.001 優化器 AdaGrad 丟棄率 1.0",
                "cross_score": 0.9148491024971008,
                "embedding_sim": 0.9000851511955261,
                "overlaps": [
                    "參數設定"
                ],
                "file_path": "dataset/paraphrased_dataset/source/ncu_2020/271.txt"
            }
        ],
        "main_analysis": "用户段落与最相似文献段落1存在大量文字重叠，表述几乎一致，仅有极少词语调整，内容顺序和描述方式高度一致，属于明显的抄袭行为。建议进行大幅度改写，避免与原文重复。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析是可信的。其明确指出用户段落与最相似文献段落1存在大量文字重叠，表述几乎一致，属于明显的抄袭行为，并建议大幅度改写，结论明确、理由充分。\n\n但分析存在一点小小的遗漏：未对用户段落与相似文献Top 2、Top 3进行简要对比。虽然与Top 1的重复已足以判定抄袭，但若能补充说明与其他相似文献的关系，会更全面。总体结论不受影响。",
            "Expert 2 Feedback: Main Model的分析是可信的。分析指出用户段落与最相似文献段落1存在大量文字重叠、内容顺序和描述方式高度一致，属于明显的抄袭行为，这一结论与两段内容的比对结果相符。分析重点聚焦于“明显抄袭”，并给出了“建议大幅度改写”的合理建议。\n\n但分析略有遗漏：用户段落只对应了最相似文献段落1，而未说明与Top 2、Top 3的关系。尽管主要重合发生在段落1，若能补充说明与其他文献的相似度较低或无实质重叠，会让结论更全面。此外，分析未提及用户段落是否有任何创新点或差异化表达，这一点可以补充说明。\n\n总结：分析结论准确，可信；可补充与其他文献的相似性情况，以及用户段落是否有独特内容。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"根据Main Model及两位专家的分析，用户段落与最相似文献段落1存在大量文字重叠和高度一致，属于明显抄袭，且未体现出独特内容或创新表达。虽然未对Top 2、Top 3文献做详细比对，但与Top 1的高度重合已足以表明抄袭嫌疑，故应选择ABSTAIN。\"\n}",
        "plagiarism_confidence": 95,
        "plagiarism_percentage": 97,
        "plagiarism_snippet": [
            "本節列出神經網路訓練時所用參數",
            "為詳細的參數設定",
            "包含學習率、批次",
            "訓練數量、Epoch",
            "其中學習率在每訓練15",
            "個Epoch",
            "後會更新一次",
            "更新方式為當",
            "前學習率乘上Gamma。",
            "參數設定",
            "Epoch"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "在深度學習訓練模型時，為了避免出現過擬合(Overfitting)的情形，通常需 要在訓練模型時輸入大量的資料，由於本研究所有的標籤(label)資料皆為人工 標計，資料量有限，為了得到更加充足及豐富的資料，通常需要對原有的圖像 進行幾何轉換，改變圖像像素的位置並保持特徵不變，而這時就需要用到data augmentation 的技術。 本論文在訓練模型時，讓訓練資料作下列的幾何轉換： (1)  旋轉 : 使圖像做0 至360 的隨機旋轉。 (2) 水平翻轉 : 設定百分之五十的機率對圖像作水平翻轉。",
                "cross_score": 0.9661250710487366,
                "embedding_sim": 0.8947814702987671,
                "overlaps": [
                    "為了避免",
                    "過擬合(",
                    "verfitting)"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/452.txt"
            },
            {
                "content": "本節列出神經網路訓練時所用參數，表2 為詳細的參數設定，包含學習率、批次 訓練數量、Epoch 等，其中學習率在每訓練15 個Epoch 後會更新一次，更新方式為當 前學習率乘上Gamma。 同時為提升網路泛化能力，我們使用資料擴增(Data Augmentation)技術，隨機將圖 片旋轉-30~30 度並隨機調整圖片的大小，介於原本大小的0.5 倍至1 倍，圖片縮小後 在周圍做zero padding，使其與原圖大小相同。為了避免過擬合(overfitting)，在訓練時 我們將2D 關鍵點位置隨機加上雜訊，此雜訊為平均值為0、標準差為1.5 的高斯分 布。 此外由於STB 資料集為六段影像資料，每段影像中背景以及手部位置都無太大變 化，所以資料集中只有六種背景，因此在實驗以STB 資料集作為訓練資料時，為避免 過擬合等問題，我們會先在RHD 資料集上訓練10 個Epoch 作為預訓練。 本論文於5.5 與5.6 小節中關鍵點估計相關實驗皆以此設定做訓練，之後不特別進 行說明。 表2、實驗相關參數 Epoch Batch size Learning rate 1e-4 Gamma 0.1 Resize Data argumentation RandomRotate:-30~30 RandomResize : 0.5~1.0 Keypoints noise : N(0, 1.5)",
                "cross_score": 0.9045343399047852,
                "embedding_sim": 0.9192529916763306,
                "overlaps": [
                    "同時為提升網路泛化能力",
                    "我們使用資料擴增(Data Augmentation)技術",
                    "隨機將圖",
                    "片旋轉-30~30",
                    "度並隨機調整圖片的大小",
                    "介於原本大小的0.5",
                    "圖片縮小後",
                    "在周圍做",
                    "zero padding",
                    "使其與原圖大小相同。為了避免過擬合(overfitting)",
                    "在訓練時",
                    "我們將2D 關鍵點位置隨機加上雜訊",
                    "此雜訊為平均值為0、標準差為1.5",
                    "的高斯分"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/21.txt"
            },
            {
                "content": "我們將在本小節介紹卷積神經網路的訓練過程與步驟。 i. 輸入與輸出 為了觀察網路的泛化性，即其對於未知樣本的偵測能力，我們以 9:1 的比例將20 個類別，一共20000 張的樣本分為訓練與驗證集，也 就是分出18000 張為訓練集，2000 張為驗證集。每張訓練樣本均以 416416 解析度輸入網路，並迴歸出2D 偵測框與3D 偵測框，再以標 記的2D 邊界框與類別來計算第一次偵測的誤差，如公式 (3.10)；最 後則以標記的3D 邊界框與類別來計算第二次偵測結果的誤差，如公 式 (3.5)，最後將兩次輸出的誤差加總來引導網路學習。 ii. 網路的訓練策略 每個實驗進行200 回合 (epoch) 的訓練，而迭代訓練所使用的優 化器為 Adam [41]，我們以學習率衰減 (learning rate decay) 策略搭配 Adam 來使訓練效果更好。相關的衰減策略有餘弦 (cosine) 學習率衰 減法、階層 (step) 學習率衰減法、指數 (exponential) 學習率衰減法 - 43 - 等等，而我們採用的學習率衰減策略為 Pytorch 所提供的 ReduceLROnPlateau 函式，該函式會針對我們所給定的值進行監測， 該監測值若在k 個回合數內都無法優化，函式會將學習率乘上n 倍來 協助網路學習，並在調整完學習率後經m 個回合後再重新開始監測 數值；我們對每回合的訓練誤差的平均值進行監測，並將k 設為3， n 設為0.6，m 設為2，初始學習率設為0.001。實驗中我們固定批次 大小 (batch size) 為12 來訓練網路，即每次迭代訓練時會取12 筆訓 練樣本進行預測後計算誤差並修正模型權重。故總訓練樣本為 20000 筆時，一個訓練週期需要經過1667 次迭代訓練。當總訓練週期為200 時，需要333400 次迭代訓練，其學習率變化方式如圖 4.3 所示，縱 軸為學習率，橫軸為回合數。 圖 4.3. ReduceLROnPlateau 學習策略。 iii. 卷積神經網路調整 為了讓網路擁有更好的效果，我們調整感興趣區塊卷積核的採樣 點數量，以77、1111、及1313 三種不同的感興趣區塊卷積核來 比較實驗結果。另外對原始深度分支網路做三種調整，第一種為以雙 0.00002 0.00004 0.00006 0.00008 0.0001 - 44 - 線性內插將原始深度影像降維至各輸出層的解析度，再將降維後的資 料並聯 (concatenate) 骨幹特徵，最後直接以感興趣區塊卷積提取特 徵，如圖 4.4 紅色線段所示。 圖 4.4. 以雙線性內插降維的原始深度影像分支網路 (紅色線段)。 第二種是全程均以步伐 (stride) 為2 的33 卷積將原始深度影像 降維至各輸出層的解析度，將所得到的特徵並聯骨幹特徵，最後交由 感興趣區塊卷積提取特徵，如 圖 4.5 所示。 - 45 - 圖 4.5. 全程均以步伐為2 的33 卷積提取特徵的原始深度分支網路 (紅 色線段)。 第三種與第二種一樣，都是全程以步伐為2 的33 卷積，不同之 處在於並聯骨幹特徵後會再做一次33 卷積，再交由感興趣區塊卷積 提取特徵，如圖 3.8 紅色線段所示。",
                "cross_score": 0.48058250546455383,
                "embedding_sim": 0.88258296251297,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/ncu_2020/349.txt"
            }
        ],
        "main_analysis": "存在大量文字重叠，用户段落与相似文献段落第二条几乎完全一致，包括数据增强的具体操作（旋转、缩放、zero padding、关节点加噪声及参数设置等），部分句子甚至一字未改。存在明显抄袭倾向。建议用户进行改写或标注引用来源。",
        "feedbacks": [
            "Expert 1 Feedback: 您的问题是：请简短指出Main Model的分析是否可信，是否遗漏了什么。\n\n审查意见如下：\n\n1. 分析可信性  \nMain Model的分析是可信的。用户段落与相似文献第二条内容高度重合，包括数据增强（旋转、缩放、zero padding、关节点高斯噪声及其参数）等表述和参数设置几乎完全一致，部分句子一字未改。这种情况已构成明显的文字抄袭。\n\n2. 是否有遗漏  \n分析已准确指出了大段内容重叠及具体相同之处，结论明确、合理。  \n不过可以补充说明：Main Model分析只关注了与第二条相似文献的重叠，未对第一、三条相似文献的相关性做进一步说明，但从内容看，用户段落与这两条的重合度较低，分析重点突出，没有明显遗漏。\n\n总结  \nMain Model的分析可信，结论充分，无明显遗漏。",
            "Expert 2 Feedback: 作为检查专家(Expert 2)，针对Main Model的分析，结论如下：\n\n1. 分析可信度  \nMain Model的分析是可信的。用户段落与相似文献Top 3中的第二条内容在数据增强细节（旋转角度、缩放范围、zero padding、关键点加噪声及其参数设置等）上几乎完全一致，部分句子表述甚至一字未改。这种高度重叠，明确属于抄袭/高度借鉴行为。\n\n2. 是否有遗漏  \n分析未明显遗漏关键点。已明确指出用户段落与文献内容高度重叠，并建议进行改写或引用。  \n补充建议：  \n- 可进一步建议用户具体标注参考文献出处（如作者、年份等），以避免学术不端。  \n- 分析可说明“相似内容主要集中在数据增强方法描述部分”，更精准定位重叠范围。\n\n结论：  \nMain Model的分析准确、可信，未明显遗漏核心问题，补充建议可使反馈更完善。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"两位专家均认为Main Model的分析准确可信，已经充分指出了用户段落与相似文献的高度重合及抄袭倾向，且无明显遗漏核心问题。没有证据显示Main Model本身存在抄袭或不确定性，因此应予以接受。\"\n}",
        "plagiarism_confidence": 78,
        "plagiarism_percentage": 31,
        "plagiarism_snippet": [
            "為了避免",
            "過擬合(",
            "verfitting)",
            "同時為提升網路泛化能力",
            "我們使用資料擴增(Data Augmentation)技術",
            "隨機將圖",
            "片旋轉-30~30",
            "度並隨機調整圖片的大小",
            "介於原本大小的0.5",
            "圖片縮小後",
            "在周圍做",
            "zero padding",
            "使其與原圖大小相同。為了避免過擬合(overfitting)",
            "在訓練時",
            "我們將2D 關鍵點位置隨機加上雜訊",
            "此雜訊為平均值為0、標準差為1.5",
            "的高斯分"
        ],
        "verdict": "ACCEPT"
    },
    {
        "top_docs_info": [
            {
                "content": "本節列出神經網路訓練時所用參數，表2 為詳細的參數設定，包含學習率、批次 訓練數量、Epoch 等，其中學習率在每訓練15 個Epoch 後會更新一次，更新方式為當 前學習率乘上Gamma。 同時為提升網路泛化能力，我們使用資料擴增(Data Augmentation)技術，隨機將圖 片旋轉-30~30 度並隨機調整圖片的大小，介於原本大小的0.5 倍至1 倍，圖片縮小後 在周圍做zero padding，使其與原圖大小相同。為了避免過擬合(overfitting)，在訓練時 我們將2D 關鍵點位置隨機加上雜訊，此雜訊為平均值為0、標準差為1.5 的高斯分 布。 此外由於STB 資料集為六段影像資料，每段影像中背景以及手部位置都無太大變 化，所以資料集中只有六種背景，因此在實驗以STB 資料集作為訓練資料時，為避免 過擬合等問題，我們會先在RHD 資料集上訓練10 個Epoch 作為預訓練。 本論文於5.5 與5.6 小節中關鍵點估計相關實驗皆以此設定做訓練，之後不特別進 行說明。 表2、實驗相關參數 Epoch Batch size Learning rate 1e-4 Gamma 0.1 Resize Data argumentation RandomRotate:-30~30 RandomResize : 0.5~1.0 Keypoints noise : N(0, 1.5)",
                "cross_score": 0.8448215126991272,
                "embedding_sim": 0.9277336597442627,
                "overlaps": [
                    "此外由於STB 資料集為六段影像資料",
                    "每段影像中背景以及手部位置都無太大變",
                    "所以資料集中只有六種背景",
                    "因此在實驗以STB 資料集作為訓練資料時",
                    "過擬合等問題",
                    "我們會先在RHD 資料集上訓練",
                    "Epoch 作為預訓練。"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/21.txt"
            },
            {
                "content": "本篇論文使用到的訓練資料來自不同場所，主要的影片來源來自四個場景， 將之列舉如下: 1.  學校實驗室 2.  商店A 3.  Bomni-DB 資料集 [14] 4.  模擬商店B 其中學校實驗室此資料集有兩支頂照式魚眼攝影機，分別架設於實驗室的前 後端，見圖3-1；商店A 為真實的商店場景，設有一支魚眼攝影機；Bomni-DB 則是網路上找到的魚眼資料集，設有一支魚眼攝影機涵蓋整個場景，見圖3-2； 而模擬商店B 此場景則設有三支魚眼攝影機，拍攝的畫面可參考圖3-2。 圖 3- 1 學校實驗室場景圖 圖 3- 2 Bomni-DB 和模擬商店場景圖 上圖3-1 是在相同實驗室場景中，兩支頂照式魚眼攝影機於不同角度的個別 拍攝畫面。取得影片後，首先將數段資料集影片擷取影像作為訓練資料，而每組 資料集的影片解析度不盡相同，詳細的資料集介紹會放在第四章節作介紹。",
                "cross_score": 0.48290541768074036,
                "embedding_sim": 0.8767383098602295,
                "overlaps": [
                    "B 資料集",
                    "作為訓練資料",
                    " 資料集"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/449.txt"
            },
            {
                "content": "此節的實驗目的主要是想測試若在訓練的資料集中加入欲測試場景的背景 圖，能否使偵測效果變好，由於在使用同場景的訓練資料實驗中，依據結果顯 示網路架構能藉由學習背景使得整體的表現更好，故本節實驗想測試在訓練資 料集放的背景圖比例是否會有所影響，以及使用同場景不同攝影機的影像當背 景圖加入訓練資料集時的效果又是如何。 從上表4-6 觀察可發現大部分的資料集在加入背景圖後的AP 均呈現上升 的狀態，和我們的預期一樣，而我們也實驗加了1/10 或1/20 比例的背景影像至 訓練資料集，發現不同的測試資料集得到的結果也不相同，而加入同場景不同 攝影機的背景圖至訓練資料的結果，在實驗室此資料集有顯著的提升。 表4- 6 交錯場景與加入背景至訓練資料比對結果 Test Data Training Dataset Add Background AP LAB-1 Shop-A + DB + Shop-B NO 0.59 LAB-1 (1/10) 0.80 LAB-1 (1/20) 0.76 LAB-2 (1/20) 0.68 Shop A LAB + DB + Shop-B NO 0.56 Shop A (1/10) 0.61 Shop A (1/20) 0.64 Shop B-2 LAB + Shop-A + DB NO 0.79 Shop B-2 (1/10) 0.81 Shop B-2 (1/20) 0.81 Shop B-3 (1/20) 0.76",
                "cross_score": 0.4203035831451416,
                "embedding_sim": 0.8782390356063843,
                "overlaps": [
                    "資料集中",
                    "訓練資料"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/463.txt"
            }
        ],
        "main_analysis": "有明显的文字重叠，用户段落与第一条最相似文献段落在“此外由於STB 資料集為六段影像資料,每段影像中背景以及手部位置都無太大變化,所以資料集中只有六種背景,因此在實驗以STB 資料集作為訓練資料時,為避免過擬合等問題,我們會先在RHD 資料集上訓練 10個 Epoch 作為預訓練。”这句话基本完全一致，仅个别标点和数字排版略有不同。存在直接抄袭的倾向。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model 的分析是可信的。分析明确指出用户段落与相似文献第一条中的相关句子基本完全一致，仅有标点和数字排版的细微差异，确实存在高度重合甚至抄袭的嫌疑。这一判断有明确的事实依据，且未出现明显遗漏。\n\n可能补充点：分析可以进一步说明，用户段落的内容与相似文献中的表述属于连续性完整复制，并非偶然的术语或表达重合，强化抄袭倾向的结论。此外，可以简要提及其余两篇相似文献与用户段落的相似度较低，不影响整体判断。\n\n综上，Main Model 的分析结论准确、可信，未有实质性遗漏。",
            "Expert 2 Feedback: Main Model的分析是可信的。分析准确地指出用户段落与相似文献（尤其是Top 1）存在高度文字重叠，句子几乎完全一致，仅有细微格式差异，确实有直接抄袭的嫌疑。此外，Main Model没有遗漏用户段落与其他相似文献的关系，但主要问题集中在与第一条相似文献的重复。\n\n可补充说明：Main Model的分析已经覆盖了最关键的抄袭证据，没有明显遗漏。若需进一步完善，可简单提及对其他两篇相似文献的比对结果，但目前分析已足够支撑抄袭判断。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"用户段落与第一条相似文献的内容高度重合，句子基本完全一致，仅有格式和标点等细微差异，存在明显抄袭嫌疑。专家意见也一致认为有直接抄袭倾向，因此不能直接接受，应选择ABSTAIN。\"\n}",
        "plagiarism_confidence": 58,
        "plagiarism_percentage": 79,
        "plagiarism_snippet": [
            "此外由於STB 資料集為六段影像資料",
            "每段影像中背景以及手部位置都無太大變",
            "所以資料集中只有六種背景",
            "因此在實驗以STB 資料集作為訓練資料時",
            "過擬合等問題",
            "我們會先在RHD 資料集上訓練",
            "Epoch 作為預訓練。",
            "B 資料集",
            "作為訓練資料",
            " 資料集",
            "資料集中",
            "訓練資料"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "本節列出神經網路訓練時所用參數，表2 為詳細的參數設定，包含學習率、批次 訓練數量、Epoch 等，其中學習率在每訓練15 個Epoch 後會更新一次，更新方式為當 前學習率乘上Gamma。 同時為提升網路泛化能力，我們使用資料擴增(Data Augmentation)技術，隨機將圖 片旋轉-30~30 度並隨機調整圖片的大小，介於原本大小的0.5 倍至1 倍，圖片縮小後 在周圍做zero padding，使其與原圖大小相同。為了避免過擬合(overfitting)，在訓練時 我們將2D 關鍵點位置隨機加上雜訊，此雜訊為平均值為0、標準差為1.5 的高斯分 布。 此外由於STB 資料集為六段影像資料，每段影像中背景以及手部位置都無太大變 化，所以資料集中只有六種背景，因此在實驗以STB 資料集作為訓練資料時，為避免 過擬合等問題，我們會先在RHD 資料集上訓練10 個Epoch 作為預訓練。 本論文於5.5 與5.6 小節中關鍵點估計相關實驗皆以此設定做訓練，之後不特別進 行說明。 表2、實驗相關參數 Epoch Batch size Learning rate 1e-4 Gamma 0.1 Resize Data argumentation RandomRotate:-30~30 RandomResize : 0.5~1.0 Keypoints noise : N(0, 1.5)",
                "cross_score": 0.979939341545105,
                "embedding_sim": 0.9037246108055115,
                "overlaps": [
                    "本論文於5.5",
                    "與5.6",
                    "小節中關鍵點估計相關實驗皆以此設定做訓練",
                    "之後不特別進",
                    "行說明。 "
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/21.txt"
            },
            {
                "content": "過去多項研究[10][38][39]皆表明，若同時學習多個相關性高的任務，對不同任務 皆有正面的影響，Gkioxari 和Girshick[10]提出以物體偵測的網路架構為基礎進行修 改，同時進行物體偵測、切割、和關鍵點估計三種任務，圖19 為實驗結果，可以看出 預測切割可以提升關鍵點估計的效果。而Popa 等人[38]或Wang 等人[39]皆以關鍵點估 計網路架構為基礎做修改，多任務的部分，Popa 等人採用的方法同時進行關鍵點估 計、語意切割和3D 重建，以提升3D 重建的結果，而Wang 等人所提出的技術則是同 時進行關鍵點估計和語意切割兩種任務。在網路架構上，前面提到的三種系統都是採 用encoder-decoder 架構，對於不同的任務使用同一個encoder 獲取特徵，再分別以不 同的decoder 估計結果。在網路訓練上，則是將不同任務的損失函數依照權重相加，成 為一個新的損失函數，來進行訓練，Eq. (8)為新的損失函數方程式。 𝐿(𝑥, 𝑇) = ∑𝑤𝑖𝐿𝑖(𝑥𝑖, 𝑇𝑖) 𝑛 𝑖=1 (8) 其中𝐿為新損失函數，𝐿𝑖為第𝑖個任務的損失函數，𝑥𝑖為第𝑖個任務的輸出，𝑇𝑖為第𝑖 個任務的ground truth。 圖19、[10]的多任務學習實驗結果 如上所述，語意切割與關鍵點估計的多任務學習可以提升關鍵點估計的結果，因 此我們嘗試將Wang 等人提出的MSPN 架構[8]與語意切割系統deeplabv3+的網路架構 [37]進行合併。讓兩者共用同一個encoder，並將語意切割系統的結果與encoder 結果輸 入到MSPN 的decoder 中。 圖20 為示意圖，虛點紅色框為MSPN 的網路架構，虛線藍色框則為deeplabv3+的 網路架構。 圖20、MSPN 與Deeplab V3+合併示意圖 第五章、實驗過程與結果",
                "cross_score": 0.9279016852378845,
                "embedding_sim": 0.9013864994049072,
                "overlaps": [
                    "的網路架構",
                    "實驗結果",
                    "可以看出 ",
                    "MSPN 的",
                    "MSPN "
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/18.txt"
            },
            {
                "content": "我們將本論文的結果與[38][39]比較，在此兩篇論文中皆是以CPM 的網路架構為 基礎做修改，因此我們在CPM、HG、MSPN 三種網路架構上都進行實驗，表4 為比較 有無多任務學習的實驗結果，有用多任務學習時在關鍵點以及語意切割上表現皆優於 不使用，表5 則是本論文結果與[38][39]比較，可以看出不論在關鍵點或是語意切割 上，本論文使用方法表現皆優於[38][39]。 表4、有無多任務學習實驗結果比較 Mean EPE/ mIOU Without multi-task learning With multi-task learning Keypoints Mask Keypoints Mask CPM 6.057 85.77% 5.857 88.62% HG 5.207 86.01% 5.101 88.65% MSPN 4.574 86.95% 4.410 88.87% 表5、本論文與[38][39]在RHD 上關鍵點與語意切割結果 [38] [39] Proposed Keypoints (Mean EPE) 7.468 5.908 5.857 Mask (mIOU) 87.25% 86.85% 88.62%",
                "cross_score": 0.8299459218978882,
                "embedding_sim": 0.9140037298202515,
                "overlaps": [
                    "的網路架構",
                    "網路架構",
                    "的實驗結果",
                    "可以看出",
                    " MSPN "
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/23.txt"
            }
        ],
        "main_analysis": "经检查，用户段落与最相似文献段落的部分内容存在明显文字重叠，例如“本論文於5.5與5.6小節中關鍵點估計相關實驗皆以此設定做訓練,之後不特別進行說明”等句子几乎完全一致。此外，关于模型比较和实验流程的描述也高度相似，仅有部分词序和细节调整，存在抄袭倾向。建议用户对相关内容进行更充分的改写和归纳总结。",
        "feedbacks": [
            "Expert 1 Feedback: 作为检查专家(Expert 1)，我的意见如下：\n\nMain Model分析基本可信。分析准确指出了用户段落与相似文献在部分内容上的高度重叠，包括具体的句子和模型比较实验流程的描述，判断存在抄袭倾向，这一结论是有依据的。\n\n但分析有轻微遗漏之处：\n\n- 未具体说明用户段落与相似文献的重合比例或重叠段落数量，仅举了一个例句，建议适当补充更详细的相似性证据（如多个重叠句子或段落）。\n- 没有评价用户段落中是否有原创内容、结构调整或补充信息，仅侧重于重合部分。\n- 没有讨论用户段落是否对引用来源、模型选择的合理性等方面进行了补充解释或创新。\n\n总体来说，Main Model分析结论可靠，但建议在相似性细节和原创性评价方面略作补充，会更为全面。",
            "Expert 2 Feedback: 经审阅，Main Model 的分析结论可信，指出了用户段落与相似文献在表述和结构上存在高度重合，确实存在抄袭嫌疑，建议用户进行改写。分析过程符合查重和学术规范的基本要求。\n\n但略有遗漏之处：  \n1. 未指出哪些具体内容属于常规实验方法描述（如参数设置、网络比较等），这些内容在学术写作中有一定模板化，简单重述容易产生重合，但不一定都算抄袭，应酌情区分。\n2. 分析未详细说明“归纳总结”的具体建议，例如可强调用自己语言重新阐述、合并实验结论、避免逐句照搬等。\n3. 未评估段落中创新或独特内容的占比，若创新成分较多，可适当降低抄袭风险评价。\n\n综上，分析可信，但建议补充上述细节，以便用户更具体地改进文本。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"根据Main Model和两位专家的反馈，用户段落与相似文献在句子和实验流程描述上存在高度重合，部分内容几乎完全一致，已达到抄袭嫌疑的程度。虽然部分内容可能为常规实验流程描述，但整体原创性不足且缺乏明显改写，无法确定为原创文本，因此应选择ABSTAIN。\"\n}",
        "plagiarism_confidence": 91,
        "plagiarism_percentage": 96,
        "plagiarism_snippet": [
            "本論文於5.5",
            "與5.6",
            "小節中關鍵點估計相關實驗皆以此設定做訓練",
            "之後不特別進",
            "行說明。 ",
            "的網路架構",
            "實驗結果",
            "可以看出 ",
            "MSPN 的",
            "MSPN ",
            "網路架構",
            "的實驗結果",
            "可以看出",
            " MSPN "
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "我們將本論文的結果與[38][39]比較，在此兩篇論文中皆是以CPM 的網路架構為 基礎做修改，因此我們在CPM、HG、MSPN 三種網路架構上都進行實驗，表4 為比較 有無多任務學習的實驗結果，有用多任務學習時在關鍵點以及語意切割上表現皆優於 不使用，表5 則是本論文結果與[38][39]比較，可以看出不論在關鍵點或是語意切割 上，本論文使用方法表現皆優於[38][39]。 表4、有無多任務學習實驗結果比較 Mean EPE/ mIOU Without multi-task learning With multi-task learning Keypoints Mask Keypoints Mask CPM 6.057 85.77% 5.857 88.62% HG 5.207 86.01% 5.101 88.65% MSPN 4.574 86.95% 4.410 88.87% 表5、本論文與[38][39]在RHD 上關鍵點與語意切割結果 [38] [39] Proposed Keypoints (Mean EPE) 7.468 5.908 5.857 Mask (mIOU) 87.25% 86.85% 88.62%",
                "cross_score": 0.9893368482589722,
                "embedding_sim": 0.9422997236251831,
                "overlaps": [
                    "我們將本論文的結果與[38][39]比較",
                    "在此兩篇論文中皆是以CPM",
                    "的網路架構為",
                    "基礎做修改",
                    "因此我們在CPM、HG、MSPN",
                    "三種網路架構上都進行實驗",
                    "有無多任務學習的實驗結果",
                    "有用多任務學習時在關鍵點以及語意切割上表現皆優於",
                    "則是本論文結果與[38][39]比較",
                    "可以看出不論在關鍵點或是語意切割",
                    "本論文使用方法表現皆優於[38][39]。"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/23.txt"
            },
            {
                "content": "過去多項研究[10][38][39]皆表明，若同時學習多個相關性高的任務，對不同任務 皆有正面的影響，Gkioxari 和Girshick[10]提出以物體偵測的網路架構為基礎進行修 改，同時進行物體偵測、切割、和關鍵點估計三種任務，圖19 為實驗結果，可以看出 預測切割可以提升關鍵點估計的效果。而Popa 等人[38]或Wang 等人[39]皆以關鍵點估 計網路架構為基礎做修改，多任務的部分，Popa 等人採用的方法同時進行關鍵點估 計、語意切割和3D 重建，以提升3D 重建的結果，而Wang 等人所提出的技術則是同 時進行關鍵點估計和語意切割兩種任務。在網路架構上，前面提到的三種系統都是採 用encoder-decoder 架構，對於不同的任務使用同一個encoder 獲取特徵，再分別以不 同的decoder 估計結果。在網路訓練上，則是將不同任務的損失函數依照權重相加，成 為一個新的損失函數，來進行訓練，Eq. (8)為新的損失函數方程式。 𝐿(𝑥, 𝑇) = ∑𝑤𝑖𝐿𝑖(𝑥𝑖, 𝑇𝑖) 𝑛 𝑖=1 (8) 其中𝐿為新損失函數，𝐿𝑖為第𝑖個任務的損失函數，𝑥𝑖為第𝑖個任務的輸出，𝑇𝑖為第𝑖 個任務的ground truth。 圖19、[10]的多任務學習實驗結果 如上所述，語意切割與關鍵點估計的多任務學習可以提升關鍵點估計的結果，因 此我們嘗試將Wang 等人提出的MSPN 架構[8]與語意切割系統deeplabv3+的網路架構 [37]進行合併。讓兩者共用同一個encoder，並將語意切割系統的結果與encoder 結果輸 入到MSPN 的decoder 中。 圖20 為示意圖，虛點紅色框為MSPN 的網路架構，虛線藍色框則為deeplabv3+的 網路架構。 圖20、MSPN 與Deeplab V3+合併示意圖 第五章、實驗過程與結果",
                "cross_score": 0.9788089394569397,
                "embedding_sim": 0.9085059762001038,
                "overlaps": [
                    "[38][39]",
                    "網路架構為基礎做修改",
                    "網路架構上",
                    "語意切割",
                    "語意切割"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/18.txt"
            },
            {
                "content": "模型篩選的部分，我們比較了三種CPM[5]、HG[7]、MSPN[8]不同的網路架構， 以RHD 和STB 此二公開資料集做測試，從中選出適合的網路架構，作為後續研究的 基礎。從表3、圖23 的實驗結果可以看出MSPN 的效果較好，故後續實驗主要以 MSPN 進行。 表3、CPM、HG、MSPN 在RHD、STB 資料集的結果 Mean EPE RHD STB CPM 6.057 7.316 HG 5.207 6.773 MSPN 4.574 6.491 圖23、CPM、HG、MSPN 在RHD、STB 結果圖表",
                "cross_score": 0.9698633551597595,
                "embedding_sim": 0.9167327284812927,
                "overlaps": [
                    "的網路架構",
                    "CPM、HG、MSPN"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/22.txt"
            }
        ],
        "main_analysis": "存在大量文字重叠，用户段落与第一篇最相似文献段落几乎完全一致，仅有极少数词语或语序调整，属于直接照搬原文内容。该行为具有明显的抄袭倾向。建议用户进行重新表述，并注明引用来源。",
        "feedbacks": [
            "Expert 1 Feedback: 审阅意见：\n\nMain Model 的分析是可信的。理由如下：\n\n- 分析准确指出了用户段落与相似文献内容高度重叠，几乎为直接照搬，仅做了极少文字调整，属于抄袭行为，并建议重新表述和注明引用来源。\n- 分析内容与实际比对结果相符，用户段落与第一篇相似文献确实几乎完全一致。\n\n可能遗漏之处：\n\n- 分析未具体列出用户段落和相似文献的重叠比例（如百分比），可以进一步量化相似度。\n- 未对其他两篇Top 3相似文献的相似程度作补充说明，仅聚焦于第一篇。\n- 没有就如何“重新表述”给出具体建议（如可否总结、归纳、或用自己语言描述结果）。\n- 未明确提醒用户即使重写，也要适当注明原文出处，避免学术不端。\n\n总结：分析结论可信，但可补充更具体的相似度数据及改写建议，增强指导性。",
            "Expert 2 Feedback: Main Model 的分析可信，理由如下：\n\n- 分析指出用户段落与相似文献第一名存在大量文字重叠，几乎完全一致，仅有极少数词语或语序调整，属于直接照搬原文，具有明显抄袭倾向。通过比对用户段落与提供的相似文献内容，可以验证这一判断成立。\n- 分析建议用户需重新表述并注明引用来源，符合学术规范要求。\n\n可能遗漏之处：\n\n- 分析仅指出了与第一篇最相似文献的重叠，但未说明与第二、第三篇相似文献的关系，是否也存在类似问题未作详细说明。\n- 未对抄袭内容的比例或相似度百分比进行量化描述，仅作了定性判断。\n- 未提及是否有表格、数据等非文字部分也存在抄袭现象。\n\n总体而言，分析结论可信，建议内容合理，但可补充对全部相似文献的覆盖性说明以及抄袭比例等量化信息。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"根据Main Model和两位专家的分析，用户段落与第一篇相似文献存在大量文字重叠，几乎为直接照搬，仅有极少数词语调整，属于明显的抄袭行为。因此存在学术不端嫌疑，不应直接接受。\"\n}",
        "plagiarism_confidence": 98,
        "plagiarism_percentage": 99,
        "plagiarism_snippet": [
            "我們將本論文的結果與[38][39]比較",
            "在此兩篇論文中皆是以CPM",
            "的網路架構為",
            "基礎做修改",
            "因此我們在CPM、HG、MSPN",
            "三種網路架構上都進行實驗",
            "有無多任務學習的實驗結果",
            "有用多任務學習時在關鍵點以及語意切割上表現皆優於",
            "則是本論文結果與[38][39]比較",
            "可以看出不論在關鍵點或是語意切割",
            "本論文使用方法表現皆優於[38][39]。",
            "[38][39]",
            "網路架構為基礎做修改",
            "網路架構上",
            "語意切割",
            "的網路架構",
            "CPM、HG、MSPN"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "當我們以神經網路所估計的2D 關鍵點位置作為輸入時，我們注意到如果有少數 2D 關鍵點估計錯誤，可能會大大影響逆向運動學之結果，因此我們將Eq. (10)稍作修 改，多加入介於0 到1 之間變數𝑟，首先將Eq.(9)中目標函數每個關鍵點的平方差都乘 上一個變數𝑟𝑖，作為每個關鍵點的權重，同時為避免最佳化演算法讓𝑟𝑖為0 來降低目標 函數的值，因此我們在目標函數後加上𝛼(1 −𝑟𝑖)2來避免，此方法可以使最佳化演算法 自己決定每個關鍵點所佔的權重，讓目標函數增加一些彈性，並非絕對相信神經網路 所估計出的結果，可將式子改寫成 ∑𝑟𝑖𝑝𝑖((𝑥𝑖−𝑢𝑖)2 + (𝑦𝑖−𝑣𝑖)2)) + 𝛼(1 −𝑟𝑖)2 𝑖=1 (10) 其中𝛼為常數。 最後為了確認本節演算法在正常狀況下的表現，我們以神經網路估計的2D 關鍵點 做為目標，MANO 作為手部模型，對本節所提到的演算法做實驗，測試個別以及同時 使用的效果，表7 為實驗結果。 表7、本節實驗結果 With Eq.(10)     Palm orientation   Hierarchical optimization   Mean EPE (mm) RHD 29.99 28.44 25.78 24.48 21.87 STB 31.29 31.03 30.88 29.57 29.47",
                "cross_score": 0.9876028895378113,
                "embedding_sim": 0.9497790932655334,
                "overlaps": [
                    "神經網路所估計的",
                    "關鍵點位置作為",
                    "逆向運動學"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/26.txt"
            },
            {
                "content": "在3D 模型中我們有兩種空間來描述模型當前的狀態，分別為關節空間(joint space) 以及直角坐標空間(Cartesian space)，前者記錄關節的旋轉角度，後者則是記錄關節的 位置。當由3D 模型的關節空間參數計算出對應的直角座標位置時稱為正向運動學，反 之由以直角坐標空間位置計算出對應關間空間參數時稱為逆向運動學。而在逆向運動 學中，因為通常不會有解析解，因此大多用非線性的最佳化演算法來求解。 論文中以神經網路估計2D 關鍵點位置做為目標，因此可將最小化目標寫為Eq. (1) ∑(𝑝𝑖 3(𝑥𝑖−𝑢𝑖))2 + (𝑝𝑖 3(𝑦𝑖−𝑣𝑖))2 𝑖=0 (1) 其中(𝑥𝑖, 𝑦𝑖)為神經網路估計之2D 關鍵點位置，(𝑢𝑖, 𝑣𝑖)則為手部模型映射在圖片中 的位置，𝑝𝑖則是神經網路所估計該點是關鍵點的機率。",
                "cross_score": 0.9830520153045654,
                "embedding_sim": 0.9216158986091614,
                "overlaps": [
                    "逆向運動學",
                    "關鍵點位置做為目標",
                    "網路估計",
                    "為手部模型",
                    "神經網路所估計"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/11.txt"
            },
            {
                "content": "當我們以正確的2D 關鍵點位置作為逆向運動學的目標時，我們發現迭代的收斂狀 況並不理想，容易陷入局部最小值，此類問題常見的解決方向有二，分別為迭代初始 值以及最佳化方式。下面我們分別從這兩個方向做改善。 首先，如同4.3 節所述，我們將估計手掌朝向視為分類問題，我們嘗試兩種分類方 式，第一種以歐拉角表示手部方向(orientation)，共有三個維度，其中兩個維度的角度 範圍為0~2π，其中一個維度為0~π，每 𝜋 4分成一類，共分成256 類。第二種，我們先 將圖片進行預處理，旋轉圖片使手掌到中指垂直，同樣以歐拉角表示方向，共有兩個 維度，其中一個維度角度範圍為0~2π，另一個維度為0~π，共分32 類。由表6 的實 驗結果可看出第二種方法較好，因此我們採用第二種分類方式。 表6、兩種分類方式結果比較 正確率/旋轉誤差角度 RHD STB 256 類 30.1% 33.19 º 32.5% 37.69 º 32 類 66.5% 18.92 º 64.5% 26.36 º 接下來我們先我們對Romero 等人所提出的資料集[30]做PCA，得到PC-space，在 使用Hierarchical Optimization 演算法[33]進行實驗，我們測試分成不同階段數量的結 果，實驗結果可見圖24，可以看出在分成四個或以上的階段數量時，效果大致相同， 因此我們最終分成四個階段來執行此演算法。圖25 為本節實驗解果 圖24、Hierarchical Optimization 不同階段數量在RHD 上的實驗結果 圖25、結果比較圖，每組包含上下兩張圖片，由左到由分別為ground truth、前人提出的逆向 運動學、以及用本論文提出的設定初始值方法所算出來的結果。",
                "cross_score": 0.972692608833313,
                "embedding_sim": 0.9415393471717834,
                "overlaps": [
                    "正確的2D",
                    "關鍵點位置作為逆向運動學的目標時",
                    "我們發現迭代的收斂狀",
                    "況並不理想",
                    "容易陷入局部最小值",
                    "此類問題常見的解決方向有二",
                    "分別為迭代初始",
                    "值以及最佳化方式。下面我們分別從這兩個方向做改善。"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/25.txt"
            }
        ],
        "main_analysis": "有部分文字重叠，尤其是“當我們以正確的2D關鍵點位置作為逆向運動學的目標時,我們發現迭代的收斂狀況並不理想,容易陷入局部最小值,此類問題常見的解決方向有二,分別為迭代初始值以及最佳化方式。下面我們分別從這兩個方向做改善。”这句话几乎与文献段落3完全一致。其余内容为技术流程和实验描述，有一定相似但未构成大面积直接抄袭。建议修改重叠部分，避免抄袭嫌疑。",
        "feedbacks": [
            "Expert 1 Feedback: 审阅意见：\n\nMain Model的分析基本可信，指出了用户段落中存在与相似文献段落3明显重叠的句子，并建议对此部分进行修改以避免抄袭嫌疑。对其余内容的判定为技术流程和实验描述，有一定相似但未构成大面积直接抄袭，这一判断合理。\n\n可能的遗漏：\n\n1. 未指出用户段落与相似文献在技术流程和实验设置上的具体相似度（如实验顺序、参数设定等），如果有高度一致的实验流程和参数描述，建议进一步核查是否存在“结构性抄袭”。\n2. 没有对用户段落是否对原有内容进行了足够的理解和改写进行评价。即使未大面积抄袭，若改写过于表面，仍存在学术不规范风险。\n3. 对于相似内容的比例及其分布未做量化说明，如“重合比例”“分布位置”等信息，有助于更准确评判抄袭风险。\n4. 没有建议对技术性描述和实验流程也进行适度改写和个人化表达，以增强原创性。\n\n结论：  \nMain Model的分析可信，核心风险点已指出，但可补充对技术流程相似度和整体原创性的进一步分析，以及对相似部分比例的量化描述。",
            "Expert 2 Feedback: 审阅意见：\n\nMain Model的分析基本可信，能够准确识别出用户段落与相似文献中“当我们以正确的2D关节点位置作为逆向运动学的目标时……”这句话存在高度重合，并指出该部分需修改以避免抄袭嫌疑。同时，分析也指出其余内容为技术流程和实验描述，虽有一定相似但未构成大面积直接抄袭，判断合理。\n\n但分析略有遗漏：\n\n1. 对于技术流程和实验描述的“相似”部分，没有进一步量化或举例说明哪些表达较为接近原文，建议补充具体相似点，帮助作者进一步优化表述，提升原创性。\n2. 未对整体结构和创新性进行评价。例如，是否只是表述方式相似，还是内容创新度不足。\n3. 未提及参考文献引用情况。若有借鉴，应建议作者适当标注引用来源，以规范学术写作。\n\n总体结论：分析可信，但建议在相似表述细节、创新性及引用规范方面补充说明，使意见更全面。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"虽然Main Model分析和两位专家意见均认为只有部分句子高度重合，且技术流程和实验描述未构成大面积直接抄袭，但也都指出存在表述高度相似、结构性抄袭或原创性不足等风险。同时对技术流程、创新性和引用规范等方面的分析尚不充分，难以完全排除学术不规范的可能。因此，为保险起见应选择ABSTAIN。\"\n}",
        "plagiarism_confidence": 98,
        "plagiarism_percentage": 99,
        "plagiarism_snippet": [
            "神經網路所估計的",
            "關鍵點位置作為",
            "逆向運動學",
            "關鍵點位置做為目標",
            "網路估計",
            "為手部模型",
            "神經網路所估計",
            "正確的2D",
            "關鍵點位置作為逆向運動學的目標時",
            "我們發現迭代的收斂狀",
            "況並不理想",
            "容易陷入局部最小值",
            "此類問題常見的解決方向有二",
            "分別為迭代初始",
            "值以及最佳化方式。下面我們分別從這兩個方向做改善。"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "過去的研究皆顯示良好的初始值對於非線性最佳化有巨大的影響([21][26])，然而 Xu 和Cheng[21]或Ye 等人[26]所提出的技術是基於深度資訊的方法，無法直接使用在 我們的研究中。根據前人研究所獲得的經驗[21][44][28]，我們可以知道，手掌是否能 找到是結果好壞的關鍵。因此我們以估計手掌朝向的方向，作為初始值。近期較為相 關的研究把估計人體的方向視為一種分類問題[22][43]，，如圖16 所示，將水平360 度分成八個方向，並用神經網路進行分類，來達到估計人體方向的目的。 圖16、人體朝向分類示意圖，圖片出自[43] 本論文的問題與Choi 等人[22]或Liu 等人[43]所提出的情況略有不同。在我們的使 用情境下，手掌朝向可能是任意方向，因此本論文必需使用不同的分類方式。我們採 用了兩種不同的方法，一是把所有3D 方向依歐拉角分成256 個不同的方向(x, z 軸各分 成8 類角度，y 軸分成4 類角度)。另一種方法則是假設掌心到中指的MP 關節的直線 在圖片中為垂直線，以y 軸為選轉軸的360 度分8 類，以x 軸為旋轉軸的180 度分4 類，共32 類。經實驗證實，以這種假設做分類相較於不做假設分成256 類的好處有 二，第一是容易製造訓練資料集，第二是圖片經過預處理後神經網路訓練結果也較 好，詳細實驗請參考5.7 節。文中坐標軸方向請參考圖17。 圖17、角度分類法的坐標軸示意圖",
                "cross_score": 0.8482962250709534,
                "embedding_sim": 0.9312074184417725,
                "overlaps": [
                    "估計手掌朝向",
                    "分類問題"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/16.txt"
            },
            {
                "content": "2D、3D 關鍵點的部分，我們用以下三種方法作為衡量效果的標準，mean EPE(endpoint error):估計結果與正解之間的歐式距離的平均，PCK(percentage of correct keypoints):估計結果EPE 低於某個閥值的資料在資料集中的占比，AUC(area under the curve):用不同閥值的PCK 所畫成的曲線下的面積。此外由於我們是以單張圖片做估 計，因此我們不考慮尺度(scale)以及平移(translation)的差異，也就是說我們會將估計結 果按比例縮放、平移。而語意分割則是使用mIOU(mean intersection over union)當作評 估的標準。手掌朝向分類的部分，我們以正確率以及角度誤差來評估結果優劣，正確 率代表分類正確的百分比，而角度誤差是預測手掌朝向方向的結果與真正的結果之間 的最短的旋轉角度。",
                "cross_score": 0.48647797107696533,
                "embedding_sim": 0.9097268581390381,
                "overlaps": [
                    "ation)"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/20.txt"
            },
            {
                "content": "本論文以一般攝影機做為使用平台，結合神經網路與手部模型，建立手部姿勢估 計系統，以多任務學習的方式與手部語意切割系統做整合。並以藉由手掌作為初始值 與修改迭代演算法來改善逆向運動學的收斂狀況。圖1 為本論文所提出系統的實際估 測結果。整體來說，本論文的主要貢獻有二： 一、設計實作一個關鍵點估計網路，並藉由多任務學習同時提升關鍵點估計以及語意 切割兩者的準確度。 二、提出以神經網路估計手掌方向來做為初始值，改善迭代的結果。 圖1、實際估測結果。左邊為輸入影像、標上估測出來的手指關鍵點，右邊為根據估測出來的 參數所繪製的3D 手模型。",
                "cross_score": 0.13236673176288605,
                "embedding_sim": 0.891815185546875,
                "overlaps": [
                    "估計手掌"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/1.txt"
            }
        ],
        "main_analysis": "有明显的文字重叠和高度相似的表述，尤其是在手掌朝向估计的分类方式、欧拉角分法、类别数量（256类、32类）、图片预处理等细节描述上。用户段落与文献段落在技术流程、方法细节和分段结构上高度一致，存在较强的抄袭倾向。建议用户对内容进行改写并注明参考来源。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析整体可信，理由如下：\n\n- 分析准确指出了用户段落与相似文献在“手掌朝向估计的分类方式、欧拉角分法、类别数量（256类、32类）、图片预处理”等细节上的高度相似，属于核心技术流程和结构性表述的重复，确实存在较强抄袭嫌疑。\n- 分析建议用户改写并注明参考来源，符合学术规范要求。\n\n可能的遗漏：\n\n- 没有具体指出用户段落与哪一篇文献（或多篇）存在高度重合，缺少对最主要重合文献的编号或出处标明。\n- 没有量化相似度或引用具体的重合语句作为例证，导致证据稍显泛泛。\n- 没有评估用户段落是否有创新性内容，或是否对原文有适当改写/融合。\n- 未提及是否涉及图表、公式等非文字内容的直接使用。\n\n总之，Main Model的结论可信，但如能补充具体重合出处、举例重合内容或分析创新点，则更为完整。",
            "Expert 2 Feedback: 作为检查专家(Expert 2)，对Main Model的分析进行审阅后，结论如下：\n\n可信度评价：\nMain Model分析是可信的。理由如下：\n\n- 它准确指出了用户段落与相似文献在“手掌朝向估计的分类方式、欧拉角分法、类别数量（256类、32类）、图片预处理”等关键技术细节上的高度相似。\n- 分析提及了技术流程、方法细节和分段结构的一致性，说明确实进行了细致比对。\n\n是否有遗漏：\n- Main Model的分析已经涵盖了主要的相似点，没有明显遗漏。  \n- 若需补充，可进一步指出用户段落与文献在实验结果分析、采用第二种分类方式的理由、以及对前人工作的承接和改进等处也有高度重合之嫌。  \n- 建议可加强对“抄袭倾向”具体表现（如句式结构、数据分法直接照搬等）的举例说明，提升说服力。\n\n结论：\nMain Model的分析可信，未有明显遗漏，已能作为判定依据。可适当补充更具体的相似内容举证。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"用户段落与现有文献在核心技术细节、流程描述、分段结构等方面高度相似，存在明显抄袭嫌疑。尽管Main Model和两位专家的分析均认定相似度高、抄袭倾向强，但未提供具体重合出处和详细举证，无法百分百确定原创性，因此应选择ABSTAIN以规避误判风险。\"\n}",
        "plagiarism_confidence": 49,
        "plagiarism_percentage": 74,
        "plagiarism_snippet": [
            "估計手掌朝向",
            "分類問題",
            "ation)",
            "估計手掌"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "Hierarchical optimization 的方法是由Schröder 等人所提出的最佳化方法[33]，主要 目的為改善逆向運動學中最佳化演算的收斂性，可以減少不自然姿勢以及收斂至局部 最小值的情況。 在實際情況下，手部不同關節的靈活度並不相同，然而在一般的最佳化演算法中 是直接對所有的維度一起求解，並且所有的維度都是一樣的權重，所以較容易有不自 然的手部姿勢出現。因此論文提出coarse-to-fine 的多階段最佳化方式，並不直接使用 全部的維度進行迭代，而是先在較低的維度中求解，再依序增加維度大小，讓演算法 先在較重要的空間中找解，再逐漸微調。而最佳化求解的空間則是以PCA 對手勢資料 集的關節角度計算來取得，得到的PCA 空間能表達各個關節之間的聯繫以及各個關節 的靈活度。演算法pseudo code 可參考圖18。 圖18、Hierarchical optimization 演算法pseudo code",
                "cross_score": 0.6713302135467529,
                "embedding_sim": 0.8964735269546509,
                "overlaps": [
                    "等人所提出的",
                    "法[33]",
                    "論文提出"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/17.txt"
            },
            {
                "content": "當我們以神經網路所估計的2D 關鍵點位置作為輸入時，我們注意到如果有少數 2D 關鍵點估計錯誤，可能會大大影響逆向運動學之結果，因此我們將Eq. (10)稍作修 改，多加入介於0 到1 之間變數𝑟，首先將Eq.(9)中目標函數每個關鍵點的平方差都乘 上一個變數𝑟𝑖，作為每個關鍵點的權重，同時為避免最佳化演算法讓𝑟𝑖為0 來降低目標 函數的值，因此我們在目標函數後加上𝛼(1 −𝑟𝑖)2來避免，此方法可以使最佳化演算法 自己決定每個關鍵點所佔的權重，讓目標函數增加一些彈性，並非絕對相信神經網路 所估計出的結果，可將式子改寫成 ∑𝑟𝑖𝑝𝑖((𝑥𝑖−𝑢𝑖)2 + (𝑦𝑖−𝑣𝑖)2)) + 𝛼(1 −𝑟𝑖)2 𝑖=1 (10) 其中𝛼為常數。 最後為了確認本節演算法在正常狀況下的表現，我們以神經網路估計的2D 關鍵點 做為目標，MANO 作為手部模型，對本節所提到的演算法做實驗，測試個別以及同時 使用的效果，表7 為實驗結果。 表7、本節實驗結果 With Eq.(10)     Palm orientation   Hierarchical optimization   Mean EPE (mm) RHD 29.99 28.44 25.78 24.48 21.87 STB 31.29 31.03 30.88 29.57 29.47",
                "cross_score": 0.5771442651748657,
                "embedding_sim": 0.8938001394271851,
                "overlaps": [
                    "因此我們",
                    "本節實驗"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/26.txt"
            },
            {
                "content": "當我們以正確的2D 關鍵點位置作為逆向運動學的目標時，我們發現迭代的收斂狀 況並不理想，容易陷入局部最小值，此類問題常見的解決方向有二，分別為迭代初始 值以及最佳化方式。下面我們分別從這兩個方向做改善。 首先，如同4.3 節所述，我們將估計手掌朝向視為分類問題，我們嘗試兩種分類方 式，第一種以歐拉角表示手部方向(orientation)，共有三個維度，其中兩個維度的角度 範圍為0~2π，其中一個維度為0~π，每 𝜋 4分成一類，共分成256 類。第二種，我們先 將圖片進行預處理，旋轉圖片使手掌到中指垂直，同樣以歐拉角表示方向，共有兩個 維度，其中一個維度角度範圍為0~2π，另一個維度為0~π，共分32 類。由表6 的實 驗結果可看出第二種方法較好，因此我們採用第二種分類方式。 表6、兩種分類方式結果比較 正確率/旋轉誤差角度 RHD STB 256 類 30.1% 33.19 º 32.5% 37.69 º 32 類 66.5% 18.92 º 64.5% 26.36 º 接下來我們先我們對Romero 等人所提出的資料集[30]做PCA，得到PC-space，在 使用Hierarchical Optimization 演算法[33]進行實驗，我們測試分成不同階段數量的結 果，實驗結果可見圖24，可以看出在分成四個或以上的階段數量時，效果大致相同， 因此我們最終分成四個階段來執行此演算法。圖25 為本節實驗解果 圖24、Hierarchical Optimization 不同階段數量在RHD 上的實驗結果 圖25、結果比較圖，每組包含上下兩張圖片，由左到由分別為ground truth、前人提出的逆向 運動學、以及用本論文提出的設定初始值方法所算出來的結果。",
                "cross_score": 0.44335097074508667,
                "embedding_sim": 0.9266441464424133,
                "overlaps": [
                    "接下來我們先我們對Romero",
                    "等人所提出的資料集[30]做PCA",
                    "得到PC-space",
                    "使用Hierarchical Optimization",
                    "演算法[33]進行實驗",
                    "我們測試分成不同階段數量的結 果",
                    "實驗結果可見圖24",
                    "可以看出在分成四個或以上的階段數量時",
                    "效果大致相同",
                    " 因此我們最終分成四個階段來執行此演算法。圖25",
                    "為本節實驗解果 圖2",
                    "5、結果比較圖",
                    "每組包含上下兩張圖片",
                    "由左到由分別為",
                    "ground truth、前人提出的逆向 運動學、以及用本論文提出的設定初始值方法所算出來的結果。"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/25.txt"
            }
        ],
        "main_analysis": "经检查，用户段落与第三个最相似文献段落存在大量文字重叠，部分句子几乎完全一致，例如“接下來我們先我們對Romero等人所提出的資料集[30]做PCA,得到PC-space,在使用Hierarchical Optimization演算法[33]進行實驗,我們測試分成不同階段數量的結果,實驗結果可見圖24,可以看出在分成四個或以上的階段數量時,效果大致相同,因此我們最終分成四個階段來執行此演算法”等。此种情况属于明显的抄袭倾向，因为用户段落几乎原封不动地照搬了文献内容，仅有极少量词语调整。建议对内容进行改写，并明确引用来源。",
        "feedbacks": [
            "Expert 1 Feedback: 审阅意见：\n\nMain Model的分析基本可信。其指出用户段落与第三篇相似文献在关键句子、表述上存在大量重合，属于明显抄袭倾向，且建议进行改写并明确引用，分析逻辑清晰、结论合理。\n\n是否遗漏：\n1. 该分析未对用户段落是否存在合理引用进行评价（如引用格式、文献标号等是否与原文一致）。\n2. 未指出具体应如何改写（比如建议同义转述、结构调整等），但这超出抄袭判别本身的职责。\n3. 未评估用户段落是否有对原文内容进行任何创新性扩展或个人观点补充。\n\n总体结论：\nMain Model分析可信，未有明显遗漏，已充分指出文字重叠和抄袭问题，建议采纳。",
            "Expert 2 Feedback: Main Model的分析基本可信，能够清楚指出用户段落与第三篇相似文献存在大量文字重叠，并举例说明了具体重合的句子，判断为明显的抄袭倾向，建议改写并标明引用，结论明确、依据充分。\n\n但略有不足之处：\n\n1. **未指出具体文献出处**：虽然提及是第三个相似文献，但没有给出完整文献信息，若需进一步追查，信息略显不足。\n2. **未评估创新性贡献**：仅指出抄袭问题，未分析用户段落中是否有创新性内容或对原文有无实质改动。\n3. **未提及引用格式问题**：虽然建议标明引用，但未具体说明应采用何种引用方式（如APA、IEEE等）。\n4. **未评估整体段落结构**：未评价用户段落整体结构是否合理，仅聚焦在文字重合上。\n\n总体而言，分析可信，但可进一步补充对创新性、引用规范等方面的评价。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"根据Main Model和两位专家的分析，用户段落与第三篇相似文献存在大量文字重叠，核心句子几乎完全照搬，属于明显抄袭倾向。虽然段落中有部分文献标号，但内容基本未作改写，也未体现创新性贡献，引用方式和创新性均存在问题，因此应怀疑其有抄袭行为，不能直接接受。\"\n}",
        "plagiarism_confidence": 56,
        "plagiarism_percentage": 78,
        "plagiarism_snippet": [
            "等人所提出的",
            "法[33]",
            "論文提出",
            "因此我們",
            "本節實驗",
            "接下來我們先我們對Romero",
            "等人所提出的資料集[30]做PCA",
            "得到PC-space",
            "使用Hierarchical Optimization",
            "演算法[33]進行實驗",
            "我們測試分成不同階段數量的結 果",
            "實驗結果可見圖24",
            "可以看出在分成四個或以上的階段數量時",
            "效果大致相同",
            " 因此我們最終分成四個階段來執行此演算法。圖25",
            "為本節實驗解果 圖2",
            "5、結果比較圖",
            "每組包含上下兩張圖片",
            "由左到由分別為",
            "ground truth、前人提出的逆向 運動學、以及用本論文提出的設定初始值方法所算出來的結果。"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "本節整理本論文對2D 關鍵點做逆向運動學的相關實驗結果，相關技術請參考4.2 節。實驗以RHD、STB 做為測試資料集，我們依序進行了兩組實驗，首先為測試LM 演算法在此問題上的效果，所以我們排除會影響收斂的其他因素，因此用正確的2D 關 鍵點位置做為目標，並將手部模型的關節間長度比例調整至正確的比例，觀察迭代的 收斂狀況及結果。再來我們測試演算法是否robust，我們改為使用網路估計的2D 關鍵 點位置做為目標，以MANO 作為手部模型，觀察演算法結果。在本節實驗中我們專注 於3D 關鍵點估計上，因此我們假設圖片中的手已被物體偵測演算法正確框出並分類為 左、右手。在目標函數上，我們以Panteleris 等人所提出目標函數[15]為基礎進行修 改，將神經網路所估計的機率𝑝𝑖由六次方改為一次方，Eq. (9)為我們的目標方程式。下 面分別說明兩個實驗的結果。 ∑𝑝𝑖((𝑥𝑖−𝑢𝑖)2 + (𝑦𝑖−𝑣𝑖)2) 𝑖=1 (9)",
                "cross_score": 0.8432848453521729,
                "embedding_sim": 0.9503107070922852,
                "overlaps": [
                    "神經網路所估計的",
                    "Eq. ("
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/24.txt"
            },
            {
                "content": "當我們以正確的2D 關鍵點位置作為逆向運動學的目標時，我們發現迭代的收斂狀 況並不理想，容易陷入局部最小值，此類問題常見的解決方向有二，分別為迭代初始 值以及最佳化方式。下面我們分別從這兩個方向做改善。 首先，如同4.3 節所述，我們將估計手掌朝向視為分類問題，我們嘗試兩種分類方 式，第一種以歐拉角表示手部方向(orientation)，共有三個維度，其中兩個維度的角度 範圍為0~2π，其中一個維度為0~π，每 𝜋 4分成一類，共分成256 類。第二種，我們先 將圖片進行預處理，旋轉圖片使手掌到中指垂直，同樣以歐拉角表示方向，共有兩個 維度，其中一個維度角度範圍為0~2π，另一個維度為0~π，共分32 類。由表6 的實 驗結果可看出第二種方法較好，因此我們採用第二種分類方式。 表6、兩種分類方式結果比較 正確率/旋轉誤差角度 RHD STB 256 類 30.1% 33.19 º 32.5% 37.69 º 32 類 66.5% 18.92 º 64.5% 26.36 º 接下來我們先我們對Romero 等人所提出的資料集[30]做PCA，得到PC-space，在 使用Hierarchical Optimization 演算法[33]進行實驗，我們測試分成不同階段數量的結 果，實驗結果可見圖24，可以看出在分成四個或以上的階段數量時，效果大致相同， 因此我們最終分成四個階段來執行此演算法。圖25 為本節實驗解果 圖24、Hierarchical Optimization 不同階段數量在RHD 上的實驗結果 圖25、結果比較圖，每組包含上下兩張圖片，由左到由分別為ground truth、前人提出的逆向 運動學、以及用本論文提出的設定初始值方法所算出來的結果。",
                "cross_score": 0.6402332782745361,
                "embedding_sim": 0.9136868715286255,
                "overlaps": [
                    "當我們以",
                    "關鍵點位置作為",
                    "逆向運動學",
                    "實驗結果",
                    "的結果。"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/25.txt"
            },
            {
                "content": "當我們以神經網路所估計的2D 關鍵點位置作為輸入時，我們注意到如果有少數 2D 關鍵點估計錯誤，可能會大大影響逆向運動學之結果，因此我們將Eq. (10)稍作修 改，多加入介於0 到1 之間變數𝑟，首先將Eq.(9)中目標函數每個關鍵點的平方差都乘 上一個變數𝑟𝑖，作為每個關鍵點的權重，同時為避免最佳化演算法讓𝑟𝑖為0 來降低目標 函數的值，因此我們在目標函數後加上𝛼(1 −𝑟𝑖)2來避免，此方法可以使最佳化演算法 自己決定每個關鍵點所佔的權重，讓目標函數增加一些彈性，並非絕對相信神經網路 所估計出的結果，可將式子改寫成 ∑𝑟𝑖𝑝𝑖((𝑥𝑖−𝑢𝑖)2 + (𝑦𝑖−𝑣𝑖)2)) + 𝛼(1 −𝑟𝑖)2 𝑖=1 (10) 其中𝛼為常數。 最後為了確認本節演算法在正常狀況下的表現，我們以神經網路估計的2D 關鍵點 做為目標，MANO 作為手部模型，對本節所提到的演算法做實驗，測試個別以及同時 使用的效果，表7 為實驗結果。 表7、本節實驗結果 With Eq.(10)     Palm orientation   Hierarchical optimization   Mean EPE (mm) RHD 29.99 28.44 25.78 24.48 21.87 STB 31.29 31.03 30.88 29.57 29.47",
                "cross_score": 0.47992604970932007,
                "embedding_sim": 0.9711164236068726,
                "overlaps": [
                    "當我們以神經網路所估計的2D",
                    "關鍵點位置作為輸入時",
                    "我們注意到如果有少數 2D 關鍵點估計錯誤",
                    "可能會大大影響逆向運動學之結果",
                    "因此我們將Eq. (10)稍作修 改",
                    "多加入介於0",
                    "之間變數",
                    "首先將Eq.(9)中目標函數每個關鍵點的平方差都乘 上一個變數",
                    "作為每個關鍵點的權重",
                    "同時為避免最佳化演算法讓",
                    "來降低目標 函數的值",
                    "因此我們在目標函數後加上",
                    ")2來避免",
                    "此方法可以使最佳化演算法",
                    "自己決定每個關鍵點所佔的權重",
                    "讓目標函數增加一些彈性",
                    "並非絕對相信神經網路",
                    "所估計出的結果",
                    "可將式子改寫成",
                    " 最後為了確認本節演算法在正常狀況下的表現",
                    "我們以神經網路估計的2D",
                    "做為目標",
                    "MANO",
                    "作為手部模型",
                    "對本節所提到的演算法做實驗",
                    "測試個別以及同時",
                    "使用的效果",
                    "為實驗結果。 "
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/26.txt"
            }
        ],
        "main_analysis": "存在大量文字重叠，尤其是关于“当我们以神经网络所估计的2D关键点位置作为输入时，我们注意到如果有少数2D关键点估计错误，可能会大大影响逆向运动学之结果，因此我们将Eq.(10)稍作修改，多加入介于0到1之间变量r……”等句子几乎与文献段落一致，且涉及具体公式与实验描述。用户段落有明显抄袭倾向，建议进行改写并注明参考来源。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析是可信的。它准确指出了用户段落与相似文献在表述、结构和实验描述上存在大量文字重叠，尤其是关于优化目标函数的修改和实验流程等内容，几乎完全一致。分析也合理判断该段落有明显抄袭倾向，并建议进行改写和注明参考来源。\n\n可能的补充：  \nMain Model未具体指出抄袭内容所涉及的公式（如Eq.(9)、Eq.(10)及相关权重α、r_i的引入）和具体实验结果（如表7、表8）也高度一致，建议后续可以更明确地标注这些重复内容，增强报告的说服力。此外，Main Model未提及是否对原文献进行了适当引用（目前看用户段落未有引用），可以补充建议需在文中明确注明原始出处。",
            "Expert 2 Feedback: 结论：Main Model 的分析可信，没有明显遗漏。\n\n简要说明：\n\n- 分析准确性：Main Model 指出用户段落与相似文献在内容、表达、公式与实验描述上有大量重叠，尤其是关于变量r、目标函数修改、实验流程等几乎原文照搬。判断“有明显抄袭倾向”是合理的。\n- 关键点覆盖：分析已涵盖文字内容重叠、实验描述相似、公式雷同等主要抄袭特征。\n- 可能遗漏：分析没有特别列出用户段落和原文的具体句子一一对应关系，但给出的例证已经足够说明重叠问题。未提及“抄袭比例”或“是否构成学术不端”最终判断，但这不是本次审核的重点。\n- 结论：整体分析可信，覆盖了主要问题，没有明显遗漏。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"根据Main Model和两位专家的分析，用户段落与相似文献在表述、结构、公式和实验描述上存在大量重叠，且未见适当引用，具有明显抄袭倾向。故应选择ABSTAIN，避免接受疑似抄袭内容。\"\n}",
        "plagiarism_confidence": 65,
        "plagiarism_percentage": 83,
        "plagiarism_snippet": [
            "神經網路所估計的",
            "Eq. (",
            "當我們以",
            "關鍵點位置作為",
            "逆向運動學",
            "實驗結果",
            "的結果。",
            "當我們以神經網路所估計的2D",
            "關鍵點位置作為輸入時",
            "我們注意到如果有少數 2D 關鍵點估計錯誤",
            "可能會大大影響逆向運動學之結果",
            "因此我們將Eq. (10)稍作修 改",
            "多加入介於0",
            "之間變數",
            "首先將Eq.(9)中目標函數每個關鍵點的平方差都乘 上一個變數",
            "作為每個關鍵點的權重",
            "同時為避免最佳化演算法讓",
            "來降低目標 函數的值",
            "因此我們在目標函數後加上",
            ")2來避免",
            "此方法可以使最佳化演算法",
            "自己決定每個關鍵點所佔的權重",
            "讓目標函數增加一些彈性",
            "並非絕對相信神經網路",
            "所估計出的結果",
            "可將式子改寫成",
            " 最後為了確認本節演算法在正常狀況下的表現",
            "我們以神經網路估計的2D",
            "做為目標",
            "MANO",
            "作為手部模型",
            "對本節所提到的演算法做實驗",
            "測試個別以及同時",
            "使用的效果",
            "為實驗結果。 "
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "本論文研究目標為以單一相機做為使用平台的手部姿勢(hand pose)估計，本論文系 統以一般低價網路攝影機拍攝的彩色影像作為輸入，主要輸出為相對於手掌心的3D 關 鍵點位置(也就是3D 坐標的原點是定位於掌心，而坐標的X, Y, Z 方向在第4.3 節會再 說明)、以及2D 手部關鍵點位置。此處2D 關鍵點是指手部關鍵點在影像中的位置，因 為我們假設了一個3D 的手部模型，即使只用單一攝影機以及2D 的關鍵點也可大約推 算出3D 的手部關鍵點坐標。手部關鍵點指的是手掌的中心、手指關節、手指指尖共 21 點，請參考圖14。而手部3D 關鍵點通常被稱為手部姿勢。 圖14、手部關鍵點示意圖，紅點為手部關鍵點位置 本論文最終選擇以Panteleris 等人所設計的系統作為基礎的系統架構[15]，在此架 構上最需要改進的地方有兩個，第一是手部關鍵點位置的正確性，第二是逆向運動學 中最佳化演算法的收斂結果正確度。本論文主要針對此二問題做改進。",
                "cross_score": 0.9966302514076233,
                "embedding_sim": 0.9026393890380859,
                "overlaps": [
                    "為使用平台",
                    "的手部姿勢"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/14.txt"
            },
            {
                "content": "本論文分成六章，第一章介紹動機與成果。第二章介紹手部姿勢與關鍵點抽取的 相關研究。第三章介紹本論文所提出的系統架構所使用到的技術描述。第四章介紹本 論文系統所針對的問題的明確定義以及如何修改、整合第三章所提到的技術成為最終 的系統架構。第五章描述實驗方式以及結果。第六章則為論文的結論以及未來方向。 第二章、手部姿勢及關鍵點抽取相關研究 手部姿勢估計一直以來都是電腦視覺領域中重要的研究方向之一，目前在此類問 題上，主流方法為藉由神經網路估計關鍵點位置，再以關鍵點資訊推論手部姿勢，因 此本章主要介紹手部姿勢以及關鍵點估計的相關研究。而在關鍵點估計的部分，由於 網路架構設計的相關研究大多都以人體關鍵點做為研究對象，且手部與人體的關鍵點 估計並無太大差異，因此此處以多人體關鍵點估計的相關研究為介紹對象。此外，本 論文最終是利用3D 手部模型做為手部姿勢估測的主要限制條件 (Model-constrained estimation method)，因此本章最後會介紹手部模型的相關研究。",
                "cross_score": 0.9903839826583862,
                "embedding_sim": 0.9129413962364197,
                "overlaps": [
                    "手部姿勢估計"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/2.txt"
            },
            {
                "content": "本論文以一般攝影機做為使用平台，結合神經網路與手部模型，建立手部姿勢估 計系統，以多任務學習的方式與手部語意切割系統做整合。並以藉由手掌作為初始值 與修改迭代演算法來改善逆向運動學的收斂狀況。圖1 為本論文所提出系統的實際估 測結果。整體來說，本論文的主要貢獻有二： 一、設計實作一個關鍵點估計網路，並藉由多任務學習同時提升關鍵點估計以及語意 切割兩者的準確度。 二、提出以神經網路估計手掌方向來做為初始值，改善迭代的結果。 圖1、實際估測結果。左邊為輸入影像、標上估測出來的手指關鍵點，右邊為根據估測出來的 參數所繪製的3D 手模型。",
                "cross_score": 0.989948034286499,
                "embedding_sim": 0.9287459850311279,
                "overlaps": [
                    "本論文以",
                    "為使用平台",
                    "神經網路",
                    "手部模型",
                    "手部姿勢估"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/1.txt"
            }
        ],
        "main_analysis": "经比对，用户段落与最相似文献段落存在部分用词和表达方式上的相似，例如“以单摄像机为平台”“结合神经网络与手部模型”“建立手部姿势估计系统”等句式，但整体未出现完整句子或大段文字的直接重叠。用户段落为简要描述，并未详细阐述技术细节，与文献段落在表述上有一定共通性，但不构成抄袭倾向。建议在后续写作中进一步突出自身创新点，避免与常见表述过度雷同。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析基本可信。分析准确指出了用户段落与相似文献在用词和表达上的共通性，但没有出现完整句子的直接抄袭，且用户段落为简要描述，未涉及技术细节，与文献内容存在一定差异，不构成抄袭。\n\n可能遗漏之处：  \n分析未特别指出用户段落与相似文献在句式结构和表达习惯上的高度重合（如“以...为平台，结合...，建立...系统”这一常见三段式结构），虽然不构成抄袭，但属于通用表述，建议提醒用户未来可更换表达方式以增强原创性。此外，分析未明确指出用户段落中的创新点或差异，也未提及是否需要补充引用或致谢相关文献来源。\n\n综上，Main Model分析可信，但可进一步细化对表述共性和创新点的提示。",
            "Expert 2 Feedback: Main Model 的分析总体可信，其判断用户段落与相似文献主要为表达方式和用词上的共通，而无大段抄袭或完整句子直接重叠，结论中认为不构成抄袭倾向，这是合理的。\n\n但分析有一点小的遗漏：  \n用户段落“以單攝影機第一人視角的頭戴式系統為使用平台”中的“第一人視角的頭戴式系統”这一具体应用场景在Top 3文献段落中未明确出现，属于用户段落的细微创新或细化，应予以强调。这说明用户段落在应用平台描述上较为具体，有一定原创性。\n\n建议补充：  \n分析可进一步指出，尽管核心方法表述类似，但用户段落在具体平台（第一人称头戴式单摄系统）描述上与文献存在差异，这部分具有一定创新性或具体化表达。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"用户段落与相似文献在用词和表达方式上存在通用表述，但未出现完整句子或大段文字的直接抄袭，且用户段落对应用平台有细微创新和具体化，整体不构成抄袭或高度相似，可接受。\"\n}",
        "plagiarism_confidence": 99,
        "plagiarism_percentage": 40,
        "plagiarism_snippet": [
            "為使用平台",
            "的手部姿勢",
            "手部姿勢估計",
            "本論文以",
            "神經網路",
            "手部模型",
            "手部姿勢估"
        ],
        "verdict": "ACCEPT"
    },
    {
        "top_docs_info": [
            {
                "content": "本次的研究流程如圖2，研究架構如下：第一章緒論1.1 研究背景說明目前的 自然語言處理技術與發展，以及目前中文在自然語言處理的處境。在1.2 研究動機 與目的說明目前中文摘要在實際應用的困境，以及該研究的方向。第二章文獻探 討文本摘要與中文自然語言處理的差異，並且介紹本研究用到的深度學習的定義 與架構模型，及其中運用到的函數。以及最佳化類神經網路中所使用的手法，並 且介紹本研究使用的深度學習演算法，循環神經網路(RNN)、長短期記憶神經網路 (LSTM) 與序列到序列架構(sequence to sequence)搭配注意力機制(Attention)與選 字階段的搜尋手法。第三章介紹使用的資料集與評估工具，並且提出實驗架構說 明。第四章呈現這幾次實驗的評估結果。第五章將會提出本研究的結論和未來研 究方向與改進。 圖 2  論文架構 第二章、 文獻探討 本章節分為九個小節，自動文本摘要的分類介紹與中文自然語言處理的特點， 接下來介紹深度學習與更進一步的循環神經網絡與其變形的雙向循環神經網絡， 再來介紹本研究神經網絡中隱藏層所使用的長短期記憶模型與本論文主要的序列 到序列架構與注意力機制及搜索法。",
                "cross_score": 0.8607978224754333,
                "embedding_sim": 0.8839601278305054,
                "overlaps": [
                    "神經網路",
                    "神經網路",
                    "神經網路"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/177.txt"
            },
            {
                "content": "本論文所提出的系統架構如圖15 所示，是以在3.2 節所介紹的系統(圖12)[15]為 基礎進行修改。在網路架構的部分，我們最終選擇MSPN[8]、yolov3[34]所採用的架 構，同時我們將系統中2D 關鍵點估計的神經網路，與deeplabv3+[31]進行整合，設計 一個多任務學習(multi-task learning)的網路架構。逆向運動學的部分，本論文以 Levenberg-Marquardt 演算法最佳化，並以ResNet[32]預測手掌orientation 作為迭代的初 始值，以及[33]中的方法修改最佳化方式，改善迭代的收斂狀況。以下介紹本論文對於 Panteleris 等人所提出的架構[15]所修改的部分。 圖15、本論文所提出的系統架構圖",
                "cross_score": 0.6845593452453613,
                "embedding_sim": 0.8819230794906616,
                "overlaps": [
                    "網路架構",
                    "神經網路",
                    "的網路架構。"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/15.txt"
            },
            {
                "content": "本研究將在第二章進文獻回顧與歸納，包含類神經網路及市場輪廓理論介 紹等。第三章描述研究方法、資料來源、資料前處理、實驗模型設計及績效評 估方式。第四章比較不同模型的實驗結果，進而分析其績效優劣。第五章闡述 實驗結果的分析與結論，並對未來研究方向等後續建議。 本論文之架構分為五章，說明分別如下: 第一章 緒論 說明研究背景與動機、研究目的、研究範圍、研究限制、研究流程與步驟等。 第二章 文獻探討 針對本論文所要研究的問題進行文獻的探討與回顧，包含市場輪廓、類神經網 路之文獻。 第三章 研究方法 描述本研究資料篩選、資料前處理、實驗組和對照組模型的設計與架構及績效 評估模式。 第四章 實驗結果與分析 分析本實驗的實驗結果並針對不同模型的實驗結果進行績效比較。 第五章 結論與未來的研究方向 總結研究結論與未來的研究方向。 第二章、文獻探討",
                "cross_score": 0.5479934215545654,
                "embedding_sim": 0.8859549164772034,
                "overlaps": [
                    "神經網路"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/1011.txt"
            }
        ],
        "main_analysis": "经检查，用户段落与最相似文献段落之间没有明显的文字重叠，表述方式和用词也有区别。用户段落为对神经网络架构实验和分析的简要描述，未见直接抄袭文献内容。总体来看，不存在抄袭倾向。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析总体可信，理由如下：\n\n- 分析指出用户段落与相似文献段落无明显文字重叠，表述方式和用词不同，未见直接抄袭，判断没有抄袭倾向，结论合理。\n- 用户段落确实只是简要说明了神经网络架构的实验与分析，并未使用文献中的具体内容或结构描述，且未涉及独特表达。\n\n但分析有如下小的遗漏：\n\n- 虽然没有文字重叠，但可以进一步检查“观点抄袭”或“结构抄袭”的可能性，例如用户段落的研究流程、实验步骤是否与文献描述的结构高度一致。\n- 可补充说明：用户段落内容较为通用，属于常见学术写作表述，未见特殊创新或独特描述，因此与文献结构类似也属于合理现象，不构成抄袭。\n\n结论：分析可信，但可适当补充关于观点或结构相似性的说明，以更全面排查抄袭风险。",
            "Expert 2 Feedback: Main Model的分析基本可信。分析指出用户段落与相似文献在表述方式和用词上有明显区别，没有直接文字重叠，且用户段落只是对实验和分析的简要描述，未见抄袭。这一判断是合理的。\n\n但分析略有遗漏：  \n1. 没有进一步说明“内容层面”的相似性。虽然没有文字重叠，但主题和研究流程（如“神经网络架构选择、实验评估、数据集对比”等）与文献有一定内容重合，宜补充说明“内容相似度”不足以构成抄袭。\n2. 未提及“表达层次”的创新性。可以进一步确认用户段落在结构和表达上是否有原创性，而不仅仅是没有抄袭。\n\n结论：分析可信，但可补充对内容相似度和表达创新性的说明，使判断更为全面。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"用户段落与相似文献在表述方式、用词和具体内容上无直接重叠，仅为常见的学术写作描述，未见抄袭迹象。虽然有专家建议补充对内容和结构相似性的说明，但现有信息未显示抄袭或高度相似，判断为可接受。\"\n}",
        "plagiarism_confidence": 70,
        "plagiarism_percentage": 28,
        "plagiarism_snippet": [
            "神經網路",
            "網路架構",
            "的網路架構。"
        ],
        "verdict": "ACCEPT"
    },
    {
        "top_docs_info": [
            {
                "content": "當我們以正確的2D 關鍵點位置作為逆向運動學的目標時，我們發現迭代的收斂狀 況並不理想，容易陷入局部最小值，此類問題常見的解決方向有二，分別為迭代初始 值以及最佳化方式。下面我們分別從這兩個方向做改善。 首先，如同4.3 節所述，我們將估計手掌朝向視為分類問題，我們嘗試兩種分類方 式，第一種以歐拉角表示手部方向(orientation)，共有三個維度，其中兩個維度的角度 範圍為0~2π，其中一個維度為0~π，每 𝜋 4分成一類，共分成256 類。第二種，我們先 將圖片進行預處理，旋轉圖片使手掌到中指垂直，同樣以歐拉角表示方向，共有兩個 維度，其中一個維度角度範圍為0~2π，另一個維度為0~π，共分32 類。由表6 的實 驗結果可看出第二種方法較好，因此我們採用第二種分類方式。 表6、兩種分類方式結果比較 正確率/旋轉誤差角度 RHD STB 256 類 30.1% 33.19 º 32.5% 37.69 º 32 類 66.5% 18.92 º 64.5% 26.36 º 接下來我們先我們對Romero 等人所提出的資料集[30]做PCA，得到PC-space，在 使用Hierarchical Optimization 演算法[33]進行實驗，我們測試分成不同階段數量的結 果，實驗結果可見圖24，可以看出在分成四個或以上的階段數量時，效果大致相同， 因此我們最終分成四個階段來執行此演算法。圖25 為本節實驗解果 圖24、Hierarchical Optimization 不同階段數量在RHD 上的實驗結果 圖25、結果比較圖，每組包含上下兩張圖片，由左到由分別為ground truth、前人提出的逆向 運動學、以及用本論文提出的設定初始值方法所算出來的結果。",
                "cross_score": 0.9952654838562012,
                "embedding_sim": 0.8977500200271606,
                "overlaps": [
                    "逆向運動學",
                    "發現迭代",
                    "局部最小值"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/25.txt"
            },
            {
                "content": "本論文以一般攝影機做為使用平台，結合神經網路與手部模型，建立手部姿勢估 計系統，以多任務學習的方式與手部語意切割系統做整合。並以藉由手掌作為初始值 與修改迭代演算法來改善逆向運動學的收斂狀況。圖1 為本論文所提出系統的實際估 測結果。整體來說，本論文的主要貢獻有二： 一、設計實作一個關鍵點估計網路，並藉由多任務學習同時提升關鍵點估計以及語意 切割兩者的準確度。 二、提出以神經網路估計手掌方向來做為初始值，改善迭代的結果。 圖1、實際估測結果。左邊為輸入影像、標上估測出來的手指關鍵點，右邊為根據估測出來的 參數所繪製的3D 手模型。",
                "cross_score": 0.9768841862678528,
                "embedding_sim": 0.9026496410369873,
                "overlaps": [
                    "迭代演算法"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/1.txt"
            },
            {
                "content": "本節整理本論文對2D 關鍵點做逆向運動學的相關實驗結果，相關技術請參考4.2 節。實驗以RHD、STB 做為測試資料集，我們依序進行了兩組實驗，首先為測試LM 演算法在此問題上的效果，所以我們排除會影響收斂的其他因素，因此用正確的2D 關 鍵點位置做為目標，並將手部模型的關節間長度比例調整至正確的比例，觀察迭代的 收斂狀況及結果。再來我們測試演算法是否robust，我們改為使用網路估計的2D 關鍵 點位置做為目標，以MANO 作為手部模型，觀察演算法結果。在本節實驗中我們專注 於3D 關鍵點估計上，因此我們假設圖片中的手已被物體偵測演算法正確框出並分類為 左、右手。在目標函數上，我們以Panteleris 等人所提出目標函數[15]為基礎進行修 改，將神經網路所估計的機率𝑝𝑖由六次方改為一次方，Eq. (9)為我們的目標方程式。下 面分別說明兩個實驗的結果。 ∑𝑝𝑖((𝑥𝑖−𝑢𝑖)2 + (𝑦𝑖−𝑣𝑖)2) 𝑖=1 (9)",
                "cross_score": 0.948387622833252,
                "embedding_sim": 0.9036632776260376,
                "overlaps": [
                    "逆向運動學",
                    "目標函數"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/24.txt"
            }
        ],
        "main_analysis": "经检查，用户段落与最相似文献段落内容高度相似，但并未出现大段一字不差的文字重叠，整体为同一主题的“逆向运动学在手势估计中的收敛与敏感性问题的改进方法”叙述。用户段落表述较为简练，但核心思路、实验步骤和改进方法与文献内容高度一致，存在明显的内容抄袭倾向，建议用户增加个人理解、改写及引用。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析整体可信，指出了用户段落与相似文献在主题、核心思路和实验方法上高度一致，没有大段文字复制，但存在明显的内容抄袭倾向，建议改写和引用。这一判断与对比段落内容基本吻合。\n\n可能的遗漏：\n- Main Model未具体指出用户段落与文献内容相似的“具体点”（如目标函数修改、初始值设定等细节），只做了整体性的归纳，略显笼统。\n- 未说明用户段落是否有加入自己的实验数据、分析或创新点，仅笼统说“表述较为简练”。\n- 未提及用户段落是否有引用相关文献，或引用格式是否规范。\n\n建议：可补充对用户段落中具体细节与文献对照的例证，及用户是否有独立贡献的判别。",
            "Expert 2 Feedback: Main Model 的分析基本可信，能够准确指出用户段落与相似文献在“逆向运动学在手势估计中的收敛与敏感性问题的改进方法”方面的高度内容一致性，并提醒存在明显抄袭倾向，建议改写和引用。分析中没有发现明显遗漏，已涵盖核心内容和主要问题。不过，分析可进一步具体指出用户段落与文献在实验设计、方法改进等细节上的对应关系，以增强说服力。此外，可建议用户在补充个人理解时，结合自身实验或实际应用背景，提升原创性。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"用户段落与相似文献在主题、核心思路和方法细节上高度一致，虽然未发现大段文字复制，但存在明显内容抄袭倾向。用户段落未体现个人独立见解、实验数据或创新性，也未见引用，无法确认其原创性，因此应选择ABSTAIN。\"\n}",
        "plagiarism_confidence": 97,
        "plagiarism_percentage": 99,
        "plagiarism_snippet": [
            "逆向運動學",
            "發現迭代",
            "局部最小值",
            "迭代演算法",
            "目標函數"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "本論文分成六章，第一章介紹動機與成果。第二章介紹手部姿勢與關鍵點抽取的 相關研究。第三章介紹本論文所提出的系統架構所使用到的技術描述。第四章介紹本 論文系統所針對的問題的明確定義以及如何修改、整合第三章所提到的技術成為最終 的系統架構。第五章描述實驗方式以及結果。第六章則為論文的結論以及未來方向。 第二章、手部姿勢及關鍵點抽取相關研究 手部姿勢估計一直以來都是電腦視覺領域中重要的研究方向之一，目前在此類問 題上，主流方法為藉由神經網路估計關鍵點位置，再以關鍵點資訊推論手部姿勢，因 此本章主要介紹手部姿勢以及關鍵點估計的相關研究。而在關鍵點估計的部分，由於 網路架構設計的相關研究大多都以人體關鍵點做為研究對象，且手部與人體的關鍵點 估計並無太大差異，因此此處以多人體關鍵點估計的相關研究為介紹對象。此外，本 論文最終是利用3D 手部模型做為手部姿勢估測的主要限制條件 (Model-constrained estimation method)，因此本章最後會介紹手部模型的相關研究。",
                "cross_score": 0.7034661769866943,
                "embedding_sim": 0.8796792030334473,
                "overlaps": [
                    "本論文所提出",
                    "手部姿勢估計"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/2.txt"
            },
            {
                "content": "在過去基於深度影像進行手部姿勢估測方法中，大多數研究皆搭配手部模型進 行，透過尋找手部模型參數，使手部模型的深度資訊與深度圖像相似，通常透過迭代 最佳化演算法求解，如PSO[20]。而近期的研究，則多以神經網路估計3D 關鍵點位置 [23][24]。Wan 等人提出讓卷積神經網路同時估計2D、3D 關鍵點以及單位向量場(指向 手指頭)，藉此提升精確度的方法[23]。Ge 等人則提出使用3D 卷積神經網路來估計3D 關鍵點位置的機制[24]。",
                "cross_score": 0.5329872965812683,
                "embedding_sim": 0.8770511746406555,
                "overlaps": [
                    "手部姿勢估"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/3.txt"
            },
            {
                "content": "MANO 手模型是在2017 年提出的開源碼手部模型[30]。以姿勢(pose)、形狀 (shape)兩種參數類型來描述模型狀態，由姿勢參數控制關節的轉動，形狀參數則影響 骨架比例與手的形狀。 MANO 不同於上面兩個手部模型使用LBS(Linear Blend Skinning)來描述骨架與網 格之間的關係，而是從手的三維掃描(3D scan)中學習姿勢、形狀兩種參數和骨架、網 格之間的關係，為此Romero 等人提出了一個包含51 種手勢的三維掃描資料集。圖9 為MANO 模型圖。這是本論文所採用的3D 手部模型。 圖9、MANO 手部模型，圖片出自[30] 第三章、本論文所採用的技術介紹 本論文所提出的手部姿勢估測系統，是參考了許多現有己發表的技術，進行實驗 分析後，抽取出各技術的長處以組合出最後的系統。本章針對我們在設計實作系統架 構的過程中所實際採用到的技術進行討論。至於我們提出的系統架構細節會在第四章 描述。",
                "cross_score": 0.5084713101387024,
                "embedding_sim": 0.8864753842353821,
                "overlaps": [
                    "手部模型",
                    "骨架比例",
                    "本論文所提出",
                    "手部姿勢估"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/8.txt"
            }
        ],
        "main_analysis": "经检查，用户段落与最相似文献段落之间没有出现明显的文字重叠，表述方式和用词均有明显差异。用户段落侧重于讨论骨架比例调整对手部姿势估计精度的影响，而文献段落则主要介绍相关研究背景、方法和手部模型（如MANO）。因此，不存在抄袭倾向。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析基本可信，能够准确指出用户段落与相似文献在内容和表述上的差异，没有发现明显抄袭。但有一点遗漏：未进一步分析用户段落中的“根据我们实验，若使用正确骨架比例可降低约10mm误差”等具体实验数据或结论，是否与文献中出现过类似数据表述或结果。建议补充核查实验结果和数据描述的独创性。",
            "Expert 2 Feedback: Main Model的分析基本可信，其指出用户段落与相似文献段落在文字表达和内容侧重点上均有明显差异，且未发现明显的文字重叠，判断为无抄袭倾向是合理的。\n\n但分析存在小幅遗漏：  \n1. 没有进一步核查“骨架比例调整对误差的具体影响”这一实验结论是否为用户独有创新，或在文献中已有类似实验结果。  \n2. 没有明确说明用户段落中的数据和结论（如“可降低约10mm的误差”）是否为原创数据，还是可能来自文献未被直接引用的部分。\n\n建议在分析时补充对上述实验数据独创性的核查，以确保全面性。"
        ],
        "judge_output": "{\n  \"verdict\": \"ABSTAIN\",\n  \"reason\": \"虽然用户段落与相似文献在表述和内容侧重点上存在明显差异，未发现直接抄袭的文字，但用户段落中出现了具体实验数据和结论（如‘可降低约10mm的误差’），而目前尚未核查这些数据和结论是否为用户独有创新，或是否已在文献中有类似表述。为避免遗漏潜在抄袭或数据引用不当的风险，建议先补充对实验数据独创性的核查，因此应选择ABSTAIN。\"\n}",
        "plagiarism_confidence": 58,
        "plagiarism_percentage": 79,
        "plagiarism_snippet": [
            "本論文所提出",
            "手部姿勢估計",
            "手部姿勢估",
            "手部模型",
            "骨架比例"
        ],
        "verdict": "ABSTAIN"
    },
    {
        "top_docs_info": [
            {
                "content": "在研究此項目時，我們希望嘗試使用不同的轉換骨架節點框架，試試看是否也能 做出成果，因此選用了Openpose[4][5][6][7]。 Openpose 是一款是由卡內基梅隆大學認知計算研究室提出的一種對多人身體骨架 節點、面部特徵節點以及手部特徵節點進行實時估計的框架，本研究僅使用其對身體 骨架節點的預估結果，其預估的節點包含：左右眼、左右耳、鼻子、脖子、左右肩 膀、左右手肘、左右手腕、中臀部、左右臀部、左右膝、左右腳踝、左右大拇指、左 右小拇指、左右腳跟，共25 個點，如下圖十所示。 圖 15: Openpose 25 節點",
                "cross_score": 0.2974153757095337,
                "embedding_sim": 0.889702320098877,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/nycu/257.txt"
            },
            {
                "content": "本論文所提出的系統架構如圖15 所示，是以在3.2 節所介紹的系統(圖12)[15]為 基礎進行修改。在網路架構的部分，我們最終選擇MSPN[8]、yolov3[34]所採用的架 構，同時我們將系統中2D 關鍵點估計的神經網路，與deeplabv3+[31]進行整合，設計 一個多任務學習(multi-task learning)的網路架構。逆向運動學的部分，本論文以 Levenberg-Marquardt 演算法最佳化，並以ResNet[32]預測手掌orientation 作為迭代的初 始值，以及[33]中的方法修改最佳化方式，改善迭代的收斂狀況。以下介紹本論文對於 Panteleris 等人所提出的架構[15]所修改的部分。 圖15、本論文所提出的系統架構圖",
                "cross_score": 0.01563429646193981,
                "embedding_sim": 0.8665293455123901,
                "overlaps": [
                    "多任務學習"
                ],
                "file_path": "dataset/paraphrased_dataset/source/nycu/15.txt"
            },
            {
                "content": "MANO 手模型是在2017 年提出的開源碼手部模型[30]。以姿勢(pose)、形狀 (shape)兩種參數類型來描述模型狀態，由姿勢參數控制關節的轉動，形狀參數則影響 骨架比例與手的形狀。 MANO 不同於上面兩個手部模型使用LBS(Linear Blend Skinning)來描述骨架與網 格之間的關係，而是從手的三維掃描(3D scan)中學習姿勢、形狀兩種參數和骨架、網 格之間的關係，為此Romero 等人提出了一個包含51 種手勢的三維掃描資料集。圖9 為MANO 模型圖。這是本論文所採用的3D 手部模型。 圖9、MANO 手部模型，圖片出自[30] 第三章、本論文所採用的技術介紹 本論文所提出的手部姿勢估測系統，是參考了許多現有己發表的技術，進行實驗 分析後，抽取出各技術的長處以組合出最後的系統。本章針對我們在設計實作系統架 構的過程中所實際採用到的技術進行討論。至於我們提出的系統架構細節會在第四章 描述。",
                "cross_score": 0.0023524852003902197,
                "embedding_sim": 0.8695217967033386,
                "overlaps": [],
                "file_path": "dataset/paraphrased_dataset/source/nycu/8.txt"
            }
        ],
        "main_analysis": "经检查，用户段落与最相似文献段落之间没有明显的文字重叠，表述方式和内容组织也有明显区别。用户段落虽然涉及“骨架参数调整”和“多任务学习”等相似主题，但表述为个人总结和改进建议，没有抄袭倾向。总体来看，未发现抄袭现象。",
        "feedbacks": [
            "Expert 1 Feedback: Main Model的分析基本可信，理由如下：\n\n- 分析中指出用户段落与相似文献在表述方式和内容组织上有明显区别，且无明显文字重叠，判断为无抄袭倾向，逻辑合理。\n- 用户段落内容主要为个人总结和改进建议，并未直接摘抄文献内容，分析结论可信。\n\n但有一点小的遗漏：\n- 虽然分析提及主题相似（如骨架参数、多任务学习），但未进一步说明这些主题的表述是否存在概念性依赖或“隐性抄袭”的可能性。例如，如果用户段落中的某些专业表达或思路与文献极为接近，虽然用词不同，也应加以说明。\n\n综上，Main Model分析可信，但建议补充对概念性相似度的说明，以增强全面性。",
            "Expert 2 Feedback: Main Model的分析总体可信，理由如下：\n\n- 分析能指出用户段落与相似文献主要在主题上有交集（如“骨架参数调整”、“多任务学习”），但表述和内容组织不同，未发现直接抄袭。\n- 用户段落为个人总结和改进建议，未出现与相似文献的明显文字重叠。\n\n可能的遗漏：\n- Main Model仅分析了文字重叠和表述方式，没有进一步评估技术内容的相似度或是否存在“结构性抄袭”（即思路、方法高度相似但用词不同）。\n- 未详细说明用户段落与相似文献在“多任务学习用于骨架参数调整”这一具体思路上是否仅为常见做法，还是有独特性。\n\n结论：分析可信，建议补充对内容创新性和结构性相似的检查。"
        ],
        "judge_output": "{\n  \"verdict\": \"ACCEPT\",\n  \"reason\": \"经综合Main Model及两位专家的分析，用户段落与相似文献无明显文字重叠，表述和内容组织也有显著差异，内容为个人总结与改进建议。虽然主题有交集，但未发现结构性或概念性高度相似的证据，且所提方法属于领域常见思路。整体不存在抄袭迹象，结论可信。\"\n}",
        "plagiarism_confidence": 11,
        "plagiarism_percentage": 4,
        "plagiarism_snippet": [
            "要能隨不同使用者調整骨架,一個可行的做法是一開始先要求使用者做一個標準姿勢,利用該姿勢來計算出標準骨架的調整參數。",
            "另一種解決方案是引進在4.5節提到的多任務學習方法,讓骨架參數也是訓練過程中學習的目標之一,這些是未來可以進一步改善的方向。"
        ],
        "verdict": "ACCEPT"
    }
]