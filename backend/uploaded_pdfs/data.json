[
    [],
    [],
    [
        "近年來虛擬實境的應用日漸增加,因此人機介面溝通的相關技術開始受到大家的重視,手勢辨識也成為一項熱門的研究。",
        "本論文以單攝影機第一人視角的頭戴式系統為使用平台,結合深度學習類神經網路與手部模型,建立一個具實務應用價值的手部姿勢估計系統,可以在任意動態影像中估算出手部姿勢的完整系統。",
        "在手部姿勢估計方面,我們利用神經網路估計2D手部關鍵點,再以一個3D手部模型來比對2D關鍵點估計結果作逆向運動學估算,藉此得到使用者手部的3D姿勢,包括掌心的方向角以及手指關節的位置。",
        "在神經網路架構方面,本論文對於神經網路架構的選擇以及組合的效益,進行多項實驗與分析。",
        "我們評估了多種神經網路架構在不同資料集中的表現,藉此找到最適合的網路架構。",
        "在逆向運動學方面,我們利用神經網路推論手掌朝向的方向,並以此做為迭代估測法的初始值,改善收斂的狀況。",
        "並以大量手勢經PCA拆解後的樣本向量空間,作為迭代估測的解空間,使最終估測出來的手勢更加自然。"
    ],
    [
        "In recent years, applications of Virtual Reality grow rapidly. Therefore, 3D hand gesture estimation that is crucial for human-computer interaction has become a hot research topic today.",
        "This thesis aims to design a 3D hand pose estimation system for virtual reality applications using a single image as input. The proposed system uses deep learning neural networks for estimating 2D hand keypoints, and inverse-kinematic inferences of the 3D hand pose, including the orientation of the palm and the 3D angles of the finger joints, using a 3D hand model.",
        "In terms of the neural network architecture, a series of experiments and analyses on various choices of neural network architecture and their efficiency to form an integrated system were conducted during design exploration. We evaluate the performance of different neural networks in multiple data sets, to find the best neural network architecture. For inverse kinematics estimation, we have improved the convergence of each iteration by using the orientation information of the palm, which was inferred by a neural network, as the initial values of iterative optimizations. Furthermore, we have used the Principal Component Analysis (PCA) technique to create a hand gesture vector space using a lot of real hand images. The PCA vector space is then used as the confined solution space of the iterative hand pose estimation process. As a result, the final estimated hand pose looks more natural."
    ],
    [
        "本篇論文的完成,首先要感謝我的指導老師蔡淳仁教授這兩年來的教導,在研究上遇到困難時,老師都能給予有用建議,並找出問題的關鍵點,使我的研究過程更加順利。此外老師也不吝於分享自己在工作上的各種經驗,來教導我應有的做事方法與態度,相信在未來這些經驗都會讓我受用無窮。",
        "也感謝胡毓志教授與張添烜教授在繁忙之中願意撥空擔任我的口試委員,並對本論文提出許多意見以及改善方向,讓我知道一些研究上的盲點,以及許多能改進的地方。",
        "接著也要感謝實驗室裡學長的幫助,感謝呂芳鎮學長在我進入實驗室後對我細心的指導,讓我能快速進入狀況並開始進行研究。也感謝實驗室的其他同學,在我遇到研究上的問題時,能和我討論並解決。同時也感謝李沿槱標同學在亞利桑那的幫助,進行研究與書寫論文時有良好的壓力抒發管道。",
        "最後要感謝家人願意支持我完成碩士學業,以及親朋好友的鼓勵,在我完成碩士學位的路上的陪伴,謝謝你們。"
    ],
    [],
    [],
    [],
    [],
    [],
    [
        "近年來虛擬實境(VR)及擴增實境(AR)的技術蓬勃發展,人機互動的方式上也更加多元且人性化,與此相關之應用、遊戲與日俱增。然而若要能精確的操縱虛擬實境中的各種物件,仍然需要依靠手把、手套等相關設備,大大降低使用上的便利程度以及使用者體驗,因此如何不借助任何特殊設備,僅從單一攝影機所錄製的影像中,獲取手部的相關資訊(手勢、動作...等),一直以來都是一個重要的課題。",
        "過去我們實驗室已經開發出可達96.18%正確率的即時動態背景手部語意切割系統[31],以及在單色背景下可辨勢36種不同手勢、具有96.71%正確率的2D手勢辨識系統[27],結合兩個研究成果,已經可以藉由手勢達成基本的人機互動,然而對於在虛擬實境中移動或拿取物品等,需要較為精細的3D操作時,仍需從影像中標記出手指關節及手掌心方向等關鍵點。因此,本次研究主要目標為手部方向角度的估計及關鍵點的標記。除此之外,目前此類問題大多以卷積神經網路解決,由於神經網路是一種資料驅動(data-driven)的方法,需要大量資料進行訓練,但3D手部姿勢不容易產生標註好的練資料,通常需借助特殊裝置才能辦到。",
        "因此本論文研究主要目的在於設計一個不須太過依賴大量具有3D關鍵點標註的資料,就可以訓練出的可靠手部姿勢估計系統,同時也將我們的系統與本實驗室之前的研究[31]進行整合。",
        "本論文以一般攝影機做為使用平台,結合神經網路與手部模型,建立手部姿勢估計系統,以多任務學習的方式與手部語意切割系統做整合。並以藉由手掌作為初始值 與修改迭代演算法來改善逆向運動學的收斂狀況。圖1為本論文所提出系統的實際估測結果。整體來說,本論文的主要貢獻有二:\n一、設計實作一個關鍵點估計網路,並藉由多任務學習同時提升關鍵點估計以及語意切割兩者的準確度。\n二、提出以神經網路估計手掌方向來做為初始值,改善迭代的結果。"
    ],
    [
        "本論文分成六章,第一章介紹動機與成果。第二章介紹手部姿勢與關鍵點抽取的相關研究。第三章介紹本論文所提出的系統架構所使用到的技術描述。第四章介紹本論文系統所針對的問題的明確定義以及如何修改、整合第三章所提到的技術成為最終的系統架構。第五章描述實驗方式以及結果。第六章則為論文的結論以及未來方向。 手部姿勢估計一直以來都是電腦視覺領域中重要的研究方向之一,目前在此類問題上,主流方法為藉由神經網路估計關鍵點位置,再以關鍵點資訊推論手部姿勢,因此本章主要介紹手部姿勢以及關鍵點估計的相關研究。而在關鍵點估計的部分,由於網路架構設計的相關研究大多都以人體關鍵點做為研究對象,且手部與人體的關鍵點估計並無太大差異,因此此處以多人體關鍵點估計的相關研究為介紹對象。此外,本論文最終是利用3D手部模型做為手部姿勢估測的主要限制條件(Model-constrained estimation method),因此本章最後會介紹手部模型的相關研究。 3D手部姿勢估計方法主要可以分成三類,配戴感測手套的方法(Gloved-Based Methods)、以深度影像作為估測資料的方法(Depth-Based Methods)、和直接以視覺影像作為估測資料的方法(Vision-Based Method)。以下分別對三者做介紹。 此方法以配戴具有感測元件[18]或是顏色經過特殊設計[19]的手套(如圖2、圖3)來獲取資訊,相較於其他方法,由於擁有較直接且有用的資訊,故能取得更加精確的結果,但相對的在使用上也有一定的不便,舉例來說手套可能會影像到手指關節的靈活度。"
    ],
    [],
    [
        "在過去基於深度影像進行手部姿勢估測方法中,大多數研究皆搭配手部模型進行,透過尋找手部模型參數,使手部模型的深度資訊與深度圖像相似,通常透過迭代最佳化演算法求解,如PSO[20]。而近期的研究,則多以神經網路估計3D 關鍵點位置[23][24]。Wan等人提出讓卷積神經網路同時估計 2D、3D 關鍵點以及單位向量場(指向手指頭),藉此提升精確度的方法[23]。Ge等人則提出使用3D卷積神經網路來估計3D 關鍵點位置的機制[24]。",
        "使用擬人視覺技術的方法是以一般光學影像資料作為輸入,只需以相機拍攝,相較於前兩者最為便利,但同時也最為困難。在近期神經網路相關技術及硬體發展逐漸成熟後,開始有大幅進展。",
        "此類方法依據架構設計,可再細分為 one-stage[13]以及two-stage[14][15] [16]兩 種。前者直接估計關鍵點3D位置,如Spurr等人藉由VAE模型學習潛在空間與不同資訊間的關係[13]。後者則是先估計2D手部關鍵點位置,再利用2D的資訊估計3D關鍵點的位置,Zimmermann 和Brox 最早提出以神經網路估計單視角RGB圖片的手部關鍵點3D位置的論文[14],藉由神經網路從2D關鍵點的heatmaps 來估計3D關鍵點位置,圖4為該論文提出的系統架構圖,目前許多研究的架構設計皆從此論文修改。其中,Panteleris 等人利用手部模型對2D關鍵點做逆向運動學(inverse kinematics)得到3D 關鍵點位置[15]。Cai 等人則是設計弱監督式學習(weakly supervised learning)的網路架構,只需要3D渲染的3D關鍵點位置以及真實影像的深度資訊就可以訓練網路,無需真實影像資料的3D關鍵點位置[16]。"
    ],
    [
        "多人關鍵點估計主要有兩種方式,分別為top-down[8][10]以及bottom-up[9][11]。前者首先找出圖片中人物的位置並裁切,再做單人的關鍵點估計。後者則是先估計出圖片中所有關鍵點位置,再區別哪些關鍵點屬於同一個人。本論文採用 top-down 的方式,因此下面針對單人關鍵點估計的方法進行討論。",
        "在過去此類問題大多先建構各個身體部位之間的關係,組成人體的 pictorial structures 模型(如圖5所示),去尋找圖片中與人相似的形狀[1][2][3][4],然而這種方法較無法處理被遮擋的部位,而神經網路可大幅改善此狀況[5]。",
        "有別於過去直接估計關鍵點在圖片上的位置[6],近期的研究則改為估計各個關鍵 點的heatmaps[5][7][8]。神經網路架構的部分,Wei等人建立一個多階段估計的網路架構,以利學習關鍵點之間的關係[5]。Newell等人則在以 encoder-decoder 架構作為多階段估計中的組件,有效的融合不同尺度的特徵[7]。圖6為他們所提出的網路架構圖。在近期研究中多以這個架構為基礎做改良,如Li等人所提出的跨階段特徵結合(cross stage feature aggregation)的方法[8],可以改善 Netwell等人的架構中,多階段估計特徵丟失的問題。"
    ],
    [],
    [
        "本節討論手部模型的選擇,包括了 Hsu [28]、Libhand [29]、和 MANO[30]等三種手部模型介紹。這三者各有其優點, Hsu 利用 Blender 所設計的模型,在手部關節轉動上符合真實人類的手部狀況,而 Libhand 以真實手部影像做渲染,視覺上較接近真實影像, MANO 則是有形狀參數,可以改變手部關節比例。考量未來的發展性,本論文最終選擇以 MANO 作為手部模型,並結合 Hsu 的手部模型中靜態關節角度限制。本論文使用 Hasson 等人所提供的 MANO 手部模型的 PyTorch 版本 [35],渲染的軟體則是使用 Kato 等人所開發的可微分渲染程式庫 [36]。",
        "Hsu [28] 的手部模型為本實驗室研究生過去以 Blender 所製作的手部模型,擁有 26 個自由度,分別為每根手指的 ADB、MP、PIP、DIP 的關節角度,以及控制掌心位置及方向的 6 維的全域自由度,同時此手部模型考量了靜態、動態的關節角度限制,因此擺出的姿勢,相當接近真實人類的狀況。表一為關節的角度限制,圖 7 為 Blender 手部模型圖。"
    ],
    [
        "Libhand 是以OGRE為基礎所製作的三維手部模型[29],用於渲染的皮膚材質是由真實手部影像掃描製作,在視覺上與真實圖像較為相似。Libhand 目的在於提供直觀且容易的介面,讓使用者能輕鬆的操縱手部模型取得各種手部姿勢的圖片,便於研究與分析。",
        "MANO 手模型是在2017年提出的開源碼手部模型[30]。以姿勢(pose)、形狀(shape)兩種參數類型來描述模型狀態,由姿勢參數控制關節的轉動,形狀參數則影響 MANO不同於上面兩個手部模型使用LBS(Linear Blend Skinning)來描述骨架與網格之間的關係,而是從手的三維掃描(3D scan)中學習姿勢、形狀兩種參數和骨架、網格之間的關係,為此Romero等人提出了一個包含51種手勢的三維掃描資料集。圖9為MANO 模型圖。這是本論文所採用的3D手部模型。"
    ],
    [],
    [
        "本論文所提出的手部姿勢估測系統,是參考了許多現有己發表的技術,進行實驗分析後,抽取出各技術的長處以組合出最後的系統。本章針對我們在設計實作系統架構的過程中所實際採用到的技術進行討論。至於我們提出的系統架構細節會在第四章描述。",
        "Multi-Stage Pose Network (MSPN) [8]為Microsoft COCO 2018 [17]關鍵點估計競賽的冠軍。對於分類問題,神經網路越深效果應該越好,因此多階段估計網路架構表現應優於單階段估計,然而當時在MS COCO 資料集上,卻是單階段估計架構表現較突出。因此Li等人以當時表現較優的Netwell等人[7]多階段網路架構為例,提出三個多階段估計網路架構的問題,並加以改進,實驗結果請參考圖 11。",
        "首先,Netwell等人提出的用來組成多階段網路架構的 encoder-decoder 模組設計並不好,在降採樣(down sampling)時,特徵的通道(channels)數量仍然保持相同,導致大量特徵資訊流失。",
        "第二,由於重複降低採樣率(down sampling)及提升採樣率(up sampling)的過程,無法保證能保留前面階段有用特徵,換句話說網路模型將不易最佳化。因此Li等人提出跨階段特徵結合(cross-stage feature aggregation),將降低採樣率所得到的特徵與前一階段的特徵相加,以保留有用的特徵。",
        "第三,在多階段估計中,在越後面的階段中,神經網路所估計之關鍵點位置會越精確,因此在訓練上採用傳統方法上常用的coarse-to-fine技巧,不同於[7]在所有階段皆以相同目標做訓練,而是在越後面的階段使用越精確的heatmaps 作為訓練目標。"
    ],
    [
        "這項技術是在2018年由Pantelerish等人所提出的論文[15],提出一個3D手部關鍵點估計的方法,分為三個步驟,首先藉由物體偵測(object detection)框出圖片中左手、右手的位置並將其裁切下來,再對裁切下來的圖片進行手部關鍵點估計,得到2D關鍵點位置,最後將左手圖片翻轉成為右手,搭配3D手部模型,以逆向運動學找出對應的3D手模型參數,以此求出3D關鍵點位置,圖12為發表在[15]的系統架構圖。論文中物體偵測和關鍵點估計直接使用當時的 state-of-the-art 模型。下面介紹逆向運動學以及 Levenberg-Marquardt 最佳化演算法。 在3D模型中我們有兩種空間來描述模型當前的狀態, 分別為關節空間(joint space)以及直角坐標空間(Cartesian space), 前者記錄關節的旋轉角度, 後者則是記錄關節的位置。當由3D模型的關節空間參數計算出對應的直角座標位置時稱為正向運動學, 反之由以直角坐標空間位置計算出對應關間空間參數時稱為逆向運動學。而在逆向運動學中, 因為通常不會有解析解, 因此大多用非線性的最佳化演算法來求解。 論文中以神經網路估計2D關鍵點位置做為目標, 因此可將最小化目標寫為Eq. 其中(xi, yi)為神經網路估計之2D關鍵點位置, (ui, vi)則為手部模型映射在圖片中的位置, pi則是神經網路所估計該點是關鍵點的機率。 LM 演算法是一個非線性最佳化演算法, 結合了梯度下降法和牛頓法的優點, 改善"
    ],
    [],
    [
        "考慮函數f: Rⁿ → Rᵐ,若想對 Eq. (2) 進行最佳化則可依 Eq. (3) 進行迭代",
        "Yolo 為 2018 年提出的物體偵測神經網路架構，當時在 [17][40] 兩個資料集皆為 state-of-the-art，同時能達到實時 (real-time) 偵測。本篇為 yolo 系列的第三代，方法與前一代相似，主要以兩種方式改良網路架構，首先，它使用了 resnet[32] 中的殘差網路架構設計更深的網路，其次，它參考了 FPN 的架構設計，加入多尺度預測以及多尺度特徵融合。",
        "在物體偵測的方法上，yolo 採用 one-stage 的方式，直接從圖片中偵測定界框 (bounding box)，其方式如下，首先將圖片等分成 S×S 個區塊 (如圖 13 所示)，而每個區塊會有 N 個事先設計好的 anchor box，而神經網路則負責預測每個 anchor box 的長寬變化、中心位置位移以及所屬類別。網路估計結果與定界框關係可參考 Eq. (4) 到 Eq. (7),",
        "其中 tx, ty, tw, th 為網路估計的結果，(bx, by) 為定界框中心位置，(bw, bh) 為定界框的寬與長，(ph, pw) 為 anchor box 的寬與長，(cx, cy) 為 anchor box 所在區域左上角的位置。"
    ],
    [],
    [
        "本論文研究目標為以單一相機做為使用平台的手部姿勢(hand pose)估計,本論文系統以一般低價網路攝影機拍攝的彩色影像作為輸入,主要輸出為相對於手掌心的3D關鍵點位置(也就是3D坐標的原點是定位於掌心,而坐標的X, Y, Z方向在第4.3節會再說明)、以及2D手部關鍵點位置。此處2D 關鍵點是指手部關鍵點在影像中的位置,因為我們假設了一個3D的手部模型,即使只用單一攝影機以及2D的關鍵點也可大約推算出3D的手部關鍵點坐標。手部關鍵點指的是手掌的中心、手指關節、手指指尖共21點,請參考圖14。而手部3D關鍵點通常被稱為手部姿勢。",
        "本論文最終選擇以Panteleris 等人所設計的系統作為基礎的系統架構[15],在此架構上最需要改進的地方有兩個,第一是手部關鍵點位置的正確性,第二是逆向運動學中最佳化演算法的收斂結果正確度。本論文主要針對此二問題做改進。 本論文所提出的系統架構如圖15所示,是以在3.2節所介紹的系統(圖12)[15]為 基礎進行修改。在網路架構的部分,我們最終選擇MSPN[8]、yolov3[34]所採用的架 構,同時我們將系統中2D關鍵點估計的神經網路,與deeplabv3+[31]進行整合,設計 一個多任務學習(multi-task learning)的網路架構。逆向運動學的部分,本論文以 Levenberg-Marquardt 演算法最佳化,並以 ResNet[32]預測手掌 orientation 作為迭代的初 始值,以及[33]中的方法修改最佳化方式,改善迭代的收斂狀況。以下介紹本論文對於 Panteleris 等人所提出的架構[15]所修改的部分。 過去的研究皆顯示良好的初始值對於非線性最佳化有巨大的影響([21][26]),然而 Xu和 Cheng[21]或Ye等人[26]所提出的技術是基於深度資訊的方法,無法直接使用在 我們的研究中。根據前人研究所獲得的經驗[21][44][28],我們可以知道,手掌是否能"
    ],
    [],
    [
        "找到是結果好壞的關鍵。因此我們以估計手掌朝向的方向,作為初始值。近期較為相關的研究把估計人體的方向視為一種分類問題[22][43],,如圖16所示,將水平360度分成八個方向,並用神經網路進行分類,來達到估計人體方向的目的。",
        "本論文的問題與Choi等人[22]或Liu等人[43]所提出的情況略有不同。在我們的使用情境下,手掌朝向可能是任意方向,因此本論文必需使用不同的分類方式。我們採用了兩種不同的方法,一是把所有3D方向依歐拉角分成256個不同的方向(x,z軸各分成8類角度,y軸分成4類角度)。另一種方法則是假設掌心到中指的MP關節的直線在圖片中為垂直線,以y軸為選轉軸的360度分8類,以x軸為旋轉軸的180度分4類,共32類。經實驗證實,以這種假設做分類相較於不做假設分成256類的好處有二,第一是容易製造訓練資料集,第二是圖片經過預處理後神經網路訓練結果也較好,詳細實驗請參考5.7節。文中坐標軸方向請參考圖17。"
    ],
    [
        "Hierarchical optimization 的方法是由Schröder 等人所提出的最佳化方法[33],主要目的為改善逆向運動學中最佳化演算的收斂性,可以減少不自然姿勢以及收斂至局部最小值的情況。",
        "在實際情況下,手部不同關節的靈活度並不相同,然而在一般的最佳化演算法中是直接對所有的維度一起求解,並且所有的維度都是一樣的權重,所以較容易有不自然的手部姿勢出現。因此論文提出 coarse-to-fine的多階段最佳化方式,並不直接使用全部的維度進行迭代,而是先在較低的維度中求解,再依序增加維度大小,讓演算法先在較重要的空間中找解,再逐漸微調。而最佳化求解的空間則是以PCA對手勢資料集的關節角度計算來取得,得到的PCA空間能表達各個關節之間的聯繫以及各個關節的靈活度。演算法 pseudo code 可參考圖18。"
    ],
    [
        "過去多項研究[10][38][39]皆表明，若同時學習多個相關性高的任務，對不同任務皆有正面的影響，Gkioxari和Girshick[10]提出以物體偵測的網路架構為基礎進行修改，同時進行物體偵測、切割、和關鍵點估計三種任務，圖19為實驗結果，可以看出預測切割可以提升關鍵點估計的效果。而Popa等人[38]或Wang等人[39]皆以關鍵點估計網路架構為基礎做修改，多任務的部分，Popa等人採用的方法同時進行關鍵點估計、語意切割和3D重建，以提升3D重建的結果，而Wang等人所提出的技術則是同時進行關鍵點估計和語意切割兩種任務。在網路架構上，前面提到的三種系統都是採用 encoder-decoder 架構，對於不同的任務使用同一個encoder 獲取特徵，再分別以不同的 decoder 估計結果。在網路訓練上，則是將不同任務的損失函數依照權重相加，成為一個新的損失函數，來進行訓練，Eq. (8)為新的損失函數方程式。",
        "其中L為新損失函數，Li為第i個任務的損失函數，xi為第i個任務的輸出，Ti為第i個任務的 ground truth。",
        "如上所述，語意切割與關鍵點估計的多任務學習可以提升關鍵點估計的結果，因此我們嘗試將Wang等人提出的MSPN架構[8]與語意切割系統 deeplabv3+的網路架構[37]進行合併。讓兩者共用同一個encoder，並將語意切割系統的結果與 encoder 結果輸入到MSPN的decoder中。"
    ],
    [],
    [
        "2D、3D 關鍵點的部分，我們用以下三種方法作為衡量效果的標準，mean EPE(endpoint error):估計結果與正解之間的歐式距離的平均，PCK(percentage of correct keypoints):估計結果 EPE 低於某個閥值的資料在資料集中的占比，AUC(area under the curve):用不同閥值的 PCK 所畫成的曲線下的面積。此外由於我們是以單張圖片做估計，因此我們不考慮尺度(scale)以及平移(translation)的差異，也就是說我們會將估計結果按比例縮放、平移。而語意分割則是使用 mIOU(mean intersection over union)當作評估的標準。手掌朝向分類的部分，我們以正確率以及角度誤差來評估結果優劣，正確率代表分類正確的百分比，而角度誤差是預測手掌朝向方向的結果與真正的結果之間的最短的旋轉角度。"
    ],
    [
        "此資料集是由3D模型渲染的人造資料集,共包含41258張訓練資料以及2728張 測試資料,並且提供手和人的分割、手部關鍵點以及場景深度三種不同的標籤。之後 以RHD稱呼此資料集。",
        "該資料集為真實影像資料,在六個不同背景的六段影片,每段影片3000張圖片, 共18000張圖片,我們以其中五段影片作為訓練資料,剩下一段做為測試資料。之後 以STB 稱呼此資料集。"
    ],
    [
        "本節列出神經網路訓練時所用參數,表2為詳細的參數設定,包含學習率、批次訓練數量、Epoch等,其中學習率在每訓練15個Epoch後會更新一次,更新方式為當前學習率乘上Gamma。",
        "同時為提升網路泛化能力,我們使用資料擴增(Data Augmentation)技術,隨機將圖片旋轉-30~30度並隨機調整圖片的大小,介於原本大小的0.5倍至1倍,圖片縮小後在周圍做 zero padding,使其與原圖大小相同。為了避免過擬合(overfitting),在訓練時我們將2D 關鍵點位置隨機加上雜訊,此雜訊為平均值為0、標準差為1.5的高斯分佈。",
        "此外由於STB 資料集為六段影像資料,每段影像中背景以及手部位置都無太大變化,所以資料集中只有六種背景,因此在實驗以STB 資料集作為訓練資料時,為避免過擬合等問題,我們會先在RHD 資料集上訓練 10個 Epoch 作為預訓練。",
        "本論文於5.5與5.6小節中關鍵點估計相關實驗皆以此設定做訓練,之後不特別進行說明。 模型篩選的部分, 我們比較了三種 CPM[5]、HG[7]、MSPN[8] 不同的網路架構, 以 RHD 和 STB 此二公開資料集做測試, 從中選出適合的網路架構, 作為後續研究的 基礎。從表 3、圖 23 的實驗結果可以看出 MSPN 的效果較好, 故後續實驗主要以 MSPN 進行。"
    ],
    [
        "本節整理多任務學習結果, 並與其他論文做比較。詳細多任務學習的細節請參考 我們將本論文的結果與[38][39]比較,在此兩篇論文中皆是以CPM的網路架構為基礎做修改,因此我們在CPM、HG、MSPN三種網路架構上都進行實驗,表4為比較有無多任務學習的實驗結果,有用多任務學習時在關鍵點以及語意切割上表現皆優於不使用,表5則是本論文結果與[38][39]比較,可以看出不論在關鍵點或是語意切割上,本論文使用方法表現皆優於[38][39]。"
    ],
    [
        "本節整理本論文對2D關鍵點做逆向運動學的相關實驗結果,相關技術請參考4.2節。實驗以RHD、STB做為測試資料集,我們依序進行了兩組實驗,首先為測試LM演算法在此問題上的效果,所以我們排除會影響收斂的其他因素,因此用正確的2D關鍵點位置做為目標,並將手部模型的關節間長度比例調整至正確的比例,觀察迭代的收斂狀況及結果。再來我們測試演算法是否robust,我們改為使用網路估計的2D關鍵 點位置做為目標,以MANO作為手部模型,觀察演算法結果。在本節實驗中我們專注於3D 關鍵點估計上,因此我們假設圖片中的手已被物體偵測演算法正確框出並分類為左、右手。在目標函數上,我們以Panteleris等人所提出目標函數[15]為基礎進行修改,將神經網路所估計的機率pi由六次方改為一次方,Eq. (9)為我們的目標方程式。下面分別說明兩個實驗的結果。 當我們以正確的2D關鍵點位置作為逆向運動學的目標時,我們發現迭代的收斂狀況並不理想,容易陷入局部最小值,此類問題常見的解決方向有二,分別為迭代初始值以及最佳化方式。下面我們分別從這兩個方向做改善。"
    ],
    [
        "首先,如同4.3 節所述,我們將估計手掌朝向視為分類問題,我們嘗試兩種分類方式,第一種以歐拉角表示手部方向(orientation),共有三個維度,其中兩個維度的角度範圍為0~2兀,其中一個維度為0~兀,每π/4分成一類,共分成256類。第二種,我們先將圖片進行預處理,旋轉圖片使手掌到中指垂直,同樣以歐拉角表示方向,共有兩個維度,其中一個維度角度範圍為0~2兀,另一個維度為0~π,共分32類。由表6的實驗結果可看出第二種方法較好,因此我們採用第二種分類方式",
        "接下來我們先我們對Romero等人所提出的資料集[30]做PCA,得到PC-space,在使用Hierarchical Optimization演算法[33]進行實驗,我們測試分成不同階段數量的結 果,實驗結果可見圖24,可以看出在分成四個或以上的階段數量時,效果大致相同, 因此我們最終分成四個階段來執行此演算法。圖25為本節實驗解果 圖25、結果比較圖,每組包含上下兩張圖片,由左到由分別為 ground truth、前人提出的逆向 運動學、以及用本論文提出的設定初始值方法所算出來的結果。"
    ],
    [
        "當我們以神經網路所估計的2D關鍵點位置作為輸入時,我們注意到如果有少數 2D 關鍵點估計錯誤,可能會大大影響逆向運動學之結果,因此我們將Eq. (10)稍作修 改,多加入介於0到1之間變數r,首先將Eq.(9)中目標函數每個關鍵點的平方差都乘 上一個變數ri,作為每個關鍵點的權重,同時為避免最佳化演算法讓r為0來降低目標 函數的值,因此我們在目標函數後加上a(1-ri)2來避免,此方法可以使最佳化演算法自己決定每個關鍵點所佔的權重,讓目標函數增加一些彈性,並非絕對相信神經網路所估計出的結果,可將式子改寫成 最後為了確認本節演算法在正常狀況下的表現,我們以神經網路估計的2D關鍵點做為目標,MANO作為手部模型,對本節所提到的演算法做實驗,測試個別以及同時使用的效果,表7為實驗結果。 在神經網路估計2D手部關鍵點實驗中,我們觀察到若關鍵點被遮擋時,準確度會大幅降低,因此我們希望能藉由3D模型的結果去 refine 2D的關鍵點。同時也能驗證我們的演算法是否能藉由一部分較為正確的2D關鍵點來推測3D手部姿勢,而不受錯誤的結果影響。由於被遮擋的部分會使神經網路估計的信心較低,因此我們將信心低於0.5的關鍵點替換成3D手部模型應設在圖片上的結果。表8為實驗結果。"
    ],
    [],
    [],
    [
        "本論文以單攝影機第一人視角的頭戴式系統為使用平台,結合卷積神經網路以及手部模型,建立一套可靠的手部姿勢估計系統。",
        "在神經網路架構方面,對於神經網路架構選擇以及架構整合,本論文進行多項實驗與分析,評估多種神經網路架構在不同資料集中的表現,藉此找到最適合的網路架構。",
        "在手勢估計中的逆向運動學方面,我們進行一連串的實驗,發現迭代演算法的收斂容易收斂於局部最小值,以及對於少數關鍵點錯誤過於敏感的問題。對於前者,我們從初始值以及迭代演算法上下手,而後者我們透過修改目標函數,來減少此種狀況,藉由上述方法,這兩個問題皆得到不小的改善。",
        "然而對於不同使用者,我們沒有一個好的方式去調整手部模型的骨架比例,而根據我們的實驗,若使用正確的骨架比例,可降低約10mm的誤差,約為本論文所提出方法誤差的一半,因此若能根據不同使用者來調整骨架比例,將可大幅提升手部姿勢估計的精確度。",
        "要能隨不同使用者調整骨架,一個可行的做法是一開始先要求使用者做一個標準姿勢,利用該姿勢來計算出標準骨架的調整參數。另一種解決方案是引進在4.5節提到的多任務學習方法,讓骨架參數也是訓練過程中學習的目標之一,這些是未來可以進一步改善的方向。"
    ],
    [],
    [],
    [],
    [],
    []
]