如下是在做文本資料的處理最常見的步驟：斷詞（Tokenization）、轉成小寫、詞幹 化（Stemming）、去除用詞、轉成詞語矩陣（Document Term Matrix）等步驟，將分別對 各步驟進行介紹及說明。 文本資料的處理步驟： (1) 斷詞（Tokenization） 斷詞（Tokenization），是自然語言處理（NLP）的基礎，也是文本資料處理的關鍵 步驟，斷詞的結果嚴重影響到後續文本資料分析的成效。斷詞是將語句按照一定規則切 割成各自獨立的詞語，這個切割過程就稱之為斷詞。 每個國家的語言的句法結構及表示方法都不同，如中文和英文的斷詞就會有所差異， 在英文語句中，單字間都是以空格表示間隔，所以英文可以使用“空格（space）”來做為 斷詞標記，然而中文的字詞中就沒有特定的分隔標記，只能透過字詞、句子、文章段落 來進行斷詞標記。中文通常會比英文來的困難及複雜，但在本研究中是使用英文斷詞， 因來源的資料集是使用英文表示的。 (2) 轉成小寫 主要功用是將斷詞後的每個字詞全部轉成小寫，以利後續完整去除停用詞，因某些 停用詞的詞庫是使用小寫表示，若沒有轉成小寫，那就會造成去除不完整，後續在進行 分析上就會些許誤差較不準確。轉換小寫的方式如將“The”內所有大寫字母轉成小寫字 母的“the”。 (3) 詞幹化（Stemming） 詞幹化處理（Stemming）[20]主要功用是去除語態、複數、代名詞所有格等字詞提 取出相對應的詞根的過程，比如說do 這個字詞會有現在式、進行式、過去式、過去完 成式，再加上又有單數及複數的情形，就會有更多種變化的字詞：do、doing、did、done、 does，雖然這些字詞因時態及單複數的情形而有所差異，但它們都是對應到相同的字根， 所以就可以利用此特性將它們轉成所對應的字根，也可以降低特徵的維度及處理的成本。 (4) 去除用詞（Stop Words） 所謂的停用詞（Stop Words）[22]是指這些字詞對文本中的意義沒有任何影響，一般 最常見的都是些無意義的語助詞、代名詞等等，如英文中的I、a、at、and、that 等等字 詞，停用詞的存在只會增加文本資料的特徵維度，當在進行文本分析過程中將會造成很 大的成本，若使用了這些停用詞做為文本分析的對象，更有可能會造成所分析出來的結 果有很大的偏差。 一般去除停用詞會使用一些方式來解決，利用詞庫比對、詞頻閾值或權重閾值的方 式來處理，目前普遍最常用的是使用詞庫比對的方式來去除。 (5) 詞語矩陣（Document Term Matrix） 詞語矩陣（Document Term Matrix，簡稱DTM），將DTM 做矩陣轉換後即為TDM （Term-Document Matrix），矩陣的行代表的是文檔，列代表的是字詞，矩陣元素代表文 檔中某一字詞出現的次數。[11] 假設有兩個文檔： 文檔一[貿易，協會，高雄，發展] 文檔二[青少年，性別，安全，程度] 將這這兩個文檔的字詞建立一個詞典： {1:貿易，2：協會，3：高雄，4：發展，5：青少年，6：性別，7：安全，8 程度} 這個詞典包含了8 種不同的字詞，我們可以利用所建立的詞典來建立索引值，那上 面的兩個文檔就會分別得到它的向量。文檔一的向量矩陣表示（1，1，1，1，0，0，0， 0）、文檔二的向量矩陣表示（0，0，0，0，1，1，1，1），向量中的元素表示所對應維 度的字詞在文檔中出現的次數，若將如上的兩個向量合併在一起，就可以生成一個詞語 矩陣（DTM）。 雖然詞語矩陣（DTM）不考慮字詞間的依存關係，但卻大大的簡化了文本處理的計 算過程，詞語矩陣（DTM）已經可以做為計算文檔間的相關性、文本的分類、文本的聚 類等所需的分析過程。
