中文相較於拼音語系的語言處理，由於沒有斷詞基準－空格的輔助，如何斷 詞就成為首要的問題，另外相較於中文單字含意、組合涵義相較多樣，不過在文 法詞性變異上較為單純，所以在文本探勘（Text Mining）工作時，注重在 Part-of-Speech 環節，尤其仰賴高效斷詞手段及詞庫輔助。 也因為中文在沒有做好斷詞或詞性標註前幾乎沒有任何技術的切入點，如 Jieba 斷詞函式庫這樣的針對中文語系應用十分廣為被使用，幾乎是所有中文語言 處理前的必要前置動作，同時也針對不同詞性用途有不同的斷詞邏輯。 另外因應機器學習的興起，中文斷詞處理的方式除「辭庫」、「統計」、「機 率分布」的方式，也可以透過神經網路紀錄語序等方式，完成中文句子的空間向 量化，讓機器區隔同義詞及反義詞進一步完成序列轉換。
