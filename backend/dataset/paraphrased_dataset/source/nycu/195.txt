本研究是實現抽象式文本摘要模型，使用雙層雙向與雙層單向循環神經網路 與長短期記憶神經網路組成的編碼(Encoder)層與解碼(Decoder)層，並加入注意力 機制的序列到序列架構，而在選字階段參考(Ranzato, Chopra, Auli, & Zaremba, 2015) 用於優化重寫時搜尋結果的集束搜索(Beam search)與使用貪婪搜索(Greedy search) 做比較，從中找出最好的模型組合，圖25 為本次訓練流程圖與圖26 為測試流程 圖。 圖 25  訓練模型架構圖 圖 26  測試流程架構圖 圖 27 模型架構圖 圖27 為本研究使用之模型架構圖，會將文本透過字典成對應的index 序列， 並依序輸入至編碼循環神經網路中訓練隱藏層的權重，使的context 中有輸入文本 的語義，再輸入起始標籤<START>後透過解碼循環神經網路與注意力機制將表示 語意的index 輸出與做為下個字的輸入，依序輸出至結束標籤<END>，在選字階段 會透過不同的搜索法來找出最後的輸出值，再將輸出的index 透過字典轉為文字做 為摘要。
