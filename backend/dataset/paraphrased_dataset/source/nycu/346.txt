以往視覺追蹤問題往往需要人工標注，而optical flow 的方法則是用虛擬圖 像來訓練，難以應用於現實場景[19]，且對於局部變化敏感，較難處理長時間的 追蹤。因此Wang 等人提出mid-level correspondence 的方法[20]改善以上兩者的 缺點，在深度特徵上學習前後幀的區域對應關係，對於不同幀之間的細部變化能 處理得更好。其做法首先使用ResNet-50 網路φ 擷取下一幀全圖以及待搜尋區域 的特徵，訓練階段以輔助網路T 找出前後幀對應區域。T 被設計為功能性較弱， 僅有兩層卷積層以及全連接層對應三個輸出，用以提升φ 在實用階段的對應能 力。 對網路φ 的訓練方式是在最後一幀隨機取一個框，對這個框進行反向追蹤， 往回k 個幀後再往前k 個幀做前向追蹤。最初選定的框與前向追蹤最後得到的框 之間的誤差即為訓練時的loss（圖2-3 左半部的黃色箭頭）。另外也加上skip loss， 其為忽略中間k 個幀，直接對應到頭再對應回尾而後計算其誤差。增強長時間變 化的對應能力。這個方法不需人工標注資料，且模型學習到的特徵泛用性強，能 用於mask 追蹤、key point 追蹤等任務。 相關方法還有Wang 於[21]提出整體架構採用CFNet 的單目標追蹤，而其訓 練方法為unsupervised：選定連續的兩幀，其中一幀為起點，選定某一小區塊後， 在另一幀找到對應區塊。接著兩幀角色對換，再進行一次追蹤。逆向追蹤得到的 區域與起始選定區域的誤差即為loss。然而僅使用兩幀來追蹤，可能發生前向追 蹤到明顯有偏差的區域，但反向追蹤卻能回到原區域不遠處，這樣loss 較低難以 修正前向追蹤的大誤差。要解決這個問題，他們使用多幀追蹤，即前向追蹤兩幀 後，於第三幀直接反向追蹤回第一幀，並計算其預測區與起始區的誤差。如果在 第二幀即發生追蹤偏差，則繼續往第三幀追蹤，與第一幀起始區的誤差會更大。 圖2-3 文獻[20] 使用的end-to-end 訓練架構 圖2-4 文獻[21] 非監督式前後追蹤一致性確認 多目標追蹤和單目標追蹤不同之處在於，多目標追蹤多以tracking-by- detection 為主，因此偵測框與追蹤序列的資料匹配將是重要的部分。本論文將以 CNN 擷取特徵，其訓練方式則著重於非監督式的學習方式，提出一套不需人工 標註即可自行蒐集訓練圖片，訓練出用於追蹤時的資料匹配任務之行人重識別模 型。並輔以一套以貪婪演算法為基礎，加上偵測框前處理、追蹤序列後處理的追 蹤方法。 第三章 研究方法
