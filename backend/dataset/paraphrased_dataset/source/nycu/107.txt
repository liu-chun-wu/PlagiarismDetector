對分類器的輸入，多數相當講究固定長度這個要件，尤其是分類樹型的分類 器。預處理後的中文欄位，多數長度無法統一，因而十分仰賴embedding 工作來 橋接分類器的輸入層。 詞袋模型的embedding 工作，仰賴鬆散矩陣方法，也就是建立不同詞編碼之 間互斥的屬性欄位，記錄不同的特徵，所需要的欄位數等於取樣的特徵數，所以 取樣特徵越細，欄位就越多。One-Hot Encoding 本身就是這個方法體現。 而空間向量模型則是在訓練時便以輸出固定長度的序列（向量）為前提，如 Tomas Mikolov 所提出的Word2vec 方法、Jeffrey Pennington 等人所提出的Glove 方法，基本上這些方法也是針對類神經網路而設計，因為不論是哪種類神經網路 的變體，都需要輸入固定維度的向量。
