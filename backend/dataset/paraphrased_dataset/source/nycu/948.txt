圖像描述是近幾 和圖像中的文字翻譯 話。看圖說話本身對 一大挑戰，它不僅僅 然後用自然語言的方 目前作此研究的 圖像描述不僅僅讓A 且連接物件間關係比 學研究團隊，提出了 負責將圖像中的文字特徵（Feature Map） 特徵向量的上下文關係；最後全連接層，Z 對每一個點用K 個anchor 進行預測，而每個 後，Zhi Tian [4]等人再用自己提出的side-r 區隔，最後結果就如下圖（如圖8）。 圖8、CTPN 的side-refinement 效果 ：https://blog.csdn.net/linchuhai/article/detail 幾年熱門的話題之一，它不單單只是前兩節 譯，而是對圖像內容本身進行文字翻譯，即 對於人類而言，是一件很容易的事情，但是 僅要理解圖片上所有的內容，還要了解這些 方式，語句通順的表達出來（如圖9）。 的大公司Google 和Microsoft，對此研究已 AI 突破了識別技巧的能力，從單一物件轉變 比重，聚焦在某一物件上然後做前後關係對 了COCO-CN 資料集 [5]，更是將MS-COC 找出來；Bi-LSTM Zhi Tian [4]等人引入 每個anchor 就是一個 refinement 演算法， ls/84191406） 節所提出找相似圖像 即是讓AI 學看圖說 是對AI 學習，卻是 些內容的對應關係， 已經有了很大的進展， 轉變成多個物件，並 對應，而中國人民大 CO 這些預處理的英文 語句資料集，翻譯成中文語句，做跨國語言的標註和檢索，最終學習的結果，也 得到很不錯的效果。 圖9、圖像描述 （資料來源：https://ppt.cc/fsylNx） 圖像描述的基本原理，則是利用上一節提到的翻譯語句的Seq2Seq 模型，將 原先input 輸入的文字語句，把它換成圖像的特徵向量，當作Encoder 去編碼，然 後Decoder 負責解碼這些特徵向量，找出它們的關聯性，最後以自己的描述方式 重現並當作output 輸出，這個動作就類似於人類在學習語言的時候，要先了解語 句的上下文關係，才能知道整句話的意思。而現在透過這樣的方式，就可以讓AI 了解圖像中的物件關係。（如圖10） 圖10、Encode-Decoder （資料來源：https://ppt.cc/fsylNx）
