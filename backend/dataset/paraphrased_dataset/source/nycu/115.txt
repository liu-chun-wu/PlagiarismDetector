「Doc2vec 產出維度數對三種分類器的表現實驗」的目的為測試Doc2vec 對模 型的適性。Doc2vec 與其他兩種預處理不同的是並非以互斥特徵為記錄依據，也就 是說以50 維為例，並不代表就只能記錄50 種特徵，混合資料的特性自然有所不 同。 表11 的實驗結果相較於上個實驗的結果，顯現了在整體評價上，Doc2vec 預 處理後的混合資料在分類模型訓練結果的總體評價上遠不如另外兩種，但從對分 類模型的影響上，完全迥異於另外兩種。 從圖15、圖16、圖17 的結果中可以發現，維度增加對分類模型確實有強化 分類能力的效果，而且MLP 模型的表現上，相較於另二種預處理方式，完全沒有 提升了某分類的鑑別力卻降低了另一個分類的鑑別力的情況，可以觀察出在神經 網路的訓練適性上，Doc2vec 預處理方式更佳；而另外兩種分類器上，則是弱化了 分類5 的鑑別力，提升了其他分類的鑑別力，分析Doc2vec 與其他預處理方法的 不同點，主要在於語序的特徵有無，推測語序的特徵含有非1、5 類的分類特徵， 從表13、表14 來看，訓練的分類模型對分類1、5 的反向資料鑑別力相對顯著， 支持推測。 單純比較分類第12 的分類效益，tfidf 沒有對這個分類有提升的效益，One-Hot Encoding 則可以達到f1 score=0.15，關鍵字數50 時在隨機森林分類器上可以達0.2， 而同樣在隨機森林模型上，Doc2vec 提供了支撐單項穩定於f1 score=0.18 到0.19 的分類基準，XGBoost 上也有0.15 到0.17。 表11 Doc2vec 產出維度數對三種分類器的表現實驗結果 圖15 Doc2vec（MLP）3 種維度分類器表現細項比較 0.39 0.08 0.050.04 0.41 0.21 0.050.05 0.41 0 0.01 0.23 0.050.06 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 7 10 12 13 15 16 22 91 92 93 95 96 97 98 模型/預處理方式&維度n Doc2vec n=50 Doc2vec n=100 Doc2vec n=300 隨機森林 0.8286 0.8245 0.8143 XGboost 0.8125 0.8156 0.8163 MLP 0.854 0.797 0.786 圖16 Doc2vec（隨機森林）3 種維度分類器表現細項比較 圖17 Doc2vec（XGBoost）3 種維度分類器表現細項比較 0.34 0.21 0.1 0.19 0.070.07 0.19 0.06 0.33 0.19 0.1 0.2 0.070.07 0.19 0.06 0.09 0.35 0.2 0.1 0.21 0.070.07 0.18 0.07 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 7 10 12 13 15 16 22 91 92 93 95 96 97 98 0.41 0.13 0.08 0.23 0.07 0.04 0.15 0.37 0.2 0.09 0.19 0.070.07 0.17 0.37 0.2 0.09 0.19 0.060.07 0.17 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 7 10 12 13 15 16 22 91 92 93 95 96 97 98 表12 Doc2vec（300 維）（MLP）3 種維度分類器表現細項比較數據 分類 號 precision recall f1-score 該分類占測試集 筆數 0.53 0.33 0.41 0.03 0.01 0.01 0.7 0.14 0.23 0.03 0.47 0.05 0.03 0.65 0.06 表13 Doc2vec（300 維）（隨機森林）3 種維度分類器表現細項比較數據 分類 號 precision recall f1-score 該分類占測試集 筆數 0.62 0.24 0.35 0.14 0.33 0.2 0.06 0.29 0.1 0.66 0.13 0.21 0.04 0.73 0.07 0.03 0.71 0.07 0.11 0.45 0.18 0.05 0.1 0.07 表14 Doc2vec（300 維）（XGBoost）3 種維度分類器表現細項比較數據 分類 號 precision recall f1-score 該分類占測試集 筆數 0.59 0.26 0.37 0.15 0.29 0.2 0.05 0.41 0.09 0.63 0.11 0.19 0.03 0.54 0.06 0.04 0.7 0.07 0.1 0.45 0.17
