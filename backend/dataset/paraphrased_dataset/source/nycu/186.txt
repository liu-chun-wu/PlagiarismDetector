損失函數(Loss function)如果降到最低就表示模型以最佳化，其作法是將輸出 值與實際值做比較，而在深度學習模型中常使用以下兩種演算法。  均方誤差(Mean Squared Error, MSE) MSE Loss = 1 𝑛∑(𝑦𝑖−𝑦̂𝑖)2 𝑛 𝑖=1 (4) 是將預測值ŷi與實際值yi的差值平方加總後再取平均，其值越小表示模型越 好，通常使用在回歸問題的模型訓練上。  交叉熵(Cross Entropy) Cross Entropy Loss = −∑[(y log 𝑦̂𝑖+ (1 −y) log(1 −𝑦̂𝑖) 𝑛 𝑖=1 ]       (5) 預測值ŷi，實際值yi將各筆的估計值取對數後加總交叉熵越接近零表示預設越 正確，通常使用於分類問題的模型中，本研究也使用此方法做為損失函數。
