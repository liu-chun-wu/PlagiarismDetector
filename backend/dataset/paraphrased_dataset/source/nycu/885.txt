The source ğ’« of ICP is the point cloud of input 3D model, and target ğ’¬ is the point cloud of scene object. Although we can get the 3D point data of scene captured by the depth sensor in the mobile device, due to its low-resolution, points of the object segmented from the plane is not complete and contains a few noise. Point cloud clustering is a solution to this problem, however, clustering is still a time-consuming approach on the mobile device, and selecting tolerance of clustering distance is also not easy. Thus, we generate the point cloud through back- projecting 2D points of foreground segmentation region to 3D space. In most of the approaches, source set ğ’« is the whole point cloud of the model. Because the target set ğ’¬ is the partial surface of scene object from the camera view, if use the whole model points for ICP, the ambiguity is more likely to happen. On account of the initial pose of the input model has been set already, we can generate the point cloud only the surface in front of the camera, which means we truncate the part that we cannot see, as shown in Figure 8. Using the partial surface point cloud of model not only decreases the poor estimated pose results, but also reduces the object jitter between frames. Before running the ICP, the point clouds are randomly down-sampled to balance the performance. Figure 9. Illustration of the surface in front of the camera, and the part which is truncated.
