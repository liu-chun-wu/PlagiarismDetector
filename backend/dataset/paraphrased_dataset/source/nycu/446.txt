若能利用圖像中的顏色、邊緣等訊息，預先找出圖中目標可能出現的位置， 即候選區域(Region Proposal)，之後僅在這些候選區域上提取特徵進行判斷，避 免不必要的冗框。R-CNN (Regions with CNN) [4]是利用深度學習作目標檢測的 開山之作，首先輸入測試圖片，接著利用候選性搜索(Selective Search)在圖像上 提取約2000 個左右可能包含物體的region proposal，因為取出的區域大小不 同，需將每個region proposal 縮放成統一的大小並輸入至CNN，再將每個 region proposal 提取到的CNN 特徵輸入至SVM 進行分類，最後經由線性回歸 校正bounding box 位置。但是利用Selective Search 所抓出的region proposal 多 達2000 個，而每個候選區域都需要進行CNN 特徵提取，且這些區域有許多都 是重疊的，致使計算量很大，偵測時間長，且不易訓練，而Fast R-CNN 在這點 上作了改進。 Fast R-CNN [5]的主要想法是改善R-CNN 需要運算高達2000 次CNN 的問 題，Fast R-CNN 只需要算一次CNN，CNN 擷取出來的特徵可以使這2000 個區 域所共用，將region proposal 對應到最後一個卷積層得到的feature map 上取各 自的MaxPooling，而每個region 會得到相同大小的矩陣，所採用的方法稱作 RoIPooling，接著再利用softmax 替代SVM 進行分類，同時利用多任務損失函 數(multi-task loss)，將bounding box 回歸也加入到網路中。Fast R-CNN 透過共 享卷積層，輸入一張完整的圖片，只需作一次CNN，在最後的卷積層得到每個 候選區域的特徵向量，再去作分類及邊界框回歸，大幅的提升了速度，也為後 來的Faster R-CNN 作下了鋪墊。 R-CNN 及Fast R-CNN 皆是透過Selective search 找出候選框，而這個步驟 十分耗時，為了更快的獲取候選框，有了後來的Faster R-CNN [3]。Faster R- CNN 的想法是與其預先選取region proposal，不如直接從CNN 的feature map 上選出region proposal，使用RPN 取代了Selective search，RPN (Region Proposal Network)是一個卷積網路，會在feature map 上作sliding window，每個 sliding window 的中心為anchor point，將k 個不同尺寸比例的anchor box 以同 個anchor point 去計算包含物體的機率，取機率最高的anchor box，接著候選框 透過RoIPooling，對每個region 作分類，並對bounding box 作回歸，找到更精 確的bounding box 座標。
