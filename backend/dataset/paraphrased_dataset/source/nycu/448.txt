YOLO (You Only Look Once) [6] 實現了real time 的object detection，它為 單一網路設計，只需對圖片作一次CNN 就能判斷圖中物體的類別和位置，辨 識速度非常快。YOLO 的概念是將圖片切割成7*7 的網格，對於每個網格都預 測兩個候選框，根據threshold 將confidence 較低的預測框刪除後，再透過 NMS(Non-Maximum Suppression)去除多餘的框，YOLO 的基本概念可參考下面 圖2-2。 本篇論文在第四章節實驗結果部分有Mask R-CNN 及YOLO 的Baseline 比 對，即為使用訓練好的model 對我們的資料集作測試。另外，[11]此篇論文應 用YOLO 網路架構結合AGMM 的前景資訊，偵測頂照式魚眼攝影機下的人， 但我們發現在其中結果較佳的實驗中，訓練資料的場景和測試資料的場景是相 同的，並且在輸入前景資訊時，忽略掉影像邊緣較難偵測的部分，因此結果部 分僅參考。 圖2- 2 YOLO 概念示意圖[6] 第三章 研究方法 此章節會介紹本篇論文人物偵測系統的網路架構以及相關細節，為了訓練 Mask R-CNN 模型，我們會將利用頂照式魚眼攝影機錄製的影片作擷取影像，標 記我們所需要的訓練資料，輸入圖片至Mask R-CNN 網路架構後，訓練適合我們 資料集的模型，接著即可利用訓練好的模型對頂照式魚眼攝影機下的人物作偵測， 下面的章節內容會詳細介紹並說明之。
