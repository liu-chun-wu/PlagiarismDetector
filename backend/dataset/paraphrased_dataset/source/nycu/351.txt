Metric learning 中常使用的loss function 還有Schroff 等人提的 FaceNet，其損失函數為triplet loss[32]，其目標為訓練一個網路辨別輸入的臉是 否為同一人。其訓練方法為，輸入一組三張的圖片，其中一張設置為anchor。 另外取與anchor 相同人的臉，此為正樣本。再取一張與anchor 不同人的臉，此 為負樣本。anchor 與正樣本經過網路擷取特徵後，其特徵的距離為Ｄ𝑎𝑝， anchor 與負樣本的特徵距離為Ｄ𝑎𝑛，其目標為使得Ｄ𝑎𝑝要小於Ｄ𝑎𝑛。 𝑇𝑟𝑖𝑝𝑙𝑒𝑡 𝐿𝑜𝑠𝑠= [Ｄ𝑎𝑝 2 −Ｄ𝑎𝑛 2 + 𝛼]+                （3-2） 此loss function 目標是使得anchor 與正樣本、負樣本的相對距離要大於一 閥值𝛼，並沒有特別訓練要將正樣本對的距離拉近。然而在追蹤任務中，需要 有個閥值能夠作為是否為同一人的標準，因此本文修改了triplet loss 的形式， 加上了anchor 和positive 的距離也必須低於其設置之閥值，此訓練目標有助於 追蹤任務中判斷是否繼續匹配。式3-3 的前項即為拉近anchor 和正樣本的距 離，而後項則參考至原triplet loss，拉遠anchor 與正樣本、負樣本的相對距 離。本文𝜏1取0.2，與contrastive loss 相同，𝜏2則是0.8。 𝑅𝑒𝑣𝑖𝑠𝑒𝑑 𝑇𝑟𝑖𝑝𝑙𝑒𝑡 𝐿𝑜𝑠𝑠= max {Ｄ 𝑎𝑝−𝜏1 ,0} + 2 max{(Ｄ 𝑎𝑝−Ｄ 𝑎𝑛) + 𝜏2, 0} （3-3）
