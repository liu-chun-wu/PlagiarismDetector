Gradient Boosting Regression 是一種透過學習不斷建立模型，每一次建 立的模型都比上一次更好，逐漸找出最佳模型[7]。Gradient Boosting 有分類 跟回歸，回歸樹生成是有競爭力的，高度可靠的，且具有可解釋的程序，特別 適合於挖掘不到乾淨的數據。 Boosting 的過程，對於一份數據建立N 个模型，可稱為弱分類器﹝weak learner﹞，每次分類都針對上一次分錯的數據提高權重然後在進行一次分類與 學習的過程，最後就能得到該資料的分類模式是在於訓練數據與測試數據上都 能得到較好的成績[20]。 Gradient Boosting 是boosting的一種方法，是在每次建立模型的時候， 讓損失函數是往梯度下降的方向，因此整個模型就會是往梯度上升的方向。損 失函數越大就代表模型可靠程度越低，因此訓練過程中要讓損失函數持續下降 以達成Gradient Boosting的梯度方向往上。 Gradient Boosting Regression是由Jerome H. Friedman在1999年2月於 「GREEDY FUNCTION APPROXIMATION：A GRADIENT BOOSTING MACHINE」中提 出，推導公式如下[7]： 訓練集：{(𝑥𝑖, 𝑦𝑖)}𝑖=1 𝑚 ，Loss function L(𝑦, 𝐹(𝑥)) F0(𝑥) = 𝑎𝑟𝑔𝑚𝑖𝑛𝛾∑𝐿(𝑦𝑖, 𝛾) 𝑚 𝑖=1 M= from 1 to M γ𝑖𝑚= −[𝜕𝐿(𝑦𝑖, 𝐹(𝑥𝑖)) 𝜕𝐹(𝑥𝑖) ] 𝐹(𝑋)−𝐹𝑚−1(𝑥) 𝑓𝑜𝑟 𝑖= 1, ⋯, 𝑚 γ𝑚= 𝑎𝑟𝑔𝑚𝑖𝑛𝛾∑𝐿(𝑦𝑖, 𝐹𝑚−1(𝑥𝑖) + 𝛾ℎ𝑚(𝑥𝑖)) 𝑚 𝑖=1 更新模型，𝐹𝑚(𝑥) = 𝐹𝑚−1(𝑥) + 𝛾𝑚ℎ𝑚(𝑥) 最後得到F𝑀(𝑥)
