這一節的實驗主要是比較將整張原圖直接作訓練及將圖片拆成兩部分(中心 區域和外圍區域)分別作訓練再把結果整合之間的差異性，相關的資料處理細節 放在3.3.6 小節，因此我們在此節不再贅述。其中外圍區域的部分，因為我們將 影像外圍作轉正拉直的處理，使人的成像和使用投射型攝影機拍攝的相同，而 外圍區域部分除了使用我們轉正後的影像作訓練模型外，我們也使用MS COCO 預先訓練好的model 直接對轉正後的影像作偵測。 下表4-7 為實驗結果，其中Merge 的欄位是將中央部分和外圍部分的偵測 結果作整合，Merge 時首先將外圍區域的偵測結果轉換為原圖的對應位置，由 於中心和外圍有overlap 的問題，因此我們將中心區域的mask 採用greedy 的方 式找出和外圍區域重疊最多pixel 的mask，並且彼此的mask 之間 IoU>=0.5 者 進行合併。 表4-7 將各場景的每支攝影機結果皆列出來，可發現大部分資料集在中心 區域模型上偵測結果都表現較佳，而外圍區域模型則表現較差，外圍區域模型 除了Shop B-1 和Shop B-3 鏡頭使用自己訓練的資料表現較佳，其他資料集皆 表4- 7 分區訓練模型比較結果 Central Peripheral Merged Full image Finetuned COCO Finetuned COCO # AP # AP # AP # AP # AP # AP LAB-1 0.83 0.49 0.69 0.60 0.75 0.59 LAB-2 0.89 0.63 0.88 0.76 0.79 0.62 Shop A 0.75 0.23 0.37 0.27 0.28 0.56 DB 0.67 0.35 1009 0.41 0.41 0.36 0.56 Shop B-1 0.90 0.94 0.91 0.97 0.99 0.95 Shop B-2 0.94 0.60 0.63 0.60 0.68 0.79 Shop B-3 0.84 0.67 0.57 0.77 0.78 0.85 是使用MS COCO 的預訓練模型能達到較好的AP 值，推測是COCO 訓練的資 料集比我們的龐大許多，所以對不同場景的適應性較佳。 訓練單張影像與訓練中心及外圍的比較部分，我們發現若是中心區域和外 圍區域的人數相差不多的時候，皆是使用Merge (外圍使用COCO 模型作偵測) 後的效果較佳，包含LAB-1、LAB-2 及Shop B-1；相反地，當外圍區域的人數 遠多於中心區域時，由於訓練外圍區域模型AP 通常較低，導致合併後整體AP 的下降，反倒是訓練單張影像模型表現的較佳。
