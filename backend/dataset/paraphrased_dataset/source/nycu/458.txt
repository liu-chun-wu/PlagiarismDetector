實驗資料來自四個場景，包括學校實驗室(以下簡稱LAB )、商店A (以下簡 稱Shop A)、Bomni-DB(以下簡稱DB)、模擬商店B (以下簡稱Shop B)，四個場 景共有七支頂照式魚眼攝影機，而不同攝影機錄製的影片，除了場景不同外，環 境光源與擷取影像的大小也不同，使我們的資料集具有多樣性。 下表4.1 列出使用的資料集詳細資訊，包含影像大小、影片擷取的影像frame 數、各資料集在整張影像上的ground truth 人數及劃分中間和外圍兩部分後各具 有的ground truth 人數。 4.2 偵測之準確度評分方法 要計算Precision 和Recall，我們首先需要辨別True Positive(簡稱TP，有人 且有被偵測到)、False Positive(簡稱FP，沒人卻有偵測到)、True Negative(簡稱 TN，沒人且沒偵測)和False Negative(簡稱FN，有人卻沒被偵測到)。為了判別 True Positive 和False Positive，我們使用IoU ( Intersection over Union )的概念， 指的是predicted bounding box 和ground truth bounding box 之間交集和聯集的比 例，當IoU >= 0.5 時我們視為True Positive，否則視為False Positive。Precision 和Recall 的公式如下： Precision = TP/(TP+FP) Recall = TP/(TP+FN) 在我們評測訓練出來的模型好壞時，若單純只比對precision 和recall 都有 失公平，所以我們主要的評測標準參考Pascal VOC Challenge[15] 2010 年後的 計算方法，來計算AP (Average Precision)，AP 也可以看成是Precision-Recall 曲 線下方的面積。 表4- 1 資料集詳細內容 Dataset LAB-1 LAB-2 Shop A DB Shop B-1 Shop B-2 Shop B-3 Image size Frame Image people Central part people Periphery people 4.3 實驗結果 本節會將第三章介紹過的實驗方法作比較，將實驗結果整理並呈現在下面 的小節中，訓練時我們採用Finetune 的方式減少訓練時間，測試資料時若使用 GTX 1080Ti 作偵測約5 FPS，使用CPU 則約0.2 FPS。
