針對第一個研究問題，本研究假設，在深度學習模型原本的損失函數上，加 上一個新的偏見損失（Bias Loss）會有助於消除偏見。如（15）式。其中，α 是 超參數，用來決定消除偏見的程度。 （15） 本研究定義偏見損失如（16）式。其中，G 是欲去偏見之族群的詞嵌入集合， 共m 個族群，本研究取 G1 為男性相關字的詞嵌入、 G2 為女性相關字的詞嵌 入，m=2。N 是選擇的中性字的詞嵌入，例如職業相關字的詞嵌入。ψ 是計算兩 個向量之間相似度的函數，本研究取𝜑為餘弦相似度（Cosine Similarity）。δ 是 計算兩個相似度數值之間差異大小的函數，本研究取δ 為絕對值（Absolute） 。 𝐽𝑏𝑖𝑎𝑠= ∑ 𝛿(𝜑(𝑁, 𝐺𝑖−𝐺𝑗)) ,   𝐺= {𝐺1, … , 𝐺𝑚} 1≤𝑖≤𝑚,1≤𝑗≤𝑚,𝑖≠𝑗 (16) 偏見損失的功用如圖15 所示，若中性字取職業字（例如: dancer、nurse、 doctor、captain）、族群字取有對應關係的性別字（例如:he 與she、her 與him）， 偏見損失的訓練目標是使中性字和族群的方向向量正交（Orthogonal），以確保 中性字的涵義儘可能地和族群無關。 第27 頁 圖15  偏見損失（Bias Loss）的預期效果 圖片來源：本研究製作 圖片說明：偏見損失的訓練目標是使中性字和族群的方向向量趨向正交（Orthogonal）
