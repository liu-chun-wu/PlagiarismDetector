Due to the poor efficiency of ICP on the mobile device, we also adopt the device motion tracking to improve the efficiency. Since the pose module of google tango API can get the pose of the device at specified timestamp, we use the API to get the poses of the depth sensor in different timestamp and computing the transform matrix of the device. The point cloud 𝑀𝑑𝑟𝑎𝑤 of tracking result that we draw on the screen, the OpenGL overlay, can be described as below. 𝑀𝑑𝑟𝑎𝑤= 𝐏𝐕𝐌𝑀𝑚𝑜𝑑𝑒𝑙,                     (28) 𝐌= 𝑃𝑑𝐓,                           (29) where 𝐏  is the projection matrix, 𝐕  is the view matrix, 𝐌  is the model matrix, and the multiplication of these three matrix is the MVP matrix in OpenGL. The model matrix is composed of the transform matrix from depth camera space to OpenGL space 𝑃𝑑 , which defined as depth pose, and the model pose of tracking result 𝐓. 𝑀𝑚𝑜𝑑𝑒𝑙 is the origin point cloud of the input model in depth camera space. The matrix 𝐏 and 𝐕 can also available from the API. We suppose that the point cloud we draw in next frame as 𝑀𝑑𝑟𝑎𝑤 ′ , and 𝑀𝑑𝑟𝑎𝑤 ′ = 𝐏′𝐕′𝑃𝑑𝐓𝑀𝑚𝑜𝑑𝑒𝑙. The new transform matrix and the new point cloud of the model can derive from the depth pose 𝑃𝑑 ′ in next frame. The new model pose 𝐓′ is described as 𝐓′ = 𝑃𝑑 ′ −1𝑃𝑑𝐓.                     (30) We can continue using the new pose in ICP tracking or pose smoothing in section 5.4. We also do the pose measurement every 𝑁 frames, to check whether the pose drifts too much or not. If 𝐸𝑡𝑟𝑎 is larger than 𝑇𝐷𝑀, the device motion tracking is marked failure, and will back to ICP tracking state.
