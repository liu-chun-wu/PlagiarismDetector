序列到序列的架構(Sequence to Sequence)是2014 年分別在(Sutskever et al., 2014)與(Cho et al., 2014)這兩篇論文中提出，此架構也可以稱為Encoder-decode 架 構。其主要架構是由兩個循環神經網路所組成，一個負責將序列單詞一個一個的 讀入，來訓練隱藏層中的詞向量神經元，然後再由另一個循環神經網路從同一個 隱藏層中輸出序列。也因為是兩個神經網絡所以不會受到輸入與輸出長度限制， 在本研究中是將較長的文本輸入後，輸出一個相同語意的短文本達成摘要的目的， (See, Liu, & Manning, 2017)與(Li, Lam, Bing, & Wang, 2017)都使用此架構做為摘要 模型的基礎。 圖 19  序列到序列的架構圖 由圖19 中是將輸入值按時間依序輸入至隱藏層進行編碼，讓上下文(context) 可以得到輸入序列的完整訊息，並且到解碼階段再依序輸出資訊，以下舉例翻譯 時的路徑。 圖 20  序列到序列執行翻譯的路徑 這邊使用較短輸入的翻譯來做序列到序列的動作說明，其動作如圖20 第一步 是將“早”“上”“好”透過Encoder 將三個字分別輸入進模型並將最後的隱藏層做為上 下文(context)語意向量，第二步將語意向量做為Decoder 的最後狀態，並且輸入 <start>標籤開始解碼，之後不斷將當下的輸出做為下一時刻的輸入繼續解碼直到輸 出<end>標籤後停止。
