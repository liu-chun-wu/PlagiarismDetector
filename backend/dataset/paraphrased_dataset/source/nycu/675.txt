資料清理包含以下幾個步驟： (1) 字元處理：將所有英文字元改為小寫，並篩掉除了英文、數字和空白以外的 字元。處理後，只剩下a-z、0-9 和空白字元。 (2) 單詞化（Tokenization）：將句子拆分為單詞。例如將「they do not」拆成 「they」、「do」、「not」。 (3) 加入起始和結束字元：加入「<EOL>」為每一句「問句」或「答句」的結束 單詞。加入「<GO>」為每一句「答句」的起始單詞。 (4) 詞數限制：令每一個句子的單詞數都介於2 到25 之間。單詞數少於2 的句 子已經於資料擷取時排除掉，單詞數大於25 的句子則將第25 個以後的單詞 除去。 (5) 建立單詞索引表：利用NLTK 取出最常出現的8000 個單詞作為字彙庫 （Vocab），頻率由高到低將每個單詞分配自然數索引值。例如將「i」轉換 第34 頁 成索引值「1」，「you」轉換成索引值「2」，若該單詞在最常出現的8000 個之外，將該單詞取代成「<unk>」並分配索引值「8001」。 (6) 索引化（Indexing）：將語料中每個句子的每個單詞都轉成索引值。例如句子 「they do not」可能被轉換為[23，50，7]。 (7) 未知詞之詞數限制：設定句子中的未知詞數佔全體詞數的比率需小於0.2， 超過此比率的句子，該「問句-答句」對則不採用。 (8) 補零（Zero Padding）：為了讓每個問句和答句的長度一致，取最大長度25， 將句子長度不足的補零至最大長度。例如：句子[208，1719，8002]長度只有 ， 在 後 面 補 零 成 為 [208 ， ， 8002,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]使長度為25。 表1  資料集參數設定 資料集參數 Vocab Size Min. Sequence Len Max. Sequence Len Start Symbol <GO> End Symbol <EOC> Unknown Symbol <unk> Unknown Ratio less than 0.2 表格來源：本研究製作 表格說明：本研究聊天問答資料集參數設定 第35 頁 資料集參數設定如表1。
