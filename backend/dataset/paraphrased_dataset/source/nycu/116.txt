從「相同詞袋實驗」及「Doc2vec 產出維度數對三種分類器的表現實驗」可以 看出不同模型對於不同預處理方法的混合資料有相當顯著的適性差異，總體評價 上，從表15 可以看出MLP 普遍有較高的總體評價，也就是對整體資料的分類上， MLP 較能夠做出較多正確的分類，搭配One-Hot Encoding 時為對分類5 有較高的 鑑別力，從而獲得較高的總體評價，而搭配Doc2vec 時則是提升了分類1、5 的反 向資料鑑別力，達到搭配Doc2vec 的所有分類模型最高的評價。 而tfidf 的場合，則在隨機森林上有總體最佳評價，從圖18 觀察，主要在分類 1、5 上有較高的鑑別力，同時擁有與MLP 搭配Doc2vec 預處理方法對分類1 的鑑 別力及MLP 搭配One-Hot Encoding 預處理方法對分類5 的鑑別力，隨然失去了對 分類7 的鑑別力但有相對最高對分類3、4 的鑑別力。 表15 預處理及模型組合比較 預處理方式& 最佳關鍵字或 維度n One-Hot Encoding n=100 tf-idf n=100 Doc2vec n=300 最佳Hamming Loss 0.6154 0.5704 0.786 最佳搭配模型 MLP 隨機森林 MLP 圖18 最佳Hamming Loss 分類器表現細項比較 雖然在三個實驗及數據比較中組合出了對模型訓練上最佳的組合，但也可以 觀察出有部分組合可以相對有效鑑別最佳組合較無法鑑別的分類，比如分類12 或 是分類90 後的分類，從圖16 可以發現隨機森林與Doc2vec 的組合對分類12 有相 對高的鑑別力，同時可以辨別分類90 後的分類。 在最佳結果中，較有效鑑別的分類（1、3、4、5、6）為：完全繳清、部分繳 清部分撤回（含300 元以下不執行）、部分繳清部分發憑證、全部發憑證、移送 機關撤回（含300 元以下不執行）。 0 0 0.04 0.61 0.06 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.41 0.04 0.08 0.56 0.06 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.41 00.01 0.23 0.050.06 0 0 0 0 0 0 0 0 0 0 0 0 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 1 3 4 5 6 7 10121315162291929395969798 onehot-100-MLP tfidf-100-RDF d2v-300-MLP 第五章、 結論與未來研究方向
