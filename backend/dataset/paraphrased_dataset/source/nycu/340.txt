Batch Normalization：批標準化（ S Ioffe and C Szegedy ,2015），⼩批量執⾏標準 化，可加快深度學習網路學習速度。 Dropout： 模型過度擬合是指太適切訓練樣本的特殊情況，⽽無法適切⼀般的資料 集。過度擬合會出現訓練集有⾮常低的錯誤率，但預測測試集卻有相對⾼的錯誤率。因此 在需要模型加上Dropout，每次訓練時隨機捨棄部分⽐例的神經元以防⽌過度擬合 （Overﬁtting）。 21 Early Stopping： 多次訓練及驗證整體樣本的過程中，如果loss反⽽增加，則提早結 束訓練，不繼續進⾏下⼀個epoch。 22 四、實驗部份
