在訓練Mask R-CNN 網路模型架構時，我們先讀取MS COCO pre-trained weights，再使用自己的資料集去作finetune，以節省訓練模型的時間。最初我 們是訓練在MS COCO 上，MS COCO 資料及總共有80 個類別，由於我們主要 的目標是人物偵測，所以在讀取COCO pre-trained weights 後，針對其中的 「Person」這個class 作finetune，再去測試訓練完的模型，但考量到MS COCO 資料集在訓練Person 這個class 時，並不是針對在頂照式魚眼攝影機下的影像 作訓練，而是針對投射型攝影機下的影像作訓練，於是我們自己新增了一個 class「Fisheye-Person」，並以此class 作訓練模型，下表4-2 為測試商店A 的兩 種方法比較結果，其中訓練資料使用LAB 和DB 這兩組dataset，訓練過程 finetune 100 個epoch 並將表現最好的model 列出來。 我們可以從表4-2 推論在創立新的class 後，相較之前的測試結果，不僅AP 部分提升了0.11，Recall 的部分也提升了0.12，可以得知使用新創立的class 能 得到較佳的結果，因此後面小節的實驗皆使用新的class 下去做訓練。 表4- 2 商店A 新類別比較結果 AP Max. Recall Person 0.46 0.52 Fisheye-Person 0.57 0.64
