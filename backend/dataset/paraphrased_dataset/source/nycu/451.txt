本篇論文所使用的網路架構是Mask R-CNN，本章節會先介紹Mask R- CNN 此架構，接著再詳細介紹如何透過此網路架構去實作頂照式魚眼攝影機下 的人物偵測。 Mask R-CNN 從Faster R-CNN [3] 此網路架構延伸而來，Faster R-CNN 僅 具有兩個分支( Classification branch 和Bounding box branch )，是流行的目標檢 測框架的一種，而Mask R-CNN 多加了一個分支Mask branch，擴展為實例分割 框架。 Mask branch 主要是由Fully Conventional Network (FCN) [8] 的概念所構 成，mask branch 會對每個RoI ( Region of Interest ) 以 pixel-to-pixel 的方式預 測出 segmentation mask。 Faster R-CNN 的 RoIPooling 使用最近插值法( Nearest Neighbor Interpolat- ion )，使得mask 會產生偏移現象，無法在inputs 和outputs 之間做到pixel-to- pixel alignment，Mask R-CNN 為了要解決對齊方面的問題，設計了 RoIAlign， RoIAlign 使用雙線性插值法( Bilinear Interpolation )來改善RoIPooling，用來保 存原本的空間位置，並使mask 位置更加準確，見圖3-4。 圖 3- 4 Mask R-CNN framework for instance segmentation[1] 本研究實現Mask-RCNN 使用的是ResNet101 + FPN 網路架構。Feature Pyramid Network ( FPN )可以在多尺度上有更好的表現，多數object detection 的 架構都只採用最頂層的特徵做預測，我們知道低層的特徵雖然語義訊息較少， 但目標位置準確，相對的高層的特徵語義訊息豐富，目標位置卻比較粗略， FPN 將頂層特徵透過上採樣和低層特徵做融合，可見圖3-5，建立特徵金字 塔，而選用哪一級的特徵是由目標的尺寸動態決定的。 圖 3- 5 Feature Pyramid Network ( FPN ) 我們的程式將Resnet101 網路分成五個階段，記為[ C1,C2,C3,C4,C5 ]，而 這五個階段分別對映著五種不同尺度的feature map [ P1,P2,P3,P4,P5 ] 輸出，用 來建立FPN 網路的特徵金字塔( feature pyramid )，其中因為P1 對應Feature map 較大較耗時所以棄用，在P5 進行下採樣得到P6，接著利用五個不同尺度 的feature map [ P2,P3,P4,P5,P6 ] 輸入至RPN 網路，分別生成RoI。 RPN 會生成若干個anchor box，經過NMS 後保留2000 個RoI，由於stride 的不同，分別對四個不同尺度的feature map 對應的stride 進行RoIAlign，將經 過此操作產生的RoI 連接後，分為三個部分: 全連接層 ( full connected layers ) classification、全連接層box regression 及全卷積層( Full Convolutional Network) 預測分割mask。 Mask-RCNN 的網路結構圖如下面圖3-6 所示。 圖 3- 6 Mask R-CNN Network Architecture
