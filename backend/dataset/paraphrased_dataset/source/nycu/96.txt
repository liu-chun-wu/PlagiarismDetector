GloVe（Global Vectors for Word Representation）是一種全局對數雙線性回歸模 型，這種模型能夠結合其他兩種主要模型的特點：全局矩陣分解（global matrix factorization）和局部上下文窗口（local context window）。 用非監督學習方法來建立詞向量時，詞語出現次數的統計資訊是最直接了當 的，而這個領域也延伸出許多進階的做法，但還是存在一些問題，比如如何從這 些資訊中關聯詞義。 一般詞頻模型會搭配global matrix factorization 方法如latent semantic analysis （LSA）[5]，全局特性的表現上相當出色，但在詞性類比上表現就相對較差，而 Word2vec 則相反，因為訓練機制的緣故，記錄了高度局部上下文資訊，但沒辦法 充分運用整個文本的統計資訊。 於是Jeffrey Pennington 等人便提出一種基於共現矩陣（表1 共現矩陣）的向 量模型，利用比較對應同一個詞的共現機率比值來學習詞向量，共現機率機率本 身就是特定單詞的某一上下文單詞出現數對所有上下文單詞出現數的比值，環繞 固定某個詞的共現機率比值訓練模型又具有局部上下文比較的資訊，透過這樣的 機制讓空間向量帶有全局及局部的資訊，便是GloVe 基礎[11]。 表1 共現矩陣 共現次數 文本 探勘 研究 文本 … 探勘 研究 …
