線性回歸是一個使用線性接近去找出模型來定義變數和值之間關係。而線 性回歸可分為：Sample linear regression、 Multiple linear regression， 其中差別在於變數數量的不同，Sample linear regression 為單一變數， Multiple linear regression 為兩個以上的變數[19]。 在線性回歸裡，關係之間是透過使用線性預測功能來建立模型，可使用預 測功能從資料中去評估預測值，而那些被建立的模型就稱為線性模型。最常見 的、廣義地，給定解釋變量（或預測變量）的值的條件均值假定為這些值的映 射函數，線性回歸著重於給出預測變量值的響應的條件概率分佈。 給定一個n 為分析單位資料集{Yi，Xi1，…，Xip} n i=1，一個線性回歸模型確 保獨立變數Y 和回歸分析因子X 為線性關係。而在這樣的線性模型中加入干擾 誤差𝜀𝑖─為一個未被觀測的隨機變數，用來捕獲對線性關係中變數之外其餘對𝑦𝑖 的影響，因此模型公式可被推導成： 𝑦𝑖 = 𝛽0 + 𝛽1𝑥1 + ⋯+ 𝛽𝑝𝑥𝑖𝑝+ 𝜀𝑖= 𝑥𝐼 𝑇𝛽+ 𝜀𝐼  ，             𝑖= 1, ⋯, 𝑛    [19] 圖 6 Linear Regression 出處：https://en.wikipedia.org/wiki/Linear_regression
