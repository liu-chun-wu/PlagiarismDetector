在整合前，預測出來的bounding box 座標是在切割後的PTZ 的影像座標系中，所以 我們需要轉回到魚眼座標系。由於直接利用bounding box 的4 個頂點座標換算回魚眼 座標的4 個頂點座標會造成換算後的bounding box 扭曲變形，所以改利用預測的4 個頂 點座標求出bounding box 的4 個邊的中點以及bounding box 中心點這五個點，如圖3-9 左圖的五個黃點所示，利用反向回推3.2.3 的座標轉換，將這五個點回推到原始魚眼影 像座標，並且利用這五個轉換的座標當做回推後的bounding box。 Bounding box 回推到魚眼座標系後，因為Yolo 模型在偵測人物時，即使人物是歪 斜的，偵測的bounding box 依然是方正的不會旋轉，如圖3-10 藍色方框所示，但是我們 所標記的ground truth bounding box 是旋轉的，這樣會造成整合時bounding box IOU 計 算不夠精確，所以我們需對偵測的bounding box 座標進行旋轉。我們將原影像切割PTZ 影像的角度加上bounding box 中心點與影像基準點的夾角角度（如圖3-9 右圖所示）作 為bounding box 的最終的旋轉角度，旋轉結果如圖3-10 所示，藍色方框為尚未旋轉的 bounding box，紅色方框為旋轉過後的bounding box，紅色的方框即作為最後轉換的結 果。 轉換所有預測框結果後，接下來要對所有的預測框做整合，若該預測框與其他預測 框IOU > 0.5 則視為同一人物之預測框，再利用connected graph 的方法，將所有預測框 分成數個集合，每一集合中的bounding box 視為同一人物的預測框，如下圖3-11 左圖 所示，各顏色代表各預測框集合結果，同顏色的預測框視為該人物在切割的PTZ 影像中 轉換回魚眼坐標系後判斷為同一人的結果，接下來會在各預測框集合中選出分數最高者 當作此預測框集合的代表，以此預測框代表與ground truth 計算 AP。 圖3-9 左：bounding box 的4 個邊中點以及中心點，右：bounding box 中心點與影 像基準點的夾角角度 圖3-10 預測bounding box 旋轉結果，藍色為旋轉之前，紅色為旋轉之後 ! 圖3-11 左：所有預測框集合結果圖，右：各預測框集合中選出分數最高者做代表
