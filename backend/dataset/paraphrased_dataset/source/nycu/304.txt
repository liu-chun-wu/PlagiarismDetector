在做文本資料處理之前，需要先對來源的資料，進行資料清除（Data Cleaning）的 動作，以確保後續在文本資料處理、建模時能有正確的來源資料，當有高品質的來源資 料，才有高質量的結果。 一般來源資料最常見的問題有如下情形： (1) 遺失資料（miss data）：資料中某個屬性值中有缺，如：員工資料裡沒有員工生日資 料存在、通訊住址等。 (2) 資料有雜訊（noise）：資料有錯誤的情形，如員工性別，將男性誤植為女性。 (3) 資料不一致（data inconsistency）：由多個來源所匯整在一起的資料，就可能會發生 資料不一致的情形發生。 最常見的解決上述資料問題的方法如下： (1) 遺失資料  直接移除:最簡單的做法就是把有遺失資料（miss data）的記錄，直接移除，但 這有可能會影響到最終的精確度（accuracy）。來源資料有可能80%以上的資料 都有此情形，若將這些資料全數移除，在最後Training 出來的model 就會有偏 差的情形。當來源資料只有小量遺失資料（miss data）時，可採用此方法來處 理。  人工修正：透過人工方式進行修正填補，但所耗費的成本比較高。  自動填補：透過計算求出中間值進行填補，或是直接填補某個值。 (2) 雜訊去除，透過回歸分析來去除雜訊，將資料切成幾個等分，求算平均值以消除資 料雜訊問題。 (3) 資料正規化，針對資料進行正規化，以達到資料的一致性。
