在衣著辨識的相關研究中，一般的方法是會先抓出衣服的位置，在對其做相 關的辨識，Lukas[6] 就先找到臉部的位置，在從相對應臉部的位置來得到上半身 衣服的Bounding Box，在對其Bounding Box 的區域中抓取各種不同特徵，如 SURF、LBP、HOG、Self-Similarity，再將這些特徵組合成一特徵序列，而後利用 Random Forest 並且配合Transfer Learning 來學習相關的衣服屬性，此做法可以 使得其各類衣服屬性的平均正確率達到41.4%，但其衣服的屬性分類僅對上半身 來實作。 若是同時考慮上下半身，Yannis [7] 則是先利用了身體的姿勢偵測，來獲得 屬於此人身體的部位，在對其偵測到的身體部分作Segmentation 與Clustering 如 圖 2 - 1，如此便可分辨出手肘、頭部、衣服……等等不同的身體部位，再利用 Locality-Sensitive Hashing 來索引到屬於穿著的屬性類別，而對於穿著的顏色屬 性則是利用RGB 和LBP 特徵來進行描述，其衣著屬性分類的平均準確率到達 54%。 圖 2 - 1 Segmentation 與 Clustering 然而隨著神經網路的崛起，Ziwei [8] 利用了類似VGG16 之網路架構來分類 衣服屬性，其網路架構FashionNet 在最後會有三段的分支如圖 2 - 2，第一段會 用來預測衣服的關鍵點，第二段會配合第一段預測出的關鍵點來得到影像局部的 特徵，最後一段則會抓取影像全域的特徵，最後合併第二段的局部特徵與第三段 的全域特徵，來預測此影像衣服的類別與屬性。 Kuan[9]提出了利用衣服屬性，判斷該衣服是否流行於該季節，其架構是先 將衣服上不相關的圖案當作Noise，並把Noise 用類似VGG16 的架構，進而訓練 一個偵測Noise 的模型，當判斷出衣服上的Noise 並且移除其影響後，對影像作 Pose Estimation 得到影像特徵，再利用SVM 去進行分類，最後再判斷是否流行， 而此衣服屬性分類的準確率高達63%。
