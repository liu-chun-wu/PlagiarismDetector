使用擬人視覺技術的方法是以一般光學影像資料作為輸入，只需以相機拍攝，相 較於前兩者最為便利，但同時也最為困難。在近期神經網路相關技術及硬體發展逐漸 成熟後，開始有大幅進展。 此類方法依據架構設計，可再細分為one-stage[13]以及two-stage[14][15] [16]兩 種。前者直接估計關鍵點3D 位置，如Spurr 等人藉由VAE 模型學習潛在空間與不同 資訊間的關係[13]。後者則是先估計2D 手部關鍵點位置，再利用2D 的資訊估計3D 關鍵點的位置，Zimmermann 和Brox 最早提出以神經網路估計單視角RGB 圖片的手 部關鍵點3D 位置的論文[14]，藉由神經網路從2D 關鍵點的heatmaps 來估計3D 關鍵 點位置，圖4 為該論文提出的系統架構圖，目前許多研究的架構設計皆從此論文修 改。其中，Panteleris 等人利用手部模型對2D 關鍵點做逆向運動學(inverse kinematics) 得到3D 關鍵點位置[15]。Cai 等人則是設計弱監督式學習(weakly supervised learning)的 網路架構，只需要3D 渲染的3D 關鍵點位置以及真實影像的深度資訊就可以訓練網 路，無需真實影像資料的3D 關鍵點位置[16]。 圖4、Zimmermann 和Brox 所提出的整體架構圖[14]
