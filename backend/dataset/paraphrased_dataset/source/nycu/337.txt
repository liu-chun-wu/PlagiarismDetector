深度學習⾝為機器學習的⼀員，在近期蓬勃發展。機器學習的歷史可以從1943年 Artiﬁcial neural network開始談起。McCullogh and Pitts 提出類神經網路，⼀個模仿⼈類神 經元的運算模型。此模型將資料輸⼊（樹突，Dendrites）經過整合決定強度（軸突， Axon）最後再進⾏（突觸，Synapses）輸出。接續著1957年Rosenblatt等⼈提出 Perceptrons，經由輸⼊隨機的樣本，做分辨模式（pattern）的學習，旨在創造出類⼈腦般 可以解決問題的系統。1969年時Marvin Minsky and Seymour A. Papert舉出XOR的例⼦來 說明Perceptron learning的侷限。直到1986年Geoffrey等⼈提出反向傳播的⽅法，並⽤多層 網路來解決⾮線性分類問題。 Peter A Flach 在Machine learning這本書裡提到機器學習的 定義，“Machine learning is the systematic study of algorithms and systems that improve their knowledge or performance with experience.”。機器學習以⾮結構性的資料作為輸⼊， 如圖像、⽂字、⾃然語⾔等，經由深度學習或由分類分群演算法等運算過後，產⽣學習的 效果，取出隱藏其中的結構化資料，加以應⽤在健康醫療、⽣物科技、⼯廠製造、資安產 業、銀⾏與電⼦商務等⾦融消費類別等等。⽽深度學習在應⽤的廣度及準確度上，是近期 熱⾨的原因。2012年，從AlexNet在ImageNet ILSVRC中獲得勝利後, 2014年VGGNet, GoogLeNet及2015年ResNet 等擁有多層卷積層的深度學習網路在圖像辨識⽐賽獲得優異的 表現。AlphaGo 2015年也以深度學習網路打敗圍棋職業棋⼠。⼜以Google翻譯為例，拋下 之前慣⽤的統計模型為基礎的機器翻譯，在2016年9⽉之後推出Google類神經網路機器翻 譯GNMT，使⽤深度學習的類神經網路架構，包含⼀個帶有8層使⽤注意機制的編碼及解 碼層的深度⾧短期記憶網路（LSTM network），快速發展⾄⼀萬多個語⾔對（共107個不 同語⾔）。2017年微軟推出以CNN-BLSTM聲學模型及基於字符和對話會話感知的LSTM 語⾔模型，整個⾃動語⾳辨認系統達到5.8％錯誤率，在LSTM-LM的加⼊後，錯誤率5.1% 已經是⽐真⼈辨認還不容易出錯。 以下對論⽂內使⽤到的類神經層加以說明:
