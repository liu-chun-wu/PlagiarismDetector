粒度是指句子的分割單位，而該如何選擇粒度在自然語言處理中有著關鍵 的要數，尤其是在搜尋引擎應用時召回與排序都會受到影響，例如中文的“大 不列顛及北愛爾蘭聯合王國”這一個名詞就可以透過不同粒度來切分，使用大 粒度切時:“大不列顛及北愛爾蘭/聯合王國”也可以進一步切“大不列顛/及/北 愛爾蘭/聯合/王國” ，其中“聯合/王國”又可以分別出“聯/合/王/國” ，也有著其 本身的意義。由此可以看出來大粒度詞的表義能力較強，能夠精準的表達句 中的含意，適合做為關鍵字或是標籤方便提取使用，所以在搜尋引擎中直接 使用大粒度詞建構倒排索引(Inverted index)會有較高的精準度（Precision）。 但是相反的會有召回率（Recall）不足的問題，例如“北愛爾蘭王國在歐洲大 地上誕生”這句話中，如果使用“大不列顛及北愛爾蘭聯合王國”到倒排索引中 是無法被索引到的，但是拆解成小粒度“大不列顛”“北愛爾蘭”“聯合王國”三個 詞時就可以檢索出來，所以中文的分詞器也必須有這對應不同使用時的分詞 策略。 且在中文中很難去解決“基本粒度詞”是否可繼續拆分的問題，這又必須由 中國古代的漢語使用方式說起，如在古書中“己所不欲，勿施於人”每個字都可 以當作一個詞來使用，但是翻成白話文後“自己都不願意的方式，不要拿來對 待別人”反而會用雙音節的詞彙來解釋單字的含意(“己-->自己，欲-->願意，勿 -->不要，施-->對待，人-->別人”) ，還有一些詞會因為粒度小的分詞造成沒 有意義的詞產生，例如“老虎”、“水果”，切成“老/虎” 、“水/果”時的“老”與“水” 有本身的涵義但與原詞沒有直接的關係，而在日常的文章中也都會夾雜這類 用詞，這也讓分詞模型很難處理。 目前產業中還未有公認的粒度標準，常見的評測語料集合有北大pku-test， 微軟亞洲研究院msr-test，人民日報標註語料等，切分標準也各有不同近年 (Mikolov et al., 2013)提出的BERT模型利用大量的文本進行詞嵌入的預訓練， 也緩解了此一問題。
