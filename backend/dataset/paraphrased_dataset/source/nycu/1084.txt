在時間t的照片中有n台車：為V(t) = {v𝑖𝑖(t)|1 ≤i ≤n}，同時從CAN Bus收 V(t) B(t) B(t) Camera V2V interface GPS Magnetometer YOLO Data Preprocessing Weight Calculation Mapping Decision I(t) x(t).loc x(t).ot W(t) S(t) 到m個廣播封包B(t) = ൛bj(t)ห1 ≤j ≤ mൟ。V(t)的資料可能包含有車牌、車色、 車款…等資訊。而B(t)的資料可能包含有車牌、車色、車款、GPS、車子方 向…等資訊。V(t)和B(t)經過資料前處理模組後，轉換成所需資訊，以供後續使 用，例如V(t)經過YOLO後得到bounding box，經資料前處理模組運算後得到距 離和角度。而透過B(t)的GPS資料與駕駛車的x(t). loc、x(t). ot，經過資料前處 理模組轉換後，取得距離及角度。得到這些資訊後，即可運用於後續模組。 我們使用YOLO做為相機拍攝照片的物體偵測方法，查找出照片中每一輛 車的bounding box。我們將根據bounding box計算駕駛車與鄰近車的距離及角 度，假設駕駛車位於照片底部的中央，角度為0°，由於照相機的視野有110°， 將拍攝的照片垂直等分為11等份，由左至右依序為 −50°, −40°, −30°, … ,0°, … ,30°, 40°, 50°，我們以bounding box的水平中心位置， 判斷它位於圖片的哪段水平區間處，決定其角度。計算駕駛車與鄰近車的距 離，我們首先計算在照片中車輛所佔據bounding box的pixel寬度，與車子實際寬 度做計算，取得車輛在平面x軸的大小𝑙𝑙𝑣𝑣，再計算𝑙𝑙𝑙𝑙/ tan 55°計算得到距離。 I(t)為時間t的照片。V(t) = {v1(𝑡𝑡), v2(𝑡𝑡), … }為在I(t)中被辨識出的車輛集 合。對每台車v𝑖𝑖(t)，它包含以下的訊息。 v𝑖𝑖(t). dist：駕駛車x與v𝑖𝑖(t)的距離。 v𝑖𝑖(t). angle：駕駛車x與v𝑖𝑖(t)的角度。 對於駕駛車x，可從GPS和磁力計分別得到時間t的車輛位置x(t). loc及方向 x(t). ot(假設感測器指向北方時，方向為0°)。x也會收到鄰近車子在時間t的廣播 資料。B(t) = {B1(𝑡𝑡), B2(𝑡𝑡), … }。對每一個B𝑗𝑗(𝑡𝑡)而言，它包含下列資訊：汽車車 款b𝑗𝑗(𝑡𝑡). 𝑡𝑡𝑡𝑡𝑡𝑡𝑡𝑡、汽車顏色b𝑗𝑗(𝑡𝑡). 𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐、汽車車牌b𝑗𝑗(𝑡𝑡). 𝑝𝑝𝑝𝑝、汽車位置b𝑗𝑗(𝑡𝑡). 𝑙𝑙𝑙𝑙𝑙𝑙及 汽車方向b𝑗𝑗(𝑡𝑡). 𝑜𝑜𝑜𝑜。我們從這些資訊中導出兩個變數：(1)距離：駕駛車x與b𝑗𝑗(t) 的距離、(2)角度：駕駛車x與b𝑗𝑗(t)的角度。 𝑏𝑏𝑗𝑗(𝑡𝑡). 𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑= ห𝑥𝑥(𝑡𝑡). 𝑙𝑙𝑙𝑙𝑙𝑙−𝑏𝑏𝑗𝑗(𝑡𝑡). 𝑙𝑙𝑙𝑙𝑙𝑙ห (3.2) 𝑏𝑏𝑗𝑗(𝑡𝑡). 𝑎𝑎𝑎𝑎𝑎𝑎𝑎𝑎𝑎𝑎= 𝑐𝑐𝑐𝑐𝑐𝑐−1 |𝑏𝑏𝑗𝑗(𝑡𝑡).𝑙𝑙𝑙𝑙𝑙𝑙.𝑦𝑦−𝑥𝑥(𝑡𝑡).𝑙𝑙𝑙𝑙𝑙𝑙.𝑦𝑦| 𝑏𝑏𝑗𝑗(𝑡𝑡).𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑 + 𝑥𝑥(𝑡𝑡). 𝑜𝑜𝑜𝑜 (3.3) 現在我們有從相片取得的距離和角度，以及從GPS和V2V的廣播封包取得 的距離和角度，接下來就可以計算權重了。
