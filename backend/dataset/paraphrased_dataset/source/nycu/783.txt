大多數的機器學習算法都會假設訓練的資料集是平衡分佈，能夠學習到所有樣本， 但是在真實世界的案例上，不會有完全平衡的資料集，通常都是多數類（Majority）與少 數類（Minority）組成，甚至會出現離群值的狀況發生，這被稱為資料類別不平衡的問 題，這個問題是一個阻礙，會造成機器學習演算法無法訓練出優秀分類器的。而本研究 所使用的資料集具有資料不平衡的情況，判斷二分類的存活率目標，都存在著不平衡的 狀況發生，如表3-2。 表3-2、1 至5 年存活率資料分佈 存活年 狀態 1 年 2 年 3 年 4 年 5 年 存活 27.24% 41.65% 52.74% 61.62% 69.14% 死亡 72.76% 58.35% 47.26% 38.38% 30.86% 總數 100% 100% 100% 100% 100% 在多類別的目標上也存在著不平衡的情況，例如存活月數大於60 個月的病患占全 部資料的30.86%，而存活在48 個月至60 個月的病患只占全人口的7.53%，在其他的 區間上也有些許的不平衡，如表3-3。 表3-3、多類別資料分布 存活月數 百分比 大於60 個月 30.86% 小於12 個月 27.24% 12~24 個月 14.42% 24~36 個月 11.09% 36~48 個月 8.88% 48~60 個月 7.53% 總數 100% 平衡資料的技術上，主要有兩種方法，超採樣（Over-Sampling）與欠採樣（Under- Sampling），過採樣主要將少數樣本進行複製，而欠採樣是將多數樣本進行刪減，透過這 種方式取得平衡，還有另一種是混合式的平衡技術，是結合上述兩種的平衡方法(Batista et al., 2004)。而本研究則使用SMOTE-ENN 混合式平衡技術，是結合超採樣的SMOTE （Synthetic Minority Over-sampling Technique）與欠採樣的ENN（Edited Nearest Neighbor） 方法來進行資料平衡。 SMOTE(Chawla et al., 2002)是一種超採樣的技術，傳統的隨機重新採樣方法會產 生過資料擬合的問題，這會使機器學習演算法所得到的資訊過於狹隘且不夠泛化，而 SMOTE 主要根據少樣類別的資料進行分析，使用差值的方式增加新樣本至原始資料 中。演算法步驟就是在原始的資料當中選擇一個少樣類的資料X，並去計算X 的k 個 鄰近，並從這k 個鄰近中選擇出一個樣本Xnn，再產生出0 到1 的隨機數，從而產生出 一個新樣本Xnew，並重複Xnew 的過程N 次（足以平衡資料的倍率）就可以產生出平衡 的樣本資料。 ENN(Wilson, 1972)是一種欠採樣的技術，也常被用來作為清理雜訊的方法之一，主 要透過刪減多數類別的樣本來達到資料平衡，其主要作法是選擇多數類別的資料Xm， 並與鄰近值進行比對，若Xm 的類別與大部分的鄰近值類別不同，則我們會將Xm 進行 剔除。若資料Xm 屬於多數類時，會根據鄰近值的類別進行比較，若不同，則進行剃除； 若資料Xn 屬於少數類時，若鄰近值將Xn 進行錯誤分類，則將剃除這些鄰近值。 但上述單一方法都存在著一些缺陷，如執行超採樣時，多數類會侵略到少數類的樣 本空間，相反的在進行欠採樣時也會過度著重在少樣樣本上，這些問題都會造成模型的 過度匹配，因此在Batista et al. (2004)就提出了結合SMOTE 與ENN 兩種方法，主要目 的是可以更好的定義類別，以下是單一方法與不同方法的資料分布狀態，可以比較結合 方法的不同，如圖3-3。 圖3-3、不同的平衡資料方法
