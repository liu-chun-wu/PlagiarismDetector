大數據及機器學習演算法中的偏見直到近年來才開始逐漸受到重視，因此 該領域的文獻尚不夠豐富、主題較為零星分散，相較其他領域，較缺乏嚴密的 歷史文獻架構。 儘管如此，本研究仍依照資料來源及應用範圍將機器學習演算法中的偏見 粗略分為「影音辨識方向」、「金融法律方向」及「自然語言方向」等不同方面 的偏見來加以討論。（參考圖7） 第12 頁 圖7  機器學習中立性方面之文獻架構 圖片來源: 本研究製作 圖片說明: 本研究將當前文獻主要依照應用領域做概略分類 「影音辨識方向」最常被探討的問題為：因不同種族和性別有不同的影音 資料量，導致某些族群的臉部辨識率[12]或聲音辨識率[8]較其他族群低。這可 能導致人工智慧產品在應用的時候，對某些族群的使用者較不方便。 「金融法律方向」最常被探討和關心的問題則為執法程序[7]和經濟政策的 公平性。藉由收集大量數據，演算法會更了解人類的生活，但是否會因為弱勢 族群的成長環境、身心健康和財務狀況通常較差，而讓AI 化的廣告投放、求職 [10][11]、投資、保險、借貸和法律工具對強勢族群較為有利，反而對弱勢族群 形成二次剝削。 而本研究的範疇屬於「自然語言方向」。非語言的數據若要化成人類可以理 解的具體概念，經常需要進一步的解釋。而自然語言經過字詞分解後，字詞本 身就攜帶相當具體的概念，也是日常生活中展示人類偏見最為直接常見的方 式。因此，透過對自然語言的拆解（例：字義、詞意和上下文的分析）或合成 （例：語句生成、句子填空），可以對人類文化的偏見進行更深入而確實的分 析，也可以與現有心理學、社會學、語言學的關聯文獻相互印證。 第13 頁
