本研究使用的序列到序列架構其中所訓練的東西不能使用純文字來訓練，所 以第一步要將需要用到的詞彙建立字典，而在研究初期使用Jieba 分詞(Junyi, Retrieved 2019)將訓練集的10,666 篇文本與摘要分詞後共有1,010,355 個詞彙做為 字典，到訓練模型後發現非常的耗時，且在最後訓練出來的模型摘要效果不好而 作罷。最後參考(Hu et al., 2015)中提到使用單字做為分詞單位，本研究使用訓練文 本與摘要中出現次數較多的6,588 個字再加上decode 使用的<start>、<end>、<nu>、 <mask>共6,592 個字做為最後使用的字典，此種方式訓練起來快速且最後的摘要 能力也較高，所以使用單字分詞做為接下來實驗的前處理。第二步字典中還需要 將每個詞都加入index ，並且使用詞向量將每個詞增加至n 個維度，本研究是使 用one-hot 編碼來做為向量起始值，範例如下: ‘我’ index=0 <-----> [1, 0, 0, 0, ..., 0] ‘你’ index=1 <-----> [0, 1, 0, 0, ..., 0] ‘他’ index=2 <-----> [0, 0, 1, 0, ..., 0] ‘好’ index=3 <-----> [0, 0, 0, 1, ..., 0]
