循環神經網路（Recurrent Neural Networks，RNN）是一種適合用來處理 序列資料的類神經網路結構，具有記憶機制，可以保存過去所擷取出的特徵。 近年來在許多自然語言處理的任務上均取得相當不錯的成果，也可被應用於筆 跡辨識[29]和語音識別[30]。 圖11  RNN 架構示意圖 圖片來源：本研究製作 圖片說明：最基本的RNN 架構 最基本的單向循環神經網路，在每一個時刻t 皆有兩個輸入與兩個輸出。兩 個輸入分別為當前時刻的外部資料輸入𝑥𝑡與前一個時刻的狀態𝑠𝑡−1，兩個輸出分 別為當前時刻的資料輸出𝑜𝑡與下一個時刻的狀態輸入𝑠𝑡。其中，而每個時刻的輸 入處理函數U、輸出處理函數V和狀態轉換函數W都是同一組可學習的參數。循環 神經網路的架構請參考圖11，數學式可簡單表述如（1）〜（3）式。 W𝑠𝑡−1 + 𝑈𝑥𝑡+ 𝑏= 𝑎𝑡                             (1) tanh （𝑎𝑡）= 𝑠𝑡                          (2) V𝑠𝑡+ 𝑐= 𝑜𝑡                          (3) 第21 頁 其中， b 和c 也是可學習的參數。U, V, W, b, c的整個參數架構一般是用類神 經網路所搭建。 最基本的循環神經網絡，由於其模型結構容易發生權重指數級爆炸 （Exploding）或梯度消失（Vanishing gradient）的問題[32]，因此有長期相依性 （Long-Term Dependencies）的困難，即難以捕捉時間序列的長期關聯。 在自然語言處理的應用上，循環神經網路可以藉由文字序列資料的訓練進行 權重學習，進而架構出一個模型，能夠找到在某種句子結構下出現機率最高的文 字/單詞。因此循環神經網路可以對句子中的文字結構進行建模，進而可以用來預 測某種語境下容易出現的文字/單詞，或反推出某個文字/單詞經常使用的語境。
