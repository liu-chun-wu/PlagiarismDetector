以不同的nn模型（分別為⼀層卷積、四層卷積、兩層卷積）做⾳節切割： ⼀層卷積仍不⾜以捕捉到全部⾳節，⽽4層⼜考量太多特徵⽽太過敏感形成誤判，2層較 佳。 24 lí    mài koh  siū khì a   hó-bòo(你不要在⽣生氣了了好嗎) Convolution Network 1 layer Convolution Network 2 layers Convolution Network 4 layers x座標為時間，每⼀個刻度為40ms. x座標為時間，每⼀個刻度為40ms. x座標為時間，每⼀個刻度為40ms. 另外錄⾳檔不完整的情況，模型也可以捕捉到⾳節。 下⽅圖為兩層卷積網路與傳統以RMS+ZR⽅法切割⾳節的⽐較圖。RMS+ZR需要調整參 數達到最佳⾳節切割，切割的結果⽐NN好。ＮＮ無法對⾳節準確作分割，但可以進⾏初 步分段。 25 RMS+ZR x座標為時間，每⼀個刻度為40ms. NN x座標為時間，每⼀個刻度為40ms. 以上述NN模型對複誦錄⾳作辨識，只取連續400ms以上皆判斷為⼈聲的段落作為新的⾳訊 樣本。 複誦11次我要（góa beh） 取連續400ms以上皆判斷為⼈聲的段落後共得到10個樣本。 複誦11次看相⽚（khuànn-siòng-phìnn） 取連續400ms以上皆判斷為⼈聲的段落後共得到10個樣本。且其中⼀個誤取得錄⾳者笑 聲。 ⼜可以看出此模型在⿐⾳部份的捕捉仍有不⾜。 26 x座標為時間，每⼀個刻度為40ms. x座標為時間，每⼀個刻度為40ms. 笑聲
