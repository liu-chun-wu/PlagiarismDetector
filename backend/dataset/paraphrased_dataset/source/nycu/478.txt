現今的行人偵測中已有很多不錯的實作，以下說明幾種常見的物件偵測。偵 測物件最簡單的方式是利用Sliding Windows，將每次框出的影像放入CNN 中來 判斷類別，但Sliding Windows 會使效率非常不佳。因此有人提出了R-CNN[1]， 利用Selective Search 預選出2000 多個Region Proposals，再利用訓練好的模型如 AlexNet 來擷取特徵，接著以SVM 來區分是否為物體，最後由線性回歸模型來 校正Bounding Box 的位置，但速度仍然不佳，因此又提出了Fast R-CNN[2]。其 採用的做法就是RoIPooling，一樣要先選Region Proposals，但是只做一次的CNN， CNN 擷取出來的特徵讓這2000 多個區域共用，因此可以節省時間。 因R-CNN 或Fast R-CNN 都預選Region Proposals 是很緩慢的，所以Faster R-CNN[3]直接從CNN 的Feature Map 選出Region Proposals 即為Region Proposals Network，經過RPN 會得到一些有可能的Bounding Box，透過類似Fast R-CNN 的RoIPooling 迅速對Bounding Box 分類，並得到最精確的Bounding Box 座標。 相較於R-CNN 都是先提Region 再作判斷，YOLO[4]在偵測與訓練時，一次 看的都是整張影像，其模型的特性是只對圖片作一次CNN 便能夠判斷圖中物體 類別及位置，其速度提升許多。 前面的方法都是找出物體的Bounding Box，而Mask R-CNN[5]不僅找出物 體的Bounding Box，也找出了其物體的遮罩。其建構在Faster R-CNN 的方法上， 透過RoIPooling 得到Region Proposals 後，針對每個Region 跑Fully Convolution Network 取得遮罩分割，並使用Bilinear Interpolation 來改善RoIPooling，即 RoIAlign，使得遮罩位置能夠更準確。
