本研究的實驗目的是訓練出可以對中文文本有最好摘要能力的抽象式自動摘 要模型組合，以下分為四個實驗分別在資料前處理、序列到序列模型訓練與選字 階段的搜索法找出最合適的摘要模型組合。 實驗一在循環神經網路的訓練中會將訓練資料重複的輸入進模型，而需要重 複幾次就稱為代(epoch)，而此參數會影響整個訓練的時間與是否可以訓練出可用 的模型，所以本次實驗先分別訓練epoch=100 與epoch=200，其於參數相同的模型， 並且每次訓練集遍歷過一次就使用損失函數(本次研究使用2.3.2 節的交叉熵)來計 算損失，並且觀察其下降幅度，來找出適合之後實驗的epoch 參數。 圖 28 實驗二與實驗三示意圖 實驗二如圖28，本次研究中是使用(Mikolov et al., 2013)詞向量的方式將字典 中的每個詞都使用N 個維度向量來取代，並且使用3.4 節的one-hot 編碼來做為向 量起始值，本次實驗分別使用128、300、500 來做每個詞的維度來進行訓練，其 於參數使用定值，透過3.5 節提到的ROUGE 算出的成績來評估模較適合的向量維 度。 實驗三如圖28，本次實驗使用2.5 節提到的雙向循環神經網絡與一般單向循 環神經網路的比較，並且隱藏層的層數分別使用128、300、512 與使用實驗一得 到的結果做為epoch 參數與實驗二的到的詞向量維度來訓練模型，並且透過3.5 節 提到的ROUGE 算出的成績來評估摘要模型找出最好的組合。 圖 29  實驗四示意圖 實驗四，在各個模型訓練完後的選字階段分別使用2.9 節的搜索法，貪婪搜索 法(集束寬度=1)與集束搜索法(集束寬度=2,3,4,5)，再透過ROUGE 算出的成績來評 估最好的摘要模型與選字搜索法組合。 第四章、 資料分析與結果
