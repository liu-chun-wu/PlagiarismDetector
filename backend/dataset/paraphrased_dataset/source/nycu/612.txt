特徵選取（Feature Selection）又稱做為子集選取（Subset Selection），通常使 用於機器學習領域，乃是結合學習演算法，依據特定的效能評估指標，從原有的特 徵集合中挑選出具有鑑別能力且有效的特徵，藉以決定最佳的特徵子集合，使其效 能指標達到最佳化的過程。簡單來說，特徵選取是希望盡量在無損於學習演算法效 能的情況下，過濾掉沒有效用、不具有關鍵影響力，以及有著重複或類似鑑別能力 的雜訊特徵，最後僅保留下真正對效能指標有影響的特徵，以達到降低特徵空間 （Feature Space）的目的。 在機器學習特徵挑選上主要有三種方法，分別是包裝法(Wrapper)、過濾器(Filter)、 入法(Embedded)。Wrapper 是一種以模型為基礎的特徵挑選方法，主要有輸入的資 料與特徵、機器學習之模型以及輸出評估分數，而評估分數可以是回歸的MSE 或 分類的準確率。 Wrapper 首先將選擇一個特徵與所有資料送入機器學習的模型當中，其輸出會 產生出一個評估分數，可以是回歸MSE 也可以是Preision，取決於原始資料的目標 值，接著會將下一個特徵與前一組已產生分數的特徵進行結合，再次計算出評估分 數，依值持續進行上述動作，直到所有的特徵都訓練到為止，最後再將這些這些分 數進行比較，找出最高評估分數的模型及最佳特徵組。
