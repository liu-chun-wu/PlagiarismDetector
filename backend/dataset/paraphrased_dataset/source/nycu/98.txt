綜觀文本探勘的歷程，不論是詞袋模型、空間向量模型，都是希望用一種代 數方式標記語言中的「特徵」，差別在於尋找那個對應代數的過程及代數本身是 否能帶有語言中最大的資訊量。 相較於拼音語系，中文最大的難處在於斷詞，拼音語系主要由固定字母組成， 故為了能夠不混淆，單字與單字間一定會用空格隔開，所以在於自然語言的處理 上，空格是區隔每個單字最基本的手段，相較之下，中文雖然有標點符號，但多 只能區別句與句，而更複雜的是字母本身就帶有含意，而且具有高度差異，中文 單字及單字組合往往會衍生出完全不同的意思，因此，如何斷詞便是中文自然語 言處理的首要課題。 從自然語言處理的歷程來看，詞袋、索引是簡單但有效的方法，故對中文斷 詞這個難題來說，人工索引法也不失一個好方法，換句話說，只要有足夠的中文 詞語料，理論上就可以解決大部分的中文斷詞。 斷詞模型的學習機制多種，一般來說會先執行詞性的判讀標記，對中文詞性 標記工作來說，最困難的仍然為沒有固定的區別單字的基準，訓練模型判斷該怎 麼區段句子中的不同詞性與職階斷詞難度相當，以最常見的中文斷詞函式庫jieba 為例，他提供了多種不同用途導向的的斷詞屬性，如精確模式及搜尋引擎模式， 所產出的結果就因模式導向段數及內容有所不同。 不論是何種語言，某種語言組合去記錄一個意義的邏輯不變，所以所有的模 型適用還是取決於斷詞的精準度跟詞性判斷。 值得一提的是縱使研究者都清楚可以透過遞歸神經網路（RNN）的技術方針去 改善斷詞，但在開源資源裡，不論是足夠的語料或是模型在華人—使用中文的人種 及地區都是相對較少，所以在相同技術下，中文語言處理的效果還是較為羸弱。 所以有另外一種作法，就是局部語料訓練，讓不論是詞袋模型、統計模型還 是空間向量模型去紀錄目前全局資訊，來達到語料不足的情況下能夠應用自然語 言方法解決文本問題。
