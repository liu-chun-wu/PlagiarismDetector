XGBoost（eXtreme Gradient Boosting）[5] [6]最開始是由Distributed Machine Learning Community（DMLC）的陳天奇所負責的一個研究項目。當在Higgs 機器學習比賽中獲 勝大放異彩，才開始廣為人知風行起來，由於受到許多機器學習比賽獲獎團隊的青睞， XGBoost 也逐漸成為機器學習領域裡實用性較強的演算選擇之一。 XGBoost 是一個開源程式碼的gradient boosting framework 的Library。它可用於C++、 Java、Python、R、Julia 等程式語言上；且適用於Windows、Linux 和MAC 等作業系統 上；此外它也支援分散式模式的架構，如Apache Hadoop、Apache Spark、Apache Flink 等。 三、假新聞預測方法與步驟
