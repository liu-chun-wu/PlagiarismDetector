為了使自駕車可以在比一般道路更複雜的環境中安全行駛，因而採用Argoverse 的運動預測(Motion Forecasting)的資料集，從邁阿密(Miami)和匹茲堡(Pittsburgh)中記 錄的交通影片採樣，擁有高度複雜性的道路環境且異質性的道路代理，由3D 追蹤模 型所標註之物體類別，如圖 14 所示(Chang et al., 2019)，包含汽車、行人、障礙物， 甚至有動物等15 種物件類型。 受限於硬體設備，本研究僅採用部分的原Motion Forecasting 資料集，訓練、驗證、 測試集數量分別為15、3、6 筆的CSV 檔，每個檔案中皆包含自駕車在不同場景行駛 五秒的資料。 圖 14 物體類別標籤 參考來源：Chang et al. (2019) 另一方面，場景則皆由自動駕駛測試車隊中篩選數個小時的駕駛數據，找到最具 挑戰性的交通狀況，包含在交叉路口出現車輛、向左或向右轉彎的車輛以及改變車道 的車輛，每個場景中皆包含每個被追蹤對象的2D 位置及鳥瞰視圖的幾何中心，並且 以10 Hz 為採樣頻率，時間共5 秒，用於訓練和驗證，數據格式包含時間戳 (TIMESTAMP)、道路代理ID(TRACK_ID)、道路代理類型(OBJECT_TYPE)、空間坐 標(X、Y)和城市名稱(CITY_NAME)，如圖 15 所示。 圖 15 資料集數據格式 圖 16 蒐集資料所用自駕車 參考來源：Chang et al. (2019) 此資料集由Argo AI 自動駕駛技術的福特融合混合動力車隊(Ford Fusion Hybrids) 蒐集數據，其自駕車所包含的硬體設備，如圖 16 所示(Chang, Lambert, Sangkloy et al., 2019)，包含2 個LiDAR 傳感器，7 個環形鏡頭和2 個兩個前視立體鏡頭，所有感測 器皆安裝在屋頂，其中，LiDAR 的感測範圍為200 公尺，環形鏡頭（1920 x 1200）以 30 Hz 的頻率記錄，且範圍具有360°的全景，前視立體鏡頭（2056 x 2464）以5 Hz 為 採樣頻率校準。
