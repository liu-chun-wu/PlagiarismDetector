機器學習模型之參數優化最常用的方法是Grid search，然而當資料量大時 往往需相當花費搜尋時間[54]，本研究使用Scikit learn 之GridSearchCV 模組 搭配RepeatedKFold 模組的交叉驗證（cross-validation），參數n_splits=10， 即10 折交叉驗證，n_repeat=1~2,即重覆1 至2 次。GridSearchCV 所搜尋之參 數範圍如表 4-10，其他未列入之參數使用預設值，最佳參數組合以MAE 值為評 估指標。 表4- 10  GridSearchCV 模組參數範圍 Grid search 產出各資料集的相對最佳化參數組合如表 4-11，從搜尋時間成 本欄中可看出搜尋最佳參數組合最耗時為Gradient Boosting Regressor，平均 約為63 小時，最快為Ridge Regression 平均約為7.22 秒。ANN 並無最佳參數 組合。 表 4- 11 各資料集最佳模型銷售金額與數量預測最佳參數 以Grid search 產出各資料集的相對最佳參數組合後，分別再進行建模與 預測績效評估結果如表4-12 所示，模型訓練最耗時為Gradient Boosting Regressor，最快為Ridge Regression。由於最佳參數組合是以MAE 為評估指標， 因此各模型MAE 值皆比預設參數好，多數模型的RMSE 值亦有改善，僅有少數模 型並未改善或改善程度有限或無太大差異。 表4- 12  最佳參數組合之各資料集最佳模型銷售金額與數量預測結果 各模型之最佳參數組合與預測參數的結果比較如表4-13，多數模型的預測 績效有改善，僅有少數模型的預測績效並未改善或改善程度有限或無太大差異， 例如在資料集（SD15,SD16）及（SD16,SD17）銷售金額與數量預測中的GBR 的 RMSE 值大於預設參數的值，資料集（SD15,SD16）銷售數量預測中的DTR 的RMSE 值也大於預設參數值，顯然GBR 與DTR 模型的穩定性不適合本研究個案。ANN 並 無最佳化之參數組合，以相同結果並列，ANN 的訓練次數（Epoch）及隱藏層的 多寡需要多次的實驗以求得更佳的績效。 表4- 13  最佳模型之參數最佳化與預設參數銷售金額與數量預測比較 特徵重要性如圖4-7 至圖4-13，由於Ridge regression 及ANN 並無特徵重 要性之屬性，因此以GBR,LightGBM,DTR 顯示預測金額與數量的特徵重要性。圖 4-7 顯示特徵依重要性為工廠1（plant_1)、工廠2（plant_2)…依序排列。 圖4- 7 （SD15,SD16）GBR 模型預測金額值特徵重要性 圖4- 8 （SD15,SD16）GBR 模型預測數量值特徵重要性 圖4- 9 （SD15,SD16）DTR 模型預測數量值特徵重要性 圖4- 10（SD16,SD17）GBR 模型預測金額值特徵重要性 圖4- 11（SD16,SD17）GBR 模型預測數量值特徵重要性 圖4- 12（SD17,SD18）LightGBM 模型預測金額值特徵重要性 圖4- 13（SD17,SD18）LightGBM 模型預測數量值特徵重要性 在應用方面，各模型皆可產出各明細產品預測的銷售金額或數量值的csv 檔如圖4-14、圖4-15，進而可以使用Scikit-learn 的Plot 多維度圖形化顯示 或將資料導入BI（Business Intelligence）系統中進行分析。 圖4- 14  各模型產出預測的銷售金額的csv 檔 圖4- 15  各模型產出預測的銷售數量的csv 檔
