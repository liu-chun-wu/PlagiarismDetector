使用激活函數的目的是讓神經網路模型的運算結果可以脫離線性運算 的框架，使神經網路模型能夠學習複雜的事物，複雜的表單數據，以及表示 輸入輸出之間非線性的複雜的任意函數映射。在類神經網路中如果不使用 激活函數，那麼在類神經網路中皆是以上層輸出的線性組合作為下一層的 輸入，輸出和輸入依然脫離不了線性關係，以二分類問題為例，使用簡單的 邏輯回歸，但不使用激活函數，只能作簡單的線性劃分。下列將介紹兩種激 活函數，分別為S 形函數和雙曲正切函數。 S 形函數(Sigmoid Function)取值範圍在(0,1)之間，單調連續，求導容易， 一般用於二分類神經網路的輸出層；缺點是很容易造成梯度消失，增大神經 網路訓練難度。此外，S 形函數輸出是非零對稱的，即輸出恆大於零，對於 神經網路訓練時會減小訓練速度，需要在神經元輸入時做預處理以避免此 問題。S 形函數在長短期記憶模型用於控制閘門的開關程度，幫助整個神經 網路更好運作。 雙曲正切函數(Hyperbolic Tangent Function, TANH)的取值範圍在(-1,1)之 間，雙曲正切函數比S 形函數收斂速度更快，且輸出均值為零，在神經網 路訓練時不會影響速度，是循環神經網路中最常用的激活函數。
