本研究的資料處理流程如下圖 3-2 所示接下來針對每個步驟進行說明。 圖3-2 資料處理流程圖 資料來源：本實驗整理 3.3.1. 資料展平與正規化 (Data flatten & normalization) 初始格式並無法直接餵入演算法分析，因此必須先進行資料前處理。資料 處理的第一步驟是資料格式轉換，目的在於將資料整併、統一分隔符號最後將評分資料 正規化以利分析。 圖3-3 資料前處理-格式轉換 資料來源：本實驗整理 3.3.2. 切割資料集 (Random  pick D date & real life split ) 本研究採用RLS〔12〕方法作資料集的切割與過濾，首先隨機挑選一個研究基準 日(D date 例如：2009/1/1)， D date 之前的資料為訓練資料集(training set)， D date 之後的資料為驗證資料集(testing set)，並參考過去研究〔40〕經驗採用70%：30%作 為訓練與驗證資料集比例：將評分資料依時間排序後只取用使用者在D date 前35 筆資 料作為訓練資料而另外D date 後15 筆則為驗證資料集，無法符合上述比例的使用者只 保留其資料在訓練資料集中實驗最後並不拿來驗證，最終資料集統計資訊如表 3-3。 表3-3 RLS 切割後資料及統計表 資料來源：本實驗整理 圖3-4 RLS 切割資料集示意圖 資料來源：本實驗整理 3.3.3. 資料彙整 (Data preprocessing for fp-growth / w2v(Word2vec)) 本研究嘗試套用使用者評分至關聯規則與Word2vec 演算法，因此必須將資料再 進行一次轉置。將評分資料依照日期與使用者ID匯總再將評分歌曲依照時間升冪排序， 以使用者(50)為例，日期(5891)先後完成(428105)、(462671)這兩首歌的評分、在日期 (5352)當天先後完成(491757)、(499437)、(488888)三首歌的評分，轉換後如圖 3-5 ， 如我們把歌曲ID 視為商品ID，資料可被模擬為購物網站行為中的購物車清單並套用在 關聯法則，如把歌曲清單視為一段連續字組則可被丟入Word2vec演算法中找出字(歌曲) 的關係。 圖3-5 資料轉換for fp-growth and Word2vec 資料來源：本實驗整理 3.3.4. 訓練模型 (Model Training) 本研究以協同過濾演算法(CF)找出表現最好的模型作為基準(Baseline)，依據CF User Based 對每位使用者Top5 推薦歌曲參考以fp-growth 與Word2vec 找出商品的關 聯性重新產生歌曲推薦清單觀察成效。以下針對CF/fp-growth/Word2vec 訓練模型的方 式做進一步說明： 3.3.4.1. 訓練協同過濾模型 本研究採用交錯最小平方法 (Alternating Least Square-ALS) 演算法解 決稀疏矩陣的問題，在Apache Spark MLlib 中的訓練ALS〔41〕模型時主要所需 參數主要有以下三個(Rank/Iterations/Lambda)，訓練時參數如表3-4： ● Rank：指的是ALS 模型中的套用在低階近似矩陣的隱藏特徵個數，一般來 說rank 數越高越好但也連帶會造成訓練時大量使用記憶體。 ● Iterations：指的是訓練時迭代執行次數，每次迭代後ALS 將能逐漸減少 重建矩陣時的誤差值。 ● Lambda：指的是模型正規化〔42〕也就是模型Overfitting〔43〕的程度。 lambda 值越高表示越符合正規化，相反的lambda 值低表示模型過於複雜 可能發生Overfitting。 表3-4 ALS 實驗參數表 資料來源：本實驗整理 在Apache Spark ALS API.〔44〕中訓練模型使用API: (ratings=訓練資料,p_rank=Rank, p_iter=Iterations, p_lamnda=Lambda) 取得model 物件後可使用API:model.predictAll 來預測使用者與歌曲的分數， 結果如下[使用者ID,歌曲ID,喜好分數] → [[49, 1280, 1.142],[49, 12344 ,1.234],....]，基於預測結果我們可以使用API: model.recommendProducts(userid, k)來取得特定使用者Top k 的推薦歌曲清單 結果(如下)並以此評估模型效果(章節3.4)。 model.recommendProducts(229388, 1)→ [254847] model.recommendProducts(229388, 5)→ [254847, 410063, 623293, 547789, 328862] model.recommendProducts(229388, 10)→[254847, 410063, 623293, 547789, 328862, 348536, 88353, 283375, 59884, 190141] 3.3.4.2. 訓練fp-growth 模型 本研究混合模型第一部分採用fp-growth 演算法找出歌曲關聯度。將資 料轉換後，圖 3-5 ，每筆資料可視為一筆交易，將資料集套入Spark MLlib 實 作fp-growth 演算法的API：pyspark.mllib.fpm，透過調整最小支持度(min Support)保留只包含兩首歌曲的規則後計算關聯商品的信賴度(Confidence)作 為商品關聯性的指摽。下圖 3-6 為歌曲[617646]的關聯商品清單(左圖為兩首歌 同時發生的頻次，右圖為其計算後的信賴度)此信賴度將是後續混合模型時需要 的重要依據。 圖3-6 fp-growth 歌曲關聯度 資料來源：本實驗整理 3.3.4.3. 訓練Word2vec 模型 本研究混合模型第二部分採用本研究採用Word2vec 演算法找出歌曲關 聯度。將資料轉換後，每筆資料內含有序的歌曲清單可模擬為文字組合，圖 3-7， 將資料集套入Word2vec Library〔45〕：gensim.models.word2vec，採用Skip-gram， 圖 2-5，找出每首歌曲出現其前後會出現歌曲的機率並透過參數，表3-5，中 window 數值調整[5、10、15、20、25、30]找出多個推薦組合做為後續混合模型 的依據。 圖3-7 歌曲ID 模擬文字組合 資料來源：本實驗整理 表3-5 Word2vec 實驗參數表 資料來源：本實驗整理 取得model 物件後可使用API:model1.most_similar 來找出跟特定歌曲的鄰近歌 曲清單與其相似度，而相似度將是後續混合模型時需要的重要依據。以下為歌曲(299143) 的結果[(歌曲ID,相似度)]， 圖3-8 Word2vec 歌曲關聯度 資料來源：本實驗整理 3.3.5. 混合協同過濾(CF)與fp-growth 與Word2vec 本研究混合模型將協同過濾計算喜好分數與兩種歌曲相似度驗算法的結 果相乘得到新的分數再加以重新排序選擇新的Top k 歌曲清單最為混合模型的成 果，以fp-growth 為例如下圖 3-9。 圖3-9 混合模型計算過程(fp-growth) 資料來源：本實驗整理
