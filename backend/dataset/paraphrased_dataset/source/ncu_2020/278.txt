Kang [14]、Gibert[15]提出了基於顏色、運鏡手法等低層視覺與音訊特徵的 隱馬爾可夫模型來分辨影片情緒，但是這些低階影片特徵沒有辦法去表示語義 概念。Xu[16] 提出一種利用文本與圖片輔助影片的情感識別，透過CNN 提取 影片中人臉表情，準確率達52%。Fan[17]在EmotiW2016 的比賽中，利用深度 學習的方法對視頻中的人物表情動作和語音語調進行綜合識別分析，以59.02% 的正確率較EmotiW2015 53.8%的正確率高出許多。 可以看出透過深度學習分析這些高階影片特徵提升了正確率與語意概念， 但目前影片情緒分類大部分都聚焦在人物的表情與動作，轉移學習到其他資料 集需有相似的特徵且正確率也遠低於圖片與文字情緒分類。 第三章 研究方法
