Yanulevskaya[11]在2008 年時即嘗試用SVM 分析IAPS 資料集中的藝術作 品做情緒分析，其平均準確率將近六成。Cetintas[12]提出一種DCNN 的方式， 分析Twitter 和Tumblr 資料集的圖片中的物體偵測，將偵測到的物體與文字特 徵分類情緒，平均準確率達到六成五，比傳統機器學習的方法還高。You[13]在 CNN 的基礎上，提出了一套PCNN 的深度模型，以去除表現不佳的圖像並使用 剩餘圖像訓練CNN，對Flickr 資料集做情感正負面分類，後將Flickr 上訓練得 到的PCNN 模型做轉移學習到Twitter 資料集上，其平均準確率將近八成。 可以看出CNN 對於圖片情感分析在正確率與泛化能力有極大的潛力，但是 目前準確率不僅遠低於文字情緒分類，且YouTube 影片的截圖情緒很可能是與 主題相關但情緒不同，因此本研究不採用圖片情緒分類。
