以三組年度銷售訂單資料集進行（訓練資料，測試資料）: （SD15,SD16）、 （SD16,SD17）、（SD17,SD18），分別預測銷售金額及銷售數量，銷售金額之預測 結果分別為表 4-2 至表4-4，表格欄位由右至左分別為訓練模型、訓練資料集 RMSE 值、訓練資料集MAE 值、測試資料集RMSE 值、測試資料集MAE 值、訓練時 間成本(單位:秒)。各模型皆以模型的預設參數進行實驗。目前研究的個案的銷 售預測仍以人工作業為主，本研究的Base line 將以各資料集的銷售金額與數量 的平均值為預測之評估基準如表4-1 所示。研究結果顯示除Linear regression 外，其他各模型的預測績效結果皆比Base line 優良。 表4- 1  Base line 評估值 表4- 2  訓練資料 SD15，測試SD16 銷售金額預測結果 表4- 3  訓練資料 SD16，測試SD17 銷售金額預測結果 表4- 4  訓練資料 SD17，測試SD18 銷售金額預測結果 銷售數量之預測結果分別為表 4-5 至表4-7，其中資料集（SD16,SD17）中 的SVR 比Base line 預測績效稍差外，其他模型的預測績效亦比Base line 優良。 表4- 5  訓練資料SD15，測試SD16 銷售數量預測結果 表4- 6   訓練資料 SD16，測試SD17 銷售數量預測結果 表4- 7  訓練資料 SD17，測試SD18 銷售數量預測結果 以各模型以預設參數所測試各資料集銷售金額與數量預測結果模型績效排 行如表4-8 所示，以Ridge regression ,ANN,GBR,LightGBM 為主。 表4- 8  預設參數之各資料集銷售金額與數量預測結果模型績效排行 類神經網路之預測績效 ANN 模型結構如表4-9 所示，在Keras 中每一層稱為 Dense.在建模程式中 的Input layer 及hidden layer 的Activation Function 皆使用ReLU，即排除 負值之意，ReLU 的使用度最高，ReLU 經研究學者多次的實驗後發現是最好的 Activation function[53]。每一層的節點如下表4-9 所示，模型的績效優劣決 定於使用的損失函數（Loss Function）、Activation Function、 優化器 （Optimizer）、成效衡量指標（Metrics）、隱藏層數（Layers 或Dense）、Kernel initializer 以及它們的參數組合，這些需透過反覆地實驗才能得到預測績效表 現更好的模型參數組合。然而超過兩層的 Hidden Layer 即為深度學習（Deep Learning），本研究有兩層的Hidden Layer，因此亦可謂之。 在本實驗的結果顯示ANN 的預測績效在本個案中並未特別出色，除在資料集 （SD15,SD16）和（SD17,SD18）之銷售金額預測中屬領先群外，其餘並非相對最 佳模型，預測績效與其他領先群模型相較也並非差異很大，然而ANN 需要反覆多 次的實驗以求最佳的預測績效，本實驗僅依表4-9 ANN 結構，訓練週期(Epochs) 皆固定為650 來進行評估。 表4- 9  ANN 結構
