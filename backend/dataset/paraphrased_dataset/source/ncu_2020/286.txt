我們透過爬蟲程式從 YouTube 網站上隨機抓取1500 部影片，從中抓取情 緒分類需要的四個區塊的 YouTube 文字特徵，之後經由專家篩選掉某些不帶 有情緒的影片共剩下 1217 部影片，再請專家標記這些影片正確的情緒，共有 六類情緒: 生氣(anger)、厭惡(disgust)、開心(happiness)、恐懼(fear)、傷心 (sadness)、驚訝(surprise)，每個情緒約為 200 部影片，影片裡面包含影片標 題、標籤、描述、評論四個區塊作為我們實驗的文字特徵。 表 1、影片種類數量 anger disgust happiness fear sadness surprise 數量 表 2、資料表欄位說明 編號 欄位名稱 欄位意義 資料型態 category 情緒類別 String title 影片標題 String keyword 標籤 String description 描述 String comment 評論 String 驗證方法我們選擇使用k-fold cross-validation，將資料隨機平均分成k 等 份，每次選擇其中k-1 份樣本當訓練資料，剩餘1 個樣本當成驗證資料，透過k 次的交叉驗證完成情緒分類的驗證，而k 值我們採用常見的10，我們將text- CN 與Bi-LSTM 和傳統機器學習方法做比較，而實驗結果較好的Ensemble Model 除了透過準確率比較之外，也會做F-Measure 的比較。 在傳統機器學習方法中我們使用之前研究[20]的Naive Bayes、J48 Decision tree 分類方法和SVM 分類器搭配TFIDF 的結果當作我們的baseline 方法做比 較，TFIDF 將四個區塊的文字特徵看成同一個文件，利用傳統的 IR 方法去建 構向量，因此一樣的字詞在不同的區塊被認為是在向量中的同一個元件。 在深度學習的方法中，由於影片標題、標籤、描述屬於較短的文本，我們 將其長度限制在20 個字，而較長的評論文本則是將長度限制在500 個字。 表 3、本文所有實驗方法 實驗方法 說明 M1: Naive Bayes 機器學習法搭配 TFIDF 由TFIDF 建構出YouTube 影片的文字 特徵向量，之後使用Naive Bayes 演 算法分類影片。 M2: J48 Decision tree 機器學習法搭 配TFIDF 由TFIDF 建構出YouTube 影片的文字 特徵向量，之後使用J48 Decision tree 演算法分類影片。 M3: SVM 機器學習法搭配TFIDF 由TFIDF 建構出YouTube 影片的文字 特徵向量，之後使用SVM 演算法分 類影片。 M4:將四個特徵看成一個文件交由 text-CNN 學習 由Word2Vec 建構出一層embedding 層的詞向量，之後使用text-CNN 演算 法分類影片。 M5:將四個特徵看成一個文件交由Bi- LSTM 學習 由Word2Vec 建構出一層embedding 層的詞向量，之後使用Bi-LSTM 演算 法分類影片。 M6:將四個特徵分別交由四個text- CNN 學習 由Word2Vec 建構出四層embedding 層的詞向量，之後使用四個text-CNN 演算法找出特徵，最後透過SoftMax 的結果分類影片。 M7:將四個特徵分別交由四個Bi- LSTM 學習 由Word2Vec 建構出四層embedding 層的詞向量，之後使用四個Bi-LSTM 演算法找出特徵，最後透過SoftMax 的結果分類影片。 M8:將除了評論以外的三個特徵分別 交由三個text-CNN 學習，較長的評 論特徵則是經過text-CNN 學習到的 高級特徵，在交給Bi-LSTM 學習， 最後將四個特徵結果整合 由Word2Vec 建構出四層embedding 層的詞向量，之後使用三個text-CNN 加上一個text-CNN 與Bi-LSTM 的 Ensemble model，最後透過SoftMax 的結果分類影片。 M9:將除了評論以外的三個特徵分別 交由三個Bi-LSTM 學習，較長的評 論特徵則是經過text-CNN 學習到的 高級特徵，在交給Bi-LSTM 學習， 最後將四個特徵結果整合 由Word2Vec 建構出四層embedding 層的詞向量，之後使用三個Bi-LSTM 加上一個text-CNN 與Bi-LSTM 的 Ensemble model，最後透過SoftMax 的結果分類影片。
