實驗環境為使用單個NVIDIA GeForce GTX 1050 Ti 規格的GPU 在Pytorch 1.2.0 中實現，模型架構如表 4 所示，使用隱藏狀態維度64 和128 分別作為單層LSTM 的 編碼器和解碼器，每個ConvNet 均使用2 個卷積層運算實現，每次運算之後皆會利用 指數化線性單元(Exponential Linear Unit, ELU)作非線性處理，接著是1個最大池化層， 其餘實模型參數之設定如表 5 所示。 表 4 模型架構 網路架構 配置 嵌入式輸入 (Embedding input) Linear(in_features=2,out_features=32, bias=True) ELU ELU(alpha=1.0) LSTM 編碼器 LSTM (32, 64) 卷積層 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1)) Conv2d(64, 16, kernel_size=(3, 1), stride=(1, 1)) 最大池化層 MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=(1, 0), dilation=1, ceil_mode=False) LSTM 解碼器 LSTM(352, 128, dropout=0.5) 表 5 模型參數設定 參數 配置 預訓練期 訓練期 批量大小 丟碼率 0.5 學習率 0.01 優化器 Adam 損失函數 RMSE
