近年來，卷積神經網絡開始應用於自然語言處理的領域之中，在句子分類 任務上取得了不錯的成績[25]，在短文本的分類任務中更是出色，與應用在計 算機視覺的任務相同，其目標即是捕捉句子的局部特徵，由使用者自行定義多 少個單詞組成滑動窗口，通常會將長度設置為三至五個單詞，類似於N-gram。 卷積神經網絡的優勢在於能夠自動地對N-gram 特徵進行組合和篩選，獲得不同 抽象層次的語義信息。 第一層為輸入層（Embedding Layer）: 輸入層可以直接在訓練text-CNN 的 過程中訓練出一套詞向量，也能透過預訓練模型通常為Word2Vec 或Glove 來 訓練詞向量，最終得到一個n×k 的矩陣，其中 k 是每個詞對應的詞向量的維 度，通常會將k 設置為200~300 之間，維度太低或太高都會致使無法正確表達 字詞間的關係，本研究採用k 為250。 第二層為卷積層（Convolution Layer）: 在計算機視覺領域中，CNN 使用 的捲積核的寬度和高度的一樣的，但是在處理文本資料時，卷積核的寬度與詞 向量的維度一致，詞為文本的最小粒度，每一行向量代表一個詞，因此在抽取 特徵的過程時其滑動窗口即是往高度方向移動。而每次滑動的長度高度則代表 一次讓神經網路看多少個單詞並取出它們的情緒特徵，若長度設為3 則代表神 經網路一次看三個詞，若長度設為4 則代表一次看四個詞，由於我們的文本屬 於短文文本，因此本研究採用長度設為3。 第三層為池化層（Pooling Layer）: 利用透過卷積層得到的特徵向量提取出 最能代表該區域的值，有最小、平均、最大三種池化層方法，又以最大池化層 （Max Pooling）的特徵提取效果最佳。在計算機視覺領域中，最大池化層即是 找出圖像上的各個局部區域的特徵，可能是線條或形狀、顏色等特徵，而在處 理文本資料時就像在文章中標記出重點，找出各個局部區域最具影響力的詞， 且最大池化層有利於減少模型過擬合問題。 在建構詞向量時可以有以下不同的方式: 1. CNN-rand: 隨機初始化每個單詞的詞向量通過後續的訓練去調整。 2. CNN-static: 使用預先訓練好的詞向量，如word2vec 訓練出來的詞向 量，在訓練過程中不再調整該詞向量。 3. CNN-non-static: 使用預先訓練好的詞向量，並在訓練過程進一步進行 調整。 4. CNN-multichannel: 將static 與non-static 作為兩通道的詞向量。 由於CNN-rand 是單純透過自己的資料集訓練出詞向量關係，我們傾向使 用大規模文本訓練的Word2Vec，且採用CNN-non-static 的方式調整詞向量，使 得詞向量更適合我們的實驗。 為了比較如何分析影片標題、標籤、描述、評論四種特徵可以有更好的情 緒分類效果，我們利用兩種text-CNN 模型將四種特徵分類，圖 五為將四種特 徵合併成一個欄位且限制每筆欄位長度為500，經過Word2Vec 的Embedding 後，採用長度為3 的卷積層取得特徵，再經由長度為5 的最大池化層找出最能 代表每個區塊的情緒特徵，再經由一次長度為3 的卷積層取得特徵，最後經由 GlobalMaxPooling1D 找出所有區塊的最大值，透過平均32 個神經元的輸出再 加上0.2 的Dropout 避免過度擬合後當作分類的結果。 圖 五、Text-CNN(M4)模型結構圖
