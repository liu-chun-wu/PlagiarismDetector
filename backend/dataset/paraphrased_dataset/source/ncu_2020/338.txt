在輸入端，YOLOv3 只使用 RGB 的色彩資訊作為輸入的資料，因為 YOLOv3 只進行平面的物件偵測；但為了偵測物件的三維空間資訊，深度 資料是不可或缺的，因此作者在輸入端增加一個單通道 (channel) 的深度 資料，變為使用 RGB-D 四通道資料作為輸入端資料，使網路可以獲得色 彩與深度資訊，並以 Darknet-53 提取特徵。 - 24 - 在偵測物件位置及類別的方面，以cx, cy 表示影像左上角至網格的水 平及垂直距離，σ為 sigmoid 函數，tx, ty 為預測物件的中心點座標，tz 為 預測之深度，pw, ph, pl 為在每個網格中設有的錨框之長寬高。在 YOLOv3 的錨框尺寸會根據特徵圖大小而調整，不同於 YOLOv3 的圖像座標之錨 框設計，採用的錨框尺寸是物件在相機座標下的長寬高，因此不會根據特 徵圖的大小而調整；tw, th, tl 為預測框之長寬高大小比例， qt , 1qt , qt , qt 為以四元數 (quaternion) 表示的預測框之旋轉姿態，預測值對應於邊界 框值bx, by, bz, bw, bh, bl, qb , 1qb , qb , 3qb ，如圖 3.2 所示。 圖 3.2. 9DoF SE-YOLO 的預測邊界框與錨框之關係。 9DoF SE-YOLO 的輸出張量 (tensor) 格式為預測之物件在三維空間 下的 9DoF 資訊，包括用來表示預測框中心點的平移分量x, y, z，預測框 - 25 - 姿態的四元數旋轉分量q0, q1, q2, q3，此外預測框的w, h, l 為物體在真實 世界下的長寬高，如圖 3.3 所示。 圖 3.3. 輸出的特徵圖張量格式。 其中預測值x, y 為圖像座標，為了求出物件在真實世界的相機座標 Tx, Ty, Tz，透過預測值Tz 與相機的內參矩陣，由公式 (3.1) 可求出物件邊 界框之平移分量Tx 和Ty，並以預測值w, h, l 建立出物件邊界框的八個角 點，最後以q0, q1, q2, q3 求出物件邊界框的旋轉姿態，         x x z y y z T x f p T T y f p T ，                     (3.1) - 26 - 其中f 為相機焦距，(px, py)為影像平面中心點。
