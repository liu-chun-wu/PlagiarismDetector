在資料科學領域當中，利用資料探勘或機器學習時常遇到欲分析研究的數 據有著類別不平衡的情況產生，尤其是在以下情況中最常發生，例如：金融詐 欺交易犯罪研究、生物醫學裡的基因研究領域亦或是癌症醫療研究領域中。其 原因仍是樣本資料數據分布不均勻，像是典型的乳腺影像數據集中可能包含正 常的影像占98%，而有異常的影像只占2%，使用機器學習訓練該資料集而建立 的預測模型可能會有偏差且不準確的情況發生[5]。 為了解決類別不平衡(Class Imbalance)所產生的問題，最簡單的方法是直接 隨機刪除多數類別的樣本，但此法有可能刪除掉有用的資料使得訓練所得到的 模型不準確;另一種方法是直接隨機複製部分少數樣本或是利用蒙地卡羅隨機 數生成方法，但其缺點是容易造成過度擬合使模型失效。目前最被廣泛採用的 方法是由Nitesh Chawla 等人於2002 年提出SMOTE(Synthetic Minority Over-sampling Technique)技術，透過創建新的合成點(synthetic points)以使類別 (class)之間具有相等的平衡。為“類別不平衡”提供另一種解決方式。其主要概 念是在少數樣本與附近的臨近的點，人工合成一些樣本，其合成方法： (1) 設定採樣倍率N：針對每個樣本需要生成多少個合成樣本。 (2) 設定近鄰值K：針對少數樣本χ1 找出K 個最近鄰樣本，並隨機   選一個 為χ2，利用該點來生成新樣本。 (3) χ2 - χ1 的差異為δ (4) 於0~1 之間產生一個隨機亂數η (5) 新樣本χnew = χ1 + ηδ 圖2：利用SMOTE 方法創建新樣本 資料來源：Upasana [9] 雖然SMOTE 方法相較於隨機欠採樣或隨機過採方法來的更為準確，但仍有 其缺點在，就如所產生的新樣本中靠近邊界的少數樣本中並未考慮到與多數樣 本重疊混合的問題，因而產生噪音資料而混淆其鑑別能力。 相關文獻回顧與比較 對於機器學習領域之演算法一直以來有許多數學家及相關學者紛紛投入研 究提出相關之技術，例如：如何處理資料以優化機器學習結果的技術，像是特 徵選取、類別不平衡等理論被提出又或是針對不同學習模式區分為非監督式學 習、半監督式學習及監督式學習，各有專家學者提出理論來分析學習的成效， 例如本研究就是利用監督式學習法，而此學習模式再細分其技術有支援向量機、 決策樹等，本研究即使用到支援向量機及隨機森林，從文獻中可得到支援向量 機與隨機森林針對預測分類有著最佳的效果。而以上所提到的皆可從專家學者 研究中之文獻擷取出來並運用在不同領域場景來補助專業從業人員給予決策之 判斷，例如：智慧醫療、金融科技等。 大數據及人工智慧時代的來臨，利用機器學習建立模型來預測未知的事物 得到一個最佳的分析結果並使用其結果來做進一步的運用，來補助人類優化人 類之生活。針對上述所提之智慧醫療，在現代醫學領域研究中所著重的一個重 點即是惡性腫瘤之相關研究，本研究即針對乳癌之議題做深入探討，並於文獻 整理中可得知利用特徵選取[9]與類別不平衡[5]之樣本對於預測過程中的影響 原因並得知隨機森林[8]與支援向量機[9]作為預測分析有較佳結果，再做進一步 探討在文獻中未針對乳癌大、小樣本資料集做訓練模型前之預處理並比較其各 別模型之效果，而本研究即對於此議題做進一步之探究。 表1: 乳癌預測及相關技術文獻整理乳癌預測及相關技術文獻整理 作者 研究題目 年份 摘要 M. Dash, H. Liu Feature Selection for Classification 特徵選取一直以來是關注的焦點，對於各種案例之資料集，從 中選擇代表性之特徵，透過不同方式選取出特徵並進行評比出 優缺點，並能根據案例及特徵加以說明解釋，並給予未來研究 領域一個方向。 Lee, Y. J., Mangasarian, O.L.and Wolberg, W. H. Breast cancer survival and chemotherapy: A support vector machine analysis 利用SVM 技術分析惡性腫瘤與良性腫瘤的分類上判斷乳癌之存 活率。 Breiman, L. Random Forests 介紹隨機森林的演算方法與優點，其演算法有較佳的穩定性， 尤其對於雜訊資訊的影響。對於樣本與變數採用隨機抽樣方 式，因隨機性足夠至考慮到各種組合的集合會更接近真實狀 況，預測錯誤率則大幅下降。 Nitesh V. Chawla, Kevin W. Bowyer, Lawrence O. Hall, W. Philip Kegelmeyer SMOTE: Synthetic Minority Over-sampling Technique 現實中有許多實例呈現類別不平衡狀態，通常正常情況佔大多 數，只有少數情況產生。而少數情況卻反而是需要關注的，在 文研究中顯示對少數樣本做過採樣比對多數類別進行欠採樣能 得到更好的效果(在ROC 空間中)。 秦聖昌 支援向量機於乳癌預測之研究 針對醫療資料中的乳癌資料集進行實驗，透過兩種大、小差異 的資料集進行特徵選取後與原始資料做比較，使用單一分類器 及多重分類器搭配不同核心參數進行實驗。實驗所得之數據評 估哪一種分類器及參數的配搭使用，能夠取得較好的效能時間 及正確率。單一分類器使用SVM 搭配RBF 核心參數、多重分類 器Bagging 和Boosting 比較則是Boosting 的正確性及效能較好。 Min-Wei Huang, Chih-Wen Chen, Wei-Chao Lin, Shih-Wen Ke, Chih-Fong Tsai SVM and SVM Ensembles in Breast Cancer Prediction 許多相關研究指出SVM 技術預測乳癌預測模型有較佳效果。而 SVM 之內核函數不同可能會導致不同的預測性能，本研究之目 的在研究不同之內核函數對於乳癌大小資料集之預測性能做評 比，以選出較佳的方法。 Dona Sara Jacob, Rakhi Viswan, V Manju, L PadmaSuresh, Shine Raj A Survey on Breast Cancer Prediction Using Data Mining Techniques 乳癌是一種常見於女性的癌症，早期治癒是一個非常關鍵的工 作，若能提早發現及可提早治療，提高治癒率。而現今可可利 用許多科學方法及資料探勘技術，運用在乳癌預測上。本研究 顯示分類演算法預測指標優於聚類演算法。 Nitasha Review on Breast Cancer Prediction Using Data Mining Algorithms 乳癌不僅是女性面臨最致命問題，早期預測和識別腫瘤及早治 癒癌症是最重要的需求。使用資料探勘與機器學習於乳癌預測 研究下，發現分類演算法，如：決策樹、隨機森林、支援向量 機優於聚類演算法，有較佳預測效果。 Md. Milon Islam, Md. Rezwanul Haque, Hasib Iqbal, Md. Munirul Hasan, Mahmudul Hasan, Muhammad Nomani Kabir Breast Cancer Prediction: A Comparative Study Using Machine Learning Techniques 乳癌導致的死亡風險指數增長，利用自動檢測系統可幫助醫療 人員進行診斷。本研究比較五種監督式機器學習技術，利用 SVM、K-nearest neighbors, random forests, artificial neural networks (ANNs)、logistic regression，從UCI 取得威斯康星州乳 癌數據集做實驗，根據準確度、敏感性、特異性、精密度、混 亂矩陣預測值等方式進行評估。類神經網絡與SVM 有不錯效果。 資料來源：本研究整理 總結 從各國文獻中皆能意識到各國對於醫療領域中癌症相關之研究一直是被重 視的議題，各國研究人員無不致力於使用資料探勘及機器學習等方法用於探討 癌症預測，從文獻中可得知用於預測類型問題多是使用監督式學習法做二元分 類，從眾多分類技術中又能得知支援向量機、隨機森林有其較佳之效果。 在許多文獻中亦指出建構預測模型好壞的影響因子，除了所蒐集獲取的資 料量之大小對訓練模型之影響外，對於所蒐集的資料集仍需再進一步做事前處 理以便讓預測分類的模型能有較佳準確度。對於醫療從業人員來說，能正確分 類預測病人是否有罹癌對於醫療人員後續在做治療決策或採用對病患最佳的診 斷是重要的。 而資料預處理的方式有許多種，從文獻中可得知所蒐集到的資料集可能會 有多種情形，如：屬高維度或低維度、樣本類別不平衡等狀況，而從過往文獻 中未能從這些可能導致預測模型不準確之因子中多加深入探討，大多只考慮一 個影響因子，做單一因子之研究，例如：只關注特徵選取或只關注類別不平衡， 而未能多方考量多種影響因子對於建構模型之影響，亦可能導致預測模型預測 失準之情形，故本研究欲從此議題進一步做深入探討，以便得知在考量資料量 之多寡及資料多種變異情形，對於資料預先處理方法採用特徵選取並搭配類別 不平衡之方式做交叉實驗及兩種預處理方法之處理順序先後是否影響模型之效 能，研究中另設置三組基準對照組與上述兩組實驗依先後順序共組成四組實驗 組相互做評比，以得到最有效之訓練模式。除此之外，對於分類器的選擇上採 用文獻中所提及支援向量機與隨機森林皆有較佳預測效果，故綜合以上兩種分 類器加以評比，針對資料量不同、維度不同與分布不同之影響，用以比較選擇 出最佳分類器，用以提高整體預測模型之準確定。值得一提的是AUC (Area Under Curve)為判斷鑑別力的關鍵，當AUC=0.5 時，是無鑑別能力的(no discrimination) 且此時的ROC 為一對角線，故AUC 數;應要超過0.5 以上才具鑑別能力。 第3章 研究方法 本研究之研究方法於此章節加以說明詳述，本章節主要包含四大部分：實 驗資料收集、資料前處理、實驗設計及預測模型評估。實驗資料集的取得方式、 資料量及資料特徵做一統整。另透過實驗步驟拆解每一階段實驗流程，對於收 集來的資料做事前的資料清理動作，將梳理完成的資料做進一步的規劃分為兩 大類資料集，分別為訓練資料集及測試資料集並著手進行實驗，本實驗針對訓 練資料切分為五摺資料集進行反覆訓練與測試驗證，於實驗設計中規劃五種機 器學習方式，每種方式依資料預處理手法及順序，交叉搭配比較使用手法與順 序之不同對於預測模型之準確度是否會有影響; 另外對照三種基準模型之比較， 此三種模型分別為資料不處理直接做SVM 與Random Forest 模型建構、只做特 徵選取後即做SVM 與Random Forest 模型建構與只做類別不平衡處理即做SVM 與Random Forest 模型建構，最後將這五大類型做一綜合比較，每摺訓練完成 之模型即使用測試資料進行驗證，選出最優之預測模型。 本研究使用資料探勘技術並採用WEKA 應用軟體做為訓練模型之工具， WEKA 全名為Waikato Environment for Knowledge Analysis 之縮寫，為紐西蘭 Waikato 大學電腦科學系於1993 年開發初版至今，本研究使用3.9.5 版。此套 軟體使用JAVA 程式語言所開發出一套資料探勘之應用軟體，可提供跨平台運行 包含Windows、Mac OS、Linux 等，該軟體包含完整的資料探勘處理流程，包含 資料預處理、機器學習演算法、成效評估方法、資訊視覺化等功能並兼具圖形 化使用者介面與指令列應用工具，更加容易比較不同演算法的分析結果。另外 WEKA 提供模組化設計，能夠擴充不同的演算法。本研究使用WEKA 資料探勘 工具中常用的監督式學習技術，如：支援向量機與隨機森林建構預測模型。 圖3：研究架構圖 資料來源：本研究整理 實驗資料集 本研究從具有知識發現與資料探勘專委會KDD官方網站與機器學習資料庫 UCI 官方網站上取得，其官方網站上之資料庫皆同被許多研究學者廣泛運用在 機器學習領域上，本研究採用上述兩者官網上同為乳癌醫療之資料集，取得資 料集分為KDD 大型資料集，屬於樣本分布不均勻且多特徵值、另一個為UCI 小 型資料集，屬於樣本分布不均勻且屬較少特徵值。 表2：資料集 資料集名稱 來源 年份 資料庫筆數 特徵屬性 有無癌症比例 Breast Cancer SIGKDD 1: 0.006 Breast Cancer UCI 1: 0.349 資料來源：本研究整理 資料前處理 資料探勘的過程中，在進行資料訓練前期為提高建立模型之品質與可信度， 事前皆會對資料進行前置處理，將資料集做清理，刪除資料中雜訊、重複或不 正確的屬性值…等，有時則採用填補遺漏值之方式以達成資料完整性，資料越 趨完整則對所建立之預測模型越有利。除了對資料完整性進行處理外，有時所 取得的資料集格式有不一致問題，需再進一步進行資料結構化之處理，以確保 資料集結構化均為一致，以減少不必要之因素干擾建模之品質。 本研究所取得資料皆具歷史性之乳癌資料，該資料集皆透過公開資料集 KDD 與UCI 官方網站取得，所取得格式分別為txt 檔及csv 檔，兩者皆為不同之 資料格式，故進一步作處理，將兩份資料集格式進行資料轉檔統一為資料探勘 工具WEKA 可使用的ARFF 格式。格式確定後，隨即進入到資料梳理程序，逐筆 確認所收集的每筆資料之完整性，若遇到資料有遺漏值的狀況，則予以刪除不 列入本研究中。因本研究皆使用歷史性資料集，為驗證訓練模型之精準度，故 分別將KDD 與UCI 資料集平均切分為五等份資料子集，並使用五摺交叉驗證方 式進行訓練與驗證。 相關技術參數設定 本研究採用WKEA 資料探勘應用軟體作為實驗工具，參考過往文獻中皆有 採用WEKA 進行乳癌預測之相關研究，此軟體功能包含資料預處理、分類、回 歸、分群、聚類、關聯規則等，本研究運用其中資料預處理與分類功能，從文 獻中亦可得知學習模式又以監督式學習對於分類有較佳預測效果，其中所使用 的演算法為支援向量機與隨機森林，用此作為預測模型之訓練方法，以下將介 紹五組實驗方法，依採用預處理的方式又分為特徵選取與類別不平衡，針對特 徵選取進一步細分為兩種不同選取方法，主要觀察其用不同特徵選取方式對訓 練出來的模型是否有其不同的表現，再依照預處理之順序分為兩種組合，分別 使用Filter 過濾法及Wrapper 包裝法作特徵選取工程，如表3，Filter 過濾法主 要是依特徵得分高低進行排序並保留前80%的特徵屬性作為特徵子集，剔除剩 餘20%得分較低的特徵屬性、另一種方法則是使用Wrapper 包裝法進行評估並 採用基因搜尋法，參數值之設定參照文獻[12]中給予的建議範圍為依據進行設 定。而本研究設定三種基準對照組(Baseline)，依據是否有做資料預處理及處理 方式作為區分，分別為第一種是未處理即進行SVM、RandomForest 訓練模型， 第二種是資料以特徵選取方法先做處理再進行SVM、RandomForest 訓練模型， 第三種是資料以類別不平衡的方式先做處理再進行SVM、RandomForest 訓練模 型。 表3：特徵選取 特徵選取法 評估函數(Attribute Evaluator) 搜尋方法(Search Method) Filter GainRatio Ranker Wrapper Wrapper GeneticSearch 資料來源：本研究整理 首先根據實驗流程依序介紹特徵選取、類別不平衡、支援向量機及隨機森 林之參數設定做說明： (1) 特徵選取： 在機器學習領域中，在做特徵選取時最常遇到overfitting 的情況，此情況指 的就是過度學習訓練資料，導致挑選特徵上有瑕疵，使得訓練出來的模型無 法預測或識別不是在訓練資料內的其他資料，為了降低模型overfitting 的狀 況，故在實驗中須先將資料分為訓練資料及驗證資料。訓練資料主要是將資 料做為訓練模型用，而測試資料就是去驗證訓練出來的模型，是否能預測或 識別訓練資料集以外的資料，本研究採用5-fold 五摺交叉驗證。首先先將乳 癌資料集平均分成五等分，取其中的一摺做為測試資料集、而其餘四摺做為 訓練資料集，分別進行五次的訓練與驗證，將每一次所被選取的特徵做保留， 其餘的特徵做剔除，再進一步用測試資料集去驗證訓練出來的模型。每摺驗 證資料集之特徵屬性皆須同相對應該摺的訓練資料集，例如第一摺訓練資料 集所刪除的特徵屬性值，在第一摺的驗證資料集亦須刪除相同的特徵屬性 值。 表4：五摺交叉驗證 資料集均分五份 第一摺 第二摺 第三摺 第四摺 第五摺 備註 白底：訓練資料、橘底：驗證資料 資料來源：本研究整理 圖4：訓練資料與驗證資料模型 資料來源：本研究整理 因本研究分為KDD 大型資料集與UCI 小型資料集，兩者皆使用兩種特徵選 取方式分別為Filter 過濾法與Wrapper。KDD 大型資料集與UCI 小型資料集 使用Filter 過濾法中的GainRatio，採用WEKA3.9.5 版本之預設Ranker 搜尋 方法與預設之參數;另一種為Wrapper 包裝法中的基因搜尋方法，對於KDD 大型資料集所使用此方法之參數是WEKA 預設之參數，而UCI 小型資料集使 用此方法之參數則是參考Instance selection and feature weighting using evolutionary algorithms[12]一篇中所研究之參數權重予以實驗。 表5：特徵選取之參數設定 參數設定 KDD 大型資料集 UCI 小型資料集 Filter GainRatio default default Ranker default default Wrapper Wrapper default default GeneticSearch default populationSize：50 crossoverRate：0.8 Mutation：0.01 資料來源：本研究整理 (2) 類別不平衡 本研究屬於醫療領域中癌症分類之資料，所蒐集KDD 大型資料集與UCI 小 型資料集資分布呈現均屬於類別不平衡之資料。在二元分類問題來說，這是 很典型常見的範例，在傳統的資料探勘方法大多是追求高的分類正確率，但 對於少數類別有較差的預測正確率。而少數類別反而是關鍵因子且是研究人 員感興趣的，本研究為了解決此問題，故針對類別不平衡的樣本預先做類別 不平衡之處理，改善類別不平衡在SVM與Random Forest分類器上學習性能。 將大部分正常情況下視為陰性(沒有罹患癌症)，只有極少數比例(about <1%) 為陽性。本研究採用Nitesh Chawla 等人所提出的SMOTE[5]方法來產生新的 合成資料，使用WEKA 工具裡資料預處理Preprocess 中的SMOTE 功能，按 資料比例調整Percentage 參數讓陽性與陰性在每一摺訓練資料集的比例達 到1:1，使資料達成平衡以利後續預測模型之訓練，其餘參數則使用SMOTE 預設值不做異動。 (3) 支援向量機 本研究使用支援向量機作為建立模型之分類器，此分類器常見的核函數分為 線性(linear)、多項式(polynomial)、徑向基函數(radial basis function，RBF)、 乙狀函數(sigmoid)等核函數，核函數主要是將非線性二元分類資料轉換至可 分割線性空間[14]，將原本在平面中無法分割的資料可於空間中實現，以一 個超平面所分割。 本研究搭配RBF 核函數的使用，其優點除了有助處理非線性高維度資料，而 KDD 資料集即屬於高緯度隻大型資料集，再則是RBF 核函數的值落在0~1 之間，將有效減少運算之難度與有較佳的處理效能，其餘參數則使用SVM 預設之參數值。並利用五摺交叉驗證方法進行模型之建構。 (4) 隨機森林 除了支援向量機之外，本研究亦採用隨機森林作為此實驗之分類器，使用 WEKA 內建Random Forest 分類器並採用預設之參數值。利用五摺交叉驗證 方法進行模型之建構。 預測模型評估 預測模型評估方式本研究為分類器所建構出之預測模型的準確率，將KDD 大型資料集與UCI 小型資料集分別建立訓練資料集與測試資料集，再利用五摺 交叉驗證方法(5-fold cross-validation)進行整個預測模型之準確率評估。 為了評估各預測模型的準確率，本研究採用分類模型中很重要的衡量機制： 混亂矩陣方法(Confusion matrix)來表示，如表6。表中的TP (True positive)為樣 本中實際的罹癌病患且預測為有罹癌之個數; FP (False Positive)為樣本中實際無 罹癌者而被預測為有罹癌之個數; FN (False Positive)為樣本中實際罹癌之病患而 被預測為無罹癌之個數; TN(True Negative)為樣本中實際無罹癌者且被預測無罹 癌之個數。 表6：混亂矩陣 預測結果 實際結果 預測有罹癌 預測無罹癌 罹癌(陽性) TP (True Positive) 真陽性 FN (False Negative) 假陰性 無罹癌(陰性) FP (False Positive) 假陽性 TN (True Negative) 真陰性 Total TP + FP FN + TN 資料來源：本研究整理 透過混亂矩陣可得知結果並加以分析再評估其預測模型之樣貌與適當性， 為能正確評估模型正確預測之效果，從混亂矩陣可得知下列幾種效能評估指標， 分別為敏感性(sensitivity)、特異性(specificity)、準確率(accuracy)等指標，本研究 採用準確率(Accuracy)指標來評估各實驗分別建構出來之模型預測能力。預測模 型能正確預測出罹患癌症病患及未罹患癌症者的結果百分比。各項效能評估指 標公式如下： ➢ 敏感性 𝑆𝑒𝑛𝑠𝑖𝑡𝑖𝑣𝑖𝑡𝑦= 𝑇𝑃 (𝑇𝑃+𝐹𝑁)，又稱為Recall 召回率，表示預測模型能正 確預測罹癌的比率。 ➢ 特異性 𝑆𝑒𝑝𝑒𝑐𝑖𝑓𝑖𝑐𝑖𝑡𝑦= 𝑇𝑁 (𝐹𝑃+𝑇𝑁)，表示預測模型能正確預測無罹癌的比率。 而1 −𝑆𝑒𝑝𝑒𝑐𝑖𝑓𝑖𝑐𝑖𝑡𝑦=  𝐹𝑃𝑅= 𝐹𝑃 (𝐹𝑃+𝑇𝑁) 即為假陽性，表示預測模型判斷有罹 癌，但實際上沒有罹癌的比率，該比例越小越好。 ➢ 準確度 𝐴𝑐𝑐𝑢𝑟𝑎𝑐𝑦= 𝑇𝑃+𝑇𝑁 (𝑇𝑃+𝑇𝑁+𝐹𝑃+𝐹𝑁) ，表示預測模型能成功預測的正確比率， 得到數值越高代表分類性能越好。 本研究除了使用WEKA 之SVM 與Random Forest 分類器所建構出的分類結 果外，並另外使用一組重要指標ROC (Receiver operator characteristic)來評估本 研究的各組實驗結果，用以分析各組實驗模型準確度之優劣程度，ROC 指標是 由上述Recall 與1-Specificity 之間的關係，當設定𝑅𝑒𝑐𝑎𝑙𝑙= 1代表陽性樣本皆被 正確分類為陽性，將所有樣本都視作陽性，即分類模型的門檻機率= 1，此時陰 性樣本皆被分類錯誤，故得知1 −𝑆𝑝𝑒𝑐𝑖𝑓𝑖𝑐𝑖𝑡𝑦= 1 −0 = 1。相反的若𝑅𝑒𝑐𝑎𝑙𝑙= 0 時，代表所有陽性樣本被錯誤分類為陰性，即分類模型的門檻機率= 0，此時所 有樣本都被視為陰性，此時陰性樣本皆被分類正確，故得知1 −𝑆𝑝𝑒𝑐𝑖𝑓𝑖𝑐𝑖𝑡𝑦= 1 −1 = 0。經推導得知Recall 與1-Specificity 存在正相關。由1-Specificity 作為 x 軸、Recall 作為Y 軸，可繪製不同門檻機率時的指標，就可得到ROC 曲線[14]， 如圖5： 圖5：ROC 曲線示意圖 資料來源：An introduction to ROC analysis[14] ROC 曲線當越靠近左上方時，代表分類模型的分類能力較佳，即ROC 越往 左上角移動時，代表模型對罹癌的敏感度越高、假陽性1-Specificity 越低。除了 利用ROC 曲線圖來評估之外，亦可用曲面下的面積AUC(Area Under Curve)來判 斷ROC 曲線的鑑別力。AUC 值域為0~1，數值越接近1 則表示鑑別力越佳，代 表建構的模型效能越好，一般判別規則：AUC=0.5 視為無鑑別能力、0.7≦AUC ≦0.8 視為可接受之鑑別力、0.8≦AUC≦0.9 視為優良之鑑別力、0.9≦AUC≦
