傳統的神經網路模型中，是從輸入層到隱藏層再到輸出層中每層之間的節 點是無連線的，所以我們輸入資料中彼此之間的關聯性是傳統的神經網路模型 無法察覺到的，尤其應用於序列資料更加不利，因為序列資料之關聯性明顯是 強烈的。遞迴神經網路（Recurrent Neural Networks）會儲存上一個神經元的輸 出，當下一個神經元經過隱藏層時便能透過上個神經元的輸出的資訊做修改， 以得到一個時間相關的結果，然後在多次的計算和反向傳播過程後，可能會發 生梯度消失（Gradient vanishing）和梯度爆炸（Gradient exploding）的問題。 長短期記憶模型（Long Short-term Memory, LSTM）[26]是一種遞迴神經網 路，長短期記憶模型增加了3 個不同的閘門，輸入閘 （Input gate）、遺忘閘 （Forget gate）、輸出閘（Output gate），輸入閘決定當前時序下輸入的資料是否 進入記憶單元，遺忘閘決定是否刪除儲存在記憶單元內的歷史資料，輸出閘決 定是否輸出記憶單元內的資料，透過這樣的機制長短期記憶模型有效的改善了 遞迴神經網路可能會發生梯度消失和梯度爆炸的問題。 Fischer [27] 將1992 年12 月至2015 年10 月在標準普爾500 指數的大型金 融市場預測任務中運用長短期記憶模型得到了很好的預測效果，Li [28]利用長 短期記憶模型與遞迴神經網路做文字情緒分類，長短期記憶模型得到了比遞迴 神經網路更好的正確率。由以前的研究可知長短期記憶模型在自然語言處理、 股價預測等一系列的應用上都取得了很好的效果。
