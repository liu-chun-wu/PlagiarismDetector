並使用 K-means (forgy's algorithm) [29] 對訓練集的邊界框尺寸類聚出K 個不同長寬的初始錨框，使得網路在迴歸分析物件大小時能更快速的收 斂，透過這種方式，YOLOv2 使用五個錨框就能得到九個錨框才能達到的 效果。Redmon 和 Farhadi 在2018 年又改進 YOLOv2 而提出了YOLOv3 [16]。在骨幹方面，採用 Darknet-53 做為新的網路骨幹，以大量1×1 及 3×3 卷積來降低參數量；且為了防止網路深度過深而導致的梯度消失 (gradient vanishing) 和網路退化 (degradation) 的問題發生，引入殘差模 組 (residual block) [9] 來解決，如圖 2.6 所示；並在每次卷積後面加入批 量正規劃 [8] 以防止過擬合 (overfitting) 的發生。 - 11 - 圖 2.6. YOLOv3 之殘差模塊。 由於大多數的偵測網路都只使用最後一層特徵圖去進行特徵提取， 從而進行目標偵測，但最後一層的特徵圖屬於高階特徵，若只使用高階特 徵圖會引此忽略小物件的部分資訊，因此對於小物件的偵測效果是會較 差的。有鑑於此，YOLOv3 引入 Lin et al. [30] 所提出的特徵金字塔網路 (Feature pyramid networks, FPN)，把低解析度的多語義資訊特徵與高解析 度的少語義資訊進行融合，並在不同特徵層裡進行預測，使得高解析度下 的特徵圖也具有豐富的語義特徵，讓小物件的辨識率上升。 圖 2.7. FPN 網路架構。 - 12 - 由於一階段方法在速度上較快，二階段網路在精確度較高，各有其優 缺點，為了繼承兩者的優點，同時克服兩者的缺點，Zhang et al. [31] 提 出了 RefineDet (single-shot refinement neural network, RefineDet)，該網路 屬於階層式物件偵測系統，這種系統有兩階段網路的準確性，並且保持了 與一階段網路相同的速度，架構如圖 2.8 所示。作者提出錨框修正模組 (anchor refinement module, ARM) 、目標檢測模組 (object detection module, ODM) 兩個模組。ARM 負責粗略地調整錨框的位置和大小做為候選區塊， 其功能類似 Faster R-CNN 裡 RPN 的功能，之後由 ODM 再進行一次 迴歸計算出候選區塊位置及大小的偏移量，由於經過兩次的迴歸，最終的 結果會比第一次來的更精確。 圖 2.8. RefineDet 網路架構。 預測框和實際 (ground truth) 框的交集面積比聯集面積 (Intersection over Union, IoU) 是用來判斷物件是否有被找出的評估數值，比值越高代 表預測框與實際框的相近；越高越好，但需要一個門檻值做為預測成功與 否的標準，也就是 IoU 門檻值 (IoU threshold)。Redmon 和Farhadi [32] 提出的 Cascade R-CNN，用隨著階層增加而不斷調升訓練時判定用的 - 13 - IoU 門檻值，來增強各聯集階段所能提出的候選區塊品質以取得更好的 預測結果。 圖 2.9. Cascade R-CNN 架構。
