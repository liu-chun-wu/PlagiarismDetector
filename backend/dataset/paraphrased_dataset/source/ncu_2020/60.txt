依據研究預測〔28〕指出全球每年資料的產出量將從2018 年的33ZB 來到2025 年 的175ZB，圖 2-6，隨著資訊科技的演進，處理資料的方法從單機到分散式計算的Apache Hadoop.〔29〕讓我們有機會能處理大量的資料例如:使用者在電商網站行為的資料、機 台產出的log，來提供更精準的分析，然而Hadoop 最令人詬病的是每次Map Reduce〔30〕 計算都必須進行檔案的存取使得運算效能不佳。 圖2-6 每年全球資料量預測 資料來源：David Reinsel et al., (2018) 2009 年加州大學柏克萊分校AMPLab〔31〕公開了一套基於記憶體儲存的分散式平 行運算框架Apache Spark，情況大為改善，Apache Spark 在記憶體中計算的特性使其 更適合使用在多次迭代的分析資料工作上，效能是Hadoop 的100 倍，圖 2-7，除此之 外對於程式語言、資料類型的支援都非常的彈性使得這個技術在短期內迅速走紅，如圖 2-8 所示，以Spark 為核心擴充的模組，本研究會使用的模組為Spark MLlib 中的ALS 演算法，相較於以Hadoop MapReduce 為計算框架的Apache Mahout〔32〕，其效能表現 極佳，如圖2-9〔33〕所示。 圖2-7 Logistic regression in Hadoop and Spark 資料來源：Apache Spark, (2009) 圖2-8 Apache Spark 框架 資料來源：Apache Spark, (2009) 圖2-9 ALS vs Hadoop Mahout 資料來源：Databricks. (2014)
