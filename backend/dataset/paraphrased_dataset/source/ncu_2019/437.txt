C4.5 演算法為一種決策樹演算法，它是ID3 的後繼者，由Ross Quinlan 所開發， 決策樹為一樹狀結構，可用來解決分類問題，由節點和分枝構成，其中每一個內部節 點(Internal Node)代表測試條件，而每一分支(Branch)則為它對應的測試結果，資料 經過內部節點測試最後會到達葉節點(Leaf Node)，葉節點代表資料分類後所得到的類 別標籤(Class Label)，決策樹的結構如圖2-5 所示。當決策樹出現了過多的分支，代 表著出現了過度學習(Overfitting)，為了避免此狀況，需要對決策樹進行修剪，常見 的修剪的方式可分為兩種，分別是事前修剪(Prepruning)和事後修剪 (Postpruning)[3]。 圖2- 5 決策樹架構圖 (資料來源：[29]) C4.5 演算法是屬於事後修剪中的悲觀修剪(Pessimistic Pruning)[30]，是利用錯 誤率來進行修剪，其錯誤率的計算是使用訓練資料集，但為避免過度樂觀產生偏差， 因此悲觀修剪除了考慮錯誤率還會在加上懲罰值(Penalty)，來避免偏差的產生[3]。 C4.5 演算法是使用獲利比率(Gain Ratio)作為其分割的準則，獲利比率的定義為 [30]： Gain Ratio(X) = Gain(X) SplitInfo(X) (2.1) 獲利比率最大的屬性將被選為分割屬性，但是當分割資訊值(Split Information) 很小時，獲利比率會很不穩定，為了避免這種情形，會加入一項限制，選作為測試的 資訊獲利值至少要與所有測試的平均資訊獲利值一樣大，不能低於平均資訊獲利值。
