樣本選取與資料離散化分別可以解決資料冗餘、複雜連續型數值影響模型準 確度的問題。本研究使用了三種常見的樣本選取演算法：基於樣本學習演算法 （Instance-Based Learning Algorithm， IB3）、基因演算法（Genetic Algorithm， GA）、遞減式縮減最佳化程序（Decremental Reduction Optimization Procedure， DROP3）；以及兩種具指標性的監督式離散化方法：最短描述長度原則（Minimum Description Length Principle， MDLP）、基於卡方分箱（ChiMerge， ChiM），以 不同排列組合互相搭配，期望能夠探討出最佳的組合方式。 為了建立客觀的比較基準，本研究使用了10 個來自UCI 與KEEL 的資料 集，這些資料集分別具有不同的特性，並且進行五折交叉驗證（5-fold Cross- validation）[20]，本驗證方法會將資料集分成五等份，其中四等份為訓練資料， 另一等份為測試資料，並且透過最近鄰居法（K-th Nearest Neighbor， KNN）來 進行分類，取得模型的平均正確率、二分類AUC 指標、多分類Kappa 指標以及 運行時間，作為其衡量指標。 本研究欲探討以下問題： 1. 分別混合不同的資料離散化與樣本選取方法，並測試檢驗先執行樣本選取後 執行離散化（IS + D）與先執行離散化後執行樣本選取（D + IS）等架構，是 否優於單一離散化方法，能夠有效提升模型的評估指標？ 2. 樣本選取與資料離散化結合執行的先後順序，是否會影響模型的準確度？何 種搭配方式最後的預測準確度最高？ 3. 針對二分類與多分類的資料集，何種搭配方式能夠提升其平均AUC 與平均 Kappa 值？並將運行時間納入考量，何種搭配方法為較適用的方法？
