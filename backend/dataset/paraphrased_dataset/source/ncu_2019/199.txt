最短描述長度原則是一種以熵（Entropy）為計算基礎的離散化方法，為Fayyad 與Irani 在1993 年提出，熵在資料探勘中是一種常見的衡量指標，常常被用來計 算資料的亂度。最短描述長度原則在進行離散化時，會參考其類別資訊的熵 （Class Information Entropy），類別資訊的熵是用來衡量各特徵值與類別間的純 度，以及屬於此類別的特徵數量，在此方法運算的過程中，會將這些資訊納入考 量，並根據這些關聯尋找適當的切割點（Cut Point），之後再計算切割點區間內的 熵，求出其資訊獲利值（Information Gain），以最大的資訊獲利值之所在位置將 原本的資料分成數個子區間，並且在這些子區間內重覆切割步驟，直到終止條件 產生，停止切割計算並且結束離散化步驟。熵的計算方法如公式2.4 所示： (2.4) S 為輸入的特徵值集合，𝑝𝑖代表的是此特徵所屬樣本為類別i 的機率，因為 資料是以位元型態做編碼，因此後面的log 運算以2 為底。用此公式計算完切割 點區間內的熵，接著再使用上述提到的資訊獲利值來評估此切割點是否為適當的 切割點。資訊獲利值的計算公式如公式2.5 所示： 𝐺𝑎𝑖𝑛=  𝐼𝑛𝑓𝑜(𝑆) − |𝑠1| |s| 𝐼𝑛𝑓𝑜(𝑆1) − |𝑠2| |s| 𝐼𝑛𝑓𝑜(𝑆2)   (2.5) S 與公式2.4 中的S 相同，為輸入的特徵值集合，𝑆1與𝑆2指的是此切割點的 左右兩部分集合，分別計算個別的亂度後，即會得到資訊獲利值，當此切割點的 資訊獲利值高於其他切割點的資訊獲利值時，代表此切割點為最佳的切割點，並 且會繼續以此切割點為基準，繼續往下做重覆的計算，直到終止條件到達為止。 最短描述長度原則的終止條件如公式2.6 所示： (2.6) 其中，終止條件公式中的δ，計算方式為公式2.7 所示： (2.7) 公式2.7 中的𝑚𝑖代表𝑆𝑖集合中的類別數量，n 表示S 集合中總共的樣本數量。 因此，由以上可以得知，當計算得到的資訊獲利小於公式2.7 的結果時，即可以 終止運算，完成最短描述長度原則的離散化計算[50]。
