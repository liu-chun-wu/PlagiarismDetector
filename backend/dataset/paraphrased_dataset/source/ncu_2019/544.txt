遞迴式最小平方演算法(Recursive least squares estimation, RLSE)是由Astrom 和 Wittenmark 在1994 年所提出的方法[58]，此概念式由最小平方估計演算法推演而 來，不同於本研究前鑑部所使用的粒子群演算法，需要經過時間學習優化參數，最 小平方估計法是利用輸入資料點，尋找一條線性函數，使資料點與該函數的平方誤 差達到最小值，而透過此方法求出的最小值非常快速。假定有一輸入資料集𝑥 ，其 線性函數模型如下表示： 𝑦̂ = ∑𝜃𝑖𝑓𝑖(𝑥 ) +  𝜀 𝑛 𝑖=1 (14) 𝑥 為該模型輸入，{𝑓𝑖, 𝑖= 1,2, … , 𝑛}則為𝑥 的函數，{𝜃𝑖, 𝑖= 1,2, … , 𝑛}則為需要尋 找的參數，𝜀則是誤差值。假設共有m 筆模型輸入資料，記為{𝑥𝑖, 𝑖= 1,2, … , 𝑚}。 將資料集𝑥 帶進去公式(14)可得一組線性方程式集合，如下表示： 𝑦̂1 = 𝜃1𝑓1(𝑥1) + 𝜃2𝑓2(𝑥1) + ⋯+ 𝜃𝑛𝑓𝑛(𝑥1) + 𝜀1 𝑦̂2 = 𝜃1𝑓1(𝑥2) + 𝜃2𝑓2(𝑥2) + ⋯+ 𝜃𝑛𝑓𝑛(𝑥2) + 𝜀2 ⋮ 𝑦̂𝑚= 𝜃1𝑓1(𝑥𝑚) + 𝜃2𝑓2(𝑥𝑚) + ⋯+ 𝜃𝑛𝑓𝑛(𝑥𝑚) + 𝜀𝑚 (15) 模糊類神經系統在時間序列之預測與應用 研究方法 研究生：侯夆霖 指導教授：李俊賢博士 最小平方問題，方程式集合以矩陣形式表示如下： Y = Aθ + E (16) Y為模型的輸出矩陣，A為輸入矩陣，θ為參數矩陣，E為誤差矩陣。經由數學 式表示如下： Y = [y1 y2 … y𝑁]T (17) A = [ 𝑓1(𝑥1) 𝑓2(𝑥1) 𝑓1(𝑥2) 𝑓2(𝑥2) ⋯ 𝑓𝑚(𝑥1) ⋯ 𝑓𝑚(𝑥2) ⋮ ⋮ 𝑓1(𝑥𝑁) 𝑓2(𝑥𝑁) ⋱ ⋮ ⋯ 𝑓𝑚(𝑥𝑁) ] (18) θ = [𝜃1 𝜃2 ⋯ 𝜃𝑚]T (19) E = [𝜀1 𝜀2 ⋯ 𝜀𝑁]T (20) 最後最小平方估計演算式可以如下表示： θ = (ATA)−1𝐴TY (21) 對於訓練所提出的模糊逼近器，使用公式(5)中的數據對來適當的持續更新後 參數，遞迴式最小平方演算法可以如下所表示： P𝑡+1 = P𝑡− P𝑡b𝑡+1(b𝑡+1)TP𝑡 1 + (b𝑡+1)TP𝑡b𝑡+1 (22) θt+1 = θt + P𝑡+1b𝑡+1(𝑦̂𝑡+1 −(b𝑡+1)Tθt) (23) 其中𝑡是遞迴次數，{𝑡= 0,1,2, … , 𝑁−1}， P𝑡為增益矩陣(Gain matrix)。θt是遞 迴式最小平方演算法在第𝑘次遞迴迭代後所算出的參數向量。進行遞迴式最小平方 演算法以前必須先將P0與θ0初始化。先將θ0初始成零矩陣，而P0的初始化如下： P0 =  𝛼𝐼 (24) 其中𝛼設為一極大整數，𝐼則為單位矩陣。RLSE 運行的原理為利用前一次 估計出的結果值，加入當次觀測的輸入以及輸出值，進而計算當次的估計 結果值。 模糊類神經系統在時間序列之預測與應用 研究方法 研究生：侯夆霖 指導教授：李俊賢博士
