在此部分將會對實驗所使用之Baseline 做介紹。本實驗採用經由單一離散化 （MDLP 與ChiMerge）過後所得之模型的平均正確率做為Baseline。首先，將本 論文所採用的資料集，分成80%訓練資料與20%測試資料，以便後續做五折交叉 驗證得到客觀的平均數據。第二，將訓練資料分別使用本論文所採用的兩種離散 化方法：MDLP 與ChiMerge，進行離散化並且紀錄其切割點（Cut Point），並且 將測試資料依據訓練資料的切割點進行離散化。第三，將該折數的訓練資料分別 放入KNN 建立模型，接著再把該折數的測試資料放入該建立好的模型（Model） 作測試，得到該模型的評估指標。在經過五折交叉驗證，得到五次的模型評估指 標後，將其平均，即可分別得到MDLP 離散化與ChiMerge 離散化的平均評估指 標，並可將其兩者作為本實驗的Baseline 數據。如下圖3-4 所示，可以藉由此圖 了解取得Baseline 數據的流程。 圖3-5 Baseline 流程圖 Train Data Test Data 依據相同cut point 作切割 Test Data Classifier KNN Discretizers MDLP ChiMerge Model 評估指標 Data Train Data 下圖3-5 為本論文實驗Baseline 流程的虛擬碼（Pseudo Code），可以藉由此 圖所示之虛擬碼，以程式的角度與運作流程，來更加了解本論文中，實驗所使用 的Baseline 數據取得流程。因為本實驗採用五折交叉驗證，故在做資料集切割後， 可以得到五份訓練資料集與五份測試資料集，虛擬碼中的i 代表該步驟正在處理 第幾折步驟的資料集，由虛擬碼中可以看出，每一折的訓練資料集與測試資料集 皆會做離散化與訓練模型的步驟，並且將測試資料集放入該折的模型中，驗證該 折的模型評估指標。接著在最後將每一折紀錄好的評估指標取出，除以五做平均 評估指標的計算，即可得到該資料集在Baseline 中評估指標的平均數據。 Algorithm: Get Baseline Input: A set of dataset S Output: Evaluating indicator e 1. For each dataset s in S 2.   Divide s into 80% Train Data & 20% Test Data by using 5-fold cross validation 3.     For i from 1 to 5 4.       Use the discretization algorithms to process train i 5.       Record the cut points p on train i 6.       Get the discrete dataset train i 7.       Use the same discretization algorithms & p to process test i 8.       Get the discrete dataset test i 9.       Put train i into classifier to train the model  //Classifier: 1-NN 10.       Put test i into the model to evaluate e 11.       Get & record fold i's e 12.   Get 5 folds' e 13.   Total the 5 folds' e and divide by 5 14.   Get the average e of dataset s 15.   Output the average e of dataset s 圖3-6 本研究Baseline 流程之虛擬碼
