由於TCN 要做到輸出的資料與輸入的資料長度相同，所以TCN 使用1 維全卷積 網路(1D fully-convolutional network) (Long et al., 2015)[13]，1 維全卷積網路的隱藏層的 長度都與輸入層長度相同，並且在每一層隱藏層都加入了補零(zero padding)的結構， 用來讓每一層接續層的長度與前一層相同。TCN 要做到只看的到過去的資訊，使用因 果卷積(Causal convolutions)，代表在時點t 的產出值只能由時點t、時點t 之前的輸入 值產生。 綜上而言，TCN 就是1D 全卷積網路加上了因果卷積。 這個結構，與Waibel et al. (1989)提出的結構相同[44]，這個結構主要的缺點是， 為了擷取足夠的歷史資訊，需要建構相當深的模型或是相當大的濾波器(filters)，這些 要求在1989 年都相當難以達成，但是現在的卷積方法可以做到相當深的神經網路、擷 取足夠的歷史資訊。
