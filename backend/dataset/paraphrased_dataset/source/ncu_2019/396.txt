在熱力學中，熵（Entropy）常被用來判斷系統混亂的程度，近代資訊之父 Shannon [37]首度將熵的概念融入資訊理論之中，提出資訊熵的概念。如同在熱力 學中熵用來測量能量差異一般，資訊理論中將資料整理前後兩狀態資訊熵的差異 視為兩狀態中所增減的資訊量，在此將資訊熵以H 表示之，其公式如下： 𝑇𝑇= ෍ 𝑃𝑃𝑖𝑖log൬1 𝑃𝑃𝑖𝑖 ൰ 𝑟𝑟 𝑖𝑖=1 , (15) 其中𝑃𝑃𝑖𝑖為離散事件變數（Event variable）𝑥𝑥𝑖𝑖發生的機率，可根據機率密度估計法算 而得，當事件發生的機率𝑃𝑃𝑖𝑖趨近於1 則資訊熵H 則趨近於0（如圖2）。 特徵選取對智慧型時間序列預測之效能研究 研究方法 研究生：陸怡廷 指導教授：李俊賢博士 圖 2：資訊熵與事件機率𝑃𝑃𝑖𝑖關係圖 將資訊理論中的資訊量以符號𝐼𝐼為記，I(X,Y)則用來表示事件變數x 的隨機變數 X（Random variable）提供給事件變數y 的隨機變數Y 的資訊量，並且以下式表示 之： 𝐼𝐼(𝑋𝑋, 𝑌𝑌) = 𝑇𝑇(𝑌𝑌) −𝑇𝑇𝑋𝑋(𝑌𝑌), (16) 其中𝑇𝑇(𝑌𝑌)為𝑌𝑌的熵，𝑇𝑇𝑋𝑋(𝑌𝑌)為𝑌𝑌受到𝑋𝑋所提供的資訊影響後的熵，而𝑇𝑇𝑋𝑋(𝑌𝑌)的計算公 式如下： 𝑇𝑇𝑋𝑋(𝑌𝑌) = −෍ ෍𝑃𝑃(𝑃𝑃, 𝑗𝑗) log𝑃𝑃𝑖𝑖(𝑗𝑗) 𝑌𝑌𝑗𝑗 𝑋𝑋𝑖𝑖 , (17) 其 中 𝑃𝑃(𝑃𝑃, 𝑗𝑗)為離散事件中同時發生𝑋𝑋𝑖𝑖和Yj的機率密度函數 ， 𝑃𝑃𝑖𝑖(𝑗𝑗)為發生Xi 的條件下，𝑌𝑌𝑗𝑗發生的機率密度函數。若𝑇𝑇(𝑋𝑋, 𝑌𝑌)為同時發生𝑋𝑋𝑖𝑖和𝑌𝑌𝑗𝑗的亂度，定義為： 𝑇𝑇(𝑋𝑋, 𝑌𝑌) = −෍ ෍𝑃𝑃(𝑃𝑃, 𝑗𝑗) log𝑃𝑃(𝑃𝑃, 𝑗𝑗) 𝑌𝑌𝑗𝑗 𝑋𝑋𝑖𝑖 , (18) 則可根據條件機率推導如下： 0.2 0.4 0.6 0.8 Pi 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 Entropy 特徵選取對智慧型時間序列預測之效能研究 研究方法 研究生：陸怡廷 指導教授：李俊賢博士 𝑇𝑇(𝑋𝑋, 𝑌𝑌) = −෍ ෍𝑃𝑃(𝑃𝑃, 𝑗𝑗) log𝑃𝑃(𝑃𝑃, 𝑗𝑗) 𝑌𝑌𝑗𝑗 𝑋𝑋𝑖𝑖 = −෍ ෍𝑃𝑃(𝑃𝑃, 𝑗𝑗)log 𝑃𝑃(𝑃𝑃)𝑃𝑃𝑖𝑖(𝑗𝑗) 𝑌𝑌𝑗𝑗 𝑋𝑋𝑖𝑖 = −෍ ෍𝑃𝑃(𝑃𝑃, 𝑗𝑗)log 𝑃𝑃(𝑃𝑃) 𝑌𝑌𝑗𝑗 𝑋𝑋𝑖𝑖 −෍ ෍𝑃𝑃(𝑃𝑃, 𝑗𝑗) log𝑃𝑃𝑖𝑖(𝑗𝑗) 𝑌𝑌𝑗𝑗 𝑋𝑋𝑖𝑖 = −෍𝑃𝑃(𝑃𝑃) log𝑃𝑃(𝑃𝑃) 𝑋𝑋𝑖𝑖 −෍ ෍𝑃𝑃(𝑃𝑃, 𝑗𝑗) log𝑃𝑃𝑖𝑖(𝑗𝑗) 𝑌𝑌𝑗𝑗 𝑋𝑋𝑖𝑖 = 𝑇𝑇(𝑋𝑋) + 𝑇𝑇𝑋𝑋(𝑌𝑌), 得： 𝑇𝑇𝑋𝑋(𝑌𝑌) = 𝑇𝑇(𝑋𝑋, 𝑌𝑌) −𝑇𝑇(𝑋𝑋). (19) Shannon（1948）所提出的互資訊（Mutual Information）即是指稱隨機變數X 與Y 彼此提供的資訊量相等，即為𝐼𝐼(𝑋𝑋, 𝑌𝑌) = 𝐼𝐼(𝑌𝑌, 𝑋𝑋)。若為連續事件變數，則H(X) 的計算公式可表示如下： 𝑇𝑇(𝑋𝑋) = න𝑝𝑝𝑑𝑑(𝑋𝑋) log 𝑝𝑝𝑑𝑑(𝑋𝑋) 𝑎𝑎𝑋𝑋, (20) 其中𝑝𝑝𝑑𝑑(X)為連續事件中隨機變數X 的機率密度函數，而公式（17） （18）改寫如下： 𝑇𝑇𝑋𝑋(𝑌𝑌) = −න න 𝑝𝑝𝑑𝑑(𝑋𝑋, 𝑌𝑌) log𝑝𝑝𝑑𝑑(𝑋𝑋, 𝑌𝑌) 𝑝𝑝𝑑𝑑(𝑌𝑌) 𝑎𝑎𝑋𝑋𝑎𝑎𝑌𝑌 𝑌𝑌 𝑋𝑋 , (21) 𝑇𝑇(𝑋𝑋, 𝑌𝑌) = −න න𝑝𝑝𝑑𝑑(𝑋𝑋, 𝑌𝑌) log 𝑝𝑝𝑑𝑑(𝑋𝑋, 𝑌𝑌) 𝑎𝑎𝑋𝑋 𝑌𝑌 𝑋𝑋 . (22) 將式（20）近似之後可改寫為下列公式： 𝑇𝑇(𝑋𝑋) = ෍𝑝𝑝𝑑𝑑(𝑋𝑋) log൬ 𝜑𝜑 𝑝𝑝𝑑𝑑(𝑋𝑋)൰∆𝑋𝑋, (23) 其中log ( 𝜑𝜑 𝑃𝑃𝑑𝑑(𝑋𝑋))為混亂密度（Disorder density factor），由於𝑃𝑃𝑎𝑎(𝑋𝑋)可能為負值，故𝜑𝜑 為𝑃𝑃𝑎𝑎(𝑋𝑋)的最大值加上ε，ε 為一非常小的常數用以確保累加的每個數必為正，在此 定義為10−10。 由於互資訊的概念忽略了正負值可能造成的影響，Tu and Li [36]認為𝐼𝐼(𝑋𝑋, 𝑌𝑌) = 𝐼𝐼(𝑌𝑌, 𝑋𝑋)應屬於一種極端的現象，故將正負號進行考量之後，另稱之為影響資訊 （Influence Information），將第i 個特徵對第j 個特徵提供的資訊量以下式計算之： 特徵選取對智慧型時間序列預測之效能研究 研究方法 研究生：陸怡廷 指導教授：李俊賢博士 𝐼𝐼൫𝐟𝐟𝐢𝐢→𝐟𝐟𝐣𝐣൯   = 𝐼𝐼൫𝐟𝐟𝐢𝐢 −,  𝐟𝐟𝐣𝐣൯න𝑝𝑝𝑑𝑑(𝐟𝐟𝐢𝐢)𝑎𝑎𝐟𝐟𝐢𝐢 −∞ + 𝐼𝐼൫fi +,  fj൯න𝑝𝑝𝑑𝑑(𝐟𝐟𝐢𝐢)𝑎𝑎𝐟𝐟𝐢𝐢 ∞ , (24) 其中𝐼𝐼൫𝐟𝐟𝐢𝐢→𝐟𝐟𝐣𝐣൯表示為第i 個特徵對第j 個特徵的影響資訊， 𝐼𝐼൫𝐟𝐟𝐢𝐢 −,  𝐟𝐟𝐣𝐣൯、𝐼𝐼൫𝐟𝐟𝐢𝐢 +,  𝐟𝐟𝐣𝐣൯分 別為𝐟𝐟𝐢𝐢的負值與正值提供給𝐟𝐟𝐣𝐣的資訊量，與事件𝐟𝐟𝐢𝐢的發生機率相乘後再進行加總，故 𝐼𝐼൫𝐟𝐟𝐢𝐢→𝐟𝐟𝐣𝐣൯可視為互資訊的期望值，當𝐼𝐼(𝑋𝑋, 𝑌𝑌) = 𝐼𝐼(𝑌𝑌, 𝑋𝑋)時即回歸於Shannon 的互資 訊理論。納入正負號的差異使影響資訊的考量範圍廣於Shannon 的互資訊，資訊量 帶有方向性之後即可透過特徵對目標的影響資訊𝐼𝐼൫𝐟𝐟𝐢𝐢→𝐭𝐭(𝐣𝐣)൯將對目標具有影響力 的特徵篩選而出，此特性即為影響資訊的核心價值所在。 然而在特徵數據中所取得的資訊有可能是不完整的，其實際機率密度未知，故 透過數據進行機率密度函數估計，將數據的分布視為該事件的完整特徵[38]，在影 響資訊當中即使用機率密度函數的積分將特徵完整化。若第i 個特徵對目標的影響 資訊為負，即代表在𝐟𝐟𝐢𝐢條件下的亂度增加且對目標產生負面影響，可事先去除之。 由於數據當中可能存在會對預測目標造成干擾的因子，例如非正常現象、特例、個 案所產生的極端值，或是無法用肉眼辨識出的雜訊，藉由資訊熵與影響資訊的計算 便能夠將這些干擾因子過濾出來並加以排除。接著根據影響資訊建構影響資訊矩 陣（Influence information matrix, IIM）如表4 所示，將多樣化的數據來源對每個預 測目標的影響資訊清楚呈現之，在下一階段中進行特徵的選取。 特徵選取對智慧型時間序列預測之效能研究 研究方法 研究生：陸怡廷 指導教授：李俊賢博士 表 4：影響資訊矩陣 𝐟𝐟𝐟𝐟 𝐟𝐟𝐟𝐟 … 𝐟𝐟|𝐶𝐶𝑃𝑃| 𝐭𝐭(𝐣𝐣) 𝐟𝐟𝐟𝐟 𝐼𝐼𝐟𝐟𝐟𝐟→𝐟𝐟𝐟𝐟 … 𝐼𝐼𝐟𝐟𝐟𝐟→𝐟𝐟|𝐶𝐶𝐶𝐶| 𝐼𝐼𝐟𝐟𝐟𝐟→𝐭𝐭(𝐣𝐣) 𝐟𝐟𝐟𝐟 𝐼𝐼𝐟𝐟𝐟𝐟→𝐟𝐟𝐟𝐟 … 𝐼𝐼𝐟𝐟𝐟𝐟→𝐟𝐟|𝐶𝐶𝐶𝐶| 𝐼𝐼𝐟𝐟𝐟𝐟→𝐭𝐭(𝐣𝐣) ⋮ ⋮ ⋮ ⋮ ⋮ 𝐟𝐟|𝐶𝐶𝑃𝑃|| 𝐼𝐼𝑓𝑓|𝐶𝐶𝐶𝐶|→𝐟𝐟𝐟𝐟 𝐼𝐼𝑓𝑓|𝐶𝐶𝐶𝐶|→𝐟𝐟𝐟𝐟 … 𝐼𝐼𝑓𝑓|𝐶𝐶𝐶𝐶|→𝐭𝐭(𝐣𝐣) 𝐭𝐭(𝐣𝐣) 𝐼𝐼𝐭𝐭(𝐣𝐣)→𝐟𝐟𝐟𝐟 𝐼𝐼𝐭𝐭(𝐣𝐣)→𝐟𝐟𝐟𝐟 … 𝐼𝐼t(j)→f|𝐶𝐶𝐶𝐶| 其中𝐭𝐭(𝐣𝐣)為第j 個目標變數，且j=1,2,…,|TS|。
