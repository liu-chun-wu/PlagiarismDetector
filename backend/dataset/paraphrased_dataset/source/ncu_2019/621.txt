MFNN 的使用上分為兩個階段：訓練、回想。這裡以一層隱藏層作為訓練時的範 例，可以分為6 個主要步驟： 1. 初始化神經網路參數，以均佈亂數設定輸入層、隱藏層、輸出層之權重矩陣W 與 偏移θ(Bias)的初始值。 2. 輸入一筆訓練樣本作為輸入向量{x1,x2,x3,…}以及對應的目標輸出向量{t1,t2,t3,…}。 3. 計算推論輸出向量{y1,y2,y3,…} i. 計算隱藏層輸出向量{h1,h2,h3,…} 𝑛𝑒𝑡𝑘= ∑𝑊𝑖𝑘 𝑖 𝑥𝑖−𝜃𝑘 (2.9) ℎ𝑘= 1+exp (−𝑛𝑒𝑡𝑘) (2.10) ii. 計算推論輸出向量{y1,y2,y3,…} 𝑛𝑒𝑡𝑗= ∑𝑊𝑘𝑗ℎ𝑘−𝜃𝑗 𝑘 (2.11) 𝑦𝑗= 1+exp (−𝑛𝑒𝑡𝑗) (2.12) 4. 計算誤差量 i. 計算輸出層誤差量δj 𝛿𝑗= (𝑡𝑗−𝑦𝑗) × 𝑦𝑗× (1 −𝑦𝑗) (2.13) ii. 計算隱藏層誤差量δk 𝛿𝑘= (∑𝛿𝑗× 𝑊𝑘𝑗 𝑗 ) × ℎ𝑘× (1 −ℎ𝑘) (2.14) 5. 計算權重矩陣與偏移值向量修正量 i. 計算輸出層權重矩陣與偏移值向量修正量 ∆𝑊𝑘𝑗(𝑛) = 𝜂𝛿𝑗ℎ𝑘+ 𝛼× ∆𝑊𝑘𝑗(𝑛−1) (2.17) ∆𝜃𝑗(𝑛) = −𝜂𝛿𝑗+ 𝛼× ∆𝜃𝑗(𝑛−1) (2.16) ii. 計算隱藏層權重矩陣與偏移值向量修正量 ∆𝑊𝑖𝑘(𝑛) = 𝜂𝛿𝑘ℎ𝑖+ 𝛼× ∆𝑊𝑖𝑘(𝑛−1) (2.18) ∆𝜃𝑘(𝑛) = −𝜂𝛿𝑘+ 𝛼× ∆𝜃𝑘(𝑛−1) (2.19) 6. 更新隱藏層權重矩陣值與偏移值向量 i. 更新輸出層權重矩陣與偏移值向量 𝑊𝑘𝑗= 𝑊𝑘𝑗+ ∆𝑊𝑘𝑗 (2.20) 𝜃𝑗= 𝜃𝑗+ ∆𝜃𝑗 (2.21) ii. 更新隱藏層權重矩陣與偏移值向量 𝑊𝑖𝑘= 𝑊𝑖𝑘+ ∆𝑊𝑖𝑘 (2.22) 𝜃𝑘= 𝜃𝑘+ ∆𝜃𝑘 (2.23) 7. 重複步驟3 至步驟6，直到所有訓練樣本皆已輸入。 8. 依照設定之訓練循環次數，重複步驟3 至步驟8。 回想過程可以分為4 個步驟： 1. 載入網路架構參數，建立網路。 2. 載入已訓練好的權重值矩陣W 與偏移值向量θ。 3. 輸入一筆未知樣本作為輸入向量{x1,x2,x3,…}。 4. 計算推論輸出向量{y1,y2,y3,…} i. 計算隱藏層輸出向量{h1,h2,h3,…} 𝑛𝑒𝑡𝑘= ∑𝑊𝑖𝑘 𝑖 𝑥𝑖−𝜃𝑘 (2.24) ℎ𝑘= 1+exp (−𝑛𝑒𝑡𝑘) (2.25) ii. 計算推論輸出向量{y1,y2,y3,…} 𝑛𝑒𝑡𝑗= ∑𝑊𝑘𝑗ℎ𝑘−𝜃𝑗 𝑘 (2.26) 𝑦𝑗= 1+exp (−𝑛𝑒𝑡𝑗) (2.27) 第三章、SOM-MFNN 語音指令辨識系統設計 本章節將使用MIAT 方法論，對SOM-MFNN 語音指令辨識系統進行IDEF0 階層 式設計，並且透過Grafcet 來進行離散事件描述。
