隨著資訊時代的來臨，我們所獲得的資料量不停地增加，當需要處理的資料 越來越龐大時，資料本身所遇到的問題也會隨之遽增。雜訊（Noisy）與冗餘值 （Redundant）皆是常見的問題，雜訊指的是資料中擁有錯誤的值，或者資料本身 為離群值（Outlier）；冗餘資料指的是資料集中有許多重複的樣本，而這些樣本不 只會造成資料處理上的錯誤，同時也會造成後續資料處理效率的降低[21]。上述 兩個常見的問題，皆能反應出我們在進行資料探勘時所面臨的「資料不乾淨」問 題，不論是雜訊或者是冗餘值，這些樣本的存在皆會導致資料探勘的結果產生偏 誤，因此，若是想要在分類正確率上獲得一定的可信度，我們必須在建立模型所 使用的訓練資料集中，篩選出具有代表性的樣本，意即將原始資料集中的冗餘值 與雜訊去除，獲得一個較精簡且更具有代表性的子資料集，樣本選取（Instance Selection）即是以上述為核心概念，所提出的資料前處理方法。 機器學習的分類問題中，妥善地移除雜訊提升資料品質是必須的步驟，在所 有的前處理方法中，樣本選取是最常被使用在資料縮減中的方法。過去已有文獻 [22]指出，利用樣本選取後，篩選出的代表性資料訓練分類器，能夠有效提高分 類效能，並且降低資料探勘整體過程的執行時間。 樣本選取的運作流程如下圖2-1 所示，T 代表一原始訓練資料集合，其中包 含了對於分類結果沒有幫助的雜訊資料，將T 放入演算法來篩選樣本，透過演算 法，即可將T 集合中多餘的樣本（Superfluous Instances）去除，並且在最後獲得 不包含雜訊與冗餘值的子集合S（S ⊂ T），由於使用不同的演算法會有不同的篩 選標準（Selection Criterion），因此最後的子集合S 所剩餘的樣本，會根據我們 使用何種演算法進行篩選而定。 圖2-1 樣本選取運作流程[23] 圖2-2 為樣本選取應用在資料探勘上的過程，先將原始資料集切分為訓練資 料集（Training Data）與測試資料集（Testing Data），並以前面提到的概念，對 訓練資料集做樣本選取的處理後，即可得到一個比較具代表性的子集合S，接著 以本身所選擇的演算法對S 做訓練模型（Model）的動作，下圖的訓練模型演算 法以C4.5 決策樹為例，在經過訓練後即可獲得訓練好的模型，並在最後將測試 資料集放入模型中，供模型做預測與分類，即可在最後依照所求獲得正確率等指 標，供研究者評估模型的好壞。 圖2-2 樣本選取應用在資料探勘的過程─以C4.5 為例[24] 樣本選取技術發展至今，已有許多不同的技術被提出，也有文獻整理各種方 法並進行彼此間的優缺點、效能比較[25]。其中，基因演算法（Genetic Algorithm， GA）、遞減式縮減最佳化程序（Decremental Reduction Optimization Procedure， DROP3）與基於樣本學習演算法（Instance-Based Learning Algorithm， IB3），皆 為具有代表性，且有較佳效能的演算法，因此，本論文選用了此三種樣本選取演 算法進行實驗，在接下來的小節裡，將會分別對這三種演算法進行介紹。
