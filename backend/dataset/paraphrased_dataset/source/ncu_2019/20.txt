本研究的TCN 每層神經層的濾波器深度(filters)分別設為32、128、512，濾波器大 小與Bai et al., (2018)研究相同[20]，設為2。隱藏層(hidden layer)總共有五層residual block，加上一個輸出層(輸出層設為線性(沒有啟動函數)，1 個神經元(neuron))。TCN 中，空洞卷積讓同一層相鄰的兩個濾波器間有著固定的間隔，空洞卷積數(dilations)設 為指數增加，神經網路中第i 層的空洞卷積數設為d=2𝑖−1，由第一層到第五層分別為 [1,2,4,8,16]。模型採用因果卷積，確保模型無法看到未來的資料，另外使用spatial dropout，整體參數如表格1。 表格1 TCN 參數設定 TCN 參數設定 濾波器深度 (depth of filters) 濾波器大小* (kernel size) 空洞卷積數 (dilations) residual block 數 spatial dropout [1,2,4,8,16] 30% [1,2,4,8,16] 30% [1,2,4,8,16] 30%
