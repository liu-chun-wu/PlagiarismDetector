基本上，倒傳遞演算法[4]是一種最陡梯度下降的方法，架構圖如圖3 所示，將誤 差函數給予最小化，屬於監督式學習網路，公式如下所示： Δ𝑤𝑖,𝑘(𝑛) = −𝜖× 𝜕𝐸 𝜕𝑤𝑖,𝑘 + 𝛼× ∆𝑤𝑖,𝑘(𝑛−1) (3) 倒傳遞網路有幾個重要參數，𝑤𝑖,𝑘是第k 個輸入值到神經元i 的連接權重，𝐸代表 訓練集上誤差平方的總和，𝑛代表第𝑛次學習回合，𝜖和𝛼是兩個非負常數參數，稱 為學習速率和慣性因子。學習速率太大或太小對網路的收斂性質均不利，若學習 效率太小時則容易浪費時間，而且可能無法跳脫局部最小值，太大易造成震盪不 ⋮ neuron i wi,1 p1 p2 pk b a wi,k f ∑ ⋮ 𝑛 wi,2 模糊類神經系統在時間序列之預測與應用 文獻探討 研究生：侯夆霖 指導教授：李俊賢博士 易收斂。較大的學習速率，有較大的網路加權值修正量，可較快逼近函數最小 值，但過大的學習速率將導致網路加權值修正過量，並造成數值振盪而難達到收 斂的目的，因此學習速率的大小對學習有很大的影響。通常會加上一個慣性項， 即加上某比例的上次加權值改變量，以改善收斂過程中振盪的現象，及加速收 斂。 不幸的是，有必要通過網路傳播整個訓練集來計算，這可能會減慢對更大訓練集 的訓練。對於某些任務，例如神經控制器[37]，沒有可用的有限訓練集。 因此， 更新僅基於實際訓練模式，更新的公式如下： Δ𝑤𝑖,𝑘(𝑛) = −𝜖× 𝜕𝐸𝑝 𝜕𝑤𝑖,𝑘 + 𝛼× ∆𝑤𝑖,𝑘(𝑛−1) (4) 𝐸𝑝表是為訓練集上的誤差平方，而𝜖和𝛼的良好選擇對於培訓成功和速度非常重 要，若想要手動調整這些參數到模型最佳化可能非常困難，可能需要很長時間才 能完成更複雜的任務，倒傳遞算法和更新訓練的結果在每次模型呈現後，很大困 難度在於參數的正確選擇。 然而，透過仔細調整學習率和權重可以取得良好的 效果[11]。 模糊類神經系統在時間序列之預測與應用 文獻探討 研究生：侯夆霖 指導教授：李俊賢博士 圖 3 多層類神經網路架構圖- 由圖3 可見，類神經網路可分為三個層次，第一層為輸入層，在此層，類神經元的 數目的多寡是由輸入數量而定。第二層為隱藏層，在此層，隱藏層的數量在設定上 並沒有固定，理論而言，適當的隱藏層、神經細胞的數量和參數數目可以讓預測結 果越有效，但過多的隱藏層有可能有過度學習的狀況發生。第三層為輸出層，為計 算的結果輸出。
