Wilson 與 Martinez（2000）提出了一系列的遞減式縮減最佳化程序 （Decremental Reduction Optimization Procedure），這一系列的程序常見於應用在 樣本選取上，透過一系列的資料過濾技術，能夠有效地篩選出具有代表性的樣本。 DROP1 為DROP 系列的基礎，其概念源自於最近鄰居縮減規則（Reduced Nearest Neighbor Rule, RNN）[40]，意即其演算法的設計機制，會與最近鄰居做 比較，並且根據其制定的規則，來縮減樣本數。其他DROP 系列的演算法都是以 DROP1 為基礎架構運行的，因此，在後續發展的DROP 系列演算法也常常與 DROP1 的效能拿來做比較。DROP1 的基本概念為：假設將樣本P 從訓練資料集 中移除，不會影響到其他訓練資料中，K 個鄰近鄰居中含有樣本P 的分類正確 率，就可以將樣本P 刪除。 舉例來說，假如我們有一個訓練資料集T，與一初始為空集合的S，DROP1 會先將每個樣本P 都建立一組k+1 個最近鄰居清單以及其關聯清單，並且判斷 若是移除樣本P 時，對於與P 有關聯的樣本，其分類效能會不會有所影響，如果 將P 移除掉後，P 的關聯樣本效能增加，則將P 移除；反之若降低，則將P 保 留，並把P 放入S 集合中。若樣本P 遭到移除，則需要將P 從所有樣本的鄰居 清單中移除，並且找到新的鄰居做替代，以維持最近鄰居規則。而樣本在找到新 鄰居做替代時，也需要將其加到新鄰居的關聯表中，才能夠維持原本的機制，保 持正確性，並且在整個演算法運行結束後，將所篩選完的S 集合留下，S 集合即 是我們所要保留的樣本。 DROP1 雖然可以有效地進行資料過濾，但是在有些情況下，可能會導致誤 判而錯誤地移除該留下的樣本，例如：先被檢查到的樣本是雜訊資料的鄰近樣本， 則鄰近樣本可能會先遭到移除，而導致雜訊反而被留下來。因此，為了改善此狀 況，逐漸演化出了DROP2 與DROP3，DROP2 比起DROP1，運用了更多的樣本 間彼此的資訊，並且改變刪除樣本的順序，將屬於不同類別中，距離最遠的樣本 先行移除；DROP3 則會在排序前先將雜訊過濾掉，如此可以讓決策邊界更為平 滑，並且透過計算排除某些樣本對於分類正確率的影響程度，再決定是否保留或 者刪除，並且調整樣本的關聯清單與鄰居清單。而DROP3 的完整運作過程，可 以參照圖2-8 所示。 圖2-8 DROP3 演算法[41] DROP3 演算法可以簡單分為三個部分，首先，先對每一筆資料做最近鄰近 鄰居（K-NN）計算，並且拿掉所有類別預測錯誤的資料，這個步驟會將集合中 的雜訊與冗餘資料移除。接著，會將逐筆資料分別去計算與不同類別的資料中最 近的距離，並且排序資料，通常排序的方法是以每筆資料的最短距離作為排序的 依據。最後一個步驟，每一筆資料依據排好的順序分別檢測對整體資料的分類正 確率影響，假如該筆資料移除後其正確率會上升，則會將該筆資料刪除；反之若 移除後造成分類器的分類正確率下降，則會選擇將該筆資料保留。 DROP3 是眾多樣本選取演算法中較具代表性的演算法[42]，其整體而言也優 於其他DROP 系列的方法。DROP3 的優點在於本身會將資料分佈納入考量中， 因此不必事先決定要選取多少資料，也由於DROP3 有保留所有鄰近樣本，因此 其演算法到最後保留的資料筆數也較多，正確率也相對較高。但因為DROP3 必 須計算每一筆樣本與其他樣本的距離，所以其計算機制相當複雜，也因為計算量 龐大的缺點，而導致了DROP3 的使用也相當費時。
