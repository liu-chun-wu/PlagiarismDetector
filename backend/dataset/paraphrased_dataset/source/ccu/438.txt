AdaBoost 方法是一種迭代演算法，在每一輪中加入一個新的弱分類器，直到達 到某個預定的足夠小的錯誤率。每一個訓練樣本都被賦予一個權重，表明它被某一個 分類器選入訓練集的機率。如果某個樣本點已經被準確地分類，那麼在構造下一個訓 練集中，它被選中的機率就被降低；相反，如果某個樣本點沒有被準確地分類，那麼 它的權重就得到提高。通過這樣的方式，AdaBoost 方法能聚焦於那些較難分的樣本 上。在具體實現上，最初令每個樣本的權重都相等，對於第k 次迭代操作，我們就根 據這些權重來選取樣本點，進而訓練分類器𝐶𝑘。然後就根據這個分類器，來提高被它 分錯的的樣本的權重，並降低被正確分類的樣本權重。然後，權重更新過的樣本集被 用於訓練下一個分類器𝐶𝑘。整個訓練過程如此迭代地進行下去。AdaBoost 演算法如 圖2.13 所示。 樣本資料經由AdaBoost 訓練後，可得到一批參數，此參數集可用來組成強分類 器。一個強分類器 C (x)通常由多個弱分類器所組成，弱分類器個數由訓練迭代次數 T 所決定。每一弱分類器包含所對應的矩形特徵值 、判斷閥值和權重 ，可由 公式2.17 所示，其中x 表示子視窗影像，j 代表特徵個數。弱分類器主要透過弱學習 過程找出最佳的閥值分類函數，使錯誤率降至最低。 多特徵自動化表情辨識系統 ℎ𝑗 (𝑥) = {1,   𝑖𝑓 𝑓𝑗 (𝑥) < 𝜃𝑗 −1,   𝑜𝑡ℎ𝑒𝑟𝑤𝑖𝑠𝑒                      (2.17) 當演算法經過T 次的迭代運算後，獲得T 個弱分類器 。此T 個弱分類器可線性 組合成一強分類器。利用強分類器來偵測影像時，相當於讓所有弱分類器進行投票， 再將每個投票結果乘上每一弱分類器相對應的權重，全部相加求得總和，最後將此總 和與預設閥值進行比較以獲得最終判斷結果。強分類器之形式則如公式2.18 所示 C (𝑥) = {1,   ∑ 𝑎𝑡ℎ𝑡 (𝑥) 𝑇 𝑡=1 ≥0 −1,   𝑜𝑡ℎ𝑒𝑟𝑤𝑖𝑠𝑒                               (2.18) 圖2.13 AdaBoost 演算程序 (資料來源：Wang, 2012) 多特徵自動化表情辨識系統 第三章 材料與研究方法
