MapReduce 最早被Google 提出，是一種用於可平行計算於大規模數據的計算模 型，其處理程序可分為「Map」和「Reduce」兩個階段。MapReduce 架構有可以用下 列例子來進行解釋，商場進行盤點時，分工每個人負責盤點之貨架，這就是「Map」， 盤點人員越多，則盤點耗時愈低，當把所有人集合統計盤點數量時，這就「Reduce」。 HDFS Client Cluster NameNode DataNode DataNode DataNode Data Pipeline Blocks Received addBlock(src) write 透過大數據與資料視覺化建構學術期刊於資訊安全研究演進 Input Files Map phase Intermediate file (on local disks) Reduce phase Output Files 圖 3 MapReduce 執行概念圖 資料來源：(Dean & Ghemawat, 2008) 圖 3 MapReduce 執行概念步驟： (1) 將MapReduce 任務呼叫給Master 和每一台Worker，並且建立於HDFS 目 錄，上傳資料。Master 會執行兩套程式，一個是負責安排MapReduce 運算 任務的JobTracker 以及負責管理HDFS 資料層的Namenode 程式。 (2) 由Master 上的JobTracker 程式指派Map 或Reduce 任務給Worker。 (3) 將檔案切成N 份的資料區塊，分配給各Worker 執行Map 任務。 (4) 將Map 結果寫入Worker 硬碟。 (5) 執行Reduce 任務的Worker，透過遠端程序呼叫讀取Map 任務中間資料結 果，並進行彙整和排序。 (6) 會依照既定的輸出格式存入HDFS。 使 用 者 程 式 Master (1)Fork (1)Fork (1)Fork (2)Assign Map (2)Assign Reduce Worker Worker Worker Worker Worker Map 結果 Map 結果 Map 結果 Map 結果 Map 結果 Map 結果 HDFS 檔案系統 資料1 資料2 資料3 資料4 資料5 HDFS 檔案系統 輸出結果1 輸出結果2 (3)Read (3)Read (4)Local Write (4)Local Write (4)Local Write (5)Remote Read (6)Write (6)Write Job Tracker Name Node 透過大數據與資料視覺化建構學術期刊於資訊安全研究演進 Google 於2008 年利用MapReduce，對Google 文件系統中未經壓縮文件檔案共 1TB 的資料量進行排序，利用1000 台電腦耗時68 秒完成排序(Czajkowski, 2008)。 Yahoo 公司團隊參與2013 年資料排序基準競賽(Sort Benchmark Competition)，參與 GraySort 項目選擇Daytona 類別為排序基準，使用2100 台Hadoop 主機處理102.5TB 的資料量，耗時72 分8.053 秒，每分鐘1.42TB 的處理速率(Graves, 2013)。為當時的 世界紀錄保持者。 Databricks 公司團隊也參與2014 年資料排序基準競賽(Sort Benchmark Competition)，使用Spark 參與GraySort 項目選擇Daytona 類別為排序基準贏得比賽， 刷新Hadoop 於2013 年競賽所保持紀錄，使用207 個節點(206 works and 1 master)之 Spark 叢集處理100TB 的資料量，耗時23 分25.98 秒，每分鐘4.27TB 的處理速率 (Xin, Deyhim, Ghodsi, Meng, & Zaharia, 2014)。
