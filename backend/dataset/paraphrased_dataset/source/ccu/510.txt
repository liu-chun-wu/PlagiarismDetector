護理記錄樣本在斷詞後的詞彙量龐大，而為了從中找到重要詞彙，可透過計算權 重分數TF-IDF 來達到特徵選取的目的，之後再從跌倒病患跌倒前的記錄中觀察權重 分數較高的關鍵字，以選取為與跌倒相關的危險因子，示意圖如圖 2 所示，Term 代 表詞彙、Rec 代表記錄。 [ ] 跌倒依變數 圖 2 詞彙-文件矩陣 第三章研究方法 而所使用的工具為Python package scikit-learn 0.19.2，其中所使用的公式依官方文 件所述，於表 8 說明API 及參數調整所使用的公式。 表 8 TF-IDF API 公式： 𝑡 𝑖  (𝑡,𝑑) = 𝑡 (𝑡,𝑑) × 𝑖  (𝑡) ( 1 ) API： CountVectorizer()： 𝑡 (𝑡,𝑑)，計算詞頻，詞t 在檔案d 中出現的次數。 TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)： 將𝑡 (𝑡,𝑑)再乘上𝑖  (𝑡)重新訓練。 參數 說明 norm 參數l2 為將𝑡 𝑖  權重分數做Euclidean normalization。 而據官方文件所述做tf–idf normalization，對于二元標記的資料，通 常可以找出更好的特徵，且對于可能出現雜訊𝑡 𝑖  值的短文，也提 供更穩定的結果。 use_idf 最後得到的權重分數 True：𝑡 𝑖 False： 𝑡 smooth_idf True：𝑖  (𝑡) = 1 + 𝑙𝑜𝑔 +𝑛𝑑 +𝑑𝑓(𝑑,𝑡) ( 2 ) False：𝑖  (𝑡) = 1 + 𝑙𝑜𝑔 𝑛𝑑 𝑑𝑓(𝑑,𝑡) ( 3 ) 𝑛𝑑=記錄總數、  (𝑑,𝑡)=包含詞t 的記錄數目。 分子分母各+1，是為了避免除以零的狀況。 𝑖  (𝑡)額外+1，是因即使詞t 在所有記錄皆有出現，其權重仍不該被 完全忽略。 sublinear_tf 詞頻公式 True： 1 + 𝑙𝑜𝑔𝑡 ( 4 ) False： 𝑡 ( 5 ) 資料來源：整理自scikit-learn
