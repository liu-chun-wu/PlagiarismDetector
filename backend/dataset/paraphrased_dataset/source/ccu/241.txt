Spark 是一個用於處理大規模數據快速閃電般的叢集分析引擎(Foundation, 2018)。 起源於加州大學柏克萊分校的AMPLab，採以開源叢集的計算框架。Spark保有Hadoop MapReduce 可擴展性和容錯能力，但擴展了幾個項目，編寫上變得更容易，提供了 Java、Python、Scala 和R 的程式語言API，支援各種複雜型計算任務，並具備以前需 透過其他工具才能處理的工作，如SQL 語法執行(Spark SQL)、串流資料處理(Spark Stemming)、圖像處理(GraphX)和機器學習(MLlib)(Zaharia et al., 2016)。Spark 提供多 種不同的叢集運作模式，分別是Local、Spark Standalone、Mesos、YARN 四種模式， Spark 擁有一個與MapReduce 類似的計算模型，稱為RDD(Resilient Distributed Datasets)(Zaharia et al., 2012)。RDD 為Spark 程式核心，RDD 計算儲存是透過記體體 來完成，而MapReduce 需透過HDFS 溝通才能完成計算結果，當MapReduce 涉及 HDFS 檔案系統，就會面臨I/O 頻繁存取效率的問題，因此Spark 的運算速度能比 透過大數據與資料視覺化建構學術期刊於資訊安全研究演進 Hadoop MapReduce 的運算速度快，並可以在不同平台執行，如Hadoop YARN、Apache Mesos 和Kubernetes，也可以探訪HDFS、Alluxio、Apache Cassandra、Apache HBase、 Apache Hive 和更多不同數據來源的數據資料，如今成為了現在主軸的大數據處理引 擎。 RDD 是由一至多個Partition 所組成(圖 4)，Partition 為資料分片區塊，會散佈在 不同的節點進行運算，並存在記憶體中。RDD 具有血統(Lineage)的特性，會記錄各個 Partition 的位置和父RDD 的依賴關係，以及父RDD 是透過何種運作而得出此RDD， 因此當某一個RDD 失效時，可透過血統(Lineage)特性，重新計算一個RDD，則為 RDD 之容錯機制。 圖 4 RDD 組成 資料來源：本研究整理 Spark 提供兩種操作RDD 的方式，轉換(Transformation)和行動(Action)。轉換是 從現有的RDD 產生新的一個RDD，行動是執行某個RDD 的運算處理，將其運算結 果回傳給客戶端或者將其儲存至外部儲存裝置。 RDD(Resilient Distributed Datasets) Partition Partition Partition 透過大數據與資料視覺化建構學術期刊於資訊安全研究演進
