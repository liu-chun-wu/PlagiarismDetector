將蒐集到的關鍵字於資料庫取出，於Science Direct 電子期刊網路平台進行期刊 搜，Python 使用Beautiful Soup 模組來進行網頁解析，以及Selenium 模組來進行模擬 網頁人為操作行為，Selenium 是因瀏覽器自動化(Browser Automation)之需求而設計的 一套工具，讓程式可以直接驅動瀏覽器進行各種網站操作執行。從Science Direct 搜 尋結果可以發現，其搜尋結果網址具有規則性，使用者設定結果篩選時，其查詢結果 畫面會把篩選條件呈現在網址上。在撰寫爬蟲程式時，可以透過此項規則，將關鍵字 和搜尋年份條件套用其規則，建立一個有效網址，再經由所撰寫的爬蟲程式進行網頁 解析後抓取搜尋結果。請參閱圖 8 網址規則範例圖。 圖 8 網址規則範例圖 資料來源：本研究整理 本研究蒐集期刊網址、期刊類型、文章標題、文章作者、文章作者介紹、期刊出 版社名稱、期刊年份、期刊卷數與期數、期刊頁碼、文章數位物件識別碼連結(Digital Object Identifier，簡稱DOI)、文章摘要和文章關鍵字。藉由中正大學電子資源入口網 Wikipedia Website Information Security 網頁內 容解析 語料庫 成功 失敗 透過大數據與資料視覺化建構學術期刊於資訊安全研究演進 站進行登入，輾轉網頁至Science Direct 電子期刊網路平台，即可查看各篇文章之全 文以及下載。資料蒐集將拆成兩個階段來進行資料蒐集。 第一階段，蒐集期刊網址、期刊類型、文章標題、文章作者、期刊出版社名稱、 期刊年份、期刊卷數與期數、期刊頁碼。請參閱圖 9 搜尋結果項目說明圖。我們使 用Beautiful Soup 模組在解析每篇期刊網址進行比較其差異性，從網址尾端會由英文 與數字組合而成之16~20 碼字串，可判斷此字串為各篇文章代碼，是唯一值，因此文 章代碼可減少資料庫資料空間。 圖 9 搜尋結果項目說明圖 資料來源：本研究整理 第二階段，蒐集文章作者介紹、文章數位物件識別碼連結(DOI)、文章摘要和文 章關鍵字。此階段藉由本校中正大學電子資源入口網頁(圖 10 中正大學電子資源入 口網頁)，藉由Selenium 模組語法執行登入動作(圖 11 Selenium 模組語法執行登入)， 再透過第一階段所蒐集各篇文章代碼，建立各篇文章有效網址，藉由瀏覽器進行網頁 探訪文章網頁獲得其網頁頁面原始碼，再透過Beautiful Soup 模組進行網頁解析，才 可蒐集文章資訊。可參閱表 3 Python 爬蟲程式資料蒐集架構。 期刊類型 期刊類型 期刊出版社名稱 文章作者 期刊年份 期刊頁碼 期刊卷數 透過大數據與資料視覺化建構學術期刊於資訊安全研究演進 圖 10 中正大學電子資源入口網頁 資料來源：本研究整理 圖 11 Selenium 模組語法執行登入 資料來源：本研究整理 透過大數據與資料視覺化建構學術期刊於資訊安全研究演進 表 3 Python 爬蟲程式資料蒐集架構 資訊安全關鍵字蒐集 期刊資料蒐集 第一階段 第二階段 資料來源：本研究整理 期刊資料蒐集需分為兩階段來進行處理，因於電子期刊網路平台搜尋結果非常巨 量，並且需要深入一層網頁蒐集其他明細資料，造成爬蟲設計在設計上的編寫難度增 加，抓取時間拉長。 分析從Wikipedia 所蒐集關鍵字和關鍵字進行期刊資料蒐集的篇數的結果，共38 個關鍵字和651326 筆期刊文章篇數，進行矩形式樹狀結構圖呈現，發現Exploits、 網頁內 容解析 語料庫 探訪Wikipedia 網站 並執行搜尋 成 功 失 敗 網頁內 容解析 資料庫 Science Direct 電子期 刊網路平台搜尋 成 功 失 敗 關鍵字 網站 登入 網頁內 容解析 資料庫 探訪各篇期刊網頁 成 功 失 敗 中正大學 電子資源入口網站 失 敗 成 功 文章代碼 透過大數據與資料視覺化建構學術期刊於資訊安全研究演進 Viruses 和Vulnerability 關鍵字為搜尋結果篇數前三名。請參閱圖 12 各關鍵字蒐集篇 數。 圖 12 各關鍵字蒐集篇數 資料來源：本研究整理
