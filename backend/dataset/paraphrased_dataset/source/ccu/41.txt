主題模型（Topic Model）為用來解析大量文本中抽象主題的技術，其結合 了機器學習與自然語言處理技術。在傳統文字探勘領域中，舊有的方法較難反 映字詞與不同文檔間字詞的關係。主題模型其結合統計與機率運算規則，對欲 分析語料庫中文件，產生主題、關鍵字與關鍵字間的分佈機率值，近年來主題 模型被廣泛應用於文件分群、推薦系統、資訊檢索等。 進行文本特徵探索，最早使用TF-IDF 方法來進行文本中關鍵字重要程度的 觀察(Salton & McGill, 1986)，之後透過SVD 奇異值取解方法衍生出LSA(Latent Semantic Analysis)潛在語意分析(Landauer, Foltz, & Laham, 1998)，在LSA 之後 使用機率方法衍生出PLSA(Probabilistic Latent Semantic Analysis)機率潛在語意 分析(Hofmann, 1999)，之後由PLSA 增加狄利克里分佈(Dirichlet Distribution)衍 生出LDA(Latent Dirichlet Allocation) 潛在狄利克里分配(Blei, Ng, & Jordan, 2003)。 在2003 年學者Beli 提出了潛在狄利克里分配的模型原理(Blei et al., 2003)，透過無監督學習的方式，僅需指定主題數量K 即可，訓練時無須手工標 註資料。其模型機率透過hyper-parameters α、β 對本身模型進行控制，α 控制文 章上主題分佈，β 控制主題模型，其表示形式為K(主題)xN(詞語)，θ 為給定參 數α 之機率分佈值，即為文本中個主題出現之機率，z 為給定參數θ 之機率分 佈值，即為主題中個詞語出現之機率，w 為文本中詞語。每篇文本θ 參數不 同，所產生主題z 分佈機率也不同，再與參數β 產生詞w，運作原理如圖2-5 與圖2-6 所示。 主題模型LDA 背後運用許多數學原理，包括Gibbs Sampling、Dirichlet Distribution、Dirichlet Multinomial、Gamma Function、Variational Inference、 新興跨領域發展趨勢智慧化分析技術之研究-以法遵科技為例 PLSI Modeling、Bayesian Statistical Modeling 等。 圖2-7 LDA Model 資料來源：(Blei et al., 2003) p(w|α, β) = ∫p(θ|α)(∏∑p(𝑧𝑛|θ)p(𝑤𝑛|𝑧𝑛, β 𝑧𝑛 𝑁 𝑛=1 )ⅆθ 圖2-8 LDA 聯合機率公式 資料來源：(Blei et al., 2003) 透過主題模型，從語料庫中文本找出抽象主題並生成對應的關鍵字，近年 來學術界與業界產生了許多應用。由於，不同領域資料特性不相同，至今有許 多不同主題模型實作版本，其適用範圍與模型特性也不同。如GibbsLDA、 JGibbsLDA 或透過Python Gensim 套件來實作。 影響LDA 模型運作指標有α、β 與主題數k，此三項指標設置有密不可分 之關係，學者Maskeri 指出為找出合適α、β 參數來建構LDA 模型，應透過充 分實驗觀察(Maskeri, Sarkar, & Heafield, 2008)。為衡量LDA 模型主題數k 設 置，學者提出Coherence 分數來衡量較佳的主題數(Mimno, Wallach, Talley, Leenders, & McCallum, 2011)。 新興跨領域發展趨勢智慧化分析技術之研究-以法遵科技為例
