對於百萬筆期刊文章資料，其儲存和計算資料是一項難題，而大數據架構可以有 效解決此難題。我們以Apache Spark 為核心建置Spark 叢集，藉由叢集式架構，可以 有效提升資料存取和計算的效率，並且於資料處理過程中，發生其中一架主機出現問 題，仍可透過Spark 容錯機制進行解決。 透過大數據與資料視覺化建構學術期刊於資訊安全研究演進 Spark 執行舉例，當我們使用Scale、Python 或Java 提請執行計算時，建立 SparkContent，其將連接到叢集管理器，透過叢集管理器來分配計算處理，後續再經 由各節點將資料回傳結果給執行端。請參閱圖 13 Spark 叢集執行概念圖。 圖 13 Spark 叢集執行概念圖 資料來源：本研究整理
