決策樹是用來處理分類問題的樹狀結構決策圖，決策樹的目的就是把數據集，依 目標類標籤嘗試進行最佳分割，選擇一個適合的特徵作為判斷節點，而這個選擇的目 標是讓分類後的類別更單一化，就是數據集更純化。首先，從上方的根開始，讓資料 依據特徵分割到兩邊，分割的原則為分割要能得到最大的資訊獲利（Information Gain，簡稱IG），資料量衡量單位為熵（Entropy），用於計算一個系統中的失序現象， 也就是計算該系統混亂的程度，圖5：分割時資訊量變化，為簡略說明分割時資料量 變化。 圖5：分割時資訊量變化 將數據集D 依照屬性月收入，將它分割為DL 與DR，其資訊獲利為： Gain(D, 收入) = H(D)－〔P(DL)× H(DL) + P(DR) × H(DR)〕                    (1) 資訊獲利（IG）=原本的資訊量－經由分割後的資訊量，而子集的分類資訊獲利就會 是：資訊獲利（IG）=原本的資訊量－左分割的資訊量－右分割的資訊量。資訊含量 值越小表示越容易辨別，因此分割後的資訊量要越小越好，才能獲得最大的資訊量（熊 平，民100）。
