人類在情緒的表達上是相當複雜的，像是透過各種表情的傳達、眼神的傳遞、各 式各樣的肢體語言、生理現象或利用文字的表達來顯現當下的情感狀態。由於人臉的 外形在不同觀察角度下產生表情、還有受光照條件（例如白天和夜晚，室內和室外等）、 遮蓋物（例如口罩、墨鏡和頭髮等）、年齡等多方面因素的影響，使得人臉的視覺圖 像也顯得不穩定。在語音方面，也受許多因素的影響，包括不同的說話人、說話方式、 環境噪音、傳輸通道等，都會造成系統在不同的應用環境、條件下辨識，讓結果無法 真正符合其本身正確性。 此外，在一般的情形下，每個人的自然表情以及當表情發生變化時的變化元素都 不完全相同，例如有些人的中性表情在一般不認識的人來看會覺得他是處在生氣的情 緒中，有些人的中性表情在一般不認識的人來看會覺得他是處在快樂的情緒中；當我 們熟識這個人的情形下，我們就會大概知道這個人的中性表情為何，而不會把他的中 性表情誤認為生氣或快樂。在機器人的應用上，我們希望將機器人比擬為人類，當這 個機器人在家庭中對於家中的成員或是機器人所熟識的人，可以知道這些人的表情變 化因素，如此，就可以讓機器人針對已知的這個人，讓機器人可以知道這個人確切的 表情，而不會誤認使用者的情緒。 因此，單純的使用單一方法來取得的情感或狀態都是不完整的，所以我們利用三 種臉部表情特徵萃取方法的結合，試圖了解人們更多的情緒資訊。並希望藉由情感運 算的參與，來加強情辨識結果的有效性、真實性及正確性。也由於近年來的文獻趨勢 發展，逐漸從單一模組進步到雙模以上的系統模組來提高情緒辨識度，這也代表系統 的開發方向逐漸往多樣化。所以，本計畫提出多方法系統為主的情緒辨識方法，來改 善只用單一方法來得出真正的結果，而且運用在智慧型手機上，在無須龐大的系統資 源下得以有效的降低系統成本，進而達到系統整合的目的。 多特徵自動化表情辨識系統
