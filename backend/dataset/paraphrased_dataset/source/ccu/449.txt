主成分分析 (Principle Component Analysis, PCA) (Calder, Burton, Miller, Young, & Akamatsu, 2001) (Kim, Jung, & Kim, 2002) 是一種常用的數據分析方法。PCA 通過線 多特徵自動化表情辨識系統 性變換將原始數據變換為一組各維度線性無關的表示，可用於提取數據的主要特徵分 量，常用於高維數據的降維。PCA 是人臉識別的主流方法之一。其核心思想是：重整 高維數據，提取其中的重要部分，忽略其中無關緊要的部分，換句話說，通過對原來 的樣本空間進行空間變換，使原來的座標投影到一個新的、維度較低的並且相互正交 的空間上。 給定維度等於 P 的數據集{x_1,…,x_n }，主成分分析的計算程序與結果可整理 成簡明的矩陣形式: 計算樣本平均 m = 𝑛∑ 𝑥𝑘 𝑛 𝑘=1 ，定義 n x p 階離差矩陣 X = [ (𝑥1 −𝑚)𝑇 (𝑥2 −𝑚)𝑇 ⋮ (𝑥𝑛−𝑚)𝑇] = [ 𝑥11 −𝑚1  𝑥12 −𝑚2 ⋯ 𝑥1𝑝−𝑚𝑝 𝑥21 −𝑚1  𝑥22 −𝑚2 ⋯ 𝑥2𝑝−𝑚𝑝 ⋮               ⋮            ⋱            ⋮ 𝑥𝑛1 −𝑚1  𝑥𝑛2 −𝑚2 ⋯ 𝑥𝑛𝑝−𝑚𝑝 ]         (3.9) P x P 階樣本共變異數矩陣則是 𝑆= 𝑛−1 ∑ (𝑥𝑘−𝑚) (𝑥𝑘−𝑚)𝑇 𝑛 𝑘=1 = 𝑛−1 𝑋𝑇𝑋          (3.10) 將 S 正交對角化為 S = 𝑊∧𝑊𝑇，其中 ∧= diag (𝜆1, … , 𝜆𝑝) 是特徵值矩陣，𝜆1 ≥ ⋯≥𝜆𝑝≥0 代表主成分的權值，W = [𝑤1 ⋯𝑤𝑝] 是單範正交特徵向量構成的 P x P 階正交主成分矩陣，𝑊𝑇𝑊= 𝑊𝑊𝑇= 𝐼𝑝。 定義 n x p 階主成分係數矩陣 Z = [𝑧𝑘𝑗]，其中 𝑧𝑘𝑗= (𝑥𝑘−𝑚)𝑇𝑤𝑗，因此 𝑍= [ (𝑥1 −𝑚)𝑇 ⋮ (𝑥𝑛−𝑚)𝑇 ] [𝑤1 ⋯𝑤𝑝] = 𝑋𝑊          (3.11) 上式等號兩邊右乘 𝑊𝑇，可得 𝑋= 𝑍𝑊𝑇。換一個說法，數據點 𝑥𝑘 的主成分分 解式為 多特徵自動化表情辨識系統 𝑥𝑘= 𝑚+ ∑𝑧𝑘𝑗𝑤𝑗 𝑝 𝑗=1 , 𝑘= 1, … , n         (3.12) 主成分係數 (𝑧𝑘1, . . , 𝑧𝑝) 是離差 𝑥𝑘−𝑚 參考單範正交基底 B = {𝑤1 ⋯𝑤𝑝} 的 座標向量。 HOG 與B-LBP 特徵向量維度很高，存在大量的冗餘訊息，這些訊息降低了識別 的精確度，也減緩了分類的速度。所以降維顯得非常重要，本研究採用PCA 對特徵 向量進行降維，能量保留比例90%。
