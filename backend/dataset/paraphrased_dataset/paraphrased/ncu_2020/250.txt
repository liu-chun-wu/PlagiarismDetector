神經網路使用激活函數是為了擺脫線性運算的限制，使其能夠學習複雜事物、處理複雜數據，並表示輸入輸出之間的非線性映射關係。如果沒有激活函數，神經網路的每一層都只是上一層輸出的線性組合，輸出和輸入始終保持線性關係，例如在二元分類問題中，不使用激活函數的簡單邏輯回歸只能進行線性劃分。以下介紹兩種激活函數：S形函數和雙曲正切函數。

S形函數的值域在(0,1)之間，具有單調連續且易於求導的特性，常用于二元分類神經網路的輸出層。然而，它的缺點是容易造成梯度消失，增加訓練難度。此外，由於輸出非零對稱（恆大於零），會減緩訓練速度，需要對神經元輸入進行預處理。S形函數也應用於長短期記憶模型中，控制閘門的開關程度。

雙曲正切函數的值域在(-1,1)之間，比S形函數收斂更快，而且輸出均值為零，不會影響訓練速度，因此是循環神經網路中最常用的激活函數。
