隨機梯度下降(SGD)是梯度下降法(GD)的一種，可用於處理迴歸和分類問題。它每次隨機從訓練集中選取一個樣本進行學習，計算參數梯度並沿梯度方向更新參數，能更快地從局部最小值趨向全局最小值。如同梯度下降法，對於凸函數，SGD可以收斂到全局極值點；對於非凸函數，則可收斂到局部極值點。
