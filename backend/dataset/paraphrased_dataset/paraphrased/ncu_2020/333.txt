Girshick et al. 提出的 R-CNN 利用選擇性搜索產生候選區域，再以卷積神經網路提取特徵，最後以 SVM 分類。但因每個候選區域都需個別提取特徵，速度較慢。

為改善速度，Girshick 後續提出了 Fast R-CNN，將整張影像輸入網路提取特徵，再利用 RoI 池化層處理不同大小的候選區域特徵，最後以 softmax 進行分類並以迴歸方法預測物件邊界框。

Ren et al. 進一步提出 Faster R-CNN，以區域建議網路(RPN)取代選擇性搜索產生候選區域，使物件偵測與辨識完全以卷積神經網路架構完成。

R-CNN 系列屬於二階段網路，需先定位再分類。而 Liu et al. 提出的 SSD 以及 Redmon et al. 提出的 YOLO 則屬於一階段網路，可同時完成偵測和分類。SSD 利用多尺度特徵圖偵測不同大小的物件。YOLO 則將影像切割成小方格，每個方格判斷是否有物件並預測其類別及大小，速度更快。Redmon 和 Farhadi 後續提出了 YOLOv2 (YOLO 9000)。
