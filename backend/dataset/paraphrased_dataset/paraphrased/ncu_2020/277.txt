Yanulevskaya (2008) 使用SVM分析IAPS藝術作品資料集，情緒分析平均準確率近六成。Cetintas 等人(年份略)提出基於DCNN的方法，分析Twitter和Tumblr資料集圖片的物體偵測，結合偵測到的物體與文字特徵進行情緒分類，平均準確率達六成五，超越傳統機器學習方法。You 等人(年份略) 基於CNN提出PCNN深度模型，去除表現不佳的圖像後訓練CNN，對Flickr資料集進行情感正負面分類，再將訓練好的PCNN模型遷移到Twitter資料集，平均準確率近八成。儘管CNN在圖像情感分析的準確率和泛化能力上展現潛力，但目前準確率仍遠低於文字情緒分類，且YouTube影片截圖的情緒可能與主題相關而非真實情緒，因此本研究不採用圖片情緒分類。
