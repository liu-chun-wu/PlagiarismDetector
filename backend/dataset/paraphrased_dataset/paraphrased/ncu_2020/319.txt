此研究改進了 Wang, Zhao, & Wang (2010) 提出的主題句提取公式(3)。原公式結合詞語頻率 (TF-IDF)、句子長度、句子位置和標題詞重疊率來提取關鍵事件句。公式(3)如下：

𝑆𝑆𝑖= 𝛼 * f(∑_{𝑤∈𝑆𝑖} 𝑡𝑓(𝑤) ⋅𝑖𝑑𝑓(𝑤)) / 𝐿𝑒𝑛𝑔𝑡ℎ𝑖 + 𝛽 * f(𝐿𝑒𝑛𝑔𝑡ℎ𝑖) + 𝛾 * f(Position𝑖) + 𝛿 * f(∑_{𝑤∈𝑇} ∑_{𝑤∈𝑆𝑖} 1 ) / (|𝑇| ⋅Length𝑖)

其中，α、β、γ、δ 分別為各部分的權重，f(x) 為正規化函數：𝑓(𝑥) = 𝑥/(∑_{𝑆𝑖∈𝐶} 𝑥)，C 為新聞內容。

考慮到 Ning & Liu (2016) 的研究發現 TextRank 結合 Word2Vec 在關鍵詞提取方面表現優於 TF-IDF，且 TextRank 亦考慮詞頻，而 TF-IDF 受語料庫影響較大，本研究將公式(3) 中的詞頻部分替換為 TextRank+Word2Vec 分數，得到公式(4)：

𝑆𝑆𝑖= 𝛼 * f(∑_{𝑤∈𝑆𝑖} 𝑇𝑒𝑥𝑡𝑅𝑎𝑛𝑘(w)) + 𝛽 * f(𝐿𝑒𝑛𝑔𝑡ℎ𝑖) + 𝛾 * f(Position𝑖) + 𝛿 * f(∑_{𝑤∈𝑇} ∑_{𝑤∈𝑆𝑖} 1 ) / (|𝑇| ⋅Length𝑖)

研究使用中文維基百科訓練 Word2Vec 模型，並使用 WikiExtractor 清理資料、OpenCC 進行簡繁轉換，再進行斷詞和停用詞去除。Word2Vec 訓練參數設置如下：`size=200`，`sg=1`，`window=10`，`min_count=64`。

TextRank 部分則改進了傳統的句子相似度計算方法，使用 Word2Vec 計算詞向量餘弦相似度取代原公式(5) 中基於共同詞語個數的計算方式。句子權重則使用 TextRank 公式(7) 計算，並進行正規化。此外，由於 TextRank 已考慮句子長度，因此正規化時移除長度因素。

句子長度分數以句子字數除以文章總字數計算。句子位置分數基於 Edmundson (1969) 的研究，段落越靠前分數越高，並進行正規化。標題重疊率分數基於 Paice (1990) 的研究，計算句子與標題共現詞數，並進行正規化。

最後，將四個正規化分數乘以各自權重，得到句子總分，選取分數最高的 N 個句子作為主題句集合。
