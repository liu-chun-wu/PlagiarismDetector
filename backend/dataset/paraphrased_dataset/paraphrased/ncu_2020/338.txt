YOLOv3 原本只使用 RGB 三通道數據進行平面物體偵測，為獲取深度資訊以進行三維物體偵測，輸入端新增單通道深度資料，形成 RGB-D 四通道輸入，並以 Darknet-53 提取特徵。物件偵測方面，cx, cy 代表影像左上角到網格的水平及垂直距離，σ為 sigmoid 函數，tx, ty 為預測物件中心點座標，tz 為預測深度，pw, ph, pl 為網格中錨框的長寬高。不同於 YOLOv3 根據特徵圖調整錨框尺寸，此處錨框尺寸代表相機座標下的物件長寬高，不隨特徵圖改變；tw, th, tl 則為預測框長寬高比例，qt , 1qt , qt , qt 為以四元數表示的預測框旋轉姿態，對應邊界框值 bx, by, bz, bw, bh, bl, qb , 1qb , qb , 3qb。9DoF SE-YOLO 輸出張量包含物件在三維空間下的 9DoF 資訊：平移分量 x, y, z，旋轉分量 q0, q1, q2, q3，以及真實世界下的長寬高 w, h, l。預測值 x, y 為圖像座標，透過預測值 Tz 與相機內參矩陣，利用公式 (3.1)  (Tx = x * Tz / f + px, Ty = y * Tz / f + py，其中 f 為相機焦距，(px, py) 為影像平面中心點)  計算物件邊界框平移分量 Tx 和 Ty，並以預測值 w, h, l 建立邊界框八個角點，最後以 q0, q1, q2, q3 計算物件邊界框的旋轉姿態。
