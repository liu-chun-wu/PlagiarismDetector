由Li Zhao構想的注意力機制結合長短期記憶模型 (Y. Wang et al., 2016) 能夠根據不同視角，將注意力集中在評論句子的不同部分。該模型基於長短期記憶模型，架構如圖3.3所示。其中，N代表句子中單詞的總數，w代表每個單詞的詞向量，h代表長短期記憶模型在各個隱藏層的輸出向量。最後一個隱藏層的輸出向量經由softmax函數得到預測結果。長短期記憶模型的計算公式如下：

𝑖𝑡= σ(𝑊𝑖𝑥𝑡+ 𝑈𝑖ℎ𝑡−1 + 𝑏𝑖) 
𝑓𝑡= σ(𝑊𝑓𝑥𝑡+ 𝑈𝑓ℎ𝑡−1 + 𝑏𝑓) 
𝑜𝑡= σ(𝑊𝑜𝑥𝑡+ 𝑈𝑜ℎ𝑡−1 + 𝑏𝑜) 
𝑔𝑡= tanh(𝑊𝑔𝑥𝑡+ 𝑈𝑔ℎ𝑡−1 + 𝑏𝑔) 
𝑐𝑡= 𝑓𝑡∙𝑐𝑡−1 + 𝑖𝑡∙𝑔𝑡 
ℎ𝑡= 𝑜𝑡∙tanh(𝑐𝑡) 

公式中，it、ft 和 ot 分別代表t時刻輸入門、遺忘門和輸出門的值。Ct-1代表上一時刻記憶體儲存的內容，ct代表當前時刻記憶體儲存的內容。σ代表Sigmoid函數，「∙」代表矩陣的逐元素相乘。xt代表當前時刻的輸入數據，ht-1代表上一時刻長短期記憶模型的輸出，ht代表當前時刻長短期記憶模型的輸出。Wi、Wf、Wo 和 Wg 分別是輸入數據的權重矩陣，Ui、Uf、Uo 和 Ug 分別是隱藏層輸出數據的權重矩陣。bi、bf、bo 和 bg 分別是偏差項。

圖 3.3 長短期記憶模型架構圖(Y. Wang et al., 2016)
