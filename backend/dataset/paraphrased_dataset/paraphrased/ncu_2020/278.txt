Kang [14] 和 Gibert [15] 使用基於顏色、運鏡等低層視覺與音訊特徵的隱馬爾可夫模型分辨影片情緒，但這些特徵無法表達語義概念。Xu [16] 利用文本和圖片輔助影片情感識別，透過 CNN 提取人臉表情，準確率為 52%。Fan [17] 在 EmotiW2016 比賽中，結合深度學習分析人物表情、動作和語音語調，達到 59.02% 的準確率，高於 EmotiW2015 的 53.8%。深度學習分析高階影片特徵提升了準確率和語義理解，但目前影片情緒分類仍主要關注人物表情和動作，遷移學習至其他資料集需特徵相似，且準確率遠低於圖片和文字情緒分類。
