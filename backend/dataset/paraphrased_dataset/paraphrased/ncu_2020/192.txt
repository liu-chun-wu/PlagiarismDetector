中文文本由字詞組成，詞彙是具有語意的最小單位，也是分析方法的重點。英文分詞可依空格切分，較為容易，還能依詞幹調整；中文則無空格和詞幹，需要依語意斷詞。

先前清洗後的資料集，進行中文詞性分詞、特徵詞提取、建立關鍵詞庫等整理。使用自行開發的詞性分類工具 (Python＋CKIP套件)，以CKIP分詞技術處理5845筆資料集。

利用文本探勘技術分析Google Play商店客訴留言，以自行開發的Python程式與CKIP套件，針對關鍵欄位 (New Review Text) 進行中文斷詞。斷詞後的CSV檔，透過Orange軟體的文字探勘套件，繪製不同詞性(名詞、動詞、連接詞、副詞、介係詞、語助詞、感嘆詞等)的特徵詞彙文字雲和語料集，包含7個主類別詞性與35種次類別詞性。接著，利用Orange軟體的文字預處理和文字雲功能，計算詞頻(TF)，篩選詞頻高於10的特徵詞彙，建立關鍵詞彙庫 (Keywords.txt)，並將這些高頻詞彙認定為有意義的詞彙，低頻詞彙則暫不列入。最後，將這些高頻關鍵詞彙作為自變數使用。

(圖 3 關鍵詞彙清單省略)

本文詞性特徵詞提取 - 自行開發Python程式碼範例：
pipeline = CkipPipeline()
strPosN = ["A","Caa","Cab","Cba","Cbb","Da","Dfa","Dfb","Di","Dk","D","Na","Nb","Nc","Ncd","Nd","Neu","Nes","Nep","Neqa","Neqb","Nf","Ng","Nh","Nv"]
strPosV = ["I","P","T","VA","VAC","VB","VC","VCL","VD","VE","VF","VG","VH","VHC","VI","VJ","VK","VL","V_2"]
利用文本探勘技術分析Google Play商店客訴留言。
