FOTS [33] 可偵測、分類影像文字並估計其二維方位。它由共享卷積網路骨幹、文字偵測分支、RoIRotate 操作和文字辨識分支組成。文字偵測分支輸出六個通道：像素分類、到邊界框四個邊界的距離，以及旋轉角度。RoIRotate 將帶角度的文字塊轉正，文字辨識分支則使用LSTM [34]、全連接層和CTC 解碼器輸出辨識結果。

R3Det [35] 是一個一階段旋轉物件偵測器，由RetinaNet [19]、特徵精煉模組 (FRM) 和精煉階段組成。RetinaNet 進行初始偵測、分類和角度預測。接著，預測的邊界框資訊和特徵圖送入FRM進行特徵重構，最後，精煉階段參考 RefineDet [31] 再次迴歸，得到更精確的輸出。

3D 物件方位估計網路可依輸入資料分為 RGB、RGB-D 和點雲三類。PoseCNN [36] 使用 RGB 影像，直接迴歸物件的 9DoF 姿態，平移分量透過中心點預測和語意分割結合霍夫投票決定，旋轉分量則使用RoI池化和全連接層迴歸四元數。

使用 RGB-D 輸入的 Tekin et al. [37] 修改了 YOLOv2 的 Darknet-19 架構，迴歸物件邊界框的八個角點和中心點，輸出3D 邊界框的圖像座標，並提出新的信心函數取代 3D IoU 計算。最後使用 PnP 演算法求解 3D 平移和旋轉分量。

PointRCNN [38] 是一個基於點雲的兩階段車輛偵測網路。第一階段使用 PointNet++ [39] 提取全域語意特徵，對點進行語意分割，並為每個前景點生成邊界框，最後用非最大值抑制篩選候選框。第二階段將候選框及其內點轉換到局部坐標系，提取局部空間特徵，並結合第一階段的全域特徵，用多層感知機迴歸精煉的邊界框和信心分數。
