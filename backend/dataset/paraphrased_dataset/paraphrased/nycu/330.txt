音訊樣本以10秒(10000毫秒)為單位嫁接。樣本的取樣頻率、音框取樣點數(23.2199546485261)以及重疊的取樣點數(11.609977324263)皆已設定。每個音訊樣本轉換成MFCC特徵，時間步長(Time Step)為861.328125。每個音訊轉換為20個特徵值 x 863個音框的MFCC圖作為輸入。模型的第一層為一維卷積神經網路，kernel size為15，輸出維度為4 x 849 x 196。接著是兩層GRU層，每層輸出128個Units。模型使用5x5的MaxPooling和Dropout (0.25)來提取特徵並防止過擬合。最後，透過平坦層和全連接層，並以Softmax函數輸出分類結果。訓練過程使用categorical_crossentropy作為損失函數，並使用Adam優化器。
