Word2vec的理想用法是直接使用預訓練模型，兼具廣度且省去訓練成本。英文已有Google團隊提供的泛用模型，但中文免費資源匱乏，通常需要自行訓練，類似其他空間向量模型的重新編碼，這是中文空間向量轉換的共同問題。Word2vec的優勢在於利用上下文預測的訓練方式，無需事先標記句子特徵，並能涵蓋局部上下文資訊。

如果重新訓練不可避免，可考慮Word2vec衍生的Doc2vec。同樣由Tomas Mikolo團隊提出，Doc2vec在訓練中加入文本ID，產生的模型如同空間向量型的句子索引，能比較句子間的上下文相似度，提供更多分類特徵。
