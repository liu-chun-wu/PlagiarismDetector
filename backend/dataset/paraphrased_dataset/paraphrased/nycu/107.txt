分類器，尤其是樹狀模型，通常要求輸入固定長度。然而，預處理後的中文文本長度不一，因此仰賴embedding技術來銜接分類器輸入層。詞袋模型使用稀疏矩陣，為每個詞彙建立獨立的屬性欄位，特徵數量決定了欄位數量，因此細緻的特徵提取會導致高維度。One-Hot Encoding 即是此方法的典型例子。空間向量模型，例如Word2vec和Glove，則在訓練過程中就輸出固定長度的向量。這些方法主要為神經網路設計，因為各種神經網路變體都需要固定維度的輸入向量。
