Camera network用於檢測和追蹤時，網路負擔很大。文獻[5]指出，正確預測目標運動方向能有效減少Camera間的訊息傳遞。當目標出現在多個Camera視野(FOV)時，資訊會傳給主節點以決定定位責任。定位過程中，即使目標運動方向隨機，系統仍會選擇距離FOV邊緣最遠的方向作為預測運動方向，以減少不必要的訊息消耗。

為提高人物辨識精度，文獻[9]提出基於3D生物識別功能的camera network框架重建方法。該方法使用深度相機捕捉目標深度資訊，利用3D背景減法獲取前景目標，並透過粒子濾波器修正圖像變形、檢測錯誤或半遮擋。若多個目標身高相同，則利用前景目標的深度資訊生成3D直方圖。系統會建立矩陣判斷目標在重疊相機中的出現和離開。對於非重疊相機，則利用時變資訊推斷目標最後速度和消失時間。各Camera間形成一個概率數據關聯(PDA)追蹤問題，最後出現目標的Camera需分享特徵向量、目標位置、ID和消失時間等資訊。

針對畫面不相交和光線變化造成的追蹤難題，文獻[10]利用時空資訊預測下一個Camera的狀態，並使用Q-learning進行訓練，無需預設camera network拓撲資訊。當目標出現在新Camera後，系統會利用數幀畫面找到目標位置並學習camera拓撲。該方法存在一些限制：1. Camera交集過少時，時間間隔顯示學習效果不佳，epsilon-greedy策略對完全探索幫助不大。2. 訓練人數增加可擴大狀態空間探索，但標註成本高昂。3.  需要線上更新標註集以重新識別，避免因識別錯誤導致追蹤錯誤的人。
