中文敘述欄位經斷詞後，分別以One-Hot Encoding、tf-idf和Doc2vec三種方式轉換。One-Hot Encoding產生二元特徵矩陣，以詞的索引編碼；tf-idf產生鬆散矩陣，包含詞的統計資訊，並體現單詞對所在句子及其他句子的重要性；Doc2vec則產生空間向量，藉由預測前後文權重組合，包含局部上下文資訊。

模型參數最佳化方面，隨機森林採用grid search，搜尋範圍為10至100棵樹以及葉節點最小資料量1至8，最終選定90棵樹、gini index作為Information Gain、葉節點最小資料量為2。XGboost則使用hyperopt函式庫，搜尋範圍包含最大深度15、樹數量300、學習率0.001至0.5、最小子權重6以及子樣本比例5，經20組參數、100個測試行程後，最佳參數為學習率0.038210、最大深度4、最小子權重5、樹數量22。MLP則搜尋三層隱藏層的組合，範圍從(10,10,10)至(100,100,100)，最終採用(19,19,19)的五層設計。

實驗採用5,210筆調整後的母體資料進行訓練，並隨機抽取34%母體資料作為測試集。實驗以三種預處理方法搭配三種分類器，共九種組合進行訓練和測試評估。
