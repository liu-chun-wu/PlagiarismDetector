深度學習常用於處理結構複雜的資料，它能藉由學習大量無標籤資料來擷取特徵。深度學習模擬生物大腦神經元運作，透過輸入值、觀測值的權重以及誤差值，並利用激勵函數調整來建立模型。模型會以損失函數評估，再使用梯度下降法和反向傳播修正參數，以降低損失並優化模型。以下介紹各階段的函數計算。

激勵函數使類神經網路成為非線性模型，提升其處理複雜問題的能力。如果只用線性組合，輸出與輸入會呈線性關係，失去模型的意義。常用的激勵函數包括：

S函數 (Sigmoid function) 將輸入值透過公式(1)轉換為0到1之間的非線性輸出值。

雙曲正切函數 (Hyperbolic tangent function, tanH) 將輸入值透過公式(2)轉換為-1到1之間的非線性輸出值。

線性整流函數 (Rectified linear unit, ReLU) 輸入小於0時輸出為0，輸入大於等於0時輸出等於輸入。它可以避免輸入接近飽和區時產生梯度消失，使訊息能有效地透過反向傳播傳導。
