為建立準確的跑步姿態辨識模型，避免個體差異造成的預測偏差，本研究採用基於個人模型的識別方法。具體來說，為每個人訓練一個模型，利用其跑步波形預測下一步的姿態。識別時，將待測者的跑步數據輸入所有個人模型，預測結果最準確的模型對應的身份即為待測者身份。

模型採用線性回歸。通過訓練，模型學習上一步姿態數據（24個x, y節點坐標，共48維）與下一步姿態數據之間的線性關係。資料來自四個人在四個不同角度拍攝的跑步數據，因此共建立16個模型。

特徵選取方面，使用五天以上、已分割且等長的十六個身體節點運動軌跡數據。由於並非所有節點都具有有效的辨識資訊（例如頭部節點移動較小，腕部節點移動具週期性但個體差異大），因此需要選取關鍵節點。考量到跑步機上人體的位移，特徵選取採用相對位置，即以身體某一點為原點，計算其他點與原點的相對坐標。

特徵選取流程如下：

1. 遍歷所有十六個節點的兩兩組合，計算相對坐標作為特徵。
2. 每個人每天的數據輪流作為測試數據。
3. 剩餘數據作為訓練數據，為每個人訓練一個模型（共四個模型）。
4. 將測試數據輸入四個模型，得到每一步的下一步預測數據。
5. 計算預測數據與真實數據的歐式距離。
6. 平均所有歐式距離。
7. 若本人模型預測結果的平均歐式距離最小，則辨識成功。
8. 若連續七天數據均辨識成功，則該節點組合有效。
9. 最終選取四個人均有效的節點組合的交集作為最終特徵。
