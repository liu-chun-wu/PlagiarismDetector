本論文基於車輛配備RGB相機拍攝前方環境，並透過深度學習辨識前方車輛。同時，假設所有車輛均配備CAN Bus，並定期透過V2V通訊交換車輛資訊（顏色、車型等）和駕駛狀態（加速、剎車等）。論文目標是將前方車輛影像與正確的車輛資訊配對。

系統架構如下：駕駛車輛使用相機拍攝前車影像，並接收V2V廣播封包，透過數據融合將車輛影像與對應資訊成功配對。

車輛偵測採用YOLO演算法標記Bounding box，以左上角和右下角座標儲存，表示式為𝑉𝑉𝑖𝑖=[(x,y)TopLeft,(x,y)BottomRight]，代表圖片中第i輛車的bounding box。例如，圖中兩台車：𝑉𝑉1 = [(251, 411), (503, 549)]，𝑉𝑉2 = [(576, 427), (745, 555)]。透過計算，可獲得駕駛車與前車的距離和角度。

每輛車定期廣播包含車輛資訊（車牌、顏色、款式、GPS位置等）和駕駛狀態（車速、剎車、轉彎等）的封包。

論文利用GPS位置和磁力計進行車輛配對。問題定義如下：駕駛車x在時間t獲取自身位置x(t).loc和方向x(t).ot（指向北方為0°，南方為180°）。同時，相機拍攝照片I(t)，經YOLO識別n台車輛，表示為V(t) = {v𝑖𝑖(t)|1 ≤i ≤n}，v𝑖𝑖(t)指第i台車。此外，車輛接收m個廣播封包B(t) = {bj(t)|1 ≤j ≤ m}，其中bj(t)包含車輛款式、顏色、車牌、位置等資訊。目標是根據V(t)和B(t)，獲得正確的配對組合S(t)：𝑆𝑆(𝑡𝑡) = {(𝑣𝑣𝑖𝑖(𝑡𝑡), 𝑏𝑏𝑗𝑗(𝑡𝑡))|𝑣𝑣𝑖𝑖(𝑡𝑡) ∈𝑉𝑉(𝑡𝑡) 且 𝑏𝑏𝑗𝑗(𝑡𝑡) ∈𝐵𝐵(𝑡𝑡)}。
