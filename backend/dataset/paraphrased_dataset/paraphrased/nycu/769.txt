YOLOv1 和 YOLOv2 的網路架構相似，都為了實現 YOLO 系列獨特的偵測流程。以 YOLOv2 為例，它將 416x416x3 的 RGB 影像輸入，輸出 13x13x125 的特徵圖。  影像被切割成 13x13 的網格，每個網格預測 5 個候選框，每個候選框用 25 個參數 (x, y, w, h, confidence, class1,...class20) 表示位置、大小、置信度和 20 個類別的概率。因此，輸出層為 13x13x125。  YOLOv2 共預測 13x13x5=845 個候選框，經過篩選低置信度和重複框後得到最終結果。YOLO 系列大致遵循此流程，YOLOv1 切割成 7x7 網格，YOLOv3 的切割方式則有所不同。

YOLOv2 的網路架構包含特徵提取器和偵測層，並利用跳過連接 (或穿過層) 將更上層的細膩特徵與下一層的特徵串連，以保留更多細節。然而，由於不斷的減量採樣，YOLOv2 在小物體偵測上表現仍有不足，這也是 YOLOv3 改進的重點。
