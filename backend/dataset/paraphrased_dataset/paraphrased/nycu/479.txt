在衣著辨識研究中，常見方法是先找出衣服位置再進行辨識。Lukas[6]先定位臉部，藉此推斷上半身衣著的邊界框，並提取SURF、LBP、HOG、Self-Similarity等特徵組成序列，再以結合遷移學習的隨機森林進行衣著屬性學習，平均準確率達41.4%，但僅針對上半身衣著。Yannis[7]則利用姿態偵測獲取身體部位，再進行區塊分割和聚類（圖2-1），區分出手肘、頭部、衣服等部位，並以局部敏感雜湊索引衣著屬性類別，以RGB和LBP特徵描述顏色屬性，平均準確率達54%。Ziwei[8]利用類似VGG16的FashionNet網路架構（圖2-2）進行分類，該網路包含三個分支：預測衣服關鍵點、結合關鍵點提取局部特徵、提取全域特徵，最後合併局部和全域特徵預測衣服類別和屬性。Kuan[9]提出利用衣著屬性判斷衣服是否當季流行，其架構先以類似VGG16的架構訓練噪聲偵測模型去除衣服上不相關圖案，再進行姿態估計提取影像特徵，最後以SVM分類並判斷是否流行，準確率高達63%。
