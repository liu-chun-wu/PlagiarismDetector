本節將使用實際拍攝的空拍影像資料集對YOLOv3進行微調訓練。首先介紹使用的空拍影像資料集，接著說明微調訓練的方法。

為使微調後的YOLOv3更適合偵測空拍影像中的人物，我們蒐集了包含不同俯仰角度、高度、場景的空拍影像，並標註人物位置，共1340張，建立空拍影像資料集。其中1250張作為訓練集，90張作為驗證集。

空拍影像人物偵測與一般影像人物偵測相似，因此可透過微調訓練使YOLOv3適應空拍影像，不必從零開始訓練。YOLOv3由特徵提取器Darknet-53和偵測層組成。原模型訓練方法為先在ImageNet上預訓練Darknet-53，再以COCO資料庫訓練整個YOLOv3。由於我們的空拍資料集比COCO小很多，因此我們沿用YOLOv3的參數繼續訓練，凍結Darknet-53的參數，僅更新偵測層參數，以適應空拍影像人物偵測。

訓練過程也進行資料擴增，包含翻轉、旋轉、調整曝光度等，以解決資料不足並提升準確度。訓練參數設定為：批次大小64，學習率0.0005，訓練10,000次迴圈。此設定是期望1250張訓練影像經資料擴增達五倍影像量，並使模型遍歷整個資料集100遍。微調訓練後，先前無法偵測到的行人也能成功偵測。
