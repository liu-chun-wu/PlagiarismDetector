LeCun 於 1989 年發明了最早的 CNN 架構 LeNet，但受限於當時的硬體和演算法發展，CNN 的效率未受重視，效果也遜於其他特徵提取方法如 SVM。隨著硬體技術的進步，ReLU 函數、Dropout 層、數據增強、GPU 平行運算和大數據的出現，促成了 2012 年 AlexNet 的誕生，並在 ImageNet 圖像分類競賽中取得突破性成果，錯誤率大幅降低，讓 CNN 重新受到關注。AlexNet 的成功主要歸功於 ReLU 函數加速收斂、Dropout 層減少誤差和避免過擬合、數據增強提升準確率，以及 GPU 平行運算縮短訓練時間。

AlexNet 的出現帶動了 CNN 架構的蓬勃發展。2013 年出現的 NIN 提出了 1x1 卷積，增加卷積層組合性並減少參數，這個概念後來被 ResNet 和 Inception 等架構沿用。2014 年，VGG 使用多次 3x3 卷積提取更複雜特徵，但訓練速度慢且權重數量多。同年，GoogLeNet  及其 Inception 微架構，結合不同大小的卷積和池化層，使網路橫向拓展，後續又發展出 Inception V2、V3 和 V4。2015 年，ResNet 結合 VGG 和 NIN 的概念，並使用全局平均池化取代全連接層，在加深網路的同時減少權重數量。

除了圖像分類，CNN 也被應用於物體檢測。2014 年的 R-CNN 和 2015 年的 SPPNet  提出先框選特徵範圍再提取特徵的概念，進一步推動了 CNN 技術的發展。
