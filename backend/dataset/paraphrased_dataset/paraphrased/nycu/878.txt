Reference images were generated by rendering reconstructed 3D models from different viewpoints.  Models are classified as either general (asymmetric) or symmetric (rotationally symmetric about a coordinate axis).  General models use 25 viewpoints (5 samples along both the x and y axes of a hemisphere). Symmetric models use 13 viewpoints sampled on a semi-circle.  These viewpoints represent out-of-plane rotation.  For each viewpoint, 24 images are rendered with 15-degree increments of in-plane rotation (z-axis). This is illustrated in Figure 3. Figure 4 shows examples of both model types and their reference images.  The general model (a) uses 25 viewpoints, with axes visualized in red (x), green (y), and blue (z). The symmetric model (b) uses 13 viewpoints on a semi-circle.  The in-plane rotation generates 24 reference images, as shown in (c).

Chapter 4 details object recognition and pose estimation in online processing.  Foreground segmentation to isolate the target object is described in Section 4.1.  The object recognition algorithm is presented in Section 4.2. Section 4.3 explains how to check and correct pose reversal in matching results. The detection state flowchart is shown in Figure 5.
