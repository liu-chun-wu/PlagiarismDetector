先前章節(3.3.2至3.3.5)的訓練和測試皆基於整張影像，如同一般網路架構的訓練方式。這些影像大多數由投射型攝影機拍攝，人物呈現頭上腳下、垂直於畫面水平線的姿態。然而，本研究針對的是頂照式魚眼攝影機下的影像，其中人物呈現不同特性：影像中心的人物僅顯示頭頂和肩膀或半身；越靠近邊緣區域，人物越完整，且頭腳方向指向影像中心，外觀變形也較大。

因此，本章節將影像劃分為中心區域和外圍區域，並針對兩區域分別訓練不同的模型。

中心區域影像以原影像中心為圓心，半徑為原影像邊長一半的2/3，擷取圓形區域。其對應的mask則以原影像中心為圓心，半徑為原影像邊長一半的1/2，凡完全包含在圓內或與圓相交的mask才被視為ground truth。

外圍區域影像以原影像中心為圓心，擷取半徑為原影像邊長一半的1/2 之圓以外的區域。此區域被分割為三個140度的扇形區域(彼此重疊20度)，再經由最近相鄰內插法轉正拼接成一張訓練影像。其mask的ground truth定義為：將每個扇形區域向內縮減30像素形成一個內接矩形，凡完全包含在內接矩形內或與其相交的mask才被視為ground truth，位於矩形外的mask則不予採計，因為這些mask通常只佔影像極小範圍或僅擷取到部分身體。

三個扇形區域彼此重疊20度是為了避免人物位於分割線上而被切斷，確保完整人型的存在。中心區域和外圍區域的設定也刻意重疊，以避免因區域分割而減少ground truth。
