自然語言方向的機器學習偏見研究，目前主要分為詞嵌入和聊天問答兩種模型。詞嵌入模型是主流方法，因其類比關係能反映真實世界概念間的關係，適合探討文化中的隱含偏見。

Aylin Caliska等人(2017)分析Glove詞嵌入，驗證心理學內隱連結測驗(IAT)揭示的認知偏見。IAT透過配對概念所需時間的長短，量化人類偏見。例如，研究發現人們將昆蟲與「不愉快」配對更快，而將花朵與「愉快」配對更快。IAT能揭示人們未意識到的深層想法，例如，研究顯示歐洲裔美國人的名字更容易與「愉快」聯繫，而非洲裔美國人的名字更容易與「不愉快」聯繫；女性的名字更容易與「家庭」聯繫，男性則與「職涯」聯繫。

Aylin Caliska等人(2017)提出了詞嵌入關聯測試(WEAT)和詞嵌入真實關聯測試(WEFAT)來評估詞嵌入的偏見，並與IAT研究結果比較以驗證其有效性。Bolukbasi等人(2016)則以Google News訓練的詞嵌入，找出性別相關的職業對（例如，護士-外科醫生），並提出Hard de-biasing和Soft de-biasing兩種方法去除詞嵌入中的性別偏見。

在聊天問答模型方面，Rudinger等人(2018)設計句子樣板，透過指代名詞替換，評估和確認語意中的性別偏見，並與真實世界的性別職業統計數據比較。Zhao等人(2017)則在影像預測的條件隨機場(CRF)模型中加入語料層級限制，降低詞彙出現機率的不均，實現影像識別任務的去偏見化。

本研究基於Bolukbasi等人(2016)的詞嵌入去偏見化研究，使用序列到序列條件生成模型(Seq2Seq)訓練聊天機器人，並加入以詞嵌入中立性為目標的限制，達成深度學習序列模型的去偏見化，並嘗試擴展中性字的定義和適用範圍，驗證模型的泛化能力。
