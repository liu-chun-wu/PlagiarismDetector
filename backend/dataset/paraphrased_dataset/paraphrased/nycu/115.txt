實驗旨在測試Doc2vec對模型的適性。Doc2vec與其他兩種預處理方法不同，它並非基於互斥特徵，例如50維並不代表僅記錄50種特徵，而是混合了資料特性。

表11的實驗結果顯示，Doc2vec預處理後的資料在分類模型訓練的整體評價上不如其他兩種方法，但對分類模型的影響卻截然不同。圖15、16、17顯示，維度增加確實強化了分類能力。MLP模型使用Doc2vec預處理時，未出現提升某分類鑑別力卻降低另一分類鑑別力的情況，顯示Doc2vec在神經網路訓練上的適性更佳。其他兩種分類器則弱化了分類5的鑑別力，同時提升了其他分類的鑑別力。分析Doc2vec與其他方法的差異，主要在於是否包含語序特徵。推測語序特徵包含了非1、5類的分類特徵。表13、14顯示，訓練的分類模型對分類1、5的反向資料鑑別力相對顯著，支持了此推測。

比較分類12的效益，tfidf無提升效果，One-Hot Encoding的f1 score可達0.15，關鍵字數50時隨機森林可達0.2。同樣在隨機森林模型中，Doc2vec的f1 score穩定在0.18到0.19之間，XGBoost則在0.15到0.17之間。
