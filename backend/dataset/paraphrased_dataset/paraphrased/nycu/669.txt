Seq2Seq模型是一種編碼器-解碼器架構，用於處理輸入和輸出皆為序列，但順序、結構或長度可能不同的問題。它在機器翻譯和聊天機器人等自然語言處理領域有廣泛應用。

Seq2Seq模型通過編碼器將輸入序列 (𝑥₁, … , 𝑥𝑀) 映射成定長表徵向量c，再由解碼器將c還原成輸出序列 (𝑦₁, … , 𝑦𝑁)。編碼器和解碼器通常由RNN，尤其是LSTM構成。模型表示如下：

p(𝑦₁, … , 𝑦𝑁|𝑥₁, … , 𝑥𝑀) = ∏ 𝑝（𝑦𝑡|𝑐, 𝑦₁, … , 𝑦𝑡−1） (t=1 to N)

**編碼階段：**

輸入序列經由編碼器函數𝑓𝑒𝑛𝑐 產生表徵向量c。若輸入為文本，c可理解為句子語境。RNN編碼器在每個時刻t，利用當前輸入𝑥𝑡和前一時刻隱向量ℎ𝑡−1 計算當前隱向量ℎ𝑡：

ℎ𝑡 = 𝑓𝑒𝑛𝑐(𝑥𝑡, ℎ𝑡−1)

表徵向量c由所有隱向量 (ℎ₁, … , ℎ𝑀) 經函數φ轉換得到：

𝑐 = φ({ℎ₁, … , ℎ𝑀})

通常，c可以直接取最後一個隱向量ℎ𝑀。

**解碼階段：**

表徵向量c輸入解碼器函數𝑓𝑑𝑒𝑐。RNN解碼器在每個時刻t，利用當前輸入𝑦𝑡、前一時刻隱向量𝑠𝑡−1 和c計算當前隱向量𝑠𝑡：

𝑠𝑡 = 𝑓𝑑𝑒𝑐(𝑦𝑡, 𝑠𝑡−1, 𝑐)

在驗證和測試階段，使用前一時刻輸出𝑦̂𝑡−1 作為當前輸入：

𝑠𝑡 = 𝑓𝑑𝑒𝑐(𝑦̂𝑡−1, 𝑠𝑡−1, 𝑐)

解碼器通過函數g將向量轉換回文字，輸出機率最大的詞彙：

𝑦̂𝑡 =  𝑔(𝑠𝑡, 𝑐) = max 𝑦̂𝑡  𝑝(𝑦̂𝑡|𝑠𝑡, 𝑐)
