向量空間模型(VSM)將文件表示為帶權重的索引詞集合，詞權重影響文件相關性評分。機器學習算法通常需要固定長度的特徵向量，詞袋模型即是一種常見的文本表示方法，但它忽略了詞序和語義。 向量空間模型本身未能解決詞序問題，Tomas Mikolov 提出的 Word2vec 則透過考慮上下文來訓練詞向量。Word2vec 使用淺層神經網絡，並以重建詞文本的方式進行訓練，網絡根據詞彙預測其相鄰詞。  與詞袋模型不同，Word2vec 關注詞序，包含 skip-gram 和 CBOW 两种模型。skip-gram 使用目標詞預測上下文，CBOW 使用上下文預測目標詞。訓練過程中產生的隱藏層權重即為詞向量。 例如，以「空間向量模型以前後文關係為訓練標的」為例，Word2vec 會用「向量」預測「空間」和「模型」，其間的權重組成詞向量。 因此，語法位置相似的詞彙會有較高的相似度。
