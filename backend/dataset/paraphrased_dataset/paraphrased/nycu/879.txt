The system uses an RGB-D camera in a Lenovo Phab 2 Pro to capture scene information, obtaining color and depth data via the Google Tango API.  Due to device movement, traditional foreground extraction is impractical.  Assuming the object rests on a flat plane, RANSAC plane fitting filters points above the plane.  These points are projected onto the color image, and a 7x7 pixel neighborhood around each point forms the initial foreground.  Low depth sensor resolution necessitates foreground expansion using color histograms.  Illumination invariance is addressed by using the a and b components of the Lab color space.  For efficiency, the image is subsampled to 1/16 of its original size and divided into four sections, each processed by a separate thread.  Flood fill, seeded from the point set center, reduces noise in the resulting foreground segmentation. Figures 5 and 6 illustrate this process, showing the color image, filtered plane points, initial and expanded foregrounds, noise reduction, and final output displayed on the device.
