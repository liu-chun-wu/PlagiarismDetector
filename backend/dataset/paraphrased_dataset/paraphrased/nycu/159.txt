過往研究直接將影像分類為14種異常，但X光片拍攝位置不同會遮蔽器官。因此，本論文先依據Metadata的拍攝位置，將影像和標籤分為AP（由前往後）和PA（由後往前）兩類，得到AP影像、PA影像、AP標籤及PA標籤，並分別訓練出適用於AP影像和PA影像的14種異常辨識模型（AP模型和PA模型）。

為驗證預先分類AP和PA的有效性，本論文以CheXNet模型作為對照組，並將AP模型和PA模型的結果平均作為新模型的結果，比較分類資料後是否提升準確率。CheXNet模型、AP模型、PA模型的參數設定均參考Rajpurkar et al.的研究，包含初始學習率0.001、Adam優化器、批次大小16、輸入影像大小224x224、Sigmoid激勵函數和二元交叉熵損失函數。

本論文訓練的模型分為兩部分：第一部分使用自建CNN架構分類AP/PA影像；第二部分使用CheXNet架構訓練CheXNet模型、AP模型和PA模型，分別針對所有影像、AP影像、PA影像辨識14種胸腔異常。

以CheXNet模型為對照組，將AP模型和PA模型結果平均，觀察預先分類AP和PA影像是否比直接訓練CheXNet模型效果更好。實驗分三組：實驗一完全參照Rajpurkar et al.的參數設定；實驗二加入自動控制學習率函數，初始學習率0.001，驗證準確率連續兩代未上升則學習率減半，最低至0.00001；實驗三調整自動控制學習率函數，驗證準確率連續兩代未上升則學習率減少10%，最低至0.00001。
