在頂照圖像的人物識別方面，[3]利用垂直向下攝影機捕捉人物，將其轉換為Temporal signature (從頭到腳的RGB)，再轉換為Aligned signature，最終生成Bodyprint。通過比較位置或軌跡相似的Bodyprint，可以提升匹配效果。由於遮擋，並非所有身體部位在所有幀中都可見。[5]則整合PTZ和頂視攝影機捕捉畫面，進行失真校正，利用兩個相鄰影像重疊區域的至少四個角點，並對頂視攝影機採用基於粒子濾波器的目標追蹤算法。同時，對每個PTZ進行校準，統一向量變換關係。鎖定目標後，PTZ會跟隨目標轉動並記錄，以判斷PTZ的延遲。[7]在頂視魚眼攝影機下使用HOG和ACF進行人物偵測，基於影像梯度信息並使用特定遮罩避免梯度平滑，並利用purposive vision paradigm進行校正，避免測量和模型擬合，利用文中公式達到最佳偵測效果，並提出ξ作為人物偵測的區分標準。然而，單人與多人偵測的精度差異顯著，主要原因是未考慮遮擋和光線因素。針對頂視圖中的遮擋問題，[8]以書店場景為例，使用深度相機分析人物行為，分別基於手的深度信息和結合深度和PSA特徵的SVM。前者可快速判斷目標的行為，例如拿書、閱讀、瀏覽書櫃、左轉、右轉等；後者則通過PAS分析特定幀數，利用像素分析區分靜止或移動狀態。

綜上所述，我們借鑒這些文獻的優點，嘗試不同的方法，例如頂視视角、座標校正、網路傳輸和追蹤等。但光線、FOV預測移動方向和定位等問題仍需進一步研究，以避免這些問題，將更多資源集中於人物追蹤。
