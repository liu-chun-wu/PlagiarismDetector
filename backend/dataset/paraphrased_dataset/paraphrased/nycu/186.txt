模型最佳化的目標是將損失函數降至最低，其方法是比較輸出值與實際值。深度學習模型常用的兩種損失函數演算法如下：

均方誤差 (MSE) 計算公式為  MSE Loss = (1/n) * Σ(yi - ŷi)^2，其中 n 為數據點數量，yi 為實際值，ŷi 為預測值。MSE 將預測值與實際值的差值平方後加總再取平均，值越小代表模型越好，常用於回歸問題。

交叉熵損失函數計算公式為 Cross Entropy Loss = -Σ[(y log ŷi + (1-y) log(1-ŷi))]，其中 y 為實際值，ŷi 為預測值。交叉熵越接近零，表示預測越準確，常用於分類問題。本研究也使用交叉熵作為損失函數。
