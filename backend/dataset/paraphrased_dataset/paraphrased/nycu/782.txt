特徵產生方法包含醫療基礎特徵挑選和機器學習特徵挑選。醫療基礎特徵參考Compton et al. (2000)和Sjo (2012)關於結腸直腸癌預後因子分析的文獻，提取與SEER資料相符的欄位；並納入NCI、TCOG兩個癌症協會和醫師評估常用的預後因子，共五組。機器學習特徵挑選則採用Wrapper方法，以Extra-Tree為核心分類器，評估特徵重要性並排序，影響目標值的程度越高，排序越靠前。詳細流程將在後續章節說明。

醫療基礎預後因子參考前述文獻，比對SEER資料集，提取交集欄位進行存活率預測。

機器學習特徵挑選方法包含Wrapper、Filter和Embedded (Guyon & Elisseeff, 2003)。Wrapper以機器學習模型為評分黑盒子，根據特徵子集的預測能力評分，常用方法包含向前選擇和向後剃除。Filter在預處理階段選擇與目標相關的特徵，與模型選擇無關。Embedded則在建模時自行挑選特徵，例如決策樹的資訊獲利或正則化方法。

Wrapper方法將資料和特徵輸入機器學習模型，產生評估分數 (例如回歸的MSE或分類的準確率)。依序加入特徵並計算評估分數，直到所有特徵都被訓練。比較所有評估分數，分數最高的模型所含的特徵組即為最佳特徵，也就是最佳預後因子。

隨機森林 (Breiman, 2001) 的特徵重要性利用袋外數據 (OOB)。隨機森林採用取後放回的Boostraping方法取樣，單一決策樹不會使用所有樣本，部分樣本留在外部，即OOB。使用OOB計算每棵決策樹的誤差率 (OOB Error)，即用未參與訓練的資料測試，計算分類錯誤與樣本總數的比例。

隨機森林利用OOB Error排序特徵值權重，避免排列組合後重新訓練的資源成本，並評估每個特徵的重要性。加入雜訊後誤差變大，表示原始特徵影響力強。評估流程如下：1. 計算每棵決策樹的OOB Error (Error 1)。 2. 對OOB的原始特徵X加入雜訊，再次計算OOB Error (Error 2)。 3. 若有N棵決策樹，特徵X的重要性計算公式為：𝐼𝑚𝑝𝑜𝑟𝑡𝑎𝑛𝑐𝑒(𝑥) = ∑(Error2−Error1)/Ntree。Error 2提升越多，表示加入雜訊後錯誤率提高，原始特徵X比後續加入的特徵更重要。反之，Error 2變化不大，則原始特徵X重要性較低。計算每棵樹的OOB Error，即可評估所有特徵重要性並排序。
