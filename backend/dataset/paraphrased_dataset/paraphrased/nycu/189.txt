循環神經網路處理長序列資料時容易遺忘早期資訊，長短期記憶(LSTM)(Hochreiter & Schmidhuber, 1997)旨在解決此問題。LSTM使用一種特殊的隱藏層架構，通過三個閘門(Gates)控制資訊的儲存和遺忘：遺忘閘(Forget Gate)決定是否遺忘當前記憶狀態；輸入閘(Input Gate)決定是否處理當前輸入；輸出閘(Output Gate)決定更新後的記憶狀態有多少輸出。這些閘門的權重由訓練數據學習而得，使LSTM能有效保存和利用長期資訊。

遺忘閘的運作方式如下：將前一時刻隱藏層狀態(ℎ𝑡−1)和當前輸入(𝑋𝑡)合併，經權重(𝑊𝑓)調整並加上誤差值(𝑏𝑓)，最後通過激活函數(𝜎)輸出遺忘閘的值(𝑓𝑡)。

輸入閘和候選神經元狀態的計算方式如下：輸入閘(𝑖𝑡)的計算與遺忘閘類似，使用不同的權重(𝑊𝑖)和誤差值(𝑏𝑖)。候選神經元狀態(𝐶̃𝑡)則通過將(ℎ𝑡−1)和(𝑋𝑡)經權重(𝑊𝑐)調整、加上誤差值(𝑏𝑐)，再經過tanh激活函數計算得出。

當前神經元狀態(𝐶𝑡)的計算方法：將遺忘閘輸出(𝑓𝑡)與前一時刻神經元狀態(𝐶𝑡−1)相乘，再加上輸入閘輸出(𝑖𝑡)與候選神經元狀態(𝐶̃𝑡)相乘。

輸出閘(𝑂𝑡)和當前隱藏層狀態(ℎ𝑡)的計算方式：輸出閘(𝑂𝑡)的計算與遺忘閘和輸入閘類似，使用不同的權重(𝑊𝑜)和誤差值(𝑏𝑜)。當前隱藏層狀態(ℎ𝑡)則由輸出閘(𝑂𝑡)與經過tanh激活函數處理的當前神經元狀態(𝐶𝑡)相乘得到。
