本研究旨在探討深度學習模型中的文化偏見，並嘗試從自然語言資料的角度減少這些偏見。研究動機源於人工智慧、機器學習和深度學習的蓬勃發展及其日益滲透人類生活。人工智慧的崛起，建立在機器學習，特別是深度學習的快速發展之上，它們是人工智慧的子集，深度學習又是機器學習的子集，透過多層次的神經網路模型，讓機器能從大量數據中學習複雜的模式。然而，演算法並非全然客觀，許多研究和案例已指出，機器學習演算法，尤其是深度學習，可能因學習帶有刻板印象的數據而產生歧視，對弱勢族群造成不公平，這與人權價值背道而馳。語言作為人類社會的重要組成部分，蘊含著豐富的文化和社會信息，但也潛藏著人類的偏見。這些偏見會滲透到自然語言數據中，進而影響演算法的中立性。因此，本研究聚焦於自然語言資料，致力於在深度學習模型中定義和減少文化偏見，期盼能預防演算法歧視，雖然無法直接解決社會問題根源，但仍能朝向更公平的演算法應用邁進。
