雙向循環神經網絡(Schuster & Paliwal, 1997)在循環神經網絡的基礎上，除了利用過去的上下文資訊，更加入了未來的上下文資訊以提高輸出準確度。這對於像中文這種常省略連接詞(例如：因為、所以)的語言來說，能有效強化前後語句的關係。雙向RNN架構新增一個隱藏層ℎ′𝑡和權重W′、Y′、V′。其運算公式如下：隱藏層的輸入𝑎′𝑡由ℎ′𝑡+1乘以權重W′，加上輸入值𝑋𝑡乘以權重Y′，再加上誤差值𝑏𝑖計算得出。接著，𝑎′𝑡經由激勵函數tanh(也可使用Sigmoid或ReLU等其他激勵函數)處理後得到隱藏層輸出ℎ′𝑡。最終輸出𝑂𝑡則是由ℎ𝑡乘以權重V，加上ℎ′𝑡乘以權重V′，再加上誤差值𝑏𝑜計算得出。
