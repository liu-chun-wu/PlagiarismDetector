GloVe，一種全局對數雙線性回歸模型，融合了全局矩陣分解（如LSA）和局部上下文窗口方法的優點。詞頻統計是詞向量非監督學習的基礎，但如何有效關聯詞義仍是挑戰。LSA等全局矩陣分解方法擅長捕捉全局特性，但在詞性類比方面表現欠佳；Word2vec則相反，由於其局部上下文訓練機制，缺乏對全局統計信息的充分利用。因此，GloVe基於共現矩陣，利用比較同一個詞的共現機率比值來學習詞向量。共現機率比值既包含全局統計信息，又保留了局部上下文比較的特性，使GloVe詞向量兼具全局和局部信息。
