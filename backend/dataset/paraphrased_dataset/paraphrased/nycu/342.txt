使用一層、兩層和四層卷積神經網路模型進行音節切割實驗，發現單層卷積模型不足以捕捉所有音節，四層模型則因過於敏感導致誤判，兩層模型效果最佳。實驗以"你不要再生氣了好嗎"(lí mài koh siū khì a hó-bòo)語音為例，x軸為時間，刻度為40ms。即使錄音不完整，模型仍能捕捉音節。

與傳統RMS+ZR方法相比，兩層卷積模型雖不如RMS+ZR精確，但可初步分段，而RMS+ZR則需調整參數才能達到最佳切割效果。

將上述模型應用於重複錄音辨識，擷取連續400ms以上判斷為人聲的段落作為新樣本。"我要"(góa beh)重複11次，得到10個樣本；"看相片"(khuànn-siòng-phìnn)重複11次，也得到10個樣本，其中一個樣本誤擷取了笑聲，顯示模型在鼻音捕捉方面仍有不足。
