計算影響資訊矩陣後，得到|T|個IIM，記作IIM(j)，j=1,2,…,|T|。接著計算第i個候選特徵對第j個目標的增益資訊量g：

g(fi→t(j)) = I(fi→t(j)) - R(fi→SP(j)) ,  (25)

其中I(fi→t(j))為第i個特徵對第j個目標的影響資訊，R(fi→SP(j))為第i個特徵對SP(j)的冗餘資訊量，用於去除已選特徵池SP(j)中重複的資訊：

R(fi→SP(j)) = (2 / |SP(j)|) * Σ[ I(fi→SPq(j)) + I(SPq(j)→fi) ], q=1到|SP(j)|,  (26)

若g(fi→t(j))為正，則將該候選特徵放入已選特徵池SP(j)。此步驟後得到|T|個已選特徵池。

將所有已選特徵池中的特徵變數形成集合Ω = {Φk, k=1,2,…,|Ω|}，Φk為集合Ω中的第k個特徵變數。計算每個Φk被選取的次數nO(Φk)及其覆蓋率ω：

ω(Φk) = nO(Φk) / |T| ,  (27)

接著計算Φk的總增益資訊量gsum(Φk)：

gsum(Φk) = Σ g(Φk→t(j)), j=1到|T| ,  (28)

利用ω(Φk)和gsum(Φk)計算Φk的貢獻指數ρ：

ρ(Φk) = ω(Φk) * gsum(Φk) ,  (29)

ρ(Φk)代表Φk對所有目標變數的有效貢獻。若ρ(Φk) > ρth，則Φk對目標變數具有顯著影響力。ρth預設為所有特徵變數覆蓋率平均值ω̅和總增益資訊量平均值𝑔̅𝑠𝑠𝑠𝑠的乘積。若ρ(Φk) > ρth，則以ntst記錄符合門檻值的個數 (1 ≤ ntst ≤ |Ω|)。設定最終特徵池FP的大小nFp，nFp介於上限nU和下限nO之間的最大值。將ρ(Φk)排序，取前nFp個特徵變數放入最終特徵池FP，這些特徵即可作為機器學習的輸入。
