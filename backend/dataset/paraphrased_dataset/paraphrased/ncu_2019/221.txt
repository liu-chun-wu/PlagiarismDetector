隨著電腦運算能力增強和資訊技術快速發展，資料探勘技術蓬勃發展，協助人們決策和獲取知識。然而，龐大的資料集也帶來了雜訊和不易判讀的連續型數值，影響模型準確度和效能。資料前處理的重要性日益凸顯，透過減少雜訊、增加資料判讀性，可提升模型預測準確度。

樣本選取和資料離散化已被證實能有效解決這些問題。本研究結合這兩種前處理方法，提出IS + D + KNN 和 D + IS + KNN 兩種架構，探討不同樣本選取方法（IB3、DROP3、GA）和監督式離散化方法（MDLP、ChiMerge）的組合及順序，如何提升模型指標（平均正確率、AUC、Kappa）。

實驗結果顯示：ChiMerge + DROP3 + KNN 和 DROP3 + ChiMerge + KNN 運算時間最長，IB3 + MDLP + KNN 和 DROP3 + MDLP + KNN 最短。先離散化再選取樣本，平均運算時間較長。

IS + D + KNN 架構下，DROP3 + ChiMerge + KNN 和 DROP3 + MDLP + KNN 平均正確率最高，且顯著優於單一離散化。由於兩者無顯著差異，建議選擇時間成本較低的 DROP3 + MDLP + KNN，其平均正確率達 85.11%，比單一 MDLP 提升約 0.8%。

針對二分類資料集，IS + D + KNN 架構下，IB3 + MDLP + KNN 和 DROP3 + MDLP + KNN 平均 AUC 最高，且顯著優於單一離散化。兩者無顯著差異，建議考慮時間成本選擇 DROP3 + MDLP + KNN，平均 AUC 達 82.28%，比單一 MDLP 提升約 0.8%。

針對多分類資料集，DROP3 + MDLP + KNN 和 MDLP + DROP3 + KNN 平均 Kappa 最高，分別達 70.96% 和 70.11%，比單一離散化分別提升約 2% 和 1.1%。

整體而言，IS + D + KNN 的平均正確率略高於 D + IS + KNN；二分類資料集的 IS + D + KNN 平均 AUC 較高；多分類資料集的 D + IS + KNN 平均 Kappa 較高。 因此，不同情境下，應選擇最適當的組合進行資料前處理，提升模型評估指標。
