在熱力學中，熵常被用來判斷系統混亂程度。資訊理論之父 Shannon 將熵的概念引入資訊理論，提出資訊熵的概念，用以測量資訊量。資訊熵 H 的公式如下：

H = Σ (Pi * log(1/Pi))  (i=1 到 r)

其中 Pi 為離散事件變數 xi 發生的機率，可根據機率密度估計法算得。當 Pi 趨近於 1 時，H 趨近於 0。

事件變數 x 的隨機變數 X 提供給事件變數 y 的隨機變數 Y 的資訊量 I(X,Y) 表示為：

I(X,Y) = H(Y) - HX(Y)

其中 H(Y) 為 Y 的熵，HX(Y) 為 Y 受到 X 影響後的熵，計算公式如下：

HX(Y) = - Σ Σ P(i,j) * log Pi(j)  (i,j)

其中 P(i,j) 為同時發生 Xi 和 Yj 的機率密度函數，Pi(j) 為發生 Xi 的條件下，Yj 發生的機率密度函數。同時發生 Xi 和 Yj 的亂度 H(X,Y) 定義為：

H(X,Y) = - Σ Σ P(i,j) * log P(i,j) (i,j)

根據條件機率推導可得：HX(Y) = H(X,Y) - H(X)。

Shannon 提出的互資訊 I(X,Y) 指的是 X 與 Y 彼此提供的資訊量相等，即 I(X,Y) = I(Y,X)。對於連續事件變數，H(X) 的計算公式為：

H(X) = ∫ p(x) * log p(x) dx

其中 p(x) 為隨機變數 X 的機率密度函數。HX(Y) 和 H(X,Y) 的公式則改寫為：

HX(Y) = - ∬ p(x,y) * log(p(x,y)/p(y)) dxdy

H(X,Y) = - ∬ p(x,y) * log p(x,y) dxdy

H(X) 近似公式：

H(X) = Σ p(x) * log(φ/p(x)) * Δx

其中 log(φ/p(x)) 為混亂密度，φ 為 p(x) 的最大值加上一個極小常數 ε (10^-10)。

Tu and Li 認為 I(X,Y) = I(Y,X) 是一種極端現象，提出影響資訊，將正負號納入考量。第 i 個特徵對第 j 個特徵的影響資訊 I(fi→fj) 計算如下：

I(fi→fj) = I(fi-,fj)∫p(fi)dfi + I(fi+,fj)∫p(fi)dfi

其中 I(fi-,fj) 和 I(fi+,fj) 分別為 fi 的負值與正值提供給 fj 的資訊量。I(fi→fj) 可視為互資訊的期望值。

由於數據中的機率密度未知，透過數據進行機率密度函數估計。若第 i 個特徵對目標的影響資訊為負，則代表 fi 對目標產生負面影響。

資訊熵和影響資訊可用於過濾干擾因子。影響資訊矩陣 (IIM) 則用於呈現數據來源對每個預測目標的影響資訊，以便進行特徵選取。
