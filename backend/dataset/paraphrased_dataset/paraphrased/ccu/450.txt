基於統計學習理論的機器學習方法，支持向量機（SVM）遵循Vapnik結構風險最小化原則。它在特徵空間中構建間隔最大的線性分類器，尤其擅長處理小樣本、非線性及高維數據問題，相較於傳統方法更具優勢。SVM旨在尋找一個能區分兩類數據點的超平面。由於數據可能存在於高維空間，超平面即指高維空間中的平面。以二維為例，如同圖3.16所示，目標是找到一條線，區分黑色和白色數據點，並使其與兩類數據的邊界（margin）最大化，以提升分類的準確性，避免計算誤差。給定數據點集合{𝑥𝑖, 𝑦𝑖}, 𝑖= 1, … , 𝑛，其中𝑥𝑖∈𝑅𝑑, 𝑦𝑖∈{1, −1}，SVM seeks a line f(x) = 𝑤𝑇𝑥−𝑏，使得所有𝑦𝑖= −1的點落在f(x) < 0的一側，而𝑦𝑖= 1的點落在f(x) > 0的一側，藉此根據f(x)的正負號區分數據點的類別。這個超平面被稱為分離超平面，而邊界最大的則稱為最佳分離超平面。與最佳分離超平面平行且最靠近數據點的超平面則稱為支持超平面。
