Python網頁爬蟲程式擷取HTML標籤，將新聞資料存成CSV格式。由於直接用Excel開啟CSV檔案可能出現亂碼，因此需要透過Excel的資料匯入功能，將文字編碼設定為UTF-8。  擷取的新聞篇章，每篇存成txt檔的一行。接著使用斷詞斷句程式（例如Python Jieba，並自定義詞庫）過濾不需要的字詞。過濾後，與停電相關的詞彙，包含災害因素和停電原因，總計64,889次，如表4所示（災害因素詞彙18,497次，停電原因詞彙46,392次）。
