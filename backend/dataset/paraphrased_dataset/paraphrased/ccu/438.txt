AdaBoost是一種迭代演算法，逐步加入弱分類器直至達到預設的低錯誤率。每個樣本的權重代表其被選入訓練集的機率。準確分類的樣本權重會降低，錯誤分類的則提高，使AdaBoost聚焦於難分樣本。初始時樣本權重相等，每次迭代根據權重選取樣本訓練分類器𝐶𝑘，然後調整權重，再用更新後的樣本集訓練下一個分類器，如此循環。訓練後，AdaBoost得到一組參數，用於構建由多個弱分類器組成的強分類器，弱分類器數量由迭代次數T決定。每個弱分類器包含特徵值、閾值和權重，其形式如公式2.17所示，目標是找到最佳閾值以最小化錯誤率。強分類器由T個弱分類器線性組合而成，相當於對所有弱分類器的加權投票結果與預設閾值比較，其形式如公式2.18所示。
