研究利用從資料庫提取的關鍵字，在Science Direct電子期刊平台上進行期刊搜尋。過程中使用Python的Beautiful Soup模組解析網頁，並以Selenium模組模擬人為操作瀏覽器行為，自動執行網站操作。Science Direct的搜尋結果網址具有規則性，篩選條件會反映在網址上。利用此特性，爬蟲程式能將關鍵字和年份等條件融入網址規則，建立有效網址，再進行網頁解析並抓取搜尋結果。

研究蒐集的期刊資料包含：期刊網址、期刊類型、文章標題、文章作者、作者介紹、期刊出版社名稱、出版年份、卷數和期數、頁碼、DOI連結、文章摘要和關鍵字。透過中正大學電子資源入口網站登入Science Direct平台，即可查看及下載文章全文。資料蒐集分為兩個階段：

第一階段蒐集期刊網址、期刊類型、文章標題、文章作者、期刊出版社名稱、出版年份、卷數、期數和頁碼。利用Beautiful Soup模組解析每篇期刊網址，發現網址尾端的16到20碼英文數字組合字串為唯一文章代碼，可用於精簡資料庫空間。

第二階段蒐集作者介紹、DOI連結、文章摘要和關鍵字。藉由中正大學電子資源入口網站，使用Selenium模組登入，並利用第一階段蒐集的文章代碼建立有效網址，透過瀏覽器訪問文章網頁取得原始碼，再使用Beautiful Soup模組解析網頁，獲取所需資訊。

期刊資料蒐集需分兩階段進行，是由於平台搜尋結果數量龐大，且需深入個別網頁才能蒐集詳細資料，增加了爬蟲設計的難度及抓取時間。

研究分析Wikipedia蒐集的38個關鍵字及651326篇相關期刊文章，以矩形式樹狀結構圖呈現，發現"Exploits"、"Viruses"和"Vulnerability"是搜尋結果篇數前三名的關鍵字。
