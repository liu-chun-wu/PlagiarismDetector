本研究使用某科技公司提供的1604張停車場汽車影像資料庫，建置車牌和字元辨識方法。  資料集分為訓練集和測試集，並針對每張影像生成5張合成影像，包含：一張右下0~3像素切除後放大回原尺寸的影像、一張仿射變換回原尺寸的影像，以及三張-8~+8度動態旋轉的影像。仿射變換公式為：𝑥′ = 𝑥 + 𝑠ℎ𝑖𝑓𝑡，𝑦′ = 𝑦 + 𝑠ℎ𝑖𝑓𝑡。  最終訓練集和測試集影像總計9624張。

初期階段，所有可能的車牌區域影像先儲存於同一目錄，再手動分類至"has" (有車牌) 和 "no" (無車牌) 目錄。每張影像接著生成5張合成影像，用於SVM和CNN模型的車牌有無判斷訓練。

字元辨識CNN訓練方面，初始階段選取包含0-9，A-H，J-N，P-Z字元(排除I、O)的車牌影像，分割字元後，將24個字元分別貼上白色背景，製成png檔，並使用OpenCV ml module的kNearest進行字元辨識學習。  訓練資料的標籤檔以左至右、上至下的順序讀取字元，轉換為整數後儲存至cv::Mat matClassificationInts，並輸出為class.xml檔。  字元圖檔則經過二值化、輪廓提取、最小矩形框選等前處理步驟，依據矩形中心點座標排序後，調整為20x40尺寸，轉換為32FC1格式，儲存至cv::Mat matTrainingImages，並輸出為image.xml檔。

kNearest訓練使用  `kNearest->train(matTrainingImages, cv::ml::ROW_SAMPLE, matClassificationInts)`。預測時，將待測影像二值化，調整為20x40尺寸，轉換為32FC1格式後，儲存至matROI，執行`cv::Mat kNearest->findNearest(matROI, 1, matCurrentChar)`，即可從`matCurrentChar.at<float>(0, 0)`取得預測字元的ASCII值。由於KNN需逐一比對，不適用於大量範例。

利用KNN辨識字元後，將字元分類儲存至各目錄，並手動校正。  針對大量的影像，此方法更有效率。  最後，每個字元影像同樣生成5張合成影像。
