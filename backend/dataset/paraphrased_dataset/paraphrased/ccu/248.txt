百萬筆期刊文章資料的儲存和計算，可藉由以Apache Spark為核心的叢集架構有效解決。此架構提升資料存取和計算效率，即使單一主機故障，Spark的容錯機制也能確保資料處理持續進行。我們以Spark建構學術期刊資訊安全研究演進的資料視覺化。例如，使用Scala、Python或Java執行計算時，SparkContent會連接叢集管理器，分配計算任務至各節點，最終將結果回傳。 (參見圖13 Spark叢集執行概念圖，資料來源：本研究整理)
